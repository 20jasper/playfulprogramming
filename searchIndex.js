const index = {
	index: {
		keys: [
			{ path: ["title"], id: "title", weight: 2, src: "title" },
			{
				path: ["authorName"],
				id: "authorName",
				weight: 1.8,
				src: "authorName",
			},
			{
				path: ["authorHandles"],
				id: "authorHandles",
				weight: 1.2,
				src: "authorHandles",
			},
			{ path: ["tags"], id: "tags", weight: 1.5, src: "tags" },
			{
				path: ["description"],
				id: "description",
				weight: 1.2,
				src: "description",
			},
			{ path: ["excerpt"], id: "excerpt", weight: 1.2, src: "excerpt" },
		],
		records: [
			{
				i: 0,
				$: {
					0: {
						v: "Setup Android Studio Emulator for AMD Ryzen CPUs",
						n: 0.354,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "tools, windows", n: 0.707 },
					4: {
						v: "While the Android Emulator isn't confined to Intel CPUs anymore, it can be tricky to setup for AMD Ryzen CPUs. Let's explain how to do so.",
						n: 0.196,
					},
				},
			},
			{
				i: 1,
				$: {
					0: {
						v: "Better Angular Form Components with ngModel and formControl Implementation",
						n: 0.333,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "angular, javascript", n: 0.707 },
					4: {
						v: "Some components make controlling their state easier with 'formControl' and 'ngModel'. Let's see how we can build our own!",
						n: 0.229,
					},
				},
			},
			{
				i: 2,
				$: {
					0: {
						v: "How to Share Lifecycle Methods Between Components in Angular",
						n: 0.333,
					},
					1: { v: "Corbin Crutchley, Lars Gyrup Brink Nielsen", n: 0.408 },
					2: {
						v: "crutchcorn, crutchcorn, crutchcorn, LayZeeDK, LayZeeDK, LayZeeDK",
						n: 0.408,
					},
					3: { v: "angular, javascript, webdev", n: 0.577 },
					4: {
						v: "Sharing code between components in Angular is TOUGH. Here's one way you can do so by utilizing base components that you extend - and why you shouldn't use them.",
						n: 0.186,
					},
				},
			},
			{
				i: 3,
				$: {
					0: { v: "Package Font Files on NPM for Angular Usage", n: 0.354 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "angular, javascript, npm", n: 0.577 },
					4: {
						v: "Do you use custom fonts that you want to share with multiple apps? Learn how to distribute those fonts on NPM and consume them in Angular!",
						n: 0.196,
					},
				},
			},
			{
				i: 4,
				$: {
					0: {
						v: "Angular Route Guards For Authorization In A Web And Mobile Application",
						n: 0.302,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "angular", n: 1 },
					4: {
						v: "Learn how to use Angular route guards for authenticating & authorizing access to certain child and parent routes.",
						n: 0.236,
					},
				},
			},
			{
				i: 5,
				$: {
					0: { v: "Angular Templates — From Start to Source", n: 0.378 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "angular, webdev", n: 0.707 },
					4: {
						v: "Learn how templates work in Angular. From the basics to being able to read Angular source code and write your own structural directives",
						n: 0.209,
					},
				},
			},
			{
				i: 6,
				$: {
					0: {
						v: "Networking 101: A Basic Overview of Packets and OSI",
						n: 0.333,
					},
					1: { v: "Kevin Mai, Corbin Crutchley", n: 0.5 },
					2: {
						v: "Reikaze0, Reikaze, crutchcorn, crutchcorn, crutchcorn",
						n: 0.447,
					},
					3: { v: "networking", n: 1 },
					4: {
						v: "You use networking every day - even to read this! Let's dive into explaining how we send data across a network and what the OSI model is.",
						n: 0.192,
					},
				},
			},
			{
				i: 7,
				$: {
					0: { v: "Change the Host File of an Android Emulator", n: 0.354 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "android", n: 1 },
					4: {
						v: "In order to test web applications with Android properly, you may need to edit the Android Emulator network host file. Here's how to do so.",
						n: 0.2,
					},
				},
			},
			{
				i: 8,
				$: {
					0: {
						v: "Chess Knight Problem: a quick and dirty solution in JavaScript",
						n: 0.316,
					},
					1: { v: "Thomas Hodges", n: 0.707 },
					2: { v: "thodges314, thomas-hodges", n: 0.707 },
					3: { v: "javascript, computer science, interviewing", n: 0.5 },
					4: {
						v: "I present a quick and dirty solution to a common interview question where the solution is not nearly as complex as it may first appear.",
						n: 0.2,
					},
				},
			},
			{
				i: 9,
				$: {
					0: { v: "My Advice to Technical Interviewers", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "interviewing", n: 1 },
					4: {
						v: "Interviewing candidates is tough. It just is. Here are just a few of my tips to make your tech recruiting go smoother.",
						n: 0.213,
					},
				},
			},
			{
				i: 10,
				$: {
					0: { v: "CSS Fundamentals", n: 0.707 },
					1: { v: "Landon Johnson", n: 0.707 },
					2: {
						v: "ljtechdotca, ljtechdotca, ljtechdotca, https://ljtech.ca",
						n: 0.5,
					},
					3: { v: "css, design", n: 0.707 },
					4: {
						v: "A beginners course for CSS box model, HTML defaults, flexbox layout, gridbox layout, responsive design, selectors, units, and variables.",
						n: 0.229,
					},
				},
			},
			{
				i: 11,
				$: {
					0: { v: "Data Storage Options for React Native", n: 0.408 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "react, react native", n: 0.577 },
					4: {
						v: "React Native contains multiple different ways you can persist data for your application. Let's look at the choices and their pros and cons.",
						n: 0.209,
					},
				},
			},
			{
				i: 12,
				$: {
					0: { v: "Debugging NodeJS Applications Using Chrome", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "node, chrome", n: 0.707 },
					4: {
						v: "Learn how to interactively debug your NodeJS applications using a GUI-based debugger built into Chrome.",
						n: 0.258,
					},
				},
			},
			{
				i: 13,
				$: {
					0: { v: "Docs, Where Can We Do Better?", n: 0.408 },
					1: { v: "Maisy Dinosaur", n: 0.707 },
					2: {
						v: "rodentman87, rodentman87, https://likesdinosaurs.com",
						n: 0.577,
					},
					3: { v: "documentation", n: 1 },
					4: {
						v: "My personal approach to writing docs, mainly aimed at frameworks and the like.",
						n: 0.277,
					},
				},
			},
			{
				i: 14,
				$: {
					0: {
						v: "A Better Way To Code: Documentation Driven Development",
						n: 0.354,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "documentation, testing, opinion", n: 0.577 },
					4: {
						v: "Test Driven Development is often taught to improve a your workflow; I present Documentation Driven Development as an alternative approach.",
						n: 0.224,
					},
				},
			},
			{
				i: 15,
				$: {
					0: { v: "Why I prefer Vue over Angular: DOM Pollution", n: 0.354 },
					1: { v: "William (Will) Lohan", n: 0.577 },
					2: {
						v: "william-lohan, splat_killwill, https://gatimus.com/, william-lohan-b202637a",
						n: 0.5,
					},
					3: { v: "webdev, angular, vue", n: 0.577 },
					4: {
						v: 'Angular differs from Vue in some keys ways, including its "Incremental rendering". This shift introduces something I call "DOM Pollution"; its why I prefer Vue over Angular.',
						n: 0.192,
					},
				},
			},
			{
				i: 16,
				$: {
					0: { v: "Doomsday Rule", n: 0.707 },
					1: { v: "Joshua Hawkins", n: 0.707 },
					3: { v: "python, math", n: 0.707 },
					4: {
						v: "In this blog I talk about the Doomsday Rule, how it works, how to put it into code then how to make a program that tests you.",
						n: 0.192,
					},
				},
			},
			{
				i: 17,
				$: {
					0: {
						v: "Draw under the Android NavBar Using React Native",
						n: 0.354,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "android, react native", n: 0.577 },
					4: {
						v: "Android allows you to draw content under the navigation bar. It's a neat effect! Let's add that to our React Native apps.",
						n: 0.213,
					},
				},
			},
			{
				i: 18,
				$: {
					0: {
						v: "Write Simpler Tests - 5 Suggestions for Better Tests",
						n: 0.333,
					},
					1: { v: "Corbin Crutchley, Robert Mennell", n: 0.5 },
					2: {
						v: "crutchcorn, crutchcorn, crutchcorn, skatcat31, rnmennell",
						n: 0.447,
					},
					3: { v: "testing, jest", n: 0.707 },
					4: {
						v: "Writing tests is a big skill for any engineer, but we often over-complicate them. Let's simplify our tests for better testing overall!",
						n: 0.213,
					},
				},
			},
			{
				i: 19,
				$: {
					0: { v: "GitHub Copilot Breaks Bad Interviews", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "interviewing, opinion, copilot", n: 0.577 },
					4: {
						v: "GitHub Copilot is a huge step forward for tech. Luckily, it improves our lives. Unfortunately, it will break your interviews. Here's why.",
						n: 0.213,
					},
				},
			},
			{
				i: 20,
				$: {
					0: {
						v: "GitHub Copilot is Amazing - It Won't Replace Developers",
						n: 0.333,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "opinion, tools, copilot", n: 0.577 },
					4: {
						v: "GitHub Copilot is an amazing tool that I think will drastically improve the way that I code. But it won't replace me. Here's why.",
						n: 0.204,
					},
				},
			},
			{
				i: 21,
				$: {
					0: {
						v: "A Guide to Python's Secret Superpower: Magic Methods",
						n: 0.354,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "python", n: 1 },
				},
			},
			{
				i: 22,
				$: {
					0: {
						v: "Hard grids & baselines: How I achieved 1:1 fidelity on Android",
						n: 0.302,
					},
					1: { v: "Eduardo Pratti", n: 0.707 },
					2: { v: "edpratti, http://pratti.design", n: 0.707 },
					3: { v: "android, design", n: 0.707 },
					4: {
						v: "Testing the limits of `firstBaselineToTopHeight` and `lastBaselineToBottomHeight` to deliver a perfect result.",
						n: 0.289,
					},
				},
			},
			{
				i: 23,
				$: {
					0: { v: "How Computers Speak: Assembly to AST", n: 0.408 },
					1: { v: "Corbin Crutchley, Kevin Mai", n: 0.5 },
					2: {
						v: "crutchcorn, crutchcorn, crutchcorn, Reikaze0, Reikaze",
						n: 0.447,
					},
					3: { v: "hardware, javascript, computer science", n: 0.5 },
					4: {
						v: "Have you wondered how programming languages are able to be ran on your hardware? This article explains how your code is processed and ran",
						n: 0.204,
					},
				},
			},
			{
				i: 24,
				$: {
					0: { v: "How to ask better questions", n: 0.447 },
					1: { v: "Alex Chadwick", n: 0.707 },
					2: {
						v: "alexchadwicc, TheAlexChadwick, AlexChadwickP, alexchadwickp, https://alexchadwick.com",
						n: 0.447,
					},
					3: { v: "opinion", n: 1 },
					4: {
						v: "We all ask questions from time to time, so here are some of my favourite tips when it comes to how to improve the quality of your questions.",
						n: 0.189,
					},
				},
			},
			{
				i: 25,
				$: {
					0: { v: "How to get started with .NET", n: 0.408 },
					1: { v: "Bobrossrtx", n: 1 },
					2: {
						v: "bobrossrtx, bobrossrtx, https://www.owenboreham.tech",
						n: 0.577,
					},
					3: { v: "dotnet, csharp", n: 0.707 },
					4: {
						v: "Did you know that 35% of developers are using .NET? This is a great article to read to get started with .NET.",
						n: 0.213,
					},
				},
			},
			{
				i: 26,
				$: {
					0: { v: "How to Interview Frontend Engineers", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "interviewing, web, javascript", n: 0.577 },
					4: {
						v: "Interviewing for frontend engineering positions can be difficult. Let's walk through some things you should focus on while interviewing.",
						n: 0.229,
					},
				},
			},
			{
				i: 27,
				$: {
					0: { v: "How to Pick Tech Stacks For New Projects", n: 0.354 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "opinion", n: 1 },
					4: {
						v: 'I often get asked "How do you pick a tech stack for your projects?". The answer is: outline what questions you should be asking early on.',
						n: 0.196,
					},
				},
			},
			{
				i: 28,
				$: {
					0: { v: "How to Upgrade to React 18", n: 0.408 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "react, webdev", n: 0.707 },
					4: {
						v: "React 18 introduces some awesome features that I'm sure you can't wait to try! Here's how you can get started with React 18 today!",
						n: 0.204,
					},
				},
			},
			{
				i: 29,
				$: {
					0: { v: "WebDev 101: How to use npm and Yarn", n: 0.354 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "webdev, javascript, node", n: 0.577 },
					4: {
						v: "You've heard a lot about Node, NPM, and Yarn - but aren't sure what they are. Let's introduce them in-depth and answer questions about them!",
						n: 0.2,
					},
				},
			},
			{
				i: 30,
				$: {
					0: { v: "Integrating Native Android Code in Unity", n: 0.408 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "unity, android, csharp, java", n: 0.5 },
					4: {
						v: "Have you ever wanted to run native Java and Kotlin code from your mobile game written in Unity? Well, you can! Let's see how.",
						n: 0.204,
					},
				},
			},
			{
				i: 31,
				$: {
					0: { v: "Introduction to HTML, CSS, and JavaScript", n: 0.408 },
					1: { v: "Micah Dutro", n: 0.707 },
					2: { v: "MDutro", n: 1 },
					3: { v: "html, css, javascript", n: 0.577 },
					4: {
						v: "Introduction to the underlying concepts of HTML, CSS, and JavaScript and how they work together.",
						n: 0.258,
					},
				},
			},
			{
				i: 32,
				$: {
					0: { v: "Introduction to Web Accessibility (A11Y)", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "accessibility, webdev", n: 0.707 },
					4: {
						v: "Accessibility allows as many people to use your product as possible. That, in turn, generates more profit. Here's how to improve it on web.",
						n: 0.204,
					},
				},
			},
			{
				i: 33,
				$: {
					0: { v: "Web Components 101: Vanilla JS", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "javascript, html, webdev", n: 0.577 },
					4: {
						v: "One of the ways web components differs from a framework is that it works right in the browser. Here's how to build them from scratch.",
						n: 0.2,
					},
				},
			},
			{
				i: 34,
				$: {
					0: {
						v: "Introduction to Android: Contexts, Intents, and the Activity lifecycle",
						n: 0.333,
					},
					1: { v: "James Fenn", n: 0.707 },
					2: { v: "fennifith, fennifith", n: 0.707 },
					3: { v: "android", n: 1 },
					4: {
						v: "A basic overview of the main components of an Android app and how they interact with each other and the Android system",
						n: 0.213,
					},
				},
			},
			{
				i: 35,
				$: {
					0: {
						v: "Introduction to TypeScript — What is TypeScript?",
						n: 0.378,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "typescript", n: 1 },
					4: {
						v: "An introduction and explanation of what TypeScript is, is not, and what it's used for",
						n: 0.258,
					},
				},
			},
			{
				i: 36,
				$: {
					0: { v: "JavaScript Fundamentals: Functions Are Values", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "webdev, javascript", n: 0.707 },
					4: {
						v: "JavaScript functions are widely used in web development... but do you KNOW them? Let's explore the fundamentals and how they can be used in unorthodox ways",
						n: 0.196,
					},
				},
			},
			{
				i: 37,
				$: {
					0: { v: "Joining Freenode IRC: A Guide", n: 0.447 },
					1: { v: "James Fenn", n: 0.707 },
					2: { v: "fennifith, fennifith", n: 0.707 },
					3: { v: "tools", n: 1 },
					4: {
						v: "Basic (but detailed) instructions for setting up a Freenode IRC account through various clients",
						n: 0.267,
					},
				},
			},
			{
				i: 38,
				$: {
					0: { v: "Keeping API Keys Secret in React Apps", n: 0.378 },
					1: { v: "Micah Dutro", n: 0.707 },
					2: { v: "MDutro", n: 1 },
					3: { v: "react, node", n: 0.707 },
					4: {
						v: "Save yourself money by hiding your API keys from prying eyes and nasty bots.",
						n: 0.267,
					},
				},
			},
			{
				i: 39,
				$: {
					0: { v: "Living off the iPad as an Engineer", n: 0.378 },
					1: { v: "Pierre Jacquier", n: 0.707 },
					2: {
						v: "PierreJacquier, pierremtb, https://pierrejacquier.com, pierrejacquier",
						n: 0.5,
					},
					3: { v: "tools, opinion", n: 0.707 },
					4: {
						v: "Tips on how to get yourself a proper development environment on the iPad to fully exploit its potential.",
						n: 0.236,
					},
				},
			},
			{
				i: 40,
				$: {
					0: { v: "Making a Slack Bot using NodeJS and MongoDB", n: 0.354 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "mongodb, node, slack", n: 0.577 },
					4: {
						v: "Join us as we teach you how to create a Slack bot from scratch using their Node SDK and MongoDB for persistence",
						n: 0.213,
					},
				},
			},
			{
				i: 41,
				$: {
					0: { v: "Building an Angular Blog With Scully", n: 0.408 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "angular, ssg, scully", n: 0.577 },
					4: {
						v: "NuxtJS and Gatsby allow you to make SSG-enabled blogs, but Angular doesn't have an equivalent... Until now. Let's build a blog with Scully!",
						n: 0.209,
					},
				},
			},
			{
				i: 42,
				$: {
					0: { v: "Master React Unidirectional Data Flow", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "react, javascript", n: 0.707 },
					4: {
						v: "Making sure your app's code is structured well is critical. Mastering React Unidirectionality is a huge part of that. Learn how to here.",
						n: 0.209,
					},
				},
			},
			{
				i: 43,
				$: {
					0: { v: "Minecraft Data Pack Programming: Command Syntax", n: 0.408 },
					1: { v: "James Fenn", n: 0.707 },
					2: { v: "fennifith, fennifith", n: 0.707 },
					4: {
						v: "Learn the beginnings of data pack development in Minecraft - using positions, entity selectors, and conditional logic in commands!",
						n: 0.229,
					},
				},
			},
			{
				i: 44,
				$: {
					0: { v: "Minecraft Data Pack Programming: Introduction", n: 0.447 },
					1: { v: "James Fenn", n: 0.707 },
					2: { v: "fennifith, fennifith", n: 0.707 },
					4: {
						v: "Learn the beginnings of data pack development in Minecraft - using commands and functions to add custom behavior from scratch!",
						n: 0.224,
					},
				},
			},
			{
				i: 45,
				$: {
					0: {
						v: "Minecraft Data Pack Programming: Scoreboard Usage",
						n: 0.408,
					},
					1: { v: "James Fenn", n: 0.707 },
					2: { v: "fennifith, fennifith", n: 0.707 },
					4: {
						v: "Learn data pack development in Minecraft - using player scoreboards, variables, and operations!",
						n: 0.277,
					},
				},
			},
			{
				i: 46,
				$: {
					0: { v: "Networking 101: UDP & TCP", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "networking", n: 1 },
					4: {
						v: "If networking is analogous to physical mail, then let's take a look at the letters being sent themselves. Let's dive into UDP and TCP",
						n: 0.204,
					},
				},
			},
			{
				i: 47,
				$: {
					0: { v: "Mutable vs Immutable Data Types", n: 0.447 },
					1: { v: "Alex Chadwick", n: 0.707 },
					2: {
						v: "alexchadwicc, TheAlexChadwick, AlexChadwickP, alexchadwickp, https://alexchadwick.com",
						n: 0.447,
					},
					3: { v: "typescript, data structures, computer science", n: 0.447 },
					4: {
						v: "Using mutable data types can be dangerous in multi-threaded applications. To help that we can make sure of thread safer immutable data types",
						n: 0.209,
					},
				},
			},
			{
				i: 48,
				$: {
					0: {
						v: "How Binary and Hexadecimal Work: An introduction to non-decimal number systems",
						n: 0.302,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "computer science", n: 0.707 },
					4: {
						v: "Learn how to convert decimal to binary and hexadecimal, how CSS colors are calculated, and how your computer interprets letters into binary.",
						n: 0.213,
					},
				},
			},
			{
				i: 49,
				$: {
					0: { v: "Pointers and References in C/C++", n: 0.447 },
					1: { v: "Sean Miller", n: 0.707 },
					2: {
						v: "beastosean, tamuseanmiller, https://sean.millerfamily.tech, tamuseanmiller",
						n: 0.5,
					},
					3: { v: "computer science, cpp", n: 0.577 },
					4: {
						v: "An overview of how pointers and references function in C/C++",
						n: 0.316,
					},
				},
			},
			{
				i: 50,
				$: {
					0: { v: "Project Management for Individuals", n: 0.5 },
					1: { v: "Alex Chadwick", n: 0.707 },
					2: {
						v: "alexchadwicc, TheAlexChadwick, AlexChadwickP, alexchadwickp, https://alexchadwick.com",
						n: 0.447,
					},
					3: { v: "opinion", n: 1 },
					4: {
						v: "Having the ability to structure your projects (and these don't exclusively have to be programming related) gives you a massive advantage when it comes to being organised, and keeping your life organised.",
						n: 0.177,
					},
				},
			},
			{
				i: 51,
				$: {
					0: {
						v: "Python List Comprehension - The Comprehensive Guide",
						n: 0.378,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "python", n: 1 },
					4: {
						v: "Python is a language with broad and powerful APIs. One such API is 'List Comprehensions'. Let's learn to use them to improve your code!",
						n: 0.204,
					},
				},
			},
			{
				i: 52,
				$: {
					0: { v: "Python None", n: 0.707 },
					1: { v: "William George Cook", n: 0.577 },
					2: {
						v: "wgeorgecook, wgeorgecook, wgeorgecook, https://williamgeorgecook.com",
						n: 0.5,
					},
					3: { v: "python, go", n: 0.707 },
					4: {
						v: "Interpreted languages have various footguns. Let's explore one such footgun I ran into recently with Python and how I fixed it.",
						n: 0.218,
					},
				},
			},
			{
				i: 53,
				$: {
					0: { v: "React Refs: The Complete Story", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "react, javascript", n: 0.707 },
					4: {
						v: "React Refs are an immensely powerful, yet often misunderstood API. Let's learn what they're capable of, and how they're usually misused.",
						n: 0.218,
					},
				},
			},
			{
				i: 54,
				$: {
					0: { v: "Rules of React's useEffect", n: 0.5 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "react, javascript", n: 0.707 },
					4: {
						v: "useEffect is prolific in React apps. Here are four rules associated with the hook and in-depth explanations of why they're important.",
						n: 0.218,
					},
				},
			},
			{
				i: 55,
				$: {
					0: { v: "Rust Enums, Matching, & Options API", n: 0.408 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "rust", n: 1 },
					4: {
						v: "Rust allows you to build super-fast and flexible applications. Let's build one leveraging enums, pattern matching, and the Options API.",
						n: 0.224,
					},
				},
			},
			{
				i: 56,
				$: {
					0: {
						v: "Autogenerate Changelogs and Manage Releases using Conventional Commit",
						n: 0.354,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "npm, javascript", n: 0.707 },
					4: {
						v: "Whether creating changelogs or just keeping track of git tags, releases matter. Learn how to automate your release process with conventional-commits!",
						n: 0.218,
					},
				},
			},
			{
				i: 57,
				$: {
					0: {
						v: "The Complete Guide to Regular Expressions (Regex)",
						n: 0.378,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "regex, computer science", n: 0.577 },
					4: {
						v: "A Regular Expression – or regex for short – is a syntax that allows you to match strings with specific patterns. Think of it as a suped-up text search",
						n: 0.186,
					},
				},
			},
			{
				i: 58,
				$: {
					0: {
						v: "Continuous Integration with Travis CI for Android",
						n: 0.378,
					},
					1: { v: "James Fenn", n: 0.707 },
					2: { v: "fennifith, fennifith", n: 0.707 },
					3: { v: "android, ci", n: 0.707 },
					4: {
						v: "An in-depth tutorial explaining how to set up Travis CI to deploy signed builds to Google Play. Among other things",
						n: 0.224,
					},
				},
			},
			{
				i: 59,
				$: {
					0: { v: "TypeScript Intermediates - Type Generics", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "typescript", n: 1 },
					4: {
						v: "An introduction to the type generic functionality in TypeScript",
						n: 0.333,
					},
				},
			},
			{
				i: 60,
				$: {
					0: {
						v: "The Ultimate Windows Development Environment Guide",
						n: 0.408,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "tools, windows", n: 0.707 },
					4: {
						v: "Many developers like MacOS or Linux for development environments, but don't know that Windows has plenty to offer. Become a Windows pro!",
						n: 0.213,
					},
				},
			},
			{
				i: 61,
				$: {
					0: {
						v: "Understanding The DOM: How Browsers Show Content On-Screen",
						n: 0.354,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "webdev, css, javascript, html", n: 0.5 },
					4: {
						v: "Learn how the browser internally handles HTML and CSS to show the user webpages on-screen",
						n: 0.258,
					},
				},
			},
			{
				i: 62,
				$: {
					0: { v: "Adding Cathage Dependencies into React Native", n: 0.408 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "ios, react native", n: 0.577 },
					4: {
						v: "CocoaPods is a great dependency manager, but some need Carthage still. Let's walk through how to integrate Carthage with React Native!",
						n: 0.218,
					},
				},
			},
			{
				i: 63,
				$: {
					0: { v: "Uttering Hello — The Site's First Post", n: 0.378 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "announcements", n: 1 },
					4: {
						v: "An introduction to Unicorn Utterances, including a mission statement and general roadmap",
						n: 0.289,
					},
				},
			},
			{
				i: 64,
				$: {
					0: { v: "Virtual Memory Overview", n: 0.577 },
					1: { v: "Sean Miller", n: 0.707 },
					2: {
						v: "beastosean, tamuseanmiller, https://sean.millerfamily.tech, tamuseanmiller",
						n: 0.5,
					},
					3: { v: "computer science, cpp", n: 0.577 },
					4: {
						v: "An overview of how operating systems give processes their own address space.",
						n: 0.289,
					},
				},
			},
			{
				i: 65,
				$: {
					0: { v: "Vue Composition API Inspector", n: 0.5 },
					1: { v: "William (Will) Lohan", n: 0.577 },
					2: {
						v: "william-lohan, splat_killwill, https://gatimus.com/, william-lohan-b202637a",
						n: 0.5,
					},
					3: { v: "webdev, vue", n: 0.707 },
					4: {
						v: "A peek under the hood of Vue compilation. See how Vue interpretes TypeScript",
						n: 0.277,
					},
				},
			},
			{
				i: 66,
				$: {
					0: { v: "Web Components 101: Framework Comparison", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "lit, vue, react, angular", n: 0.5 },
					4: {
						v: "While web components can be used standalone, they're paired best with a framework. With that in mind, which is the best and why?",
						n: 0.209,
					},
				},
			},
			{
				i: 67,
				$: {
					0: { v: "Web Components 101: History", n: 0.5 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "webdev, history", n: 0.707 },
					4: {
						v: "Web components have had a long history to get where they are today. Let's look back to see where they came from & their immense growth!",
						n: 0.196,
					},
				},
			},
			{
				i: 68,
				$: {
					0: { v: "Web Components 101: Lit Framework", n: 0.447 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "webdev, lit", n: 0.707 },
					4: {
						v: "Google pushed for web components, sure, but they didn't stop there. They also went on to make an amazing framework to help build them: Lit!",
						n: 0.2,
					},
				},
			},
			{
				i: 69,
				$: {
					0: { v: "What do file extensions do?", n: 0.447 },
					1: { v: "Robert Mennell", n: 0.707 },
					2: { v: "skatcat31, rnmennell", n: 0.707 },
					3: { v: "computer science", n: 0.707 },
					4: {
						v: "A file extension isn't the only way a file is inditified, so what does it do?",
						n: 0.25,
					},
				},
			},
			{
				i: 70,
				$: {
					0: { v: "What's An Algorithm?", n: 0.577 },
					1: { v: "Qarnax", n: 1 },
					2: { v: "qarnax_, qarnax, qarnax801", n: 0.577 },
					3: { v: "computer science", n: 0.707 },
					4: {
						v: "A quick introduction into what algorithms are, what they're made of and why they're an important part of understanding how programming languages work",
						n: 0.209,
					},
				},
			},
			{
				i: 71,
				$: {
					0: { v: "What is Primitive obsession and how to fix it", n: 0.333 },
					1: { v: "Alex Chadwick", n: 0.707 },
					2: {
						v: "alexchadwicc, TheAlexChadwick, AlexChadwickP, alexchadwickp, https://alexchadwick.com",
						n: 0.447,
					},
					3: { v: "opinion, csharp, computer science", n: 0.5 },
					4: {
						v: "Primitive obsession is an extremely common code smell, and when identified and fix, it greatly helps to reduce the amount of bugs that you may find in your code.",
						n: 0.186,
					},
				},
			},
			{
				i: 72,
				$: {
					0: {
						v: "What is Server Side Rendering (SSR) and Static Site Generation (SSG)?",
						n: 0.302,
					},
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "ssr, ssg, nextjs, react", n: 0.5 },
					4: {
						v: "An explanation of what server-side rendering is, what static site generation is, and how you can utilize them in React, Angular, or Vue!",
						n: 0.209,
					},
				},
			},
			{
				i: 73,
				$: {
					0: { v: "When to use HashMap instead of Loop", n: 0.378 },
					1: { v: "Kaleem", n: 1 },
					2: { v: "kaleemniz, kaleem68, nixamani5", n: 0.577 },
					3: { v: "javascript, computer science", n: 0.577 },
					4: {
						v: "Learn to use when to use HashMap instead of Loop",
						n: 0.316,
					},
				},
			},
			{
				i: 74,
				$: {
					0: { v: "Why React 18 Broke Your App", n: 0.408 },
					1: { v: "Corbin Crutchley", n: 0.707 },
					2: { v: "crutchcorn, crutchcorn, crutchcorn", n: 0.577 },
					3: { v: "react, webdev", n: 0.707 },
					4: {
						v: "React 18's internal changes improved a lot, but may have broken your app in the process. Here's why and how you can fix it",
						n: 0.204,
					},
				},
			},
			{
				i: 75,
				$: {
					0: { v: "Windows Subsystem for Linux", n: 0.5 },
					1: { v: "William (Will) Lohan", n: 0.577 },
					2: {
						v: "william-lohan, splat_killwill, https://gatimus.com/, william-lohan-b202637a",
						n: 0.5,
					},
					3: { v: "windows, linux", n: 0.707 },
					4: {
						v: "Utilize the best of both worlds — Windows and Linux — without having to dual boot. Windows Subset for Linux (WSL) lets you run software designed for Linux in Windows.",
						n: 0.183,
					},
				},
			},
			{
				i: 76,
				$: {
					0: {
						v: "Writing better tests for Angular with Angular Testing Library",
						n: 0.333,
					},
					1: { v: "Robert Mennell", n: 0.707 },
					2: { v: "skatcat31, rnmennell", n: 0.707 },
					3: { v: "testing, angular", n: 0.707 },
					4: {
						v: "A simple explination of writing better tests for Angular applications and setting up Angular Testing Library",
						n: 0.25,
					},
				},
			},
		],
	},
	posts: [
		{
			title: "Setup Android Studio Emulator for AMD Ryzen CPUs",
			description:
				"While the Android Emulator isn't confined to Intel CPUs anymore, it can be tricky to setup for AMD Ryzen CPUs. Let's explain how to do so.",
			published: "2020-05-05T13:45:00.284Z",
			authors: ["crutchcorn"],
			tags: ["tools", "windows"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "android-studio-setup-for-ryzen-cpus",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Setup Android Studio Emulator for AMD Ryzen CPUs",
				description:
					"While the Android Emulator isn't confined to Intel CPUs anymore, it can be tricky to setup for AMD Ryzen CPUs. Let's explain how to do so.",
				published: "2020-05-05T13:45:00.284Z",
				authors: ["crutchcorn"],
				tags: ["tools", "windows"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				'\nIn the past, Android Studio did not support AMD\'s CPUs for hardware emulation of an Android device. [That all changed in 2018 when Google added Hyper-V support to the Android Emulator](https://android-developers.googleblog.com/2018/07/android-emulator-amd-processor-hyper-v.html).\n\nHowever, while working on my Ryzen CPU powered desktop, I had difficulties getting the program working on my machine. \n\n# BIOS Setup {#bios}\n\nTo use Hyper-V, we have to have various settings configured on our motherboards.\n\nTwo of the settings we need to enable are:\n\n- `IOMMU` - Provides resources to be passed directly to virtual machines\n- `SVM Mode` - "Secure Virtual Machine" features, enabling applications to use features for VMs\n\nI personally have a Gigabyte motherboard (the Gigabyte GA-AB350M-Gaming 3), so I\'ll showcase the places I had to find the options for these motherboard settings.\n\n## SVM Mode {#gigabyte-svm}\n\nTo enable SVM mode, first start at the first screen to the left, labeled **"M.I.T"**.\n\n![The MIT menu item](./mit_menu.jpg)\n\nThen, select **"Advanced Frequency Settings"**.\n\n![The Advanced Frequency Settings page](./frequency_settings.jpg)\n\nFinally, open the **"Advanced CPU Core Settings"**.\n\n![The CPU Core settings page](./svm_mode.jpg)\n\nOnce on this page, you should see **"SVM Mode"** as the fourth option from the bottom. _Toggle that to **"Enabled"**_, then move onto enabling IOMMU\n\n## IOMMU {#gigabyte-iommu}\n\nEnabling IOMMU on a Gigabyte AMD motherboard is much easier than enabling SVM mode. Simply _go to the **"Chipset"** root tab, and it should be the first option at the top_. Even if it\'s set to "Auto", go ahead and _update that to be **"Enabled"**_.\n\n![The chipset tab](./iommu.jpg)\n\n\n\nOnce changed, tab over to "Save & Exit" and select "Exit and save changes".\n\n# Windows Features Setup {#windows-features}\n\nNow that we have our BIOS (UEFI, really) configured correctly, we can enable the Windows features we need for the Android Emulator.\n\nTo start, press <kbd>Win</kbd> + <kbd>R</kbd>, which should bring up the **"Run"** dialog. Once open, _type `OptionalFeatures` and press **"OK"**_. \n\n![The "run dialog" box with the typed suggestion](./run_dialog.png)\n\nOnce that\'s run, you\'ll see a **"Turn Windows features on or off"** window.\n\n![](./windows_10_add_features.png)\n\nYou\'ll want to turn on the following options:\n\n- Hyper-V\n- Windows Hypervisor Platform\n- Windows Sandbox\n\nAfter these three settings are selected, press **"OK"** and allow the features to install. After your features are installed, your machine will need a reboot. Go ahead and restart your computer before proceeding to install Android Studio.\n\n# Setup Android Studio {#android-studio}\n\nYou have a few different methods for installing Android Studio. You can choose to use [Google\'s installer directly](https://developer.android.com/studio/install), you can [utilize the Chocolatey CLI installer](https://chocolatey.org/packages/AndroidStudio), or even use [JetBrain\'s Toolbox utility to install and manage an instance of Android Studio](https://www.jetbrains.com/toolbox-app/). _Any of these methods work perfectly well_, it\'s down to preference, really. \n\nOnce you get Android Studio installed, go ahead and _open the SDK Manager settings screen_ from the **"Configure"** dropdown.\n\n![The startup screen showing "configure" dropdown](./android_studio_configure.png)\n\nOnce you see the popup dialog, you\'ll want to _select the "SDK Tools" tab_. There should be a selection of tools that you can install or update. One of those selections (in about the middle of the list) should be called _"Android Emulator Hypervisor Driver for AMD Processors (installer)"_\n\n![The mentioned screen with the AMD hypervisor selected](./select_amd_hypervisor.png)\n\n\n\n\n\nOnce you\'ve selected it, press **"Apply"** to download the installer. _Because the "Apply" button only downloads the installer, we\'ll need to run it manually._ \n\n## Run the Installer {#amd-hypervisor-installer}\n\nTo find the location of the installer, you\'ll want to go to the install location for your Android SDK. For me (who used the Jetbrains Toolbox to install Android Studio), that path was: `%AppData%/../Local/Android/Sdk`. \n\nThe hypervisor installer is located under the following subpath of that path:\n\n```\nSDK_INSTALL_LOCATION\\extras\\google\\Android_Emulator_Hypervisor_Driver\n```\n\n![The location of the hypervisor visually using OneCommander app](./hypervisor_filesystem_path.png)\n\n> If you like having this macOS-like preview pane of files, you can find it in the OneCommander application. We covered this app in [our "Ultimate Windows Development Environment Guide" article](posts/ultimate-windows-development-environment-guide/#Paid)\n\nOnce you have the path located, you\'ll want to run the `silent_installer.bat` inside of an elevated shell. I did this by pressing <kbd>Win</kbd> + <kbd>X</kbd> and pressing **"Windows PowerShell (Admin)"**. Once that was opened, I copied the path to the PowerShell window via `cd` and ran the installer.\n\n![The Win+X dialog](./win_x.png)\n\n![The "Success" of the installer once ran](./installer_ran.png)\n\nYou should see the message _"DeleteService SUCCESS"_ if everything ran as expected.\n\n> If you get an error `[SC] StartService FAILED with error 4294967201.`, make sure you\'ve followed the steps to [enable BOTH settings in your BIOS](#bios) as well as ALL of the [features mentioned in Windows](#windows-features)\n\n## AVD Setup {#avd}\n\nTo run the emulator, you need to set up a device itself. You do this through the **"AVD Manager"** in the "configure" menu.\n\n![The AVG manager submenu](./avd_manager.png)\n\nYou\'ll then see a list of the devices that you currently have setup. I, for example, have three different devices already setup as you can see here:\n\n![The three devices as mentioned](./virtual_devices.png)\n\nYou can create a new one by _pressing **"Create Virtual Device"**_.\n\nUpon the dialog creation, you\'ll see a list of devices that you can use as a baseline for your emulator. This sets the hardware information (screen size and such). Even if you pick a device, it does not restrict the versions of Android you can use with it. I picked Pixel 2 and KitKat for my KK testing device, despite the Pixel 2 being released well after that OS release. \n\n![The "select hardware" screen as mentioned](./select_virtual_device.png)\n\nOnce you\'ve selected a device, you can pick the version of Android to run. You\'ll want to select an `x86` or `x86_64` build of Android you\'re looking for. I\'ve noticed better performance from `x86_64` emulators myself, so I went with an `x86_64` build of Android Pie.\n\n![The selected image for x86_64 Pie](./pie_device.png)\n\nAfterward, you\'ll want to name your emulator. I try to keep them without strings and not too long, so if I need to run the emulator manually in the CLI, I can do so with the name of the emulator easily.\n\n![Naming the emulator device](./finalize_avd.png)\n\nFinally, once you\'ve selected **"Finish"**, it should save the emulator\'s settings and start the emulator itself.\n\n\n> You may get an error such as `HAXM is not installed` when trying to set up an emulator. If you get this error, it\'s most likely that you have not [enabled the settings in BIOS](#bios). I know in my case, I had recently performed a BIOS upgrade, and it had reset my BIOS settings, making me go back and re-enable them.\n\n![The emulator once ran](./device_running.png)\n\n# Conclusion\n\nI\'ve had incredible success with my Ryzen powered desktop during my Android development. Not only is it cost-efficient for my usage compared to the Intel option, but it\'s able to run the emulator quickly. Hopefully, this article has been able to help you set up your machine as well. \n\nLet us know what your thoughts on this article were! We not only have our comments down below, but we have [a Discord community](https://discord.gg/FMcvc6T) as well that we invite you to join! We chat about all kinds of programming and CS related topics there!\n',
		},
		{
			title:
				"Better Angular Form Components with ngModel and formControl Implementation",
			description:
				"Some components make controlling their state easier with 'formControl' and 'ngModel'. Let's see how we can build our own!",
			published: "2020-06-09T13:45:00.284Z",
			authors: ["crutchcorn"],
			tags: ["angular", "javascript"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "angular-components-control-value-accessor",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title:
					"Better Angular Form Components with ngModel and formControl Implementation",
				description:
					"Some components make controlling their state easier with 'formControl' and 'ngModel'. Let's see how we can build our own!",
				published: "2020-06-09T13:45:00.284Z",
				authors: ["crutchcorn"],
				tags: ["angular", "javascript"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nOne of Angular's greatest strengths over its contemporaries like React or Vue is that it's a framework. What does this mean in the practical sense? Well, because you're providing the defaults for everything right out-of-the-box, you have a set of guard rails to follow when architecting new things. A set of baseline rules for things to follow, so to speak.\n\nOne such guard rail comes in the form of the `@angular/forms` package. If you've used Angular for long, you're doubtlessly familiar with [the `[(ngModel)]` method of two-way data binding in the UI](https://angular.io/guide/forms#two-way-data-binding-with-ngmodel). Seemingly all native elements have support for this feature (so long as you have `FormsModule` imported in your module).\n\nMore than that, if you want more powerful functionality, such as disabling an entire form of fields, tracking a collection of fields in a form, and doing basic data validation, [you can utilize Angular Reactive Forms' `[formControl]`](https://angular.io/guide/reactive-forms#adding-a-basic-form-control) and do all of that and more.\n\nThese features are hugely helpful when dealing with complex form logic throughout your application. Luckily for us, they're not just exclusive to native elements - we can implement this functionality into our own form!\n\n# Example {#code-demo}\n\nIt's hard for us to talk about the potential advantages to a component without taking a look at it. Let's start with this component, just for fun.\n\nIt'll allow you to type in data, have a header label (as opposed to a floating label, [which is notoriously bad for A11Y](https://www.matsuko.ca/blog/stop-using-material-design-text-fields/)), and even present a fun message when \"Unicorns\" is typed in.\n\nHere's the code:\n\n```typescript\nimport { Component, Input } from \"@angular/core\";\n\n@Component({\n  selector: \"app-example-input\",\n  template: `\n    <label class=\"inputContainer\">\n      <span class=\"inputLabel\">{{ placeholder }}</span>\n      <input\n        placeholder=\"\"\n        class=\"inputInput\"\n        [(ngModel)]=\"value\"\n      />\n    </label>\n    <p\n      class=\"hiddenMessage\"\n      [class.hideTheMessage]=\"!isSecretValue\"\n      aria-hidden=\"true\"\n    >\n      You unlocked the secret unicorn rave!<span>🦄🦄🦄</span>\n    </p>\n    <!-- This is for screen-readers, since the animation doesn't work with the 'aria-live' toggle -->\n    <p aria-live=\"assertive\" class=\"visually-hidden\">\n      {{\n        isSecretValue\n          ? \"You discovered the secret unicorn rave! They're all having a party now that you summoned them by typing their name\"\n          : \"\"\n      }}\n    </p>\n  `,\n  styleUrls: [\"./example-input.component.css\"]\n})\nexport class ExampleInputComponent {\n  @Input() placeholder: string;\n  value: any = \"\";\n\n  get isSecretValue() {\n    return /unicorns/.exec(this.value.toLowerCase());\n  }\n}\n```\n\nWith only a bit of CSS, we have a visually appealing, A11Y friendly, and quirky input component. Look, it even wiggles the unicorns!\n\n<iframe src=\"https://stackblitz.com/edit/angular-unicorns-text-input?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nNow, this component is far from feature complete. There's no way to `disable` the input, there's no way to extract data out from the typed input, there's not a lot of functionality you'd typically expect to see from an input component. Let's change that.\n\n# ControlValueAccessor {#intro-concept}\n\nMost of the expected form functionality will come as a complement of [the `ControlValueAccessor` interface](https://angular.io/api/forms/ControlValueAccessor). Much like you implement `ngOnInit` by implementing class methods, you do the same with ControlValueAccessor to gain functionality for form components.\n\nThe methods you need to implement are the following:\n\n- `writeValue`\n- `registerOnChange`\n- `registerOnTouched`\n- `setDisabledState`\n\nLet's go through these one-by-one and see how we can introduce change to our component to support each one.\n\n## Setup {#forwardRef}\n\nTo use these four methods, you'll first need to `provide` them somehow. To do this, we use a combination of the component's `providers` array, `NG_VALUE_ACCESSOR`, and `forwardRef`.\n\n```typescript\nimport { forwardRef } from '@angular/core';\nimport {ControlValueAccessor, NG_VALUE_ACCESSOR} from '@angular/forms';\n\n/**\n * Provider Expression that allows your component to register as a ControlValueAccessor. This\n * allows it to support [(ngModel)] and ngControl.\n */\nexport const EXAMPLE_CONTROL_VALUE_ACCESSOR: any = {  \n  /**\n   * Used to provide a `ControlValueAccessor` for form controls.\n   */\n  provide: NG_VALUE_ACCESSOR,\n  /**\n   * Allows to refer to references which are not yet defined.\n   * This is because it's needed to `providers` in the component but references\n   * the component itself. Handles circular dependency issues\n   */\n  useExisting: forwardRef(() => ExampleInputComponent),\n  multi: true\n};\n```\n\nOnce we have this example provide setup, we can now pass it to a component's `providers` array:\n\n```typescript\n@Component({\n  selector: 'app-example-input',\n  templateUrl: './example-input.component.html',\n  styleUrls: ['./example-input.component.css'],\n  providers: [EXAMPLE_CONTROL_VALUE_ACCESSOR]\n})\nexport class ExampleInputComponent implements ControlValueAccessor {\n```\n\nWith this, we'll finally be able to use these methods to control our component.\n\n> If you're wondering why you don't need to do something like this with `ngOnInit`, it's because that functionality is baked right into Angular. Angular _always_ looks for an `onInit` function and tries to call it when the respective lifecycle method is run. `implements` is just a type-safe way to ensure that you're explicitly wanting to call that method.\n\n\n## `writeValue` {#write-value}\n\n`writeValue` is a method that acts exactly as you'd expect it to: It simply writes a value to your component's value. As your value has more than a single write method (from your component and from the parent), it's suggested to have a setter, getter, and private internal value for your property.\n\n```typescript\n private _value: any = null;\n\n  @Input()\n  get value(): any { return this._value; }\n  set value(newValue: any) {\n    if (this._value !== newValue) {\n      // Set this before proceeding to ensure no circular loop occurs with selection.\n      this._value = newValue;\n    }\n  }\n```\n\nOnce this is done, the method is trivial to implement:\n\n```typescript\n writeValue(value: any) {\n    this.value = value;\n  }\n```\n\nHowever, you may notice that your component doesn't properly re-render when you update your value from the parent component. Because you're updating your value outside of the typical pattern, change detection may have a difficult time running when you'd want it to. To solve for this, provide a `ChangeDetectorRef` in your constructor and manually check for updates in the `writeValue` method:\n\n```typescript\nexport class ExampleInputComponent implements ControlValueAccessor {\n  // ...\n  constructor(private _changeDetector: ChangeDetectorRef) { }\n   // ...\n writeValue(value: any) {\n    this.value = value;\n    this._changeDetector.markForCheck();\n  }\n```\n\nNow, when we use a value like `new FormValue('test')` and pass it as `[formControl]` to our component, it will render the correct default value\n\n## `setDisabledState` {#disabled-state}\n\nImplementing the disabled state check is extremely similar to [implementing value writing](#write-value). Simply add a setter, getter, and `setDisabledState` to your component, and you should be good-to-go:\n\n```typescript\n private _disabled: boolean = false;\n\n  @Input()\n  get disabled(): boolean { return this._disabled; }\n  set disabled(value) {\n    this._disabled = coerceBooleanProperty(value);\n  }\n\n  setDisabledState(isDisabled: boolean) {\n    this.disabled = isDisabled;\n    this._changeDetector.markForCheck();\n  }\n```\n\nJust as we did with value writing, we want to run a `markForCheck` to allow change detection to work as expected when the value is changed from a parent\n\n> It's worth mentioning that unlike the other three methods, this one is entirely optional for implementing a `ControlValueAccessor`. This allows us to disable the component or keep it enabled but is not required for usage with the other methods. `ngModel` and `formControl` will work without this method implemented.\n\n## `registerOnChange` {#register-on-change}\n\nWhile the previous methods have been implemented in a way that required usage of `markForCheck`, these last two methods are implemented in a bit of a different way. You only need look at the type of the methods on the interface to see as much:\n\n```typescript\nregisterOnChange(fn: (value: any) => void);\n```\n\nAs you might be able to deduce from the method type, when `registerOnChange` is called, it passes you a function. You'll then want to store this function in your class instance and call it whenever the user changes data.\n\n```typescript\n/** The method to be called to update ngModel */\n_controlValueAccessorChangeFn: (value: any) => void = () => {};\n\nregisterOnChange(fn: (value: any) => void) {\n    this._controlValueAccessorChangeFn = fn;\n}\n```\n\nWhile this code sample shows you how to store the function, it doesn't outline how to call it once stored. You'll want to make sure to call it with the updated value on every update. For example, if you are expecting an `input` to change, you'd want to add it to `(change)` output of the `input`:\n\n```html\n<input\n       placeholder=\"\"\n       [disabled]=\"disabled\"\n       [(ngModel)]=\"value\"\n       (change)=\"_controlValueAccessorChangeFn($event.target.value)\"\n/>\n```\n\n## `registerOnTouched` {#register-on-touched}\n\nLike how you [store a function and call it to register changes](#register-on-change), you do much of the same to register when a component has been \"touched\" or not. This tells your consumer when a component has had interaction or not.\n\n```typescript\nonTouched: () => any = () => {};\n\nregisterOnTouched(fn: any) {\n\tthis.onTouched = fn;\n}\n```\n\nYou'll want to call this `onTouched` method any time that your user \"touches\" (or, interacts) with your component. In the case of an `input`, you'll likely want to place it on the `(blur)` output:\n\n```html\n<input\n    placeholder=\"\"\n    [disabled]=\"disabled\"\n    [(ngModel)]=\"value\"\n    (change)=\"onChange($event)\"\n    (blur)=\"onTouched()\"\n/>\n```\n\n# Consumption {#consume-demo}\n\nNow that we've done that work let's put it all together, apply [the styling from before](#code-demo), and consume the component we've built!\n\nWe'll need to start by importing `FormModule` and `ReactiveFormModule` into your `AppModule` for `ngModel` and `formControl` support respectively.\n\n```typescript\nimport { NgModule } from '@angular/core';\nimport { BrowserModule } from '@angular/platform-browser';\nimport { FormsModule } from '@angular/forms';\n\nimport { ReactiveFormsModule } from '@angular/forms';\n\nimport { AppComponent } from './app.component';\nimport { ExampleInputComponent } from './example-input/example-input.component';\n\n@NgModule({\n  imports:      [ ReactiveFormsModule, FormsModule, BrowserModule ],\n  declarations: [ AppComponent, ExampleInputComponent ],\n  bootstrap:    [ AppComponent ]\n})\nexport class AppModule { }\n```\n\nOnce you have support for them both, you can move onto adding a `formControl` item to your parent component:\n\n```typescript\nimport { Component } from '@angular/core';\nimport {FormControl} from '@angular/forms';\n\n@Component({\n  selector: 'my-app',\n  templateUrl: './app.component.html',\n  styleUrls: [ './app.component.css' ]\n})\nexport class AppComponent  {\n  control = new FormControl('');\n  modelValue = \"\";\n}\n```\n\nFinally, you can pass these options to `ngModel` and `formControl` (or even `formControlName`) and inspect the value directly from the parent itself:\n\n```html\n<h1>Form Control</h1>\n<app-example-input placeholder=\"What's your favorite animal?\" [formControl]=\"control\"></app-example-input>\n<p>The value of the input is: {{control.value}}</p>\n<h1>ngModel</h1>\n<app-example-input placeholder=\"What's your favorite animal?\" [(ngModel)]=\"modelValue\"></app-example-input>\n<p>The value of the input is: {{modelValue}}</p>\n```\n\nIf done properly, you should see something like this:\n\n\n<iframe src=\"https://stackblitz.com/edit/angular-value-accessor-example?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n# Form Control Classes\n\nAngular CSS masters might point to [classes that's applied to inputs when various state changes are made](https://angular.io/api/forms/NgControlStatus#css-classes-applied).\n\nThese classes include:\n\n\n- `ng-pristine`\n- `ng-dirty`\n- `ng-untouched`\n- `ng-touched`\n\nThey reflect states so that you can update the visuals in CSS to reflect them. When using `[(ngModel)]`, they won't appear, since nothing is tracking when a component is `pristine` or `dirty`. However, when using `[formControl]` or `[formControlName]`, these classes _will_ appear and act accordingly, thanks to the `registerOnChange` and `registerOnTouched` functions. As such, you're able to display custom CSS logic for when each of these states are met.\n\n# Gain Access To Form Control Errors {#form-control-errors}\n\nSomething you'll notice that wasn't implemented in the `ControlValueAccessor` implementation is support for checking whether validators are applied. If you're a well-versed Angular Form-ite, you'll recall the ability to [validate forms using validators appended to `FormControl`s](https://angular.io/guide/form-validation). Although a niche situation — since most validation happens at the page level, not the component level — wouldn't it be nice to check when a form is valid or not directly from the component to which the form is attached?\n\nWell, thanks to Angular's DI system, we can do just that!\n\nHowever, we'll need to make a few changes to the form input [we made before](#forwardRef). While we previously implemented a provider for form controls, we now need to manually assign the provider ourselves in the constructor:\n\n```typescript\nimport {\n  Component,\n  Input,\n  ChangeDetectorRef,\n  Optional,\n  Self,\n  AfterContentInit\n} from \"@angular/core\";\nimport { ControlValueAccessor, NgControl } from \"@angular/forms\";\n\n@Component({\n  selector: \"app-example-input\",\n  templateUrl: \"./example-input.component.html\",\n  styleUrls: [\"./example-input.component.css\"]\n})\nexport class ExampleInputComponent implements ControlValueAccessor, AfterContentInit {\n  constructor(\n    @Optional() @Self() public ngControl: NgControl,\n    private _changeDetector: ChangeDetectorRef\n  ) {\n    if (ngControl != null) {\n      // Setting the value accessor directly (instead of using\n      // the providers) to avoid running into a circular import.\n      ngControl.valueAccessor = this;\n    }\n  }\n    \n  // ...\n}\n```\n\nIn this code sample, we're using [the `@Self` decorator](https://angular.io/api/core/Self) to tell the dependency injection system that \"this component _itself_ should have been provided a `formControl` or `formControlName`\". However, we want the component to work even when `FormModule` isn't being used, so we allow the dependency injection to return `null` if nothing's passed by utilizing [the `@Optional` decorator](https://angular.io/api/core/Optional).\n\nNow that you have the `ngControl`, you can access the `formControl` by using `ngControl.control`.\n\n```typescript\nngOnInit() {\n    const control = this.ngControl && this.ngControl.control;\n    if (control) {\n        console.log(\"ngOnInit\", control);\n        // FormControl should be available here\n    }\n}\n```\n\nYou have [a ton of different props you're able to access for the control's metadata](https://angular.io/api/forms/NgControl). For example, if you want to check when errors are present, you can do the following:\n\n```typescript\nget errors() {\n    const control = this.ngControl && this.ngControl.control;\n    if (control) {\n    \treturn control.touched && control.errors;\n    }\n    return null;\n}\n```\n\nAnd then reference it in the template:\n\n```html\n<span class=\"inputLabel\" [class.redtext]=\"errors\">{{ placeholder }}</span>\n```\n\nNow that you have the component implementation, you can add validators to your `FormControl`:\n\n```typescript\nimport { Component } from '@angular/core';\nimport {FormControl, Validators} from '@angular/forms';\n\n@Component({\n  selector: 'my-app',\n  templateUrl: './app.component.html',\n  styleUrls: [ './app.component.css' ]\n})\nexport class AppComponent  {\n  control = new FormControl('', Validators.required);\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/angular-value-accessor-dep-inject?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n\nNot only do you have [a wide range of Angular-built validators at your disposal](https://angular.io/api/forms/Validators), but you're even able to [make your own validator](https://angular.io/api/forms/Validator)!\n\n# Conclusion {#conclusion}\n\nEnabling `formControl` and `ngModel` usage is an extremely powerful tool that enables you to have feature-rich and consistent APIs across your form components. Using them, you can ensure that your consumers are provided with the functionality they'd expect in a familiar API to native elements. Hopefully, this article has provided you with more in-depth insight that you're able to use with your own components.\n\nIf you're interested in learning more about Angular, please sign up for our newsletter down below! We don't spam and will notify you when new Angular articles are live! Additionally, if you'd like to ask in-depth questions or chat about anything Angular related, don't forget to [join our Discord Server, where we talk code and more!](https://discord.gg/FMcvc6T)\n",
		},
		{
			title: "How to Share Lifecycle Methods Between Components in Angular",
			description:
				"Sharing code between components in Angular is TOUGH. Here's one way you can do so by utilizing base components that you extend - and why you shouldn't use them.",
			published: "2022-08-20T21:52:59.284Z",
			authors: ["crutchcorn", "LayZee"],
			tags: ["angular", "javascript", "webdev"],
			attached: [],
			license: {
				id: "cc-by-4",
				footerImg: "https://i.creativecommons.org/l/by/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by/4.0/",
				name: "Attribution 4.0 International (CC BY 4.0)",
				displayName: "Creative Commons Attribution 4.0 International License",
			},
			slug: "angular-extend-class",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
				{
					id: "LayZee",
					name: "Lars Gyrup Brink Nielsen",
					firstName: "Lars",
					lastName: "Gyrup Brink Nielsen",
					description:
						"Hi there, I'm Lars 👋\n\nI am a public tech contributor. I write articles and books, I organize communities, and I maintain open source software.",
					socials: {
						twitter: "LayZeeDK",
						github: "LayZeeDK",
						twitch: "LayZeeDK",
					},
					pronouns: "he",
					profileImg: "./lars-gyrup-brink-nielsen.jpg",
					color: "#1b9bf0",
					roles: ["author"],
					profileImgMeta: {
						height: 477,
						width: 477,
						relativePath: "./lars-gyrup-brink-nielsen.jpg",
						relativeServerPath: "/content/data/lars-gyrup-brink-nielsen.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\lars-gyrup-brink-nielsen.jpg",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "How to Share Lifecycle Methods Between Components in Angular",
				description:
					"Sharing code between components in Angular is TOUGH. Here's one way you can do so by utilizing base components that you extend - and why you shouldn't use them.",
				published: "2022-08-20T21:52:59.284Z",
				authors: ["crutchcorn", "LayZee"],
				tags: ["angular", "javascript", "webdev"],
				attached: [],
				license: "cc-by-4",
			},
			contentMeta:
				"\nIn recent years, we've seen frameworks like React and Vue develop utilities to share code that uses lifecycle methods. What does that look like?\n\n> I promise this article is about Angular, stick with me on this.\n\nFor example, if you wanted to have a component that measures the browser window, you might write some code like so:\n\n<!-- tabs:start -->\n\n# React\n\n```jsx\nconst App = () => {\n  const [height, setHeight] = useState(window.innerHeight);\n  const [width, setWidth] = useState(window.innerWidth);\n\n  useEffect(() => {\n    function onResize() {\n      setHeight(window.innerHeight);\n      setWidth(window.innerWidth);\n    }\n\n    window.addEventListener('resize', onResize);\n\n    return () => window.removeEventListener('resize', onResize);\n  }, []);\n  \n  return <p>The window is {height}px high and {width}px wide</p>\n}\n```\n\n# Vue\n\n```vue\n<!-- App.vue -->\n<template>\n\t<p>The window is {{height}}px high and {{width}}px wide</p>\n</template>\n\n<script setup>\nimport {ref, onMounted, onUnMounted} from 'vue';\n  \nconst height = ref(window.innerHeight);\nconst width = ref(window.innerWidth);\n  \nfunction onResize() {\n  height.value = window.innerHeight;\n  width.value = window.innerWidth;\n}\n  \nonMounted(() => {\n  window.addEventListener('resize', onResize);\n});\n\nonUnMounted(() => {\n  window.removeEventListener('resize', onResize);\n});\n</script>\n```\n\n<!-- tabs:end -->\n\n> Like seeing equivical code between multiple frameworks at once? You might like the book I'm writing called [\"The Framework Field Guide\", which teaches React, Angular, and Vue all at once](https://framework.guide).\n\nThis works great for a single component, but what if you want to reuse this `window` logic in more than one component?\n\nWhile you _could_ copy and paste the code between multiple components, or even export functions to setup and take down the event listeners, both of these methods are clunky. This is where the aforementioned Hooks and Composition APIs come into play for React and Vue respectively.\n\n<!-- tabs:start -->\n\n# React\n\n```jsx\nconst useWindowSize = () => {\n  const [height, setHeight] = useState(window.innerHeight);\n  const [width, setWidth] = useState(window.innerWidth);\n\n  useEffect(() => {\n    function onResize() {\n      setHeight(window.innerHeight);\n      setWidth(window.innerWidth);\n    }\n\n    window.addEventListener('resize', onResize);\n\n    return () => window.removeEventListener('resize', onResize);\n  }, []);\n\n\treturn {height, width};  \n}\n\nconst App = () => {\n  const {height, width} = useWindowSize();\n  return <p>The window is {height}px high and {width}px wide</p>\n}\n```\n\n# Vue\n\n```typescript\n// useWindowSize.ts\nimport {ref, onMounted, onUnMounted} from 'vue';\n\nexport const useWindowSize = () => {\n  const height = ref(window.innerHeight);\n  const width = ref(window.innerWidth);\n\n  function onResize() {\n    height.value = window.innerHeight;\n    width.value = window.innerWidth;\n  }\n\n  onMounted(() => {\n    window.addEventListener('resize', onResize);\n  });\n\n  onUnMounted(() => {\n    window.removeEventListener('resize', onResize);\n  });\n  \n  return {height, width};\n}\n```\n\n```vue\n<!-- App.vue -->\n<template>\n\t<p>The window is {{height}}px high and {{width}}px wide</p>\n</template>\n\n<script setup>\nimport {useWindowSize} from './useWindowSize';\n  \nconst {height, width} = useWindowSize();\n</script>\n```\n\n<!-- tabs:end -->\n\nThis enables us to use the `useWindowSize` logic in more than one component - lifecycle methods and all.\n\nBut what about Angular? How can you reuse code logic, including lifecycle methods, without having to copy and paste code?\n\nAnswer: A base component class that you extend.\n\nIn this article we'll learn:\n\n- [What a base component class is](#base-class)\n- [How to use a base class in Angular](#base-class-angular)\n- [How to simplify Angular base class usage using an abstract class](#abstract-class)\n- [Overwriting lifecycle methods in Angular extended classes](#lifecycle-methods)\n- [Using dependency injection with your extended class](#dependency-injection)\n- [Why you don't want to use base classes with Angular](#dont-extend-base-classes)\n\n# What is an extension class, anyway? {#base-class}\n\nLet's work off of the assumption that you're familiar with what a class is, but may not be familiar with what class extension or inheretence is.\n\nVery quickly, let's assume that we have this JavaScript class:\n\n```javascript\nclass HelloMessage {\n\tmessage = \"Hello\";\n \tname = \"\";\n  \n  constructor(name) {\n    this.name = name;\n  }\n  \n  sayHi() {\n    console.log(`${this.message} ${this.name}`);\n  }\n}\n\nconst messageInstance = new HelloMessage(\"Corbin\");\nmessageInstance.sayHi(); // Will log \"Hello Corbin\"\n```\n\nThis class has a few things going on:\n\n- Two properties: `message` and `name`\n- A constructor, with a parameter to set `name` to a new value\n- A method of `sayHi`\n\nWhen we create an \"instance\" of this class, it will in turn call the `constructor` and give us an object with all of the properties and methods associated with `HelloMessage` as an \"instance\" of that class.\n\n\n\nNow, let's say that we want to reuse the `sayHi` logic in multiple classes at a time.\n\n> Sounds like a familiar problem, doesn't it?\n\nWe can create a class that provides the `sayHi` method:\n\n```javascript\nclass BaseHelloMessage {\n\tmessage = \"Hey there!\";\n \tname = \"\";\n  \n  constructor(name) {\n    this.name = name;\n  }\n  \n  sayHi() {\n    console.log(`${this.message} ${this.name}`);\n  }\n}\n```\n\nNow, we can create multiple classes that have the same properties and methods as `BaseHelloMessage` by using `extends`:\n\n```javascript\nclass HelloMessage extends BaseHelloMessage {\n}\n\nconst helloMsgInstance = new HelloMessage(\"Corbin\");\n// Inhereted from \"BaseHelloMessage\"\nhelloMsgInstance.sayHi();\n\nclass OtherHelloMessage extends BaseHelloMessage {\n}\n\nconst otherHelloMsgInstance = new OtherHelloMessage(\"Corbin\");\n// Also inhereted from \"BaseHelloMessage\"\nconsole.log(otherHelloMsgInstance.name);\n```\n\nBut oh no! `message` is set to `\"Hey there!\"`, which isn't what we want for `OtherHelloMessage`. Instead, let's _overwrite_ the `message` property to be `\"Hi-a!\"`\n\nWe can easily do this by using an \"Override\":\n\n```javascript\n// `sayHi` will output \"Hey there! Corbin\"\nclass HelloMessage extends BaseHelloMessage {\n}\n\n// `sayHi` will output \"Hi-a! Corbin\"\nclass OtherHelloMessage extends BaseHelloMessage {\n  message = \"Hi-a!\";\n}\n```\n\nThis works in JavaScript, but TypeScript will give you a small warning:\n\n> TS4114: This member must have an 'override' modifier because it overrides a member in the base class 'BaseComponent'.\n\nTo solve this, we can simply change `OtherHelloMessage` to be:\n\n```typescript\n// `sayHi` will output \"Hi-a! Corbin\"\nclass OtherHelloMessage extends BaseHelloMessage {\n  override message = \"Hi-a!\";\n}\n```\n\nOkay, now that we understand class extensions, let's see how we can use them in Angular!\n\n# How to use basic class extension usage in Angular {#base-class-angular}\n\nLet's assume that we're writing the following class in Angular, in order to get the window size and display it to the user:\n\n```typescript\n@Component({\n  template: `\n    <p>The window is {{height}}px high and {{width}}px wide</p>\n  `,\n  selector: 'app-root'\n})\nclass AppComponent implements OnInit, OnDestroy {\n  height = window.innerHeight;\n  width = window.innerWidth;\n\n  // This needs to be an arrow function\n  onResize = () => {\n    this.height = window.innerHeight;\n    this.width = window.innerWidth;\n  }\n\n  ngOnInit() {\n    window.addEventListener('resize', this.onResize);\n  }\n\n  ngOnDestroy() {\n    window.removeEventListener('resize', this.onResize);\n  }\n}\n```\n\nBut still wanted to share this `window` size logic between multiple components.\n\nLuckily, we can do this using a traditional Object-Oriented Programming (OOP) method: Create a base class that we extend later.\n\nLet's try this really quick and create a `BaseComponent` class:\n\n```typescript\nclass BaseComponent implements OnInit, OnDestroy {\n  height = window.innerHeight;\n  width = window.innerWidth;\n\n  // This needs to be an arrow function\n  onResize = () => {\n    this.height = window.innerHeight;\n    this.width = window.innerWidth;\n  }\n\n  ngOnInit() {\n    window.addEventListener('resize', this.onResize);\n  }\n\n  ngOnDestroy() {\n    window.removeEventListener('resize', this.onResize);\n  }\n}\n\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>The window is {{height}}px high and {{width}}px wide</p>\n  `,\n})\nclass AppComponent extends BaseComponent {\n}\n```\n\nThis might look correct, but yields us a compiler error:\n\n```\nError: src/app/app.module.ts:5:7 - error NG2007: Class is using Angular features but is not decorated. Please add an explicit Angular decorator.\n```\n\nTo fix this, we simply need to follow the instructions of the TypeScript compiler warning. Because `BaseComponent` could be almost considered to be a component, let's create it as an instance of such:\n\n```typescript\n@Component({\n  template: '',\n  selector: 'base-component'\n})\nclass BaseComponent implements OnInit, OnDestroy {\n  height = window.innerHeight;\n  width = window.innerWidth;\n\n  // This needs to be an arrow function, otherwise `this` will bind to the Window\n  // For more, see: https://twitter.com/crutchcorn/status/1530104879271645184\n  onResize = () => {\n    this.height = window.innerHeight;\n    this.width = window.innerWidth;\n  }\n\n  ngOnInit() {\n    window.addEventListener('resize', this.onResize);\n  }\n\n  ngOnDestroy() {\n    window.removeEventListener('resize', this.onResize);\n  }\n}\n\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>The window is {{height}}px high and {{width}}px wide</p>\n  `,\n})\nclass AppComponent extends BaseComponent {\n}\n```\n\nThis solves the error and now `AppComponent` tracks resizing as-expected!\n\nYou'll notice, however, that while `BaseComponent` does have the `implements` keyword, the `AppComponent` does not. While it's seemingly not a _requirement_ to have the `implements` keyword on `AppComponent` in modern versions of Angular, I'd personally still highly suggested.\n\n```typescript\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>The window is {{height}}px high and {{width}}px wide</p>\n  `,\n})\nclass AppComponent extends BaseComponent implements OnInit, OnDestroy {\n}\n```\n\nThis is because it's easier to glance at the `AppComponent` code and see what lifecycle methods are used in the extended class or not.\n\n# Simplify Base Component Usage by using an abstract class {#abstract-class}\n\nWhile our `BaseComponent` is extendible now, there's a new frustration that's arose as a result of using the `@Component`: We just registered a new component that can be accidentally used in another component's template.\n\nFor example, if we had a template that looked like:\n\n```html\n<base-component></base-component>\n```\n\nWe wouldn't get a compiler error, but would have a loose bit of code running needlessly. Ideally we'd like to have `BaseComponent` still able to use lifecycle methods without registering a new template tag.\n\nFortunately, that's possible, as of Angular 9; simply remove `BaseComponent`'s `@Component` `selector` property and it won't register a new tag.\n\n```typescript\n@Component({\n  template: ''\n})\nclass BaseComponent implements OnInit, OnDestroy {\n  // ...\n}\n```\n\nThat solves one problem, but still leaves one present with using `@Component`: you must add a declaration of the `BaseComponent` into an `NgModule`. Otherwise, you'll end up with the following error during compilation:\n\n```\nBaseComponent is not declared in any Angular module \n```\n\nTo solve this, we can either import `BaseComponent` in an `NgModule` or, alternatively, mark `BaseComponent` as an abstract class:\n\n```typescript\n@Component({\n  template: ''\n})\nabstract class BaseComponent implements OnInit, OnDestroy {\n  // ...\n}\n```\n\n## `@Injectable` is an alternative of an abstract class {#injectable}\n\n[Since Angular 10 you can now use `@Injectable` to declare your `BaseComponent` instead](https://angular.io/guide/migration-injectable). This sidesteps the problem of having to mark a component `class` as abstract because even without it `Injectable`s do not need to be declared in a module:\n\n```typescript\n@Injectable()\nclass BaseComponent implements OnInit, OnDestroy {\n  // ...\n}\n```\n\nYou might expect there to be some migration of `AppComponent` when you're using `@Injectable` instead of `@Component` for the `BaseComponent`, but alas there is not.\n\n```typescript\n@Injectable()\nclass BaseComponent implements OnInit {\n  ngOnInit() {\n    console.log('I AM BASE COMPONENT');\n  }\n}\n\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>Test</p>\n  `,\n})\nclass AppComponent extends BaseComponent {\n}\n```\n\nThat said, [while using `@Injectable` is explicitly supported](https://github.com/angular/angular/issues/41229#issuecomment-800310757), it's very hacky to use this in place of `@Component`. This is because Angular's `@Injectable`s do not support lifecycle methods without a `Component` that extends it.\n\nAs such, we'll be sticking to the `abstract` class solution.\n\n# Overwriting Lifecycle Methods {#lifecycle-methods}\n\nIf you recall from our quick overview of what a base class does, you can replace the base class implementation of both methods and properties.\n\nThe same is true for lifecycle methods, since they're just a type of method on the component class instance.\n\n```typescript\n@Component({\n  template: ''\n})\nabstract class BaseComponent implements OnInit {\n  ngOnInit() {\n    console.log('I AM BASE COMPONENT');\n  }\n}\n\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>Test</p>\n  `,\n})\nclass AppComponent extends BaseComponent implements OnInit {\n  override ngOnInit() {\n    console.log(\"And I am the AppComponent\")\n  }\n}\n```\n\nThe downside here, however, is that `ngOnInit` on `AppComponent` will no longer call the `BaseComponent`'s `ngOnInit` logic. After all, what if you wanted to simply _add_ behavior to `ngOnInit`, rather than replace it entirely?\n\nLuckily, we can use the `super` keyword to refer to the base class instance and call the original method inside of the overwritten method:\n\n```typescript\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>Test</p>\n  `,\n})\nclass AppComponent extends BaseComponent implements OnInit {\n  override ngOnInit() {\n    // This will log `I AM BASE COMPONENT`\n  \tsuper.ngOnInit();\n    console.log(\"And I am the AppComponent\")\n  }\n}\n```\n\n# Use Dependency Injection with your extended class {#dependency-injection}\n\nWhile you're able to use global `window` variable in a browser environment, if you're attempting to use `window` in a [server-side rendered](/posts/what-is-ssr-and-ssg) Angular application, it will throw an error.\n\n```\nwindow is not defined\n```\n\nTo solve this problem you can use Angular's dependency injection to inject an instance of `document` to `BaseComponent`, and get access to the `window` through `defaultView` that way:\n\n```javascript\n@Component({\n  template: ''\n})\nabstract class BaseComponent implements OnInit, OnDestroy {\n  window!: Window;\n  constructor(@Inject(DOCUMENT) private document: Document) {\n    this.window = document.defaultView!;\n  }\n}\n```\n\nBecause of this, this is the recommended way to get access to the `document` and `window` instance inside of an Angular component, even if it's a non-SSR app.\n\nLuckily, this works out-of-the-box with extended Angular component classes:\n\n```typescript\nimport {Component, Inject, Injectable, OnDestroy, OnInit} from '@angular/core';\nimport {DOCUMENT} from \"@angular/common\";\n\n@Component({\n  template: ''\n})\nabstract class BaseComponent implements OnInit, OnDestroy {\n  window!: Window;\n  constructor(@Inject(DOCUMENT) private document: Document) {\n    this.window = document.defaultView!;\n  }\n\n  height = this.window.innerHeight;\n  width = this.window.innerWidth;\n\n  // This needs to be an arrow function\n  onResize = () => {\n    this.height = this.window.innerHeight;\n    this.width = this.window.innerWidth;\n  }\n\n  ngOnInit() {\n    this.window.addEventListener('resize', this.onResize);\n  }\n\n  ngOnDestroy() {\n    this.window.removeEventListener('resize', this.onResize);\n  }\n}\n\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>The window is {{height}}px high and {{width}}px wide</p>\n  `,\n})\nclass AppComponent extends BaseComponent implements OnInit, OnDestroy {\n}\n```\n\n\n\n## Overwriting `constructor` behavior {#overwriting-constructors}\n\nWhen working with class extension, regardless of being used in Angular or in JavaScript itself, you need to call `super()` when trying to overwrite a constructor:\n\n```javascript\nclass BaseClass {\n  name = \"\";\n  constructor() {\n    name = \"Frank\";\n  }\n}\n\nclass AppClass extends BaseClass {\n\tconstructor() {\n\t\t// This is required\n    super();\n\t}\n}\n```\n\nWithout calling `super`, you'll get the following error:\n\n```\nUncaught ReferenceError: must call super constructor before using 'this' in derived class constructor\n```\n\nLikewise, you need to call `super` when overwriting a class component's `constructor` as well.\n\n```typescript\n@Component({\n  template: ''\n})\nabstract class BaseComponent {\n  name = \"\";\n  constructor() {\n    this.name = \"Kevin\";\n  }\n}\n\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>{{name}}</p>\n  `,\n})\nclass AppComponent extends BaseComponent {\n  constructor() {\n    super();\n    this.name = \"Corbin\";\n  }\n}\n```\n\nThis water gets muddied when using dependency injection in a base component that utilizes dependency injection.\n\n```typescript\n@Component({\n  template: ''\n})\nabstract class BaseComponent {\n  window!: Window;\n  constructor(@Inject(DOCUMENT) private document: Document) {\n    this.window = document.defaultView!;\n  }\n\n  // ...\n}\n\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>Test</p>\n  `,\n})\nclass AppComponent extends BaseComponent {\n  // This code doesn't work. Read on to learn why\n  constructor() {\n    super();\n  }\n}\n```\n\nAs the `super` method needs to be passed with the same arguments from dependenct injection, least we see the following error:\n\n```\nTS2554: Expected 1 arguments, but got 0.\n  app.component.ts(8, 15): An argument for 'document' was not provided.\n```\n\nTo solve this, we need to pass `document` from a new instance of `AppComponent`'s dependency injection to `BaseComponent`:\n\n```typescript\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>Test</p>\n  `,\n})\nclass AppComponent extends BaseComponent implements OnInit {\n  // This code doesn't work. Read on to learn why\n  constructor(@Inject(DOCUMENT) private document: Document) {\n    super(document);\n    console.log(document.body);\n  }\n}\n```\n\nBut alas, this does not work!\n\nSimilar to how we had to add `override` to our `AppComponent`'s lifecycle methods, we need to do the same with our constructor. Otherwise, we'll get this error:\n\n```\nTS4115: This parameter property must have an 'override' modifier because it overrides a member in base class 'BaseComponent'.\n```\n\nLet's update the code to show what that might look like:\n\n```typescript\n@Component({\n  template: ''\n})\nabstract class BaseComponent implements OnInit {\n  constructor(@Inject(DOCUMENT) private document: Document) {}\n  ngOnInit() {\n    console.log(document.title);\n  }\n}\n\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>Test</p>\n  `,\n})\nclass AppComponent extends BaseComponent implements OnInit {\n  constructor(@Inject(DOCUMENT) private override document: Document) {\n    super(document);\n    console.log(document.body);\n  }\n}\n```\n\nSomething worth mentioning is that this code _still_ doesn't work. You'll see a compiler error with the following code:\n\n```\nTS2415: Class 'AppComponent' incorrectly extends base class 'BaseComponent'.\n   Types have separate declarations of a private property 'document'.\n```\n\nTo solve this, we simply need to make our `BaseComponent`'s `constructor` properties `public` instead of `private`:\n\n```typescript\n@Component({\n  template: ''\n})\nabstract class BaseComponent implements OnInit {\n  constructor(@Inject(DOCUMENT) public document: Document) {}\n  ngOnInit() {\n    console.log(document.title);\n  }\n}\n\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>Test</p>\n  `,\n})\nclass AppComponent extends BaseComponent implements OnInit {\n  constructor(@Inject(DOCUMENT) public override document: Document) {\n    super(document);\n    console.log(document.body);\n  }\n}\n```\n\n> Remember to keep your `override` property in the `AppComponent` `constructor`, otherwise you'll have errors.\n\nAlternatively, we can stop using parmeter properties in `BaseComponent` and just not mark the field as `public` _or_ `private`, like so:\n\n```typescript\n@Component({\n  template: ''\n})\nabstract class BaseComponent implements OnInit {\n  private document: Document;\n\n  constructor(@Inject(DOCUMENT) document: Document) {\n    this.document = document;\n  }\n\n  ngOnInit() {\n    console.log(document.title);\n  }\n}\n\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>Test</p>\n  `,\n})\nclass AppComponent extends BaseComponent implements OnInit {\n  constructor(@Inject(DOCUMENT) document: Document) {\n    super(document);\n    console.log(document.body);\n  }\n}\n```\n\n## You don't need to use `constructor` to use Dependency Injection {#inject-function}\n\nWhile our previous code works, it comes with the caveat that you have to still refactor your extended classes in the instance that you want to add a new injection into your base class.\n\nLuckily, Angular 14 introduces the ability to use the `inject` function which removes the need to use `constructor` to use dependency injection. The API is relatively straightforward, replace `constructor` usage of Dependency Injection with the `inject` function as a property initializer:\n\n```tsx\nimport { inject } from '@angular/core';\n\n@Component({\n  template: ''\n})\nabstract class BaseComponent {\n  // The `Document` type annotation is optional as it can be inferred by the `inject` function\n  private document: Document = inject(DOCUMENT);\n  \n  window!: Window = this.document.defaultView;\n\n  // No constructor needed as we use property injection instead of constructor injection\n  \n  // ...\n}\n```\n\nBecause of this, our `AppComponent` class can be much simpler:\n\n```tsx\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>Test</p>\n  `,\n})\nclass AppComponent extends BaseComponent {\n  // This code now works as the base class doesn't have constructor parameters anymore\n  constructor() {\n    super();\n  }\n}\n```\n\n\n\n# Why you don't want to extend Angular base classes {#dont-extend-base-classes}\n\nNow that we've learned how to extend base classes in Angular to share lifecycle methods, allow me to flip the script:\n\n**You shouldn't use a base class in Angular**.\n\n<video title=\"A shocked sock puppet monkey\" src=\"./shocked-monkey-gif.mp4\"></video>\n\nWhy?\n\nWell, it's often cited by Angular experts that using a base class is brittle and difficult to maintain.\n\nFor example, let's say that you have a base component that doesn't use dependency injection, but then suddenly need to add dependency injection. What do you do?\n\nWell, you'd have to refactor every instance that you extended that class.\n\nSimilarly, if you add a lifecycle method that you want to overwrite in the future, there can be someheadaches depending in which order you do things in.\n\nWhile [the `inject` function](#inject-function) solves some of these problems, it implicitly introduces a new dependency, which might:\n\n- Result in run-time errors thanks to missing providers\n- Break or make testing more difficult for the same reason\n\nPlus, there are more than a few ways to write this code in a different, more stable, way.\n\n## Fixing things the right way {#the-fix}\n\nThere are better ways to write the `WindowSize` code differently today that solve the problems of maintainability a bit better.\n\nLet's take a look at two different methods for fixing the problem:\n\n- A naïve implementation that replaces lifecycle methods for manual function calls\n- A more \"Angular\" way of fixing the issue, using RxJS\n\n## The naïve way to fix the issue\n\nA simple way of fixing some of the maintainability problems of using lifecyle methods , using an `@Injectable` class that's provided on a per-class level enables you to have the `constructor` method setup side effects and the `Injectable`'s `ngOnDestroy` lifecycle method take it down:\n\n> Remember, `Injectable`s don't have `ngOnInit`!\n\n```typescript\n@Injectable()\nclass WindowSizeService implements OnDestroy {\n  private window!: Window;\n  height = 0;\n  width = 0;\n\n  constructor(@Inject(DOCUMENT) document: Document) {\n    this.window = document.defaultView!;\n    this.height = this.window.innerHeight\n    this.width = this.window.innerWidth\n    window.addEventListener('resize', this.onResize);\n  }\n\n  onResize = () => {\n    this.height = window.innerHeight;\n    this.width = window.innerWidth;\n  }\n\n  ngOnDestroy() {\n    window.removeEventListener('resize', this.onResize);\n  }\n}\n\n@Component({\n  selector: 'app-root',\n  template: `\n    <p>The window is {{windowSize.height}}px high and {{windowSize.width}}px wide</p>\n  `,\n  providers: [WindowSizeService]\n})\nclass AppComponent {\n  constructor(public windowSize: WindowSizeService) {\n  }\n}\n```\n\nThis code functions, but introduces other issues when it comes to maintainability. After all, if you want to pass something into `addListeners` or `removeListeners`, you introduce the same refactoring issue you had previously.\n\nFurther, `height` and `width` are simply mutated which, while will still trigger change detection, makes it difficult to impossile to track when they've changed. Ideally, we should have a way to know when `height` and `width` are changed.\n\nIf only Angular had a way to track a series of changes in some kind of... Observable...\n\nOh!\n\n## The Angular way to fix the code\n\nWhile mutable properties can get the job done, they're far from optimal. Let's instead leverage `rxjs`, which is built into Angular after all, to create an observable.\n\nFor this type of DOM event listening, RxJS exposes a [`fromEvent`](https://rxjs.dev/api/index/function/fromEvent) method that we can pipe into a [`map`](https://rxjs.dev/api/operators/map) to create an [Observable](https://rxjs.dev/guide/observable).\n\n```typescript\nimport {fromEvent, debounceTime, map, Subject, takeUntil, Observable} from 'rxjs';\n\ninterface WindowSize {\n  readonly height: number;\n  readonly width: number;\n}\n\n@Injectable()\nclass WindowSizeService implements OnDestroy {\n  private destroy$ = new Subject<void>();\n\n  size$: Observable<WindowSize>;\n\n  constructor(@Inject(DOCUMENT) document: Document) {\n    const window = document.defaultView!;\n    this.size$ = fromEvent(window, 'resize').pipe(\n      debounceTime(50),\n      map(() => ({\n        height: window.innerHeight,\n        width: window.innerWidth,\n      })),\n      startWith({\n        height: window.innerHeight,\n        width: window.innerWidth,\n      }),\n      takeUntil(this.destroy$)\n    );\n  }\n\n  ngOnDestroy() {\n    this.destroy$.next();\n    this.destroy$.complete();\n  }\n}\n```\n\nThis is a much more straightforward setup process that's much more Angular-ific!\n\nAs an added benifit, we now can utilize an [`AsyncPipe`](https://angular.io/api/common/AsyncPipe) in order to listen for changes on the `size$` observable:\n\n```typescript\n@Component({\n  selector: 'app-root',\n  template: `\n    <p *ngIf=\"windowSize.size$ | async as size\">The window is {{size.height}}px high and {{size.width}}px wide</p>\n  `,\n  providers: [WindowSizeService]\n})\nclass AppComponent {\n  windowSize = inject(WindowSizeService);\n}\n```\n\n\n\n# Conclusion\n\nAnd that's it! I hope this has been an insightful look into how you can extend component logic.\n\nAnd this isn't an area of stagnation within Angular - they're introducing new functionality to share component logic using [the upcoming `hostDirectives` API](https://github.com/angular/angular/pull/46868).\n\nHey, while you're here - do you want to learn more Angular in-depth like this? Maybe you've been working in Angular for some time and want to learn React or Vue, but not start from scratch?\n\nCheck out [my free book, \"The Framework Field Guide\", that teaches React, Angular, and Vue all at the same time.](https://framework.guide).\n",
		},
		{
			title: "Package Font Files on NPM for Angular Usage",
			description:
				"Do you use custom fonts that you want to share with multiple apps? Learn how to distribute those fonts on NPM and consume them in Angular!",
			published: "2020-11-24T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["angular", "javascript", "npm"],
			attached: [],
			license: {
				id: "cc-by-4",
				footerImg: "https://i.creativecommons.org/l/by/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by/4.0/",
				name: "Attribution 4.0 International (CC BY 4.0)",
				displayName: "Creative Commons Attribution 4.0 International License",
			},
			slug: "angular-npm-font-usage",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Package Font Files on NPM for Angular Usage",
				description:
					"Do you use custom fonts that you want to share with multiple apps? Learn how to distribute those fonts on NPM and consume them in Angular!",
				published: "2020-11-24T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["angular", "javascript", "npm"],
				attached: [],
				license: "cc-by-4",
			},
			contentMeta:
				'\nWhile working on my company\'s shared component system, I got a request from our design team. They wanted to keep our branding consistent with internal documents and other assets. As such, they requested we use a font called "Stirling Foundry".\n\nWhile we\'re prepping our shared component system for an open-source release to the public, we quickly acknowledged that we couldn\'t possibly ship this font with the package we intend for public publishing [due to it\'s licensing and cost](https://www.fonts.com/font/the-foundry/foundry-sterling).\n\nHowever, we have multiple teams that rely on our shared component system, and we don\'t want to have to copy+paste the relevant `@font-face` definition or font files. What was our solution? Ship a second `npm` package (in our internal `npm` registry) that contained all of our private assets - including font files.\n\nLet\'s walk through how we did that.\n\n# Setup Assets Package {#assets-package}\n\nAs we\'re wanting to ship our packages separately, we opted for two Git repositories for the component system and private assets. In a new repository, I have the following for the `package.json`:\n\n```json\n{\n  "name": "ecp-private-assets",\n  "version": "1.0.0",\n  "main": "index.js",\n  "scripts": {\n    "release": "standard-version"\n  },\n  "devDependencies": {\n    "@commitlint/cli": "^11.0.0",\n    "@commitlint/config-angular": "^11.0.0",\n    "husky": "^4.3.0",\n    "standard-version": "^9.0.0"\n  },\n  "husky": {\n    "hooks": {\n      "commit-msg": "commitlint -E HUSKY_GIT_PARAMS"\n    }\n  },\n  "commitlint": {\n    "extends": [\n      "@commitlint/config-angular"\n    ]\n  }\n}\n```\n\nWhile this package will not maintain code, I still believe it important to maintain a semver for the package. If a path of the package changes, the semver will communicate that with your package\'s consumers alongside the changeling. As such, this `package.json` utilizes [Conventional Commit and `commitlint` to auto-generate changelogs and maintain history version](/posts/setup-standard-version/).\n\n## Add Font Files {#font-files}\n\nThe "Foundry Stirling" font that I\'m shipping is a combination of 7 `.otf` files. I start by creating a `fonts` directory. Inside that directory, I place the `.otf` files in the `fonts` directory.\n\nOnce done, your project repo should look something like this:\n\n```\n.\n├── CHANGELOG.md\n├── README.md\n├── fonts\n│   ├── foundry_sterling_bold.otf\n│   ├── foundry_sterling_book.otf\n│   ├── foundry_sterling_book_italic.otf\n│   ├── foundry_sterling_demi.otf\n│   ├── foundry_sterling_extra_bold.otf\n│   ├── foundry_sterling_light.otf\n│   └── foundry_sterling_medium.otf\n├── index.js\n├── package-lock.json\n└── package.json\n```\n\n## `@font-face` CSS Definition {#css-declare}\n\nNow that we have the fonts in their place, we need to create a common `foundry_stirling.css` file to access those fonts from CSS.\n\nBecause we\'re planning on using Angular CLI, we\'ll want to set the `src` property to be prefixed with `/assets/`, since that\'s where Angular sends it\'s assets.\n\n```css\n/* foundry_stirling.css */\n\n@font-face {\n    font-family: \'Foundry Sterling\';\n    font-style: normal;\n    /* Light */\n    font-weight: 300;\n    src: local(\'Foundry Sterling Light\'), local(\'FoundrySterling-light\'), url("/assets/foundry_sterling_light.otf") format(\'opentype\')\n}\n\n/* ... */\n\n@font-face {\n    font-family: \'Foundry Sterling\';\n    font-style: normal;\n    /* Extra-Bold */\n    font-weight: 800;\n    src: local(\'Foundry Sterling Extra Bold\'), local(\'FoundrySterling-extra-bold\'), url("/assets/foundry_sterling_extra_bold.otf") format(\'opentype\')\n}\n```\n\n> While we\'re using CSS here, if you wanted to set the `src` to a different location for non-Angular projects, you could use a SCSS `@mixin` to define the `@font-face` declarations with a customizable `$base_path`.\n>\n> ```scss\n> @mixin foundry_sterling($base_path) {\n> @font-face {\n>  font-family: \'Foundry Sterling\';\n>  font-style: normal;\n>  /* Extra-Bold */\n>  font-weight: 800;\n>  src: url("#{$base_path}/foundry_sterling_extra_bold.otf") format(\'opentype\')\n> }\n> \n> // ... Other @font-face declarations\n> }\n> ```\n>\n> Then, when consuming the package in your client-side app, you\'ll want to use something like this:\n>\n> ```scss\n> @include foundry_sterling("/assets")\n> ```\n\n### Font Name Value Mapping {#font-val-mapping}\n\nBecause our font had multiple files to declare the different CSS values weights, we had to declare the `@font-face` for each of the font files. This is the mapping we used:\n\n| Value | Common weight name        | Related File                      |\n| ----- | ------------------------- | --------------------------------- |\n| 100   | Thin / Hairline           | N/A                               |\n| 200   | Extra-Light / Ultra-Light | N/A                               |\n| 300   | Light                     | `foundry_sterling_light.otf`      |\n| 400   | Normal / Regular          | `foundry_sterling_book.otf`       |\n| 500   | Medium                    | `foundry_sterling_medium.otf`     |\n| 600   | Semi-Bold / Demi-Bold     | `foundry_sterling_demi.otf`       |\n| 700   | Bold                      | `foundry_sterling_bold.otf`       |\n| 800   | Extra-Bold / Ultra-Bold   | `foundry_sterling_extra_bold.otf` |\n| 900   | Black / Heavy             | N/A                               |\n\n# Consume Assets Package in Angular CLI {#angular-cli}\n\nNow that we have our `npm` package configured for usage, we\'ll start preparing for consuming that package by installing it into our app\'s `package.json`:\n\n```\nnpm i ecp-private-assets\n```\n\n> Remember, `ecp-private-assets` is the name of our internal package. You\'ll need to replace this `npm i` command with your own package name\n\n## `angular.json` modification {#angular-json}\n\nOnce this is done, two steps are required. First, add the following to `angular.json`\'s `assets` property. This will copy the files from `ecp-private-assets` to `/assets` once you setup a build. \n\n```json\n{\n  "glob": "**/*",\n  "input": "./node_modules/ecp-private-assets/fonts",\n  "output": "./assets/"\n}\n```\n\nThis way, when we use the CSS `url(\'/assets/\')`, it will point to our newly appointed `fonts` files. Once this is added, your `angular.json` should look like this:\n\n```json\n{\n  "architect": {\n    "build": {\n      "builder": "@angular-builders/custom-webpack:browser",\n      "options": {\n        "customWebpackConfig": {\n          "path": "./webpack.config.js"\n        },\n        "outputPath": "www",\n        "index": "src/index.html",\n        "main": "src/main.ts",\n        "polyfills": "src/polyfills.ts",\n        "tsConfig": "tsconfig.app.json",\n        "aot": true,\n        "assets": [\n          "src/assets",\n          {\n            "glob": "**/*",\n            "input": "./node_modules/ecp-private-assets/fonts",\n            "output": "./assets/"\n          }\n        ],\n        "styles": [\n          "src/main.scss"\n        ],\n        "scripts": []\n      }\n    }\n  }\n}\n```\n\n## Import CSS {#css-import}\n\nNow that we have our assets in place, we need to import the CSS file into our app.\n\n\nIf your app utilizes `postcss`\'s `import` plugin or if you\'re using vanilla CSS, add the following line to your `main.scss` file:\n\n```css\n@import "ecp-private-assets/fonts/foundry_sterling.css";\n```\n\n> Remember to keep the `@import`s at the top of your file, as you will receive an error otherwise. \n\nHowever, if you\'re not using `postcss` and have SCSS installed, you can use the following:\n\n```scss\n@import \'~ecp-private-assets/fonts/foundry_sterling.css\';\n```\n\n# Conclusion\n\nOnce you\'ve added the file to your CSS imports and `angular.json`, you should see your font loading as-expected. Because you\'ve setup your fonts to use `npm` to distribute them, you can now reuse your fonts across multiple apps.\n\nIf you\'d like to learn more or have questions about this setup, feel free to leave a comment down below or join [our Discord](https://discord.gg/FMcvc6T) and ask questions there!\n',
		},
		{
			title:
				"Angular Route Guards For Authorization In A Web And Mobile Application",
			description:
				"Learn how to use Angular route guards for authenticating & authorizing access to certain child and parent routes.",
			published: "2018-07-13T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["angular"],
			attached: [],
			license: {
				id: "cc-by-4",
				footerImg: "https://i.creativecommons.org/l/by/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by/4.0/",
				name: "Attribution 4.0 International (CC BY 4.0)",
				displayName: "Creative Commons Attribution 4.0 International License",
			},
			originalLink:
				"https://www.thepolyglotdeveloper.com/2018/07/angular-route-guards-authorization-web-mobile-application/",
			slug: "angular-route-guards-authorization-web-mobile-application",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title:
					"Angular Route Guards For Authorization In A Web And Mobile Application",
				description:
					"Learn how to use Angular route guards for authenticating & authorizing access to certain child and parent routes.",
				published: "2018-07-13T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["angular"],
				attached: [],
				license: "cc-by-4",
				originalLink:
					"https://www.thepolyglotdeveloper.com/2018/07/angular-route-guards-authorization-web-mobile-application/",
			},
			contentMeta:
				"\nYou’re about to release your new Angular web app. It’s a photo  sharing site and you want to test it, so you send a link to it to your  hacker sister. She’s always messing with your stuff and she found out  the URL to your admin page you added to your web app. Before you know  it, she’s flushed your database using a button on that admin page that  you didn’t restrict access to. Not a problem when using development data - but I’m sure your users wouldn’t be any too keen on a service where  they lost all of their data. Let’s fix that\n\n## Component Checks\n\nThe most basic way to restrict a user’s access to any given page is to use  logic that will run at the load time of the component and redirect the  user if needed. Given [Angular’s lifecycle hooks](https://angular.io/guide/lifecycle-hooks), we can use `ngOnInit` in order to do so.\n\n```javascript\nimport {Component, OnInit} from '@angular/core';\nimport {Router} from '@angular/router';\nimport {MyAuthService} from '../../core/auth/auth.service';\n\n@Component({\n    selector: 'super-secret-component',\n    templateUrl: '<comp-here></comp-here>',\n    styles: []\n})\nexport class SecretComponent implements OnInit {\n\n    constructor(private myAuthService: MyAuthService, private router: Router) { }\n\n    ngOnInit() {\n        this.myAuthService.checkAuth().subscribe(isAllowed => {\n            if (!isAllowed) {\n                this.router.navigate(['/']);\n            }\n        })\n    }\n\n}\n```\n\nThis code sample is pretty straightforward - on  loading the component, let’s go ahead and check that the user is allowed to see the page, if not - let’s move them to somewhere they are allowed to see. You could even add a snackbar to let them know that they’re  trying to access something they shouldn’t, maybe move them to a login  page? It’s fairly customizable.\n\nThis works perfectly fine if  there’s a single route you’d like to restrict users from being able to  see, but perhaps you’d like to lockdown an entire module’s routes (or  just a route with child routes) or there are many different routes you’d like to protect in a similar way. Of course, you could always copy and  paste the code we’ve made before, but Angular actually provides a much  easier, cleaner way of doing so.\n\n## Introducing: Route Guards\n\nIn essence, a route guard is simply a check to tell if you’re allowed to view a page or not. It can be added to any route using `canActivate` (a fairly verbose property, I’d say) with a custom interface that follows [Angular’s CanActivate API](https://angular.io/api/router/CanActivate). The most simplistic example of a router guard is as follows:\n\n```javascript\n// route.guard.ts\nimport {Injectable} from '@angular/core';\nimport {CanActivate, ActivatedRouteSnapshot, RouterStateSnapshot} from '@angular/router';\nimport {Observable} from 'rxjs';\n\n@Injectable()\nexport class RouteGuard implements CanActivate {\n\n    canActivate(next: ActivatedRouteSnapshot, state: RouterStateSnapshot): Observable<boolean> | Promise<boolean> | boolean {\n        return true;\n    }\n\n}\n// route-routes.module.ts\nimport {NgModule} from '@angular/core';\nimport {Routes, RouterModule} from '@angular/router';\nimport {RouteComponent} from './posts.component';\nimport {RouteGuard} from '../core/route.guard';\n\nconst routes: Routes = [\n    {\n        path: '',\n        pathMatch: 'full',\n        component: RouteComponent,\n        canActivate: [RouteGuard]\n    }\n];\n\nexport const routeRoutedComponents = [\n    RouteComponent\n];\n\n@NgModule({\n    imports: [RouterModule.forChild(routes)],\n    exports: [RouterModule]\n})\nexport class RouteRoutingModule { }\n```\n\nAs you can see from the typing of `canActivate`, Angular is fairly lenient with what you need to return in order to let a user to access the page or not - it accepts a `Promise` or `Observable` of a `boolean` or even just a `boolean` itself as a return value. This guard has limited value currently, because it always returns `true` regardless of any parameters or changes. However, if we replace the `canActivate` method with something a little more useful, we can easily add back the functionality our old `ngOnInit` had:\n\n```javascript\ncanActivate(next: ActivatedRouteSnapshot, state: RouterStateSnapshot): Observable<boolean> | Promise<boolean> | boolean {\n    return this.myAuthService.checkAuth();\n}\n```\n\nTada! We suddenly have the same logic as before! We can now remove the `ngOnInit` from the previously added route, and keep things just as secure as before! Because we can return an `Observable`, we can even use `Observable` `pipes` like so:\n\n```javascript\nreturn this.myAuthService.checkAuth().pipe(tap(allowed => {\n    if (allowed) {\n        this.snackBar.open(\"Welcome back!\");\n    }\n}));\n```\n\nOf course, it might not be the best bet to add  this logic in a guard, but it’s still representative of what you’re  capable of doing inside of a guard.\n\n## Children Guarding\n\nWhen I first learned about this, I thought it was the coolest thing in the  world. I started adding it to all of my routes. Next thing I knew, I was adding it to all my routes I wanted protected in some form or another.\n\n```javascript\n[\n    { path: '', pathMatch: 'full', component: RouteComponent, canActivate: [RouteGuard] },\n    { path: 'list', component: RouteComponent, canActivate: [RouteGuard] },\n    { path: 'detail/:id', component: RouteComponent, canActivate: [RouteGuard] }\n];\n```\n\nThis isn’t too bad alone - but when you have  hundreds of routes on a large scale project, this easily becomes  unmanageable. I also had times when I wanted to add additional security  to a route’s children, for example a dashboard page that included some  admin routes that I wanted to lock down. This is where child guards come into play.\n\nChild guards do exactly what you think they would. They add an additional guard for children. They use a similar API as `canActivate`, and the reference to that API can be found [here](https://angular.io/api/router/CanActivateChild). So, if I were to add the following guard to my child routes:\n\n```javascript\nimport {Injectable} from '@angular/core';\nimport {ActivatedRouteSnapshot, RouterStateSnapshot, CanActivateChild} from '@angular/router';\nimport {Observable} from 'rxjs';\n\n@Injectable()\nexport class ChildGuard implements CanActivateChild {\n    canActivateChild(childRoute: ActivatedRouteSnapshot, state: RouterStateSnapshot): Observable<boolean> | Promise<boolean> | boolean {\n        console.log('This child was activated!');\n        return true;\n    }\n}\n```\n\nIt would console log ‘This child was activated’ every time you accessed a child route. How do you apply this to your routes?\n\n```javascript\n[\n    { path: '', canActivateChild: [ChildGuard], children: [\n        { path: '', pathMatch: 'full', component: RouteComponent, canActivate: [RouteGuard] },\n        { path: 'list', component: RouteComponent, canActivate: [RouteGuard] },\n        { path: 'detail/:id', component: RouteComponent, canActivate: [RouteGuard] }      \n    ]}\n];\n```\n\nHowever, I’m sure you’re wondering what happens if you apply a `canActivate` alongside a `canActivateChild`. If you were to change the code so the `canActivate` runs a `console.log('This is the canActivate!')` and your routes were to look like this:\n\n```javascript\n[\n    { path: '', canActivate: [ActivateGuard], canActivateChild: [ChildGuard], children: [\n        { path: '', pathMatch: 'full', component: RouteComponent },\n        { path: 'list', component: RouteComponent },\n        { path: 'detail/:id', component: RouteComponent }\n    ]}\n];\n```\n\nAnd accessed the `list` route, your  console would output ‘This is the canActivate!’ and then ‘This child was activated!’. Of course, this has limited application when making an  empty route without a component to load (that’s not a child), but it’s  massively helpful when you have a component in the parent route such as  this:\n\n```javascript\n[\n    {\n        path: '',\n        canActivate: [AuthenticationGuard],\n        canActivateChild: [AuthorizationGuard],\n        children: [\n            { path: 'admin', component: AdminComponent },\n        ]\n    }\n];\n\n// NOT SHOWN: AuthenticationGuard and AuthorizationGuard. Just pretend they're code that checks what you think they would, based on the names (remember, authentication is if the user is who they say they are [AKA logged in]; authorization is making sure they have the right access [AKA if they're admin])\n```\n\nIn this example, when you access the `''` path, you’ll make sure the user is authenticated, but doesn’t care  about authorization. However, when you access a child of that path (in  this example, `'admin'`), it will check both authentication AND authorization.\n\n### Route Data\n\nBut let’s say that I wanted to be able to change my child route based on  information that I’ve stored about that particular route. For example, I typically layout my breadcrumbs by using a `data` property on my routes like such:\n\n```javascript\n[\n    {\n        path: '',\n        canActivateChild: [ChildGuard],\n        component: RouteComponent,\n        data: {\n            title: 'Main Page'\n        },\n        children: [\n            { path: 'list', component: RouteComponent, data: {title: 'List Page'} },\n            { path: 'detail/:id', component: RouteComponent, data: {title: 'Detail Page'} }\n        ]\n    }\n];\n```\n\nIf I wanted to be able to add a welcome message for each page that printed their `title` on every route you accessed, you could add that logic to a `ChildGuard` logic.\n\n```javascript\ncanActivateChild(childRoute: ActivatedRouteSnapshot, state: RouterStateSnapshot): boolean { // The return type has been simplified\n    console.log(childRoute.data.title);\n    return true;\n}\n```\n\nBecause the first argument to `canActivateChild` is an `ActivatedRouteSnapshot`, you can grab [any of the methods or properties from the API](https://angular.io/api/router/ActivatedRouteSnapshot) from the routes that are currently being called. However, something  you’ll probably want to keep in mind is that this will occur once for  every single child route being called.\n\n## Lazy Loading\n\nBecause lazy loading using `loadChildren` is still considered a child route, all of the same rules from [Children Guarding](https://www.thepolyglotdeveloper.com/2018/07/angular-route-guards-authorization-web-mobile-application/#ChildrenGuarding) still apply. However, there are more tricks that are available for lazy loaded routes that are not otherwise available.\n\n### Can Load\n\nThe [API for canLoad](https://angular.io/api/router/CanLoad) looks very similar to what we’ve seen before with `canActivate` and `canActivateChild`.\n\n```javascript\nimport {Injectable} from '@angular/core';\nimport {Route, CanLoad} from '@angular/router';\nimport {Observable} from 'rxjs';\n\n@Injectable()\nexport class LoadGuard implements CanLoad {\n\n    canLoad(route: Route): Observable<boolean> | Promise<boolean> | boolean {\n        return true;\n    }\n\n}\n```\n\nMuch like before, if we were to add it on a lazy loaded route:\n\n```javascript\n[\n    {\n        canLoad: [LoadGuard],\n        path: '',\n        loadChildren: './feature.module#FeatureModule'\n    }\n]\n```\n\nIt would prevent the route from loading if the return was `false`. However, the bigger difference between, say, `canActivateChild`, is how it interacts with the other methods shown here.\n\nLet’s say we have some routes shown like this:\n\n```javascript\n[\n    {\n        path: '',\n        canActivate: [AuthenticationGuard],\n        canActivateChild: [AuthorizationGuard],\n        children: [{\n            canLoad: [LoadGuard],\n            path: 'feature',\n            loadChildren: './feature.module#FeatureModule'\n        }, {\n            path: 'otherfeature',\n            component: RouteComponent\n        }]\n    }\n];\n```\n\nIn this example, if you access the `''` route, only the `AuthenticationGuard` would be called. Meanwhile, if you accessed the `'otherfeature'` route, you would load the `AuthenticationGuard`, THEN call the `AuthorizationGuard`. What order would you think the guards would load for the `'feature'` route? The answer might be a little more tricky than you expect.\n\nThe answer? `canLoad` runs first. Before `AuthenticationGuard` and before `AuthorizationGuard`. It also, unlike the other two, prevents the entire loading of the  route. The advantage here is that you can stop the loading of a  lazy-loaded route before doing any checks you’d want to run to prevent.  This would increase performance greatly in situations where you’d block  the loading of a page and it would be much more secure. After `canLoad` runs, then the other two run in order as they would before\n\n## Wrap Up\n\nJust like anything else, an Angular Router Guard is a tool. It has many uses that are really only restricted by how you’re able to utilize that  tool. You’re able to do service calls, logic changes, and more in order  to restrict access to a page. However, it’s not a one-tool-fits-all  solution. There will be times that a [resolver](https://angular.io/api/router/Resolve) might be able to help better, or sometimes even component logic might  fit your use-case better. That being said, Guards are incredibly helpful when the time comes to use them\n",
		},
		{
			title: "Angular Templates — From Start to Source",
			description:
				"Learn how templates work in Angular. From the basics to being able to read Angular source code and write your own structural directives",
			published: "2019-07-11T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["angular", "webdev"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "angular-templates-start-to-source",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Angular Templates — From Start to Source",
				description:
					"Learn how templates work in Angular. From the basics to being able to read Angular source code and write your own structural directives",
				published: "2019-07-11T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["angular", "webdev"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\n# Article Overview {#overview}\n\n> This article was written with the idea that the reader is at least somewhat familiar with the introductory concepts of Angular. As a result, if you haven't done so already, it is highly suggested that you make your way through the fantastic [Angular getting started guide](https://angular.io/start).\n\nOne of the core concepts to the Angular framework is the idea of templates. Templates allow developers to create embedded views of UI from other locations.\n\nThese templates not only power many of Angular's baseline features, but are extremely versatile in their capabilities and serve as powerful tools to leverage:\n\n- Templates can be passed and called manually in a similar way to functions.\n- You can leverage a set of APIs built into these templates to pass and manipulate data from one template to another during the render process\n\nWhile this article is far from a comprehensive list of all template related APIs, I want to walk through as much as I can to help you understand how templates work in Angular, what you're able to do with them, and loosely how they're used within Angular itself. Some of the APIs we'll be going through include:\n\n- `ng-template`\n- `TemplateRef`\n- `EmbeddedViewRef`\n- `ViewContent`/`ViewChildren`\n- `ViewContainerRef`\n- `createEmbeddedView`\n- [Structural Directives](https://angular.io/guide/structural-directives#asterisk) (such as `*ngIf`)\n\nBy the end of this article, you'll not only have read some of Angular's source code ([as of 8.0.1](https://github.com/angular/angular/commit/e1f6d1538784eb87f7497bef27e3c313184c2d30)), but you should have a better understanding of how to implement many of these tools and how some of the APIs you use daily work under-the-hood.\n\nIt's going to be a long article, so please feel free to take breaks, grab a drink to enjoy while reading, pause to tinker with code, or anything in-between. Feedback is always welcomed and appreciated.\n\nSound like a fun time? Let's goooo! 🏃🌈\n\n> The contents of this post was also presented in a talk under the same name. You can [find the slides here](./slides.pptx) or a live recording of that talk given by the post's author [on our YouTube channel](https://www.youtube.com/watch?v=7AilTMFPxqQ).\n\n# Introduction To Templates {#intro}\n\n## `ng-template` {#ng-template}\n\nBefore we dive into the meat of this article, let's do a quick recap of what templates are and what they look like.\n\nWhile Angular templates come in many shapes and sizes, a simple but common use for them might look something like this:\n\n```html\n<ng-template #falseTemp>\n\t<p>False</p>\n</ng-template>\n<p *ngIf=\"bool; else falseTemp\">True</p>\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-1-ng-template?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nIn this example, we are creating a template and assigning it to a [template reference variable](https://blog.angulartraining.com/tutorial-the-magic-of-template-reference-variables-3183f0a0d9d1). _This template reference variable makes `falseTemp` a valid variable to use as a value for other inputs in the same template._ It then handles that variable similarly to how a variable from the component logic is handled when referenced from the template.\n\nWe are then adding the [`ngIf`](https://angular.io/api/common/NgIf) structural directive to the paragraph tag to render content to the screen conditionally.\n\n- If `bool` is true, it renders `<p>True</p>`, and the template containing `<p>False</p>` does not\n- If `bool` is false, it then checks if the [`else` condition built into `ngIf`](https://angular.io/api/common/NgIf#showing-an-alternative-template-using-else) has a value assigned to it. If there is a value assigned to the `else` condition, it renders that template.\n\t- In this example, it does; the template we've assigned to `templHere`. Because of this, `<p>False</p>` is rendered\n\nIf you had forgotten to include the `ngIf`, it would never render the `False` element because **a template is not rendered to the view unless explicitly told to — this includes templates created with `ng-template`**\n\n## Rendering Manually with `ngTemplateOutlet` {#ng-template-outlet}\n\nBut there's a ~~simpler~~ ~~much more complex~~ another way show the same template code above!\n\n```html\n<ng-template #falseTemp>\n\t<p>False</p>\n</ng-template>\n<ng-template #ifTrueCondTempl>\n\t<p>True</p>\n</ng-template>\n<ng-template [ngTemplateOutlet]=\"bool ? ifTrueCondTempl : falseTemp\"></ng-template>\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-2-conditional-render?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n> While this is not how the `ngIf` structural template works internally, this is a good introduction to the `ngTemplateOutlet` directive, which adds functionality to the `ng-template` tag.\n>\n> If you're curious to how Angular's `ngIf` works, read on dear reader.\n\nWhile I'd mentioned previously that `ng-template` does not render to the DOM, because we're using `ngTemplateOutlet`, it renders the template defined in the passed `ng-template`.\n\nThis template that's defined by `ng-template` is called a \"view\", and when it is rendered to the screen, it is called an \"embedded view\".\n\nThis embedded view is located in the DOM, where the `ng-template` that used the `ngTemplateOutlet` resides. That is to say, if you look at the element inspector, the element is placed where you'd expect the `ng-template` to be located based on the structure of your code.\n\nKnowing that, you can see that the following example would show the user three of the most mythical beasts imaginable:\n\n```html\n<ng-template #unicorns><button>🦄🦄🦄</button></ng-template>\n<ng-template [ngTemplateOutlet]=\"unicorns\"></ng-template>\n```\n\nWith this, combined with template reference variables, you may find it easier to use a ternary operator to pass the correct template based on the value of `bool` to create an embedded view of that template.\n\n## Pass Data To Templates — The Template Context {#template-context}\n\nDo you know how I mentioned that you can pass data between templates (at the start of the article)? This can be accomplished by defining the _context_ of the template. This context is defined by a JavaScript object you pass to the template with your desired key/value pairs (just like any other object). When looking at an example below, **think of it in terms of passing data from a parent component to a child component through property binding**. When you define the context of a template, you're simply giving it the data it needs to fulfill its purpose in much the same way.\n\nSo, now that we know what they are in broad terms, what do they look like?\n\nWhile we used the `ngTemplateOutlet` directive before to render a template, we can also pass an input to the directive `ngTemplateOutletContext` to pass a context. A context is just an object with a standard key/value pairing.\n\n```html\n<ng-template\n\t[ngTemplateOutlet]=\"showMsgToPerson\"\n\t[ngTemplateOutletContext]=\"{$implicit: 'Hello World', personName: 'Corbin'}\"\n>\n</ng-template>\n```\n\nFrom there, you can use `let` declarations to create template variables in that template based on the values passed by the context like so:\n\n```html\n<ng-template #showMsgToPerson let-message let-thisPersonsName=\"personName\">\n\t<p>{{message}} {{thisPersonsName}}</p>\n</ng-template>\n```\n\nHere, you can see that `let-templateVariableName=\"contextKeyName\"` is the syntax to bind any named context key's value to the template input variable with the name you provided after `let`. There is an edge-case you've probably noticed though, the `$implicit` key of the context is treated as a default of sorts, allowing a user to simply leave `let-templateVariableName` to be the value of the `$implicit` key of the context value.\n\nNow let's see it in action!\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-3-context?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nAs a quick note, _I only named these template input variables differently from the context value key to make it clear that you may do so_. `let-personName=\"personName\"` is not only valid, but it also can make the code's intentions clearer to other developers.\n\n# View References — `ViewChild`/`ContentChild` {#view-references}\n\n## Keeping Logic In Your Controller using `ViewChild` {#viewchild}\n\nWhile template reference variables are very useful for referencing values within the template itself, there may be times when you'll want to access a reference to an item in the template from the component logic. Luckily, there's a way to get a reference to any component, directive, or view within a component template.\n\nUsing [`ViewChild`](https://angular.io/api/core/ViewChild), you're able to grab a reference to the `ng-template` from the component logic rather than the template code:\n\n```typescript\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<div>\n\t\t\t<ng-template #helloMsg>Hello</ng-template>\n\t\t</div>\n\t\t<ng-template [ngTemplateOutlet]=\"helloMessageTemplate\"></ng-template>\n\t`\n})\nexport class AppComponent {\n\t// Ignore the `static` prop for now, we'll cover that in just a bit\n\t@ViewChild('helloMsg', {static: false}) helloMessageTemplate: TemplateRef<any>;\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-4-viewchild?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n> While this example is effectively not-much-more than an alternative API to `ngTemplateOutlet`, it serves as a basis for introducing into further concepts.\n\n_`ViewChild` is a \"property decorator\" utility for Angular that searches the component tree to find what you pass it as a query._ In the example above, when we pass the string `'templName'`, we are looking for something in the tree that is marked with the template variable `helloMsg`. In this case, it's an `ng-template`, which is then stored to the `helloMessageTemplate` property when this is found. Because it is a reference to a template, we are typing it as `TemplateRef<any>` to have TypeScript understand the typings whenever it sees this variable.\n\n### Not Just for Templates! {#viewchild-not-just-templates}\n\n`ViewChild` isn't just for templates, either. You can get references to anything in the view tree:\n\n```typescript\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<my-custom-component #myComponent [inputHere]=\"50\" data-unrelatedAttr=\"Hi there!\"></my-custom-component>\n\t`\n})\nexport class AppComponent {\n\t@ViewChild('myComponent', {static: false}) myComponent: MyComponentComponent;\n}\n```\n\nFor example, would give you a reference to the `MyComponentComponent` instance of the template. If you ran:\n\n```typescript\n/* This would be added to the `AfterViewInit` lifecycle method */\nconsole.log(this.myComponent.inputHere); // This will print `50`\n```\n\nIt would give you the property value on the instance of that component. Angular by default does a pretty good job at figuring out what it is that you wanted to get a reference of and returning the \"correct\" object for that thing.\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-5-view-not-template?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nDespite the examples thus far having only used a string as the query for `ViewChild`, you're also able to use the ComponentClass to query for a component with that component type.\n\n```typescript\n/* This would replace the previous @ViewChild */\n@ViewChild(MyComponentComponent) myComponent: MyComponentComponent;\n```\n\nFor the particular example listed above, this code change would still yield the same results. _When using `ViewChild`, it might be dangerous to do this if you have many components with that class._ This is because when using `ViewChild`, _it only returns the first result that Angular can find_ — this could return results that are unexpected if you're not aware of that.\n\n### My Name is ~~Inigo Montoya~~ the `read` Prop {#viewchild-read-prop}\n\nAwesome! But I wanted to get the value of the `data-unrelatedAttr` attribute dataset, and my component definition doesn't have an input for that. How do I get the dataset value?\n\nAhh, so you've seen the problem with Angular's guessing of what datatype you're looking for. There are times where we, the developers, know better of what we're looking for than the framework services.\n\nFancy that.\n\nWhen we want to overwrite the type of data we expect `ViewChild` to return, we can use a second property passed to the `ViewChild` decorator with the type we want to be returned. With the use-case mentioned above, we can tell Angular that we want a reference to the element of the component itself by using the `ElementRef`.\n\n\n```typescript\n/* This would replace the previous @ViewChild */\n@ViewChild('myComponent', {read: ElementRef, static: false}) myComponent: ElementRef;\n```\n\nNow that we've configured the `ViewChild` to read this as an `ElementRef` (a class provided from `@angular/core` which helps us get the right value back from the query) rather than a component reference, we're able to use the `nativeElement` property of that class to get the HTMLElement object for that component instance.\n\n```typescript\n/* This would be added to the `AfterViewInit` lifecycle method */\nconsole.log(myComponent.nativeElement.dataset.getAttribute('data-unrelatedAttr')); // This output `\"Hi there!\"`\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-6-read-prop?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n`ViewChild` isn't an only child, though (get it?). There are other APIs similar to it that allow you to get references to other items in your templates from your component logic.\n\n## `ViewChildren`: More references then your nerdy pop culture friend {#viewchildren}\n\n`ViewChildren` allows you to get a reference to any items in the view that match your `ViewChildren` query as an array of each item that matches:\n\n```typescript\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<div>\n\t\t\t<my-custom-component [inputHere]=\"50\"></my-custom-component>\n\t\t\t<my-custom-component [inputHere]=\"80\"></my-custom-component>\n\t\t</div>\n\t`\n})\nexport class AppComponent {\n\t@ViewChildren(MyComponentComponent) myComponents: QueryList<MyComponentComponent>;\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-7-viewchildren?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nWould give you a list of all components with that base class. You're also able to use the `{read: ElementRef}` property from the `ViewChild` property decorator to get a `QueryList<ElementRef>` (to be able to get a reference to the DOM [Elements](https://developer.mozilla.org/en-US/docs/Web/API/Element) themselves) instead of a query list of `MyComponentComponent` types.\n\n### What is `QueryList` {#viewchildren-querylist}\n\nWhile `QueryList` (from `@angular/core`) returns an array-like, and the core team has done an outstanding job at adding in all the usual methods (`reduce`, `map`, etc.) and it _extends an iterator interface_ (so it works with `*ngFor` in Angular templates and `for (let i of _)` in TypeScript/JavaScript logic), _it is not an array_. [A similar situation occurs when using `document.querySelectorAll` in plain JavaScript](https://developer.mozilla.org/en-US/docs/Web/API/NodeList). _If you're expecting an array from an API that returns `QueryList`, it might be best to use `Array.from`_ on the value (in this case the `myComponents` component prop) when you access it in logic later.\n\nA `QueryList` also allows for some nice additions like the `changes` observable property that allows you to listen for changes to this query. For example, if you had some components that were hidden behind a toggle:\n\n```html\n<!-- This would make up the template of a new component -->\n<input type=\"checkbox\" [(ngModel)]=\"bool\"/>\n<div *ngIf=\"bool\">\n\t<my-custom-component></my-custom-component>\n</div>\n<my-custom-component></my-custom-component>\n```\n\nAnd wanted to get the value of all component's `numberProp` values reduced into one, you could do so using the `changes` observable:\n\n```typescript\n/* This would be added to the `AfterViewInit` lifecycle method */\nthis.myComponents.changes.subscribe(compsQueryList => {\n\tconst componentsNum = compsQueryList.reduce((prev, comp) => {\n\t\treturn prev + comp.numberProp;\n\t}, 0);\n\tconsole.log(componentsNum); // This would output the combined number from all of the components' `numberProp` fields. This would run any time Angular saw a difference in the values\n});\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-8-querylist?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nIt might be a good idea to gain familiarity of doing this as the Angular docs give the following warning in the [`QueryList` docs](https://angular.io/api/core/QueryList#changes):\n\n> NOTE: In the future this class will implement an Observable interface.\n\n## `ContentChildren`: If this article had kids {#contentchildren}\n\nAuthor's note:\n\n> This section of the article assumes that you know what the `ng-content` tag is. While I could do an in-depth dive on what `ng-content` and content projection is, it's somewhat outside of the scope of this current article. Let me know if this is something that interests you; I might do another deep, deep dive into how Angular parses tags like `ng-content` and how it's handled by Angular's AST and template parsing/etc.\n>\n> If you're less familiar with `ng-content`, you can probably get by with just knowing how parent/child relationships elements work and just reading through carefully. Never be afraid to ask questions!\n>\n> There's also the `:host` selector used in these demos. Think of each component creating their own wrapper `div` — the `:host` selector applies styling to the component wrapper element itself.\n\nI always love nesting some of my code into `ng-content`s. I don't know what's so appealing about having my code look like it's straight out of HTML spec, but just being able to pass component instances and elements as children to one of my components and then tinkering with them is so satisfying.\n\nOne thing I always run into though is that I always end up wanting to style the components that are passed in. Take the following example:\n\n```html\n<cards-list> <!-- Cards list has default styling with grey background -->\n\t<action-card></action-card> <!-- Action card has default styling with grey background -->\n\t<action-card></action-card> <!-- It's also widely used across the app, so that can't change -->\n</cards-list>\n```\n\nAnyone with a sense of design might be cringing about now. Grey on grey? On cards? Yuck! Let's make those cards have some white backgrounds.\n\nThis might seem like a trivial task to anyone assuming that these components are built-in HTML elements as of course a CSS stylesheet like so would apply:\n\n```css\n// cards-list.component.css\naction-card {\n\tbackground: white;\n}\n```\n\nBut this is often not the case. _[Angular's `ViewEncapsulation`](https://angular.io/api/core/ViewEncapsulation) prevents styles from one component from affecting the styling of another_. This is especially true if you're using a configuration that allows the native browser to handle the components under the browser's shadow DOM APIs, which restricts stylesheet sharing on a browser-level. This is why the [Angular-specific CSS selector `::ng-deep`](https://angular.io/guide/component-styles#deprecated-deep--and-ng-deep) has been marked for depreciation (sorry old-school Angular developers [including myself, so much to migrate 😭]).\n\nIt's no matter, though. We have the power of `ViewChildren` on our side! Corbin already showed us how to get a reference to an element of a rendered component! Let's spin up an example:\n\n```typescript\n@Component({\n\tselector: 'action-card',\n\ttemplate: `<div></div>`,\n\tstyles: [`\n\t\t:host {\n\t\t\tborder: 1px solid black;\n\t\t\tdisplay: inline-block;\n\t\t\theight: 300px;\n\t\t\twidth: 100px;\n\t\t\tbackground: grey;\n\t\t\tmargin: 10px;\n\t\t}\n\t`]\n})\nexport class ActionCard {}\n\n@Component({\n\tselector: 'cards-list',\n\ttemplate: `<div><ng-content></ng-content></div>`,\n\tstyles: [`:host {background: grey; display: block;}`\n})\nexport class CardsList implements AfterViewInit {\n\t@ViewChildren(ActionCard, {read: ElementRef}) actionCards;\n\n\tngAfterViewInit() {\n\t\t// Any production code should absolutely be cleaning this up properly,\n\t\t// this is just for demonstration purposes\n\t\tthis.actionCards.forEach(elRef => {\n\t\t\tconsole.log(\"Changing background of a card\");\n\t\t\tthis.renderer.setStyle(elRef.nativeElement, \"background\", \"white\");\n\t\t});\n\t}\n}\n```\n\nAwesome, let's spin that up and… Oh.\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-9-cardlist-broke?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nThe cards are still grey. Let's open up our terminal and see if the `console.log`s ran.\n\nThey didn't.\n\nAlright, I could keep going, but I know you've all read the section title (👀 at the skim-readers).\n\n`ViewChildren` is a fantastic tool but only works for the items defined in the template of the component itself. Any children that are passed to the component are not handled the same way and require `ContentChildren` instead. The same applies to `ViewChild` (which has the adjacent API of `ContentChild`). The `ContentChild/ren` should share the same API with their `ViewChild/ren` counterparts.\n\nIf we change the `ViewChildren` line to read:\n\n```typescript\n@ContentChildren(ActionCard, {read: ElementRef}) actionCards;\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-10-cardlist-fixed?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nWe'll see that the code now runs as expected. The cards are recolored, the `consoles.log`s ran, and the developers are happy.\n\n### The Content Without the `ng` {#viewchildren-without-ng-content}\n\n`ContentChild` even works when you're not using `ng-content` but still passing components and elements as children to the component. So, for example, if you wanted to pass a template as a child but wanted to render it in a very specific way, you could do so:\n\n```html\n<!-- root-template.component.html -->\n<render-template-with-name>\n\t<ng-template let-userName>\n\t\t<p>Hello there, {{userName}}</p>\n\t</ng-template>\n</render-template-with-name>\n```\n\n```typescript\n// render-template-with-name.component.ts\n@Component({\n\tselector: 'render-template-with-name',\n\ttemplate: `\n\t<ng-template\n\t\t[ngTemplateOutlet]=\"contentChildTemplate\"\n\t\t[ngTemplateOutletContext]=\"{$implicit: 'Name here'}\">\n\t</ng-template>\n`\n})\nexport class AppComponent {\n\t@ContentChild(TemplateRef, {static: false}) contentChildTemplate;\n}\n```\n\nThis is a perfect example of where you might want `@ContentChild` — not only are you unable to use `ng-content` to render this template without a template reference being passed to an outlet, but you're able to create a context that can pass information to the template being passed as a child.\n\n\n# How Does Angular Track the UI {#understand-the-tree}\n\nAwesome! We've been blowing through some of the real-world uses of templates like a bullet-train through a tunnel. 🚆 But I have something to admit: I feel like I've been doing a pretty bad job at explaining the \"nitty-gritty\" of how this stuff works. While that can often be a bit more dry of a read, I think it's very important to be able to use these APIs to their fullest. As such, let's take a step back and read through some of the more abstract concepts behind them.\n\nOne of these abstract concepts comes from how Angular tracks what’s on-screen; just like the browser has the _Document Object Model_ tree (often called the DOM), Angular has the _View Hierarchy Tree_.\n\n## The DOM Tree {#the-dom}\n\nOkay, I realize I just dropped some vocab on you without explaining first. Let's change that.\n\nSo, when you build out an HTML file, you're defining the shape the document object model (DOM) takes. When you load a file similar to this:\n\n```html\n<!-- index.html -->\n<!-- ids are only added for descriptive purposes -->\n<main id=\"a\">\n\t<ul id=\"b\">\n\t\t<li id=\"c\">Item 1</li>\n\t\t<li id=\"d\">Item 2</li>\n\t</ul>\n\t<p id=\"e\">Text here</p>\n</main>\n```\n\n_The browser takes the items that've been defined in HTML and turns them into a tree that the browser can understand how to layout and draw on the screen_. That tree, internally, might look something like this:\n\n![A chart showing the document object model layout of the above code. It shows that the 'main' tag is the parent to a 'ul' tag, and so on](./dom_tree.svg \"Diagram showing the above code as a graph\")\n\nThis tree tells the browser where to place items and includes some logic when combined with CSS, even. For example, when the following CSS is applied to the `index.html` file:\n\n```css\n#b li {\n\tbackground: red;\n}\n```\n\nIt finds the element with the ID of `b`, then the children of that tag are colored red. They're \"children\" because the DOM tree keeps that relationship info that's defined by the HTML.\n\n![A chart showing the 'ul' tag highlighted in green with the children 'li' tags marked in red](./dom_tree_with_css.svg \"Diagram showing the above code as a graph\")\n\n> The `ul` element is marked as green just to showcase that it is the element being marked by the first part of the selector\n\n> If you want to have a better grasp on the DOM and how it relates to the content you see on-screen, [check out our article that outlines what the DOM is and how your code interfaces with it through the browser](/posts/understanding-the-dom/).\n\n## View Hierarchy Tree\n\nIn the same way, the browser keeps track of what's rendered into the dom using the DOM tree, Angular has its own tree to keep track what's rendered on-screen.\n\nThe reason Angular has its own tree is due to the dynamic nature of Angular. In order to understand how to hide content on the fly, change out the content on-screen, and know how to keep consistent expected interactions between all of this, Angular needs to have a tree to keep track of its state.\n\n_While Angular renders to the DOM in the end_ (just as vanilla HTML would), _Angular has the original information that described how to render things onto screen. When Angular detects changes to this tree, it will then update the DOM with the changes that Angular has tracked_.\n\n> I will make a note that, while Angular's _View Hierarchy Tree_ is used by Angular to keep track of component/template composition (and some might argue that this is a \"virtual DOM\" of sorts as it updates the DOM based off of it's own tree), Angular makes no claims that this is a virtual DOM (AFAIK).\n>\n> Virtual DOMs have highly contested conversation surrounding them and have no standard definition as-to what one is or is not. I only used the DOM to present a foundational understanding of hierarchy trees in general.\n\nBecause this tree is used to update the DOM rather than being part of the DOM itself, _the tree Angular uses to track its state is called the \"view hierarchy tree\"_. This tree is composed of various \"views\". _A view is a grouping of elements and is the smallest grouping of elements that can be created or destroyed together_. **A view is defined by a template.** _This template on its own is not a view, but does define a view_\n\nBecause of this, despite there being many templates — this code sample does not have any views in it, because they are not being created from any of the templates:\n\n```html\n<ng-template>I am a view that's defined by a template</ng-template>\n<ng-template>\n\t<p>So am I! Just a different one. Everything in THIS template is in the same view</p>\n\t<div>Even with me in here? <span>Yup!</span></div>\n</ng-template>\n```\n\nHowever, when you create a view from a template, you're able to display them on-screen. When a view is displayed on-screen, they're then called an _embedded view_. So, when we render a template using `ngTemplateOutlet`, we are creating a view from a template, then embedding the view in the view that you called the `ngTemplateOutlet` in.\n\nAs such, the following code example would create the view hierarchy in the chart below the code sample:\n\n```html\n<ng-template>\n\t<p>I am in a view right now</p>\n\t<ng-template #rememberMsg>\n\t\tBut as you might recall, this is also a view\n\t</ng-template>\n\t<ng-template\n\t\t[ngTemplateOutlet]=\"rememberMsg\"\n\t\t[ngTemplateOutletContext]=\"{$implicit: 'So when we render it, it\\'s a view within a view'}\"\n\t></ng-template>\n</ng-template>\n```\n\n![A chart showing the relationship between the templates. The first item is a template, with an elment, view, and template as children. There is an arrow pointing from the child view to the child template](./hierarchy_example_intro.svg \"Diagram showing the above code as a graph\")\n\n> The arrow in this chart simply shows that the view is being defined by the template itself\n\nIt's this composition of views that make up the \"view hierarchy\".\n\n## View Containers\n\nAdmittedly, that chart above isn't QUITE right. A more accurate version of the chart might look something like this:\n\n![The same chart from above but the top-level template now has an arrow pointing to an item \"view container\" before listing the other children](./hierarchy_example_intro.svg \"Diagram showing the above code as a graph\")\n\nLittle has changed, yet there's something new! A _view container_ is just what it sounds like: It's a container for views. That is to say, whenever you see a view embedded, you can be sure it's a child of a view container. While our code might not make it apparent, when we're using `ngTemplateOutlet`, Angular creates a view container for us to place the view into. It will create the view container from a template, view, or even from an element.\n\n```html\n<p>\n\t<ng-template #letsRender>\n\t\tLet's render this thing!\n\t</ng-template>\n\t<ng-template [ngTemplateOutlet]=\"letsRender\"></ng-template>\n</p>\n```\n\n\n![A chart showing an element as the root with two children, a template and a view. The view points towards the template](./hierarchy_view_container_on_element.svg \"Diagram showing the above code as a graph\")\n\n\n\n_It is because Angular's view containers being able to be attached to views, templates, and elements that enable the dependency injection system to get a `ViewContainerRef` regardless of what you're requested the `ViewContainerRef` on_.\n\n## Host Views {#components-are-directives}\n\nIf you're looking for them, you might notice a few similarities between a component declaration's `template` and `ng-template`s:\n\n- Both of them allow for values to be passed into them (`@Input` props for components, context for templates)\n- Both of them contain the same support for tags and template creation (using `ng-template`).\n\nWell, there's a good reason for that: _A component is actually just a directive with a special view — a \"host view\" (defined by the `template` or `templateUrl` field in the decorator) associated with it_.\n\n[To quote the Angular documentation](https://angular.io/guide/architecture-components#directives):\n\n> A component is technically a directive. However, components are so distinctive and central to Angular applications that Angular defines the `@Component()` decorator, which extends the `@Directive()`decorator with template-oriented features.\n\nThis host view can also be attached to another view by using the `selector` value of that component's.\n\n```typescript\n@Component({\n\tselector: \"child-component\",\n\ttemplate: `\n\t\t<p>I am in the host view, which acts as a view container for other views to attach to</p>\n\t\t<div><p>I am still in the child-component's host view</p></div>\n\t\t<ng-template #firstChildCompTempl>\n\t\t\t<p>I am in a view outside of the child-component's host view</p>\n\t\t</ng-template>\n\t\t<ng-template\n\t\t\t[ngTemplateOutlet]=\"firstChildCompTempl\"\n\t\t\t[ngTemplateOutletContext]=\"{$implicit: 'And now I'm attaching that template to the host view by embedding the view'}\"\n\t\t></ng-template>\n\t`\n})\nexport class ChildComponent {}\n\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<p>I am in app's host view, and can act as a view container for even other host views by using the component's selector</p>\n\t\t<child-component></child-component>\n\t`\n})\nexport class AppComponent {}\n```\n\n\n![A chart showing the heirarchy of the above code. It shows \"my-app\" having a host view, which has a view container. This view container is the parent to an element and \"child-component\", which has its own host view, view container, and children](./hierarchy_tree_example.svg \"Diagram showing the above code as a graph\")\n\n\n\n## Template Input Variable Scope\n\nTemplate input variables are the variables you bind to a template when using context. `<ng-template let-varName>`. _These variables are defined from the context that is applied to the template_. As a result **these templates are able to be accessed by the children views of the templates, but not from a higher level** — as the context is not defined above the template:\n\n```html\n<!-- ✅ This is perfectly fine -->\n<ng-template let-varName><p>{{varName}}</p></ng-template>\n\n<!-- ❌ This will throw errors, as the template context is not available from anywhere that isn't a child of the template -->\n<ng-template let-thisVar></ng-template>\n<p>{{thisVar}}</p>\n```\n\n## Template Reference Variable Scope\n\nTemplate reference variables, however, have a much more complex answer in regards to how they're able to be accessed.\n\nAs a small review of what they are:\n_A template reference variable is a variable assigned to a tag so that other items in the same template are able to reference that tag._\n\n```html\n<div>\n\tHello There!\n\t<ng-template #testingMessage><p>Testing 123</p></ng-template>\n</div>\n<ng-template [ngTemplateOutlet]=\"testingMessage\"></ng-template>\n\n<!-- Will now show the following in the DOM: -->\n<!--        <div>Hello There!</div>          -->\n<!--           <p>Hi There</p>               -->\n```\n\nIn this example, we're getting a reference to `testingMessage` template to be able to provide as an input. We're then passing that value to another `ng-template`'s `ngTemplateOutlet` directive to get it rendering on-screen.\n\nStraightforward enough example, let’s see a more difficult example:\n\n```html\n<ng-template #helloThereMsg>\n\t<p>Hello There!</p>\n\t<ng-template #testingMessage>\n\t\t<p>Testing 123</p>\n\t</ng-template>\n</ng-template>\n<div>\n\t<ng-template [ngTemplateOutlet]=\"helloThereMsg\"></ng-template>\n</div>\n<ng-template [ngTemplateOutlet]=\"testingMessage\"></ng-template>\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-11-broke-template-var?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nIf you look at the output of this example, you'll notice that `testingMessage` isn't rendering. This is because template reference variables bind to the view that they're present in; and as a result are unable to be accessed from parent views.\n\n[Like how CSS is applied to a dom when bound to a selector](#the-dom), template reference variables can be accessed within the view itself and child views, but not the parent views.\n\n![Chart showing the above code sample to match the prior visualization aids](./template_reference_scope.svg \"Visualization of the hierarchy tree for the prior cod example\")\n\n\n\nWhen the view that is trying to render `testMessage` looks for that template reference variable, it is unable to, as it is bound to the `helloThereMsg` template view. Because it cannot find a template reference variable with the id `testMessage`, it treats it like any other unfound variable: an `undefined` value. The default behavior of `undefined` being passed to `ngTemplateOutlet` is to not render anything.\n\nIn order to fix this behavior, we'd need to move the second `ng-template` into the `helloThereMsg` template view so that the `ngTemplateOutlet` is able to find the matching template reference variable within its view scope.\n\n```html\n<ng-template #helloThereMsg>\n\tHello There!\n\t<ng-template #testingMessage><p>Testing 123</p></ng-template>\n\t<ng-template [ngTemplateOutlet]=\"testingMessage\"></ng-template>\n</ng-template>\n<div>\n\t<ng-template [ngTemplateOutlet]=\"helloThereMsg\"></ng-template>\n</div>\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-12-fixed-template-var?embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n# The Bane of All JavaScipt Developer: Timings {#timings}\n\n## Understanding timings with `ViewChildren` {#viewchildren-timings}\n\nBut the example immediately above doesn't have the same behavior as the one we likely intended. We wanted to get:\n\n```html\n<div>Hello there!</div>\n<p>Testing 123</p>\n```\n\nAnd instead got:\n\n```html\n<div>Hello there! <p>Testing 123</p></div>\n```\n\nThis is because, when we moved the template into the correct view scope, we moved it in the element tree as well.\n\nLuckily, we've already covered `@ViewChild`, which is able to get references all the way down the view hierarchy tree and provide the value to the component logic. Because the **component logic variables are accessible from any child view of the component host view**, you can pass the `testingMessage` template reference variable to the top level.\n\n```typescript\n@Component({\n\tselector: \"my-app\",\n\ttemplate: `\n\t\t<ng-template #helloThereMsg>\n\t\t\tHello There!\n\t\t\t<ng-template #testingMessage>Testing 123</ng-template>\n\t\t</ng-template>\n\t\t<ng-template [ngTemplateOutlet]=\"helloThereMsg\"></ng-template>\n\t\t<ng-template [ngTemplateOutlet]=\"testingMessageCompVar\"></ng-template>\n\t`\n})\nexport class AppComponent {\n\t@ViewChild(\"testingMessage\", { static: false }) testingMessageCompVar;\n}\n```\n\nSomething you'll see if you open the console in that example is an error you may already be familiar with if you’ve used Angular extensively in the past (I know I sure saw it more then a few times!):\n\n```\nError: ExpressionChangedAfterItHasBeenCheckedError: Expression has changed after it was checked. Previous value: 'ngTemplateOutlet: undefined'. Current value: 'ngTemplateOutlet: [object Object]'.\n```\n\n> This error is being thrown by Angular's developer mode, so if you're running a production build, this error will not show.\n\nWhy is this error happening? What can we do to fix it?\n\nThis, my friends, is where the conversation regarding change detection, lifecycle methods, and the `static` prop come into play.\n\n## Change Detection, How Does It Work {#change-detection}\n\n> Change detection in Angular is deserving of its own massive article: This is not that article. That said, understanding how change detection and how it affects the availability of templates is imperative to understanding some of the more ambiguous aspects of Angular template’s behaviors.\n>\n> More information can be found on lifecycle methods and change detection on [the official docs page for them](https://angular.io/guide/lifecycle-hooks).\n\n_Angular has specific hooks of times when to update the UI_. Without these hooks, Angular has no way of knowing when data that's shown on-screen is updated. These hooks essentially simply check when data has changed. While these checks are imperfect, they have default behavior that will handle most cases and and the ability to overwrite it and even manually trigger a check.\n\nOne of the default checks that is ran when Angular is starting the initial render of a component. During this time, it will do a check of all of the values stored within the component's state. Afterwards, it will run checks whenever any data has changed whether or not to update the UI.\n\nThese checks trigger the lifecycle method `DoCheck`, which you can manually handle. The `DoCheck` lifecycle method will trigger every time Angular detects data changes, regardless of if the check of that data does not decide to update the item on-screen or not.\n\n\nSo let's look at the example we had previously, but let's add some lifecycle methods to evaluate when `ViewChild` is able to give us our value.\n\n```typescript\nexport class AppComponent implements DoCheck, OnChanges, AfterViewInit {\n\trealMsgVar: TemplateRef<any>;\n\t@ViewChild(\"testingMessage\", { static: false }) testingMessageCompVar;\n\n\tngOnInit() {\n\t\tconsole.log(\"ngOnInit | The template is present?\", !!this.testingMessageCompVar)\n\t}\n\n\tngDoCheck() {\n\t\tconsole.log(\"ngDoCheck | The template is present?\", !!this.testingMessageCompVar);\n\t\tthis.realMsgVar = this.testingMessageCompVar;\n\t}\n\n\tngAfterViewInit() {\n\t\tconsole.log('ngAfterViewInit | The template is present?', !!this.testingMessageCompVar);\n\t}\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-13-lifecycle-explain?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nLooking at the console logs, you'll be left with the following messages in your console:\n\n```diff\nngOnInit        | The template is present? false\nngDoCheck       | The template is present? false\nngAfterViewInit | The template is present? true\nngDoCheck       | The template is present? true\n```\n\nYou can see that the `testingMessageCompVar` property is not defined until the `ngAfterViewInit`. _The reason we're hitting the error is that the template is not defined in the component logic until `ngAfterViewInit`._ It is not defined until them due to timing issues:* **the template is being declared in an embedded view, which takes a portion of time to render to screen**. As a result, the `helloThereMsg` template must render first, then the `ViewChild` can get a reference to the child after the initial update.\n\nWhen using `ViewChild` by itself, it updates the value of the `testingMessageCompVar` at the same time that the `AfterViewInit` lifecycle method is ran. This value update is then in turn reflected in the template itself.\n\nAngular, however, does not like values being updated directly within the `AfterViewInit`. Angular runs change detection often after an `ngDoCheck` and, after that method, does not like to re-check if there are things to update on-screen (as there can be timing conflicts under-the-hood that require a lot of foundation regarding how the change detection process works to explain properly — well outside the scope of this post).\n\nBecause of this — when using the `ngDoCheck` — you're manually running the variable update, which in turn informs Angular’s change detection process to include this in it’s list of screen updates.\n\n> I realize there’s a lot going on in this example and that can be very confusing, even for me writing it! If you’re wanting to learn more but feeling discouraged after reading through this section a time or two, give [this resource](https://blog.angular-university.io/angular-debugging/) (from \"Angular University\", a great un-official Angular resource hub) a shot. It’s what I used to re-learn the elements at play with this error.\n\n> If there’s more interest in an article from me about Angular change detection, reach out — I'd love to gauge interest!\n\n### Great Scott — You Control The Timing! The `static` Prop {#static-prop}\n\nThat said, there might be times where having the value right off the bat from the `ngOnInit` might be useful. After all, if you're not embedding a view into a view, it would be extremely useful to be able to get the reference before the `ngAfterViewInit` and be able to avoid the fix mentioned above.\n\n> Before I go much further, I will remind readers that [the `static` prop was introduced in Angular 8](https://github.com/angular/angular/pull/28810); this section does not apply to `ViewChild`/`ContentChild` prior to that version\n\nWell, that can be controlled via the `static` prop! Before this example, I was defaulting to use `static: false` to avoid running into [the issue we covered in the last section](#change-detection), but you’re able to set this flag to `true` to get access to the template reference from within the `ngOnInit` lifecycle method:\n\n```typescript\n@Component({\n\tselector: \"my-app\",\n\ttemplate: `\n\t\t<div>\n\t\t\t<p>Hello?</p>\n\t\t\t<ng-template #helloThereMsg>\n\t\t\t\tHello There!\n\t\t\t</ng-template>\n\t\t</div>\n\t\t<ng-template [ngTemplateOutlet]=\"realMsgVar\"></ng-template>\n\t`\n})\nexport class AppComponent {\n\t@ViewChild(\"helloThereMsg\", { static: true }) realMsgVar;\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-14-static?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nBecause this example does not have the `helloThereMsg` template within another view (outside of the host view), it is able to render without the errors we found when using `static: true`). Likewise, if you were to add an `OnInit` lifecycle method, you'd be able to get a reference to that template.\n\n```typescript\nngOnInit() {\n\tconsole.log(!!this.realMsgVar); // This would output true\n}\n```\n\nWhile you might wonder \"Why would you use `static: false` if you can get the access within the `ngOnInit`\", the answer is fairly similarly: _when using `static: true`, the `ViewChild` prop never updates after the initial `DoCheck` lifecycle check_. This means that your value will never update from `undefined` when trying to get a reference to a template from within a child view.\n\nWhen taking the example with the `testingMessageCompVar` prop and changing the value to `true`, it will never render the other component since it will always stay `undefined`.\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-15-static-first-check?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n# View Manipulation {#view-manipulation}\n\n## View Limitations {#view-limitations}\n\nHaving covered views in the last section, it's important to mention an important limitation regarding them:\n\n>Properties of elements in a view can change dynamically, in response to user actions; the structure (number and order) of elements in a view can't. You can change the structure of elements by inserting, moving, or removing nested views within their view containers.\n>\n>\\- Angular Docs\n\n## Embed Views {#embed-views}\n\nWhile we've covered how to insert a component using `ngTemplate`, Angular also allows you to find, reference, modify, and create them yourself in your component/directive logic! 🤯\n\nLet's show an example of how we can render an `ng-template` using TypeScipt component logic:\n\n```typescript\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<ng-template #templ>\n\t\t\t<ul>\n\t\t\t\t<li>List Item 1</li>\n\t\t\t\t<li>List Item 2</li>\n\t\t\t</ul>\n\t\t</ng-template>\n\t\t<div #viewContainerRef class=\"testing\">\n\t\t</div>\n\t`\n})\nexport class AppComponent implements OnInit {\n\t@ViewChild('viewContainerRef', {read: ViewContainerRef, static: true}) viewContainerRef;\n\t@ViewChild('templ', {read: TemplateRef, static: true}) templ;\n\n\tngOnInit() {\n\t\tthis.viewContainerRef.createEmbeddedView(this.templ);\n\t}\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-16-createembeddedview?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nThis example has a lot going on, so let's dissect it bit-by-bit.\n\nStarting with some small recap:\n\n- We're creating a template with the `ng-template` tag and assigning it to a template reference variable `templ`\n- We're also creating a `div` tag, assigning it to the template reference variable `viewContainerRef`\n- Lastly, `ViewChild` is giving us a reference to the template on the `templ` component class property.\n\t- We're able to mark both of these as `static: true` as neither of them are obfuscated by non-host-view views as parents\n\nNow the new stuff:\n\n- We're also using `ViewChild` to assign the template reference variable `viewContainerRef` to a component class property.\n\t- We're using the `read` prop to give it the [`ViewContainerRef`](https://angular.io/api/core/ViewContainerRef) class, which includes some methods to help us create an embedded view.\n- Then, in the `ngOnInit` lifecycle, we're running the `createEmbeddedView` method present on the `ViewContainerRef` property to create an embedded view based on the template.\n\nIf you take a look at your element debugger, you'll notice that the template is injected as a sibling to the `.testing` div:\n\n```html\n<!---->\n<div class=\"testing\"></div>\n<ul>\n\t<li>List Item 1</li>\n\t<li>List Item 2</li>\n</ul>\n```\n\n> The empty comment `<!---->` will show up in your element tab of your browser and was therefore left in. The empty comment block is used by Angular to showcase where a template is\n\n[While this has confused many developers, who have expected the embedded view to be children of the `ViewContainer` reference element](https://github.com/angular/angular/issues/9035), this is intentional behavior, and is consistent with other APIs similar to it.\n\nThe reason for this is that _Angular is creating a `ViewContainer` as the parent of the element when the user queries for one_. From there, Angular is \"appending\" the new view into the view container (as a view container is a view itself, and a view cannot have the number of elements in it modified without inserting a new view).\n\nWhy would it make one as a parent rather than the element itself?\n\nNot all elements accept children inputs, IE: `</br>`. As a result, the Angular team thought it be best to make the parent the view container when a user queries for one (or uses the dependency injection to get a reference to one, as we are in this example).\n\n### See How The View Is Tracked\n\nBecause all views are unable to mutate the number of items without explicitly moving, creating, or destroying themselves, the view container is able to track all of the views via index.\n\nFor example, if you wanted to see the index, we could use an API on the view container to get the index of the embedded view. To do this, we'd first need a reference of the embedded view in our template logic.\n\nJust like how we have `ViewContainerRef`, there's also [`EmbeddedViewRef`](https://angular.io/api/core/EmbeddedViewRef#embeddedviewref). Luckily, with our previous example, getting that ref is trivial, as it's returned by the `createEmbeddedView` method:\n\n```typescript\nconst embeddRef: EmbeddedViewRef<any> = this.viewContainerRef.createEmbeddedView(this.templ);\n```\n\nFrom there, we can use the `indexOf` method on the parent `ViewContainerRef`:\n\n```typescript\nconst embeddIndex = this.viewContainerRef.indexOf(embeddRef);\nconsole.log(embeddIndex); // This would print `0`.\n// Remember that this is a new view container made when we queried for one with DI, which is why this is the only view in it currently\n```\n\nThe view container keeps track of all of the embedded views in its control, and when you `createEmbeddedView`, it searches for the index to insert the view into.\n\n\nYou're also able to lookup an embedded view based on the index you're looking for using `get`. So, if you wanted to get all of the indexes being tracked by `viewContainerRef`, you'd do:\n\n```typescript\nngOnInit() {\n\tfor (let i = 0; i < this.viewContainerRef.length; i++) {\n\t\tconsole.log(this.viewContainerRef.get(i));\n\t}\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-17-see-viewcontainer-indexes?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n#### Context\n\nJust as we can use `contextRouterOutlet`, you're able to pass context to a template when rendering it using `createEmbeddedView`. So, let's say that you wanted to have a counting component and want to pass a specific index to start counting from, you could pass a context, [with the same object structure we did before](#template-context), have:\n\n```typescript\nimport { Component, ViewContainerRef, OnInit, AfterViewInit, ContentChild, ViewChild, TemplateRef , EmbeddedViewRef} from '@angular/core';\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t<ng-template #templ let-i>\n\t\t\t\t<li>List Item {{i}}</li>\n\t\t\t\t<li>List Item {{i + 1}}</li>\n\t\t</ng-template>\n\t\t<ul>\n\t\t\t<div #viewContainerRef></div>\n\t\t</ul>\n\t`\n})\nexport class AppComponent implements OnInit {\n\t@ViewChild('viewContainerRef', {read: ViewContainerRef, static: true}) viewContainerRef;\n\t@ViewChild('templ', {read: TemplateRef, static: true}) templ;\n\n\tngOnInit() {\n\t\tconst embeddRef3: EmbeddedViewRef<any> = this.viewContainerRef.createEmbeddedView(this.templ, {$implicit: 3});\n\t\tconst embeddRef1: EmbeddedViewRef<any> = this.viewContainerRef.createEmbeddedView(this.templ, {$implicit: 1});\n\t}\n}\n```\n\nIn this example, because we want to have an unordered list with list elements being created using embedded views, we're getting a `ViewContainerRef` directly from inside the unordered list.\nBut you'll notice a problem with doing this if you open up your inspector (or even just by reading the code):\nThere's now a `div` at the start of your list.\n\nTo get around this, we can use the `ng-container` tag, which allows us to get a view reference without injecting a DOM element into the fray. _`ng-container` can also be used to group elements without using a DOM element_, similar to how [React Fragments](https://reactjs.org/docs/fragments.html) work in that ecosystem.\n\n```html\n<ng-container #viewContainerRef></ng-container>\n```\n\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-18-create-embedd-context?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n#### Move/Insert Template\n\nBut oh no! You'll see that the ordering is off. The simplest (and probably most obvious) solution would be to flip the order of the calls. After all, if they're based on index — moving the two calls to be in the opposite order would just fix the problem.\n\nBut this is a blog post, and I needed a contrived example to showcase how we can move views programmatically:\n\n\n```typescript\nconst newViewIndex = 0;\nthis.viewContainerRef.move(embeddRef1, newViewIndex); // This will move this view to index 1, and shift every index greater than or equal to 0 up by 1\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-19-move-template?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nAngular provides many APIs to take an existing view and move it and modify it without having to create a new one and run change detection/etc again.\n\nIf you're wanting to try out a different API and feel that `createEmbeddedView` is a little too high-level for you (we need to go deeper), you can create a view from a template and then embed it yourself manually.\n\n```typescript\nngOnInit() {\n\tconst viewRef1 = this.templ.createEmbeddedView({ $implicit: 1 });\n\tthis.viewContainerRef.insert(viewRef1);\n\tconst viewRef3 = this.templ.createEmbeddedView({ $implicit: 3 });\n\tthis.viewContainerRef.insert(viewRef3);\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-20-insert-template?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n[And in fact, this is how the `createEmbeddedView` works internally](https://github.com/angular/angular/blob/e1f6d1538784eb87f7497bef27e3c313184c2d30/packages/core/src/view/refs.ts#L174):\n\n```typescript\n// Source code directly from Angular as of 8.0.1\ncreateEmbeddedView<C>(templateRef: TemplateRef<C>, context?: C, index?: number):\nEmbeddedViewRef<C> {\n\tconst viewRef = templateRef.createEmbeddedView(context || <any>{});\n\tthis.insert(viewRef, index);\n\treturn viewRef;\n}\n```\n\n# Accessing Templates from a Directive {#directives}\n\nThus far, we've only used components to change and manipulate templates. However, [as we've covered before, directives and components are the same under-the-hood](#components-are-directives). As a result, _we have the ability to manipulate templates in the same way using directives rather than components_. Let's see what that might look like:\n\n```typescript\n@Directive({\n\tselector: '[renderTheTemplate]'\n})\nexport class RenderTheTemplateDirective implements OnInit {\n\tconstructor (private parentViewRef: ViewContainerRef) {\n\t}\n\n\t@ContentChild(TemplateRef, {static: true}) templ;\n\n\tngOnInit(): void {\n\t\tthis.parentViewRef.createEmbeddedView(this.templ);\n\t}\n}\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<div renderTheTemplate>\n\t\t\t<ng-template>\n\t\t\t\t\t<p>Hello</p>\n\t\t\t</ng-template>\n\t\t</div>\n\t`\n})\nexport class AppComponent {}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-21-directive-template?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nYou'll notice this code is almost exactly the same from some of our previous component code.\n\n## Reference More Than View Containers {#directive-template-ref}\n\nHowever, the lack of a template associated with the directive enables some fun stuff, for example, _we can use the same dependency injection trick we've been using to get the view container reference_ to get a reference to the template element that the directive is attached to and render it in the `ngOnInit` method like so:\n\n\n```typescript\n@Directive({\n\tselector: '[renderTheTemplate]'\n})\nexport class RenderTheTemplateDirective implements OnInit {\n\tconstructor (private parentViewRef: ViewContainerRef, private templToRender: TemplateRef<any>) {}\n\n\tngOnInit(): void {\n\t\tthis.parentViewRef.createEmbeddedView(this.templToRender);\n\t}\n}\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<ng-template renderTheTemplate>\n\t\t\t\t<p>Hello</p>\n\t\t</ng-template>\n\t`\n})\nexport class AppComponent {}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-22-directive-template-reference?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n## Input Shorthand {#directive-same-name-input}\n\nWith directives, we can even create an input with the same name, and just pass that input value directly to the template using a context:\n\n```typescript\n@Directive({\n\tselector: '[renderTheTemplate]'\n})\nexport class RenderTheTemplateDirective implements OnInit {\n\tconstructor (private parentViewRef: ViewContainerRef, private templToRender: TemplateRef<any>) {}\n\n\t@Input() renderTheTemplate: string;\n\n\tngOnInit(): void {\n\t\tthis.parentViewRef.createEmbeddedView(this.templToRender, {$implicit: this.renderTheTemplate});\n\t}\n}\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<ng-template [renderTheTemplate]=\"'Hi there!'\" let-message>\n\t\t\t\t<p>{{message}}</p>\n\t\t</ng-template>\n\t`\n})\nexport class AppComponent {}\n```\n\n> I want to make clear that this trick is present in all directives. If you name the input the same as the directive name, it will bind the value you're passing in to that directive name while also associating the directive with the component. No need for a separate input and directive name!\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-23-directive-input-name?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nStarting to look a bit more like the `ngTemplateOutlet`, no? Well, why not go even further! Let's lean into that!\nWith this syntax, we can add a second input, pass an object as the context to the template we want to render, and then a template reference variable, and be able to recreate Angular's `ngTemplateOutlet`'s API almost to-a-T:\n\n```typescript\n@Directive({\n\tselector: '[renderTheTemplate]'\n})\nexport class RenderTheTemplateDirective implements OnInit {\n\tconstructor (private parentViewRef: ViewContainerRef) {\n\t}\n\n\t@Input() renderTheTemplate: TemplateRef<any>;\n\t@Input() renderTheTemplateContext: Object;\n\n\tngOnInit(): void {\n\t\tthis.parentViewRef.createEmbeddedView(this.renderTheTemplate, this.renderTheTemplateContext);\n\t}\n}\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<ng-template [renderTheTemplate]=\"template1\"\n\t\t\t\t\t\t\t\t[renderTheTemplateContext]=\"{$implicit: 'Whoa 🤯'}\"></ng-template>\n\t\t<ng-template #template1 let-message>\n\t\t\t\t<p>Testing from <code>template1</code>: <b>{{message}}</b></p>\n\t\t</ng-template>\n\t`\n})\nexport class AppComponent {}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-24-directive-outlet-alternative?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nThe nice part is that not only does it look like the directive from its usage, [but it's also not entirely dissimilar to how Angular writes the component internally](https://github.com/angular/angular/blob/e1f6d1538784eb87f7497bef27e3c313184c2d30/packages/common/src/directives/ng_template_outlet.ts#L35):\n\n```typescript\n// This is Angular source code as of 8.0.1 with some lines removed (but none modified otherwise).\n// The lines removed were some performance optimizations by comparing the previous view to the new one\n@Directive({selector: '[ngTemplateOutlet]'})\nexport class NgTemplateOutlet implements OnChanges {\n\tprivate _viewRef: EmbeddedViewRef<any>|null = null;\n\n\t@Input() public ngTemplateOutletContext: Object|null = null;\n\t@Input() public ngTemplateOutlet: TemplateRef<any>|null = null;\n\n\tconstructor(private _viewContainerRef: ViewContainerRef) {}\n\n\tngOnChanges(changes: SimpleChanges) {\n\t\t\tif (this._viewRef) {\n\t\t\t\tthis._viewContainerRef.remove(this._viewContainerRef.indexOf(this._viewRef));\n\t\t\t}\n\n\t\t\tif (this.ngTemplateOutlet) {\n\t\t\t\tthis._viewRef = this._viewContainerRef.createEmbeddedView(\n\t\t\t\t\tthis.ngTemplateOutlet, this.ngTemplateOutletContext);\n\t\t\t}\n\t}\n}\n```\n\n# Structural Directives — What Sorcery is this? {#structural-directives}\n\nIf you've used Angular in any scale of application, you've ran into Angular helpers that look a lot like directives and start with a `*` such as `*ngIf` and `*ngFor`. These helpers are known as **structural directives** and are built upon all of the things we've learned to this point.\n\nThe main idea behind structural directives is that **they're directives that will wrap the tag that you've applied it to inside of a template without the need for an `ng-template` tag**.\n\nLet's look at a basic sample to start:\n\n\n```typescript\n@Directive({\n\tselector: '[renderThis]'\n})\nexport class RenderThisDirective implements OnInit {\n\tconstructor (private templ: TemplateRef<any>,\n\t\t\t\t\t\t\tprivate parentViewRef: ViewContainerRef) {\n\t}\n\n\tngOnInit(): void {\n\t\tthis.parentViewRef.createEmbeddedView(this.templ);\n\t}\n}\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t\t<p *renderThis>\n\t\t\t\t\tRendering from <code>structural directive</code>\n\t\t\t</p>\n\t`\n})\nexport class AppComponent {}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-25-structural-directive-intro?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n[Just as we previously used Angular's dependency injection (DI) system to get a reference to the `ViewContainerRef`](#embed-views), we're using DI to get a reference to the `TemplateRef` created by the `*` in the invocation of this directive and embedding a view.\n\nToo much CS (computer science) speak? Me too, let's rephrase that. When you add the `*` to the start of the directive that's being attached to the element, you're essentially telling Angular to wrap that element in an `ng-template` and pass the directive to the newly created template.\n\nFrom there, the directive can get a reference to that template from the constructor (as Angular is nice enough to pass the template to our directive when we ask for it [this is what the DI system does]).\n\nThe cool part about structural directives, though? Because they're simply directives, **you can remove the `*` and use it with an `ng-template` directly**. Want to use the `renderThis` without a structural directive? No problem! Replace the template with the following code block and you've got yourself a rendered template:\n\n```html\n<ng-template renderThis>\n\t<p>\n\t\tRendering from <code>ng-template</code>\n\t</p>\n</ng-template>\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-26-structural-directive-manually-apply?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nIt is for this reason that **only one structural directive can be applied to one element**. Otherwise, how would it know what order to wrap those directives in? What template should get what reference to what template?\n\n### Building A Basic `*ngIf`\n\nBut rendering a template without changing it in any way isn't a very useful structural directive. Remove that structural directive and your code has exactly the same behavior. However, Angular provides something not-altogether-different from what we started on as a useful utility to hide/show a view based on a boolean's truthiness: `ngIf`.\n\nSo if we added an input with the same name as the directive ([as we did previously](#directive-same-name-input)) to accept a value to check the truthiness of, added an `if` statement to render only if the value is true, we have ourselves the start of an `ngIf` replacement that we've built ourselves!\n\n\n```typescript\n@Directive({\n\tselector: '[renderThisIf]'\n})\nexport class RenderThisIfDirective implements OnInit {\n\tconstructor (private templ: TemplateRef<any>,\n\t\t\t\t\t\t\tprivate parentViewRef: ViewContainerRef) {\n\t}\n\n\t@Input() renderThisIf: any; // `any` since we want to check truthiness, not just boolean `true` or `false`\n\n\tngOnInit(): void {\n\t\tif (this.renderThisIf) {\n\t\t\tthis.parentViewRef.createEmbeddedView(this.templ);\n\t\t}\n\t}\n}\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<label for=\"boolToggle\">Toggle me!</label>\n\t\t<input id=\"boolToggle\" type=\"checkbox\" [(ngModel)]=\"bool\"/>\n\t\t<div *renderThisIf=\"bool\">\n\t\t\t<p>Test</p>\n\t\t</div>\n\t`\n})\nexport class AppComponent {\n\tbool = false;\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-27-render-if-intro?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nSuper cool! Image we kept developing this structural directive out, but you noticed while running your test (which you should totally have 👀) that toggling the checkbox doesn't actually show anything! This is because it's running the check once on `ngOnInit` and not again when the input changes. So let's change that:\n\n```typescript\n@Directive({\n\tselector: '[renderThisIf]'\n})\nexport class RenderThisIfDirective {\n\tconstructor (private templ: TemplateRef<any>,\n\t\t\t\t\t\t\tprivate parentViewRef: ViewContainerRef) {\n\t}\n\n\tprivate _val: TemplateRef<any>;\n\n\t@Input() set renderThisIf(val: TemplateRef<any>) {\n\t\tthis._val = val;\n\t\tthis.update();\n\t}\n\n\tupdate(): void {\n\t\tif (this._val) {\n\t\t\tthis.parentViewRef.createEmbeddedView(this.templ);\n\t\t}\n\t}\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-28-render-if-work-toggle-true?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nYou'll notice that I removed the `OnInit` lifecycle and replaced it with an input `set`ter. We could have changed the lifecycle method to use `ngOnChanges` to listen for input changes, given that we only have one input, but as your directive adds more inputs and you want to maintain the local state, that logic can get more complex.\n\nRunning our tests again, we see that toggling it once now shows the embedded view, but toggling it again after that does not hide it again. With a simple update to the `update` method, we can fix that:\n\n```typescript\nupdate(): void {\n\tif (this._val) {\n\t\tthis.parentViewRef.createEmbeddedView(this.templ);\n\t} else {\n\t\tthis.parentViewRef.clear();\n\t}\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-29-render-if-fully-working?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nHere, we're using the `clear` method on the parent view ref to remove the previous view when the value is false. Because our structural directive will contain a template only used for this directive, we can safely assume that `clear` will only remove templates created within this directive and not from an external source.\n\n#### How Angular Built It {#angular-ngif-source}\n\nWhile Angular goes for a more verbose pattern due to additional features available in their structural directive, the implementation is not too different from our own.\n\n[The following is the Angular source code for that directive](https://github.com/angular/angular/blob/e1f6d1538784eb87f7497bef27e3c313184c2d30/packages/common/src/directives/ng_if.ts#L151). To make it easier to explain with our current set of knowledge, there have been lines of code removed and a single conditional modified in a very minor way. Outside of these changes, this is largely unchanged.\n\n```typescript\n@Directive({selector: '[ngIf]'})\nexport class NgIf {\n\tprivate _context: NgIfContext = new NgIfContext();\n\tprivate _thenTemplateRef: TemplateRef<NgIfContext>|null = null;\n\tprivate _thenViewRef: EmbeddedViewRef<NgIfContext>|null = null;\n\n\tconstructor(private _viewContainer: ViewContainerRef, templateRef: TemplateRef<NgIfContext>) {\n\t\tthis._thenTemplateRef = templateRef;\n\t}\n\n\t@Input()\n\tset ngIf(condition: any) {\n\t\tthis._context.$implicit = this._context.ngIf = condition;\n\t\tthis._updateView();\n\t}\n\n\tprivate _updateView() {\n\t\tif (this._context.$implicit) {\n\t\t\tif (!this._thenViewRef) {\n\t\t\t\tthis._viewContainer.clear();\n\t\t\t\tif (this._thenTemplateRef) {\n\t\t\t\t\tthis._thenViewRef =\n\t\t\t\t\t\tthis._viewContainer.createEmbeddedView(this._thenTemplateRef, this._context);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tthis._viewContainer.clear();\n\t\t\t}\n\t\t}\n\t}\n}\nexport class NgIfContext {\n\tpublic $implicit: any = null;\n\tpublic ngIf: any = null;\n}\n```\n\nJust to recap, let's run through this line-by-line:\n\n1. `_context` is creating a default of `{$implicit: null, ngIf: null}`\n\t- The object shape is defined by the `NgIfContext` class below\n\t- This is to be able to pass as a context to the template. While this is not required to understand how Angular implemented this directive in basic terms, it was left in to avoid editing code elsewhere\n2. We're then defining a variable to keep track of the template reference and the view reference ([what `createEmbeddedView` returns](https://angular.io/api/core/EmbeddedViewRef)) for usage later\n3. The constructor is then assigning the template reference to the variable, and getting a reference to the view container\n4. We're then defining an input with the same name as a setter, as we did with our implementation\n\t- This setter is also calling an update function, just as were with our implementation\n5. The update view is then seeing if the `$implicit` value in the context is truthy (as we're assigning the value of the `ngIf` input to the `$implicit` key on the context)\n6. Further checks are made to see if there is a view reference already.\n\t- If there is not, it will proceed to make one (checking first that there is a template to create off of)\n\t- If there is, it will not recreate a view, in order to avoid performance issues by recreating views over-and-over again\n\n## Microsyntax\n\nAlright, we've made it thus far! The following section is going to be kinda a doozy so if you're feeling tired, a nap is certainly in order. 😴 🛌 Otherwise, let's get up — do a little shoulder shimmy to get ourselves moving for a bit 🏋 (I'm totally not just writing this for my future self who's gonna be editing this, noooope 😬), and dive in.\n\n### Bind Context\n\nJust as Angular parses the rest of the template you pass in to be able to convert your custom Angular components into template tags, **Angular also provides a small language-like syntax into its own query system**. This syntax is referred to as a \"microsyntax\" by the Angular devs. _This syntax is able to let the user create specific APIs that tie into this syntax and call/leverage specific parts of their code_. Sound vague? I think so too, let's look at a fairly minimal example:\n\n```typescript\nfunction translatePigLatin(strr) {\n\t// See the code here: https://www.freecodecamp.org/forum/t/freecodecamp-algorithm-challenge-guide-pig-latin/16039/7\n}\n\n@Directive({\n\tselector: '[makePiglatin]'\n})\nexport class MakePigLatinDirective {\n\tconstructor(private templ: TemplateRef<any>,\n\t\tprivate parentViewRef: ViewContainerRef) {}\n\n\t@Input() set makePiglatin(val: string) {\n\t\tthis.parentViewRef.createEmbeddedView(this.templ, {\n\t\t\t$implicit: translatePigLatin(val)\n\t\t});\n\t}\n}\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<p *makePiglatin=\"'This is a string'; let msg\">\n\t\t\t{{msg}}\n\t\t</p>\n\t`\n})\nexport class AppComponent {}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-30-microsyntax?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nThis might look familiar. We're using the `$implicit` value from the context within our structural directive! However, [if you review the section we introduced that concept in](#template-context), you'll notice that the syntax here is different but similar from a template variable that would be used to bind the context from an `ng-template` tag.\n\nThe semicolon is the primary differentiator between the two syntaxes in this particular example. The semicolon marks the end to the previous statement and the start of a new one (the first statement being a binding of the `makePiglatin` property in the directive, the second being a binding of the `$implicit` context value to the local template variable `msg`). This small demo already showcases part of why the microsyntax is so nice — it allows you to have a micro-language to define your APIs.\n\nLet's continue exploring how leveraging this tool can be advantageous. What if we wanted to export more than a single value in the context? How would we bind those named values?\n\n```typescript\n@Directive({\n\tselector: '[makePiglatin]'\n})\nexport class MakePigLatinDirective {\n\tconstructor(private templ: TemplateRef<any>,\n\t\tprivate parentViewRef: ViewContainerRef) {}\n\n\t@Input() set makePiglatin(val: string) {\n\t\tthis.parentViewRef.createEmbeddedView(this.templ, {\n\t\t\t$implicit: translatePigLatin(val),\n\t\t\toriginal: val\n\t\t});\n\t}\n}\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<p *makePiglatin=\"'This is a string'; let msg; let ogMsg = original\">\n\t\t\tThe message \"{{msg}}\" is \"{{ogMsg}}\" in 🐷 Latin\n\t\t</p>\n\t`\n})\nexport class AppComponent {}\n```\n\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-31-structural-named-context?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nJust as before, we would use semicolons to split the definitions, then bind the external (as in: from the directive) context value of `original` to the local (this template) variable of `ogMsg`.\n\n\n### Additional Attribute Inputs\n\nWith a typical — non-structural — directive, you'd have inputs that you could add to your directive. For example, you could have a directive with the following inputs:\n\n```typescript\n@Directive({\n\tselector: '[consoleThing]'\n})\nexport class ConsoleThingDirective {\n\t@Input() set consoleThing(val: string) {\n\t\tif (this.warn) {\n\t\t\tconsole.warn(val)\n\t\t\treturn\n\t\t}\n\t\tconsole.log(val)\n\t}\n\n\t@Input() warn: boolean = false;\n}\n```\n\nAnd then call them with the following template:\n\n```html\n<ng-template [consoleThing]=\"'This is a warning from the 👻 of code future, refactor this please'\" [warn]=\"true\"></ng-template>\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-32-console-non-structural-directive?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nThis can be super useful for both providing concise APIs as well as provide further functionalities to said directive simply. Structural directives offer similar, although it comes with its own syntax and limitations due to the microsyntax API.\n\n```typescript\n@Directive({\n\tselector: '[makePiglatin]'\n})\nexport class MakePigLatinDirective implements OnInit {\n\tconstructor(private templ: TemplateRef<any>,\n\t\tprivate parentViewRef: ViewContainerRef) { }\n\n\t@Input() makePiglatin: string;\n\t@Input() makePiglatinCasing: 'UPPER' | 'lower';\n\n\tngOnInit() {\n\t\tlet pigLatinVal = translatePigLatin(this.makePiglatin)\n\t\tif (this.makePiglatinCasing === 'UPPER') {\n\t\t\tpigLatinVal = pigLatinVal.toUpperCase();\n\t\t} else if (this.makePiglatinCasing === 'lower') {\n\t\t\tpigLatinVal = pigLatinVal.toLowerCase();\n\t\t}\n\t\tthis.parentViewRef.createEmbeddedView(this.templ, {\n\t\t\t$implicit: pigLatinVal,\n\t\t\toriginal: this.makePiglatin\n\t\t});\n\t}\n}\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<p *makePiglatin=\"'This is a string'; casing: 'UPPER'; let msg; let ogMsg = original\">\n\t\t\tThe message \"{{msg}}\" is \"{{ogMsg}}\" in 🐷 Latin\n\t\t</p>\n\t`\n})\nexport class AppComponent { }\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-33-pig-latin-microsyntax?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nYou can see that I've had to tweak our previous pig latin directive example a bit.\n\nFor starters, I moved away from a `set`ter for the input value and towards `ngOnInit`, just to ensure that everything was defined in the right timing.\n\nI'm also binding the value \"upper\" to `makePiglatinCasing` by adding `casing: 'UPPER'` to the input to the structural directive and then separating it by `;`.\n\nThe magic in the syntax comes from that input name. I know in previous examples I've mentioned when things were similarly named only for readability purposes and not because the syntax demands such — this is not one of those times. **The microsyntax is taking the `casing` binding from the input, making the first letter uppercase, then prepending it to the template selector to get the name of the `@Input` directive property to pass that value to.**\n\n**This is why we usually call the directive selector the structural directive prefix — it should prefix the names of any of your microsyntax inputs**. Outside of the prefix rule, there's little else that you'll need to keep in mind with these input names. Want to make it `makePiglatinCasingThingHere`? No problem, just change that part of the input syntax to read `casingThingHere: 'upper'`\n\n\n#### Why not bind like a typical input?\n\nNow, I remember when I was learning a lot of the structural directive stuff, I thought \"well this syntax is cool, but it might be a bit ambiguous\". I decided I was going to change that a bit:\n\n```html\n<p *makePiglatin=\"'This is a string'; let msg; let ogMsg = original\" [makePiglatinCasing]=\"'UPPER'\">\n\tThe message \"{{msg}}\" is \"{{ogMsg}}\" in 🐷 Latin\n</p>\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-34-pig-latin-non-binding?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nI was not, however, greeted by praises on my PR making this change, but rather by an error in my console:\n\n> Can't bind to `makePiglatinCasing` since it isn't a known property of `p`\n\nThis may seem strange upon first glance, but remember: **the structural directive wraps the tag it is on the inside of a template**. Because of this, _the `makePiglatinCasing` input is not set to the directive anymore, but rather on the `p` element inside the template created by the structural directive_.\n\nThis becomes more apparent when you expand the syntax to look something like this:\n\n```html\n<ng-template makePiglatin=\"'This is a string'; let msg; let ogMsg = original\">\n\t<p [makePiglatinCasing]=\"'UPPER'\">\n\t\tThe message \"{{msg}}\" is \"{{ogMsg}}\" in 🐷 Latin\n\t</p>\n</ng-template>\n```\n\n### Bind as you would — They're JUST directives!\n\nBut, of course, because structural directives are just normal directives under-the-hood, you can use the same directive code you'd expect to, even with some of the binding syntaxes.\n\nSo if we did want to take the non-functional example above and fix it to not use structural directives, we could do so:\n\n```html\n<ng-template [makePiglatin]=\"'This is a string'\" [makePiglatinCasing]=\"'UPPER'\" let-msg let-ogMsg=\"original\">\n\t<p>The message \"{{msg}}\" is \"{{ogMsg}}\" in 🐷 Latin</p>\n</ng-template>\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-35-pig-latin-normal-directive?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n### `as` to preserve values in template variable\n\nOne of my favorite tools at the microsyntax's disposal is the `as` keyword. On paper, it sounds extremely straightforward and duplicative of the `let` keyword:\nIt saves the context output of a specific value as a template variable.\n\nIf it sounds duplicative with that description, that's because it can absolutely be used in the same ways:\n\n```html\n<!-- These do exactly the same things -->\n<p *makePiglatin=\"let msg casing 'UPPER'; original as ogMsg\"></p>\n<p *makePiglatin=\"let msg casing 'UPPER'; let ogMsg = original\"></p>\n```\n\nBecause `original` is being exported by the `makePiglatin` context, you can save the value to a template variable `ogMsg`.\n\nBut this example doesn't showcase very much of what makes the `as` keyword as powerful as it is: _You can preserve the initial value passed to an input_. This can be used to significant effect when passing in complex expressions, such as piped values (in this example, the [uppercase pipe](https://angular.io/api/common/UpperCasePipe)):\n\n```typescript\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t\t<p *ngIf=\"message | uppercase as uppermessage\">{{uppermessage}}</p>\n\t\t<!-- Will output \"HELLO THERE, WORLD\" -->\n\t`\n})\nexport class AppComponent {\n\tmessage = \"Hello there, world\"\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-36-as-keyword?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nWhile this example can be seen clearly with this usage of `ngIf` , let's try to add it into our `pigLatin` example:\n\n```html\n<p *makePiglatin=\"'test'; let msg; casing 'upper' | uppercase as upperInUpper\">{{upperInUpper}}: {{msg}}</p>\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-37-pig-latin-as-keyword-broken?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nIn this example, we're expecting `'upper'` to be turned into `'UPPER'` by the `uppercase` pipe, then to be passed as the input to `makePiglatinCasing` and for the `$implicit` value of that context to be assigned to a local variable `msg`. If you load this, you'll noticed that the uppercased pig lattin displays as expected but the `upperInUpper` variable (which we expected to be `'UPPER'`) is undefined.\n\nThe reason is because we're not exporting a key of `makePiglatinCasing` in our context to supply this value.\n\n```typescript\nthis.parentViewRef.createEmbeddedView(this.templ, {\n\t$implicit: pigLatinVal,\n\toriginal: this.makePiglatin,\n\tmakePiglatinCasing: this.makePiglatinCasing\n});\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-38-pig-latin-as-keyword?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nNow that we're exporting the output with the `as`, it should show on-screen as expected. So why is this? **Well, `as` exports the outputted value that it's bound to.** In this case, we're binding the value to `casing` (because that's what `'upper'` is being passed as an input to).\n\nOf course, this means that you can send any value as the context. Change the code to read:\n\n```typescript\n{\n  $implicit: pigLatinVal,\n  original: this.makePiglatin,\n  makePiglatinCasing: 'See? Any value'\n}\n```\n\nAnd the DOM would now show:\n\n> See? Any value: ISTHAY ISWAY AWAY ESTTAY\n\n#### But it worked in `ngIf`\n\nAnd this is true, but only because the Angular devs were kind enough to make this syntax approachable without having to understand the inner-workings of it before using it.\n\nIf we [go back to the original section where we showed `ngIf` code from the Angular syntax](#angular-ngif-source), you can see they're using the same trick to provide the `as` value for a call to `ngIf`:\n\n```typescript\nthis._context.$implicit = this._context.ngIf = condition;\n```\n\n## Syntax Rules {#microsyntax-rules}\n\nThus far, I've been doing my best to keep the examples using a fairly consistent microsyntax. Because of this, you might think that you must use `;` to separate the calls, you need to have things in a certain order, or that there might be more rules you don't yet understand about how to use the syntax. This is not the case — the syntax is fairly loose, actually, although it can be hard to understand.\n\n### Parts Make Up The Whole {#microsyntax-parts}\n\nThe rules behind microsyntax can seem overwhelming, so let's take a look at each part on their own before coming them together.\n\nAngular's microsyntax has 4 building blocks, that when combined in a particular way, make up the entire microsyntax API. These building blocks are:\n\n- Expressions\n- The `as` keyword\n- Keyed expressions\n- `let` bindings\n\n![A chart taking a microsyntax and turning it into a diagram. This diagram will be explained thoroughly via text in this section](./microsyntax.svg \"A diagram showing the different parts of the microsyntax\")\n\n#### Expressions {#microsyntax-explain-expressions}\n\nThe way I describe expressions in simple terms is \"anything that, when referenced, returns a value\". Like the example above, it could mean using an operator (`5 + 3`), calling a function (`Math.random()`), a variable (assuming `const numberHere = 12`, `numberHere`) or just a value itself (`'a string here'`).\n\nWhile \"what is and isn’t an expression in JavaScript\" could be its own post, suffice it to say that if you’re able to pass a piece of code to a function as an argument — it’s an expression.\n\n```html\n<!-- This code is not super useful in the real-world, -->\n<!-- but is used To demonstrate the correct syntaxes -->\n<p *makePigLatin=\"'This is an expression'\"></p>\n<p *makePigLatin=\"'So is this' | uppercase\"></p>\n<p *makePigLatin=\"'So is ' + ' this'\"></p>\n<p *makePigLatin=\"varsToo\"></p>\n<p *makePigLatin=\"functionsAsWell()\"></p>\n```\n\n#### The `as` keyword {#microsyntax-explain-as}\n\nThe rules behind the `as` keyword as an alternative to `let` are fairly straightforward:\n\n- You **start with the name of the exported key** from the context\n- Then, you **use the name you want to save the value to** (as a template input variable)\n\nSo, if you had the context as `{personName: 'Corbin', personInterests: ['programming']}`, and wanted to save the value from `personInterests` to a template input variable `interestList`, you could use: `personInterests as interestList`.\n\n#### `keyExp` — Key Expressions {#microsyntax-explain-keyexp}\n\nA key expression is simply an expression that you’re able to bind to an input on a structural directive.\n\n- You **start with the `key` you’d like to bind to** the input that is prefixed with the directive selector (so `[ngIf]`’s `then` key would map to the `ngIfThen` input)\n- Then, you **optionally can place a colon** (having it or not does not affect the behavior in any way)\n- You’ll then want to **place an expression that will be passed as the input value** for the `key` you started the key expression with\n- Finally, _if you’d like to save the input value_, you’re able to **use the `as` keyword**, followed by the name you’d like to save the input value to (as a template input variable)\n\n\n```html\n<p *makePigLatin=\"inputKey: 'This is an expression' as localVar\"></p>\n<p *makePigLatin=\"inputKey: 'This is an expression'\"></p>\n<p *makePigLatin=\"inputKey 'This is an expression' as localVar\"></p>\n<p *makePigLatin=\"inputKey 'This is an expression'\"></p>\n```\n\n#### `let` bindings {#microsyntax-explain-let}\n\nThe `let` binding:\n\n- Starts with a `let` preserved keyword\n- Then lists the template input variable to save the value to\n- You’ll then want to put the key of the context you want to save a value of after a `=` operator\n\t- It’s worth mentioning that this is optional. This is because of the `$implicit` key in context.\n\t\tEG: a context of `{$implicit: 1, namedKey: 900}` and `let smallNum; let largerNum = namedKey` would assign `1` to `smallNum` and `900` to `largerNum`\n\n### Combining Them Together\n\nNow that we understand all of the parts by themselves, let’s combine them together to get a macro view at the microsyntax.\n\n![A chart showing the microsyntax rules all-together. Rules explained below](./microsyntax_main.svg \"Microsyntax combined chart\")\n\n- The start to any structural directive call is **the `*` reserved token** (a token, in this case, is just a symbol marked to do something). This just marks the directive call to be handled as a structural directive.\n\n- Then, you have **the `selector` value** of the directive itself (which acts as a prefix to the inputs)\n\n- You bind to the selector as you would any other input using **`=\"`** tokens\n\nThe contents of the input itself is where the microsyntax goes.\n\n#### First Item\n\nThe first item that’s allowed in the microsyntax is either an expression or a `let` binding.\n\nIf an expressing `*prefix=\"5 + 3\"` is passed, this value will be passed to the same input name as the selector itself: EG the `ngIf` input on the directive with the `[ngIf]` selector value.\n\nIf a `let` binding is the first item, it will work exactly as it’s explained in [the previous section](#microsyntax-explain-let)\n\n```html\n<!-- ✅ These ARE valid for the first item -->\n<p *makePigLatin=\"'Expression'\"></p>\n<p *makePigLatin=\"let localVar = exportKey\"></p>\n\n<!-- 🛑 But these are NOT valid for the first item -->\n<p *makePigLatin=\"inputKey: 'Input value expression'\"></p>\n<p *makePigLatin=\"exportKey as localVar\"></p>\n```\n\n#### Second Item and Beyond\n\nAfter the first item, _you’re able to pass in a `let` binding, an `as` binding, or a key expression_. **There can be as many of these items in a microsyntax as you’d like, so long as they’re one of those 3**. These will act the way you expect them to as before. You’re not, however, able to pass an expression to act as the default input value — that’s preserved only for the first item.\n\n```html\n<p *makePigLatin=\"'First'; let localVar = exportKey\"></p>\n<p *makePigLatin=\"'First'; exportKey as localVar\"></p>\n<p *makePigLatin=\"'First'; inputKey: 'Input value expression'\"></p>\n<!-- And you can do more than one! -->\n<p *makePigLatin=\"'First'; let localVar = exportKey; exportKey as localVar; inputKey: 'Input value expression'\"></p>\n```\n\n## Optional Separators\n\nJust as the `:` is optional in a [key expression](#microsyntax-explain-keyexp), **all separators in the microsyntax are optional**.\n\nThese are all valid:\n\n```html\n<!-- You can mix and match which tokens you leave or don't -->\n<p *makePigLatin=\"'First'; let localVar = exportKey; exportKey as localVar; inputKey: 'Input value expression'\"></p>\n\n<!-- Remember that the key expression's `:` token is optional -->\n<p *makePigLatin=\"'First'; let localVar = exportKey exportKey as localVar; inputKey 'Input value expression'\"></p>\n\n<!-- All separator tokens are optional -->\n<p *makePigLatin=\"'First' let localVar = exportKey exportKey as localVar inputKey 'Input value expression'\"></p>\n\n<!-- You can shorten the `as` binding, as it's also part of the `let` binding -->\n<!-- as an optional second part -->\n<p *makePigLatin=\"'First' let localVar = exportKey as localVar; inputKey 'Input value expression'\"></p>\n```\n\n## Let's remake `ngFor`\n\n[The Angular section on structural directives say that you should probably study the `ngFor` code to understand them better](https://angular.io/guide/structural-directives#microsyntax). Let's do them one better — let's make our own.\n\nWell, admittedly, the code for `ngFor` is a bit complex and handles a lot more than I think would be covered by the scope of this post; Let's at least make a version of it that supports a limited part of its API (just for conciseness).\n\nSo, what is the API we want to support?\n\n`*uniFor=\"let item of items; let firstItem = isFirst\"`\n\nSounds reasonable enough. Just to make things even easier on us, let's not worry about re-rendering the list if it updates or properly cleaning up if this directive view unrenders. These requirement changes make our code much more simple for demonstration purposes, but inherently makes the resulting code unfit for production.\n\n```typescript\n@Directive({ selector: '[uniFor]' })\nexport class UniForOf<T> implements AfterViewInit {\n\t@Input() uniForOf: Array<T>;\n\n\tconstructor(\n\t\tprivate viewContainer: ViewContainerRef,\n\t\tprivate template: TemplateRef<any>\n\t) {}\n\n\tngAfterViewInit() {\n\t\tthis.uniForOf.forEach((ofItem, i) => {\n\t\t\tthis.viewContainer.createEmbeddedView(this.template, {\n\t\t\t\tisFirst: i === 0,\n\t\t\t\t$implicit: ofItem,\n\t\t\t\tuniForOf: this.uniForOf\n\t\t\t})\n\t\t})\n\t}\n}\n\n@Component({\n\tselector: 'my-app',\n\ttemplate: `\n\t<p *uniFor=\"let num of numbers | async as allNumbers; let firstItem = isFirst\">\n\t\tNumber in a list of {{allNumbers.length}} numbers: {{num}}\n\t\t<ng-container *ngIf=\"firstItem\"> it's the first number!</ng-container>\n\t</p>\n\t`\n})\nexport class AppComponent {\n\t// `import {of} from 'rxjs';`\n\tnumbers = of([1,2,3,4,5])\n}\n```\n\n<iframe src=\"https://stackblitz.com/edit/start-to-source-39-uni-for?ctl=1&embed=1&file=src/app/app.component.ts\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n- We're starting with enabling `uniFor` as the structural directive name\n- Then we're defining an input to accept `of` as a key in the syntax (to match the `ngFor` structural directive syntax).\n\n- We can then reference this value later with `this.uniForOf` just as we are in the `ngAfterViewInit`.\n\n- In that lifecycle method, we're then creating an embedded view for each item in the array\n\t- This view is passed a context with an implicit value (so that `_var` in`let _var of list` will have the value of this item)\n\t- We also pass the index to the context to give a boolean if an item is the first in a list\n\t- Then we pass a `uniForOf` so that we can use `as` to capture the value passed to the `of` portion of the syntax\n- Finally, we use the [async pipe](https://angular.io/api/common/AsyncPipe) to get the value of the array that's inside of an observable\n\n# Conclusion\n\nAll in all, Angular has extremely powerful tools that it provides to you out-of-the-box for managing templates across your application. While a lot of these examples have been small, silly, and contrived, they've loosely come from patterns I've seen in very large Angular libraries. As a result, utilizing them can solve many problems and serve as a starting point for highly extensible code.\n\nOther than that, that's it! You reached the end! You did it! 🎊\n\nThank you so much for taking the time to read through, always feel free to reach out on Twitter or comment in the comment section below to ask further questions or add to the conversation/teach me something, always happy to help and always loving to learn!\n",
		},
		{
			title: "Networking 101: A Basic Overview of Packets and OSI",
			description:
				"You use networking every day - even to read this! Let's dive into explaining how we send data across a network and what the OSI model is.",
			published: "2020-03-11T13:45:00.284Z",
			authors: ["reikaze", "crutchcorn"],
			tags: ["networking"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			series: "Networking 101",
			order: 1,
			slug: "basic-overview-of-packets-and-osi",
			locale: "en",
			authorsMeta: [
				{
					id: "reikaze",
					name: "Kevin Mai",
					firstName: "Kevin",
					lastName: "Mai",
					description:
						"Hello! I'm Kevin Phong Mai, aka Reikaze or RockmanDash12, a Computer Engineering Student and Freelance Writer passionate about Tech, Anime, Visual Novels and much more. I'm the Owner of RockmanDash Reviews Blog, and I write for the AniTAY & FuwaNovel blogs.",
					socials: { twitter: "Reikaze0", github: "Reikaze" },
					pronouns: "he",
					profileImg: "./reikaze.jpg",
					color: "#ba68c8",
					roles: ["author"],
					profileImgMeta: {
						height: 718,
						width: 718,
						relativePath: "./reikaze.jpg",
						relativeServerPath: "/content/data/reikaze.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\reikaze.jpg",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Networking 101: A Basic Overview of Packets and OSI",
				description:
					"You use networking every day - even to read this! Let's dive into explaining how we send data across a network and what the OSI model is.",
				published: "2020-03-11T13:45:00.284Z",
				authors: ["reikaze", "crutchcorn"],
				tags: ["networking"],
				attached: [],
				license: "cc-by-nc-sa-4",
				series: "Networking 101",
				order: 1,
			},
			contentMeta:
				"\nNetworking is the foundation that all interactions on the internet are built upon. Every chat you send, every website you visit, _every interaction that is digitally shared with another person is built upon the same fundamentals_. These fundamentals layout and explain how computers are able to communicate with one another and how they interlink with one another in order to provide you with the experience you've come to know and love with the internet.\n_This article is the beginning of a series that will outline the core components that construct those very same fundamentals_. However, without a holistic view, it may be difficult to follow along with many of the more minute details. As such, we'll be covering what each of the core components at play is and how they fit into the grand scheme of things. The articles to follow will explain and expand upon this base of knowledge.\n\nIt's important to note that _\"networking\" is a broad, catch-all term that infers **any** communication between one-or-more computer devices_. This includes parts in your computer communicating between themselves. For example, do you need your computer keyboard input to be processed by your CPU to display data on-screen? That requires the networking to transfer the data to the CPU and from your CPU to your monitor, so on and so forth. As a result, this article will be a bit broad in order to cover not just cross-device hardware, but inter-device communication fundamentals as well. We'll dive deeper into cross-device communication in future articles in the series\n\n> If you don't understand how CPUs work, that's okay, it's not required knowledge for this post. Just know that they take in binary data, process it, then send data out to other devices to use. They convert binary data into binary instructions for other devices to follow\n>\n> That said, you need the right binary data to be input into the CPU for it to process, just like our brains need the right input to find the answer of what to do. Because of this, communication with the CPU is integral\n\n# Architecture {#network-architectures}\nThere are a lot of ways that information can be connected and transferred. We use various types of architecture to connect them. \n\n_Computers speak in `1`s and `0`s, known as binary_. These binary values come in incredibly long strings of combinations of one of the two symbols to _construct all of the data used in communication_.\n\n> [We covered how these two numbers can be combined to turn into other data in another post](/posts/non-decimal-numbers-in-tech/). For a better understanding of how binary represents data, check out that post.\n\nThis is true regardless of the architecture used to send data - it’s all binary under-the-hood somewhere in the process. The architecture used to send data is simply a way of organizing the ones and zeros effectively to enable the types of communication required for a specific use-case.\n\n## Bus Architecture {#bus-architecture}\n\nFor example, one of the ways that we can send and receive data is by, well, sending them. _The bus architecture_, often used in low-level hardware such as CPU inter-communication, _simply streams the ones and zeros directly_.\n\nIt doesn't wait for a full message to be sent or provide many guidelines for how to send the data, it just tells them to \"come on over\".\n\n<video src=\"./bus_animation.mp4\" title=\"A series of cars driving across 3 lines at various speeds. This is meant to represent the data flow of binary data on a bus architecture\"></video>\n\nIn this example, the bus icons are similar to binary data - either a one or a zero. They're able to _move as quickly as possible down a \"lane\" that is allocated for a specific stream of data to come through_. A collection of \"lanes\" is called a \"bus\" (which is where the name of the architecture comes from. I was just being silly by representing the binary data as buses in the video above). Your system, right now, is streaming through _**many**_ thousands of these busses to communicate between your CPU and I/O devices (like your keyboard or speakers) and tons of other things. They're _typically divided to send specific data through specific lanes (or busses)_, but outside of that, there's little high-level organization or concepts to think through.\n\nFurthermore, because error-handled bi-directional cancelable subscriptions (like the ones you make to servers to connect to the internet) are difficult using the bus architecture, _we typically don't use it for large-scale multi-device networks like the internet_.\n\n## Packet Architecture {#packet-architecture}\n\nThe weaknesses of the bus architecture led to the creation of the packet architecture. The packet architecture requires a bit more of a higher-level understanding of how data is sent and received. To explain this concept, we'll use an analogy that fits really well. \n\nLet's say you want to send a note to your friend that's hours away from you. You don't have the internet so you decide to send a letter. In a typical correspondence, you'd send off a letter, include a return address, and wait for a response back. That said, _there's nothing stopping someone from sending more than a single letter before receiving a response_. This chart is a good example of that:\n\n![An image showcasing the rules of data sending both ways](./image_of_unidirectional_data_being_sent.svg)\n\nSimilarly, a packet is _sent from a single sender, received by a single recipient, addressed where to go, and contains a set of information_.\n\n### Metadata {#packet-metadata}\n\nLetters may not give you the same kind of continuous stream of consciousness as in-person communications, but they do provide something in return: structure.\n\nThe way you might structure your thoughts when speaking is significantly different from how you might organize your thoughts on paper. For example, in this article, there is a clear beginning, end, and structured headings to each of the items in this article. Such verbose metadata (such as overall length) cannot be communicated via in-person talking. _The way you may structure data in a packet may also differ from how you might communicate data via a bus_. \n\nThat said, simply because there's a defined start and an end does not mean that you cannot _send large sequences of data through multiple packets and stitch them together_. Neither is true for the written word. This article does not contain the full set of information the series we hope to share, but rather provides a baseline and structure for how the rest of the information is to be consumed. So too can packets provide addendums to other packets, if you so wish.\n\n#### Headers\n\nNot only does the spoken-word lack the same form of structure that can be provided by the written word, but _you're also able to categorize and assign metadata to a letter_ that you wouldn't be able to do with a conversation. You do this every time you send a letter to someone through the mail: You include their name, address, and return address on the envelope that's used to send the letter. The same is done with packets.\n\nWhile the \"body\" of your packet would contain the data you want the other party to receive, the \"header\" of the packet might contain data **about** said data. Such metadata might include the size of the contained data or the format that data is in.\n\n![A breakdown of a packet showing a combination of a header with metadata and a body with data for the client](./breakdown_of_a_packet.svg)\n\nAs a result, you might have a middleware packet handler that reads only the header of the packet in order to decide where to send the packet in question - much like the mail service you use will read the outside of the envelope to see where to send your letter\n\n<video src=\"./header_routing.mp4\" title=\"An example of a small packet being sent to a small file server and a larger packet being sent to the large file server based on the data in the packet header\"></video>\n\n# [It Takes A Village](https://en.wikipedia.org/wiki/It_takes_a_village) To Send A Letter {#osi-layers}\n\nUnderstanding what a letter is likely the most important part of the communication aspect if you intend to write letters, but if someone asked you to deliver a letter it helps to have a broader understanding of how the letter gets sent. That's right: _there's a whole structure set in place to send the letters (packets) you want to be sent_. This structure is comprised of many levels, which we'll outline here.\n\n> For each of these levels, there are many intricacies that we won't be touching on. This is for the sake of conciseness. As this article is only the start of the series, you can expect these intricacies to be explained with greater detail as these articles are released\n\nThis structure is comprised of seven levels for most networking applications. _These layers interact with one another as a form of stack-the-blocks method_. For example, describing layer 4 encapsulates the behavior of layers 3 and 2. As a result, lower-level applications of networking may have fewer than seven layers. That said, those seven levels are, in order:\n\n- Application\n- Presentation\n- Session\n- Transport\n- Network\n- Data Link\n- Physical\n\nAs you communicate with others online, and as computers communicate within themselves using packets, they go down those layers, then back up them to be processed and interpreted\n\n![A diagram of the aforementioned layers with lines communicating data flow down then up that list](./osi_layer.svg)\n\nThis breakdown of layers is referred to as the [OSI model](https://en.wikipedia.org/wiki/OSI_model). This conceptual model allows us to think abstractly about the different components that make up our network communications. While we won't do a deep-dive into each layer here, we'll try to at least make them fit into our mailroom analogy.\n\nLet's start from the bottom and make our way up. Remember that each of these layers builds on top of each other, allowing you to make more complex but efficient processes to send data on each step.\n\n## Physical {#osi-layer-1-physical}\n\nThe physical layer is similar to the trucks, roads, and workers that are driving to send the data. Sure, you could send a letter just by handing letters one-by-one from driver to driver, but without some organization that's usually dispatched to higher levels, things can go wrong (as they often do [in a game of telephone](https://en.wikipedia.org/wiki/Chinese_whispers)).\n\nIn the technical world, _this layer refers to the binary bits themselves_ ([which compose to makeup letters and the rest of structure to your data](/posts/non-decimal-numbers-in-tech/)) _and the physical wiring_ constructed to transfer those bits. As it is with the mail world, this layer alone _can_ be used alone, but often needs delegation from higher layers to be more effective.\n\n## Data Link {#osi-layer-2-data-link}\n\nData link would be like UPS or FedEx offices: sending information between post office to post office. These offices don't have mail sorters yet (that's a layer up) but they do provide a means for drivers to arrive to exchange mail at a designated area. As a result, instead of having to meet the drivers in the road to receive my mail, I can simply go to a designated office to receive my mail.\n\nLikewise, _the data link layer is the layer that transfers binary data between different locations_. This becomes especially helpful when _dealing with local networks that only exchange data between a single physical location_, where you might not need the added complexity large-level packet sorting might come into play.\n\n## Network {#osi-layer-3-network}\n\nThe network layer is similar to the mail sorters. Between being transferred from place to place, there may be instances where the mail is needed to be sorted and organized. This is _done with packets in the network layer to handle routing_ and other related activities between clients\n\n## Transport {#osi-layer-4-transport}\n\nThe transport layer delivers it from the post office to my apartment building. This means that not only does the package gets delivered from post-office building to post-office building, but it gets to-and-from its destination as intended.\n\n## Session {#osi-layer-5-session}\n\nWith newer packages delivered through services like UPS, you may want a tracking number for your package. This is similar to the session layer. With this layer, it includes a back-and-forth that can give you insight into the progress of the delivery or even include information like return-to-sender.\n\n## Presentation {#osi-layer-6-presentation}\n\nBut when a package gets received by you, it doesn't stop there, does it? You want to bring the package inside your home. For most packages, this is relatively trivial - you simply take it inside. However, for some specialized instances, this may require hiring movers to get a couch in your house. In this same way, HTTP and other protocols don't typically differentiate between the presentation layer and the application layer, but some networks do. When they do, they use the presentation layer to outline how the data is formed for sending and receiving\n\n## Application {#osi-layer-7-application}\n\nYou've just been delivered the fancy new blender you ordered for smoothies. After unwrapping the package, you plug it in and give it a whirl, making the most delicious lunch-time smoothie you've ever had. Congrats, you've just exemplified the application layer. In this layer, it encapsulates the layer your user (developer or end-user alike) will use, the application that communicates back-and-forth and the reason you wanted to send data in the first place.\n\n# Conclusion\n\nWe've done an initial overview of what layers you utilize when accessing a network. Although we've only done an initial glance at those layers, the next few steps will outline what those layers comprise of, and how data can transfer across a network. These steps will come in the order of various articles in the series in the future. To make sure you don't miss those next articles, be sure to subscribe to our newsletter down below!\n\nYou can also [join us in our community Discord](https://discord.gg/FMcvc6T) and chat with us there!\n",
		},
		{
			title: "Change the Host File of an Android Emulator",
			description:
				"In order to test web applications with Android properly, you may need to edit the Android Emulator network host file. Here's how to do so.",
			published: "2019-12-27T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["android"],
			attached: [],
			license: {
				id: "cc-by-4",
				footerImg: "https://i.creativecommons.org/l/by/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by/4.0/",
				name: "Attribution 4.0 International (CC BY 4.0)",
				displayName: "Creative Commons Attribution 4.0 International License",
			},
			originalLink:
				"https://www.thepolyglotdeveloper.com/2019/12/change-host-file-android-emulator/",
			slug: "change-host-file-android-emulator",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Change the Host File of an Android Emulator",
				description:
					"In order to test web applications with Android properly, you may need to edit the Android Emulator network host file. Here's how to do so.",
				published: "2019-12-27T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["android"],
				attached: [],
				license: "cc-by-4",
				originalLink:
					"https://www.thepolyglotdeveloper.com/2019/12/change-host-file-android-emulator/",
			},
			contentMeta:
				"\nWhile working on a bug in one of my projects recently, I found an  issue that I could only recreate on an Android device. However, due to  some cross-origin resource sharing (CORS) issues on my server, I had to  serve my development environment from a changed hostfile that had a  specific subdomain of my project.\n\nWith the ability to use a remote Chrome debugger from your desktop to a mobile device, you can use an  emulator and still have your full Chrome debugging capabilities. The  only problem then, is how to get the host file to match your desktop  environment. Following these steps will allow you to do just that!\n\n## Pre-Requisites\n\nIn order to do this, you’ll need to install a few things first:\n\n- [Download and install Android Studio](https://developer.android.com/studio/install)\n\nDuring installation, it will ask you if you want to setup an emulator. You’ll  want to install all of the related Intel Virtualization packages, as it  will greatly increase your speed of the emulator.\n\n- Download and install the android-platform-tools. This will include \n\n  ```\n  adb\n  ```\n\n   command directly on your path for you to utilize\n\n  - For macOS, I suggest using [the Homebrew package manager](https://brew.sh/) and running `brew cask install android-platform-tools`\n  - For Windows, I suggest using [the Chocolatey package manager](https://chocolatey.org/) and running `choco install adb`\n  - For Linux, you’ll want to check with your package manager for one of the two above-mentioned package names\n\n## Setup Steps\n\nOnce you have Android Studio installed, we’ll need to setup an emulator. To do so, open the application:\n\n![The opening screen to Android Studio](./1.png)\n\nThen, press “Configure” in the bottom right corner. Then press the “AVD Manager” in the sub-menu.\n\n![The sub-menu for configure in the Android Studio startup screen](./2.png)\n\nYou’ll see a popup window that will show you the list of virtual devices. *These are devices that will be used in order to run an emulator*. You may already have a virtual device setup from the initial setup of  Android Studio. They include the version of the operating system you use when you boot up the device. While the virtual device that was setup  out-of-the-box is fine for most operations, we’ll want to setup an older version of the emulator. This will allow us to change the host file in  Android, which requires root (something the default images won’t allow).\n\nSelect **Create Virtual Device**, then select a device type. In my example, I selected **Nexus 5**, but any device definition of a relatively modern phone should work.\n\n![A popup dialog for creating a new virtual device setup](./3.png)\n\nAs mentioned before, the default images that are provided will not allow us to replace the host files. In order to do so, *we have to download an older Android image* (and one that does not include Google Play Store). To do this, I selected the **x86_64 Android 7.1.1** (non Google API version) image to download and then selected **Next**.\n\n![The selection of the aforementioned Nougat image](./4.png)\n\nIt’s worth noting that we specifically must select a non-Google version,  otherwise our future commands will not work (per Google’s restrictions  on Google API images).\n\nAfter this step, proceed to name the Android Device. *I’d suggest you name it something without any spaces in order to run a command later that you’ll need to run*. In this case, I called the image **Nexus5**.\n\n![My naming of the AVD](./5.png)\n\n## Handling the Emulator\n\nOnce the AVD is initially setup, open your terminal, and find your installation path of Android Studio.\n\n- For MacOS, this should be under **~/Library/Android/sdk**\n- For Windows, this *should* be **C:\\Users<username>\\AppData\\Local\\Android\\sdk**\n\nOnce in that path, you want to run a specific emulator command:\n\n```bash\n./emulator/emulator -writable-system -netdelay none -netspeed full -avd <AVDName>\n```\n\nFor example, given that I’m on macOS and my AVD name is **Nexus5**, I ran:\n\n```bash\n~/Library/Android/sdk/emulator/emulator -writable-system -netdelay none -netspeed full -avd Nexus5\n```\n\nThis will start the emulator under specific  pretenses. These pretenses will allow you to write to any file on your  OS, including the host file.\n\n![A screenshot of the above command running and the emulator started](./6.png)\n\nOnce you’re done with running the emulator, open a new tab and run the  following commands (in a folder you want to have the host file within):\n\n- `adb root`\n- `adb remount`\n- `adb pull /system/etc/hosts`\n\n![A screenshot of the above commands running](./7.png)\n\nUpon running these commands, you’ll find a **hosts** file. *This file is the file that tells your OS what path a given domain has.* You can, for example, map `example.com` to go to a specific IP address, similar to how DNS works for most domains.\n\nInside the emulator, the IP address `10.0.2.2` refers to the *host* OS. For example, if you’re running a local server on your Windows/MacOS/Linux machine on `localhost:3000`, you can access it using `10.0.2.2:3000` from the Android emulator.\n\nKnowing these two things, you can change the host file to make `example.com` refer to the host by adding the following to the host file:\n\n```plaintext\n10.0.2.2 example.com\n```\n\n![A screenshot of the host file being edited using micro](./8.png)\n\n## Pushing the Changes\n\nOnce you’ve made the changes to the host file that you want to have changed, you’ll have to push the host file to the OS of the AVD:\n\n- `adb push ./hosts /etc/hosts`\n- `adb push ./hosts /etc/system/hosts`\n- `adb push ./hosts /system/etc/hosts`\n\nWhile only one of these host file locations is needed to replaced, it’s  easier to run all three than only run one to see if it worked\n\n![A screenshot of the above commands being ran](./9.png)\n\nIn order for the changes to the host file to take effect, you’ll have to  restart the emulator. In order to do so, you’ll want to press and hold  the power button off to the right of the emulator. Then, press  “Restart”.\n\nIf you close the emulator and re-open it using the  command above, it may work, but I’ve found instances where it seems to  reset the host file, making you go through the whole process again\n\n![A screenshot of the above commands being ran](./10.png)\n\n## Seeing the Results\n\nFinally, you’re able to [sideload the Chrome APK’s x86 variant](https://www.apkmirror.com/apk/google-inc/chrome) in order to load the example codebase.\n\nSo, for example, using the above hostfile as an example, we can visit `example.com:8000` when running the development mode for [the project’s GitHub code](https://github.com/unicorn-utterances/unicorn-utterances/), you’re able to see a preview of the [Unicorn Utterances](https://unicorn-utterances.com) website from a different domain.\n\n![A screenshot of the above commands being ran](./11.png)\n\nAnd that’s it! You now know how to modify and update the host file for an  emulated Android device. I hope this has helped with your development  usage!\n",
		},
		{
			title: "Chess Knight Problem: a quick and dirty solution in JavaScript",
			description:
				"I present a quick and dirty solution to a common interview question where the solution is not nearly as complex as it may first appear.",
			published: "2020-04-29T12:27:06.284Z",
			authors: ["thodges314"],
			tags: ["javascript", "computer science", "interviewing"],
			attached: [],
			license: {
				id: "cc-by-4",
				footerImg: "https://i.creativecommons.org/l/by/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by/4.0/",
				name: "Attribution 4.0 International (CC BY 4.0)",
				displayName: "Creative Commons Attribution 4.0 International License",
			},
			slug: "chess-knight-problem",
			locale: "en",
			authorsMeta: [
				{
					id: "thodges314",
					name: "Thomas Hodges",
					firstName: "Thomas",
					lastName: "Hodges",
					description:
						"A software engineer with a mathematical background, professional experience in frontend, primarily with Reactjs and D3js, and a strong interest in mathematical modeling and visualisations.",
					socials: { github: "thodges314", linkedIn: "thomas-hodges" },
					pronouns: "he",
					profileImg: "./thodges.png",
					color: "#ba68c8",
					roles: ["author"],
					profileImgMeta: {
						height: 455,
						width: 455,
						relativePath: "./thodges.png",
						relativeServerPath: "/content/data/thodges.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\thodges.png",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Chess Knight Problem: a quick and dirty solution in JavaScript",
				description:
					"I present a quick and dirty solution to a common interview question where the solution is not nearly as complex as it may first appear.",
				published: "2020-04-29T12:27:06.284Z",
				authors: ["thodges314"],
				tags: ["javascript", "computer science", "interviewing"],
				attached: [],
				license: "cc-by-4",
			},
			contentMeta:
				"\nHere's a classic problem in Computer Science that is said to come up in various forms on programming interviews: given an 8 x 8 chessboard, a selected starting square, and a selected ending square, what is the minimum number of legal moves required to get a knight piece from the starting square to the ending square? Note that this is _not_ the same as Knight's Tour, which is a much more involved problem where we try to find a path around the board such that the knight touches every square once without repeat.\n\nFor some background - a chess knight moves in an L-shaped pattern - two up and one to the right, two to the left and one up, and so on. The knight jumps from it's starting location to it's ending location.\n\nThis is a diagram showing all possible knight moves:\n\n![A list of possible moves for a knight centered on a chessboard, following the L pattern mentioned above](./knight-moves-0.png)\n\nThe red mark above is an arbitrary starting point, and the green marks are all of the possible places that the knight can jump from that point.\n\n# Solution Method {#solution-method}\n\nAt first glance, this may look like a bizarre maze navigation algorithm with complex rules, and inspires any number of thoughts of number of possible iterations, how to decide if a move is constructive or not, etc.\n\nHappily, our solution is much simpler, such that I was able to tap one up in JavaScript in a single evening after I decided to look into this problem.\n\nIf, in the diagram above, we start in the red space, all of the green spaces are places we can go in one move. Let's label out starting spot '0', and the places that we can go in one move with '1.'\n![Possible moves for a knight centered on a chessboard with the initial location populated by a 0 and the possible moved populated by 1s.](./knight-moves-1.png)\n\nLet's choose one of those spots and see all of the places that we can go from there. Any spot that we can reach from this spot is a place that we can reach in two moves from our starting spot. Let's label them with '2's.\n![Same image as above, but with one of the 1s highlighted, and the possible moved from there populated by 2s.  In the starting space, we see both a 0 and a 2.](./knight-moves-2.png)\n\nNotice that our starting square is double occupied. We can reach this spot in either zero moves or two moves. However, we want to know the _least_ number of possible moves to get to this spot. Zero is fewer than two, so we shall occupy this space with a '0.' I will remove the '2' and fill in the remaining spots that we can reach in two moves as being those that are one move away from the other '1' squares:\n![All of the squares labeled for 0, 1 or 2 moves with no overlap, based on the images above.  There are a few blank squares.](./knight-moves-3.png)\n\nSo, right now, we have all of the squares labelled that we can get to in zero, one or two moves. If you would like, you can fill in three moves and possibly four moves if that is required to fill every square. Remember to give precedent to the lower number in any already occupied squares.\n\nIf any of the labeled squares is the desired destination, then we know the minimum number of moves required to reach that square. So, all we have to do is start with our starting square and repeat this process until we happen to fill our ending destination with a number. The number in that square will be the minimal number of moves required to reach that spot.\n\n# JavaScript Execution {#js-execution}\n\nSo, let's get started. I hacked this together in CodePen, and I didn't build an interface for it, but that would be an easy enough step. We could do all kinds of animations in D3js, etc, but that's not for this blog post.\n\nTo begin, let's define a two dimensional array to be our chess board:\n\n```javascript\nconst board = [];\nfor (let i = 0; i < 8; i++) {\n\tboard[i] = [];\n}\n```\n\nThat's it. All we need is a two-dimensional 8x8 array. I've not explicitly defined the number of entries in either dimension of the array because that's one of the idiosyncrasies of JavaScript. (It would be possible to say something like `let board = Array(8);` but it's not clear how much that will benefit performance here. JavaScript is famous for not having the same memory management optimizations of languages like FORTRAN - also note that I didn't need to prepopulate the array with null values, as I would have to with many other languages).\n\nLet's make a function to add a move to the board. We need to see if the location is both in range and not occupied by another number before adding that move:\n\n```javascript\nconst addMove = (x, y, level) => {\n\tif (x >= 0 && x <= 7 && y >= 0 && y <= 7 && board[x][y] == null) {\n\t\tboard[x][y] = level;\n\t}\n};\n```\n\nYou may have noticed that I have checked if `board[x][y] == null`, rather than just `!board[x][y]`. This is because `0` is a potential entry for one of the squares (our staring square) and `0` is falsy.\n\nLet's call this from another function that for any given location, tries to add all of the moves for that can be reached from that location:\n\n```javascript\nconst addAllMoves = (x, y, level) => {\n\taddMove(x + 1, y + 2, level);\n\taddMove(x + 2, y + 1, level);\n\taddMove(x + 2, y - 1, level);\n\taddMove(x + 1, y - 2, level);\n\taddMove(x - 1, y - 2, level);\n\taddMove(x - 2, y - 1, level);\n\taddMove(x - 2, y + 1, level);\n\taddMove(x - 1, y + 2, level);\n};\n```\n\nThere might be a way to do this systematically, but for what I was doing, it was easier to tap it out by hand. Notice that we didn't have to check for valid moves because that is handled by `addMove()`.\n\nNow, let's make a function to scan the board, look for all squares occupied by a given number, and to call `addAllMoves()` for each occupied space:\n\n```javascript\nconst addAllPossible = (level) => {\n\tfor (let i = 0; i < 8; i++) {\n\t\tfor (let j = 0; j < 8; j++) {\n\t\t\tif (board[i][j] === level) {\n\t\t\t\taddAllMoves(i, j, level + 1);\n\t\t\t}\n\t\t}\n\t}\n};\n```\n\nI hope that you can predict where this is going. Let's make a master function to tie all of this together:\n\n```javascript\nconst findPath = (startX, startY, endX, endY) => {\n\taddMove(startX, startY, 0);\n\tlet index = 0;\n\tdo {\n\t\taddAllPossible(index++);\n\t} while (board[endX][endY] == null);\n\treturn board[endX][endY];\n};\n```\n\nFinally: I'll test this function with some of the spots we have labeled in the diagram above. Labeling the columns left to right and the rows start to finish, we start from `[3,3]`. One of the spots we can get in one move is `[2,1]`.\n\n```javascript\nconsole.log(findPath(3, 3, 2, 1));\n```\n\nI correctly got 1.\n\nOne of the spots that we can reach in 2 moves is \\[4,6\\].\n\n```javascript\nconsole.log(findPath(3, 3, 4, 6));\n```\n\nI correctly got 2.\n\nIf you want to try this yourself, [here is my CodePen project](https://codepen.io/thodges314/pen/ZEbJzPX). Enlarge the JavaScript panel and open the console along the bottom of the page to try this out.\n\n![Image of the codepen interface with the JavaScript panel and the built in concole panel expanded.](./display-knight.png)\n",
		},
		{
			title: "My Advice to Technical Interviewers",
			description:
				"Interviewing candidates is tough. It just is. Here are just a few of my tips to make your tech recruiting go smoother.",
			published: "2021-05-03T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["interviewing"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink: "https://coderpad.io/blog/5-tips-for-tech-recruiting/",
			slug: "corbin-advice-to-technical-interviewers",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "My Advice to Technical Interviewers",
				description:
					"Interviewing candidates is tough. It just is. Here are just a few of my tips to make your tech recruiting go smoother.",
				published: "2021-05-03T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["interviewing"],
				attached: [],
				license: "coderpad",
				originalLink: "https://coderpad.io/blog/5-tips-for-tech-recruiting/",
			},
			contentMeta:
				"\nTech recruiting is difficult. Interviews are tricky for candidates - and for interviewers. One of the untold challenges of interviewing is knowing how to set up good candidates for success. After all, you want a process that tests the right skills, and filters out the noise that is not helpful to evaluating candidates.\n\n\nThis can be done in many ways, but let’s talk about a few today.\n\n# Don’t Be Afraid To Help\n\nSomething to keep in mind while interviewing candidates is that they’re just like you and me: people. People that make mistakes from time-to-time or might get stuck on a certain phrasing of a question. \n\nOftentimes, lending a gentle helping hand can be the ticket to a successful interview. It can be as simple as rephrasing the question in a way that points towards the solution, or providing a structural bit of code that needs tweaking in order to be solved.\n\nThis is particularly beneficial for junior engineers, who’s interviews should focus more on “thought process” and “ability to learn and communicate” than existing skill sets. However, even senior engineers can have the solution escape them until it finally clicks with some small assistance.\n\n\nWhile this all might seem counterintuitive to assist a candidate (even in small ways) during an interview, you have to remember that they need support. In their future role with your company, they won’t (and shouldn’t) be working in isolation. Instead, they will have a team to lean on. By giving a small hint here and there, you’re able to understand how they receive feedback and when they need help.\n\n# Allow for Resources\n\nAs mentioned earlier, candidates are just people. Because of that, you will never find an all-knowing candidate who only ever relies solely on their existing knowledge to fix an issue (no matter what big-ego Jim says). Time-and-time again I’ve heard from seasoned developers that research and cheat-sheets are part of their daily engineering work. \n\nWhile it might not be immediately obvious, knowing how to search for and find the relevant content is incredibly important. Not only that, it’s something that’s developed gradually alongside a developer’s journey - just like any other skill.\n\n\nAfter all, the point of coding interviews is to see how capable a developer is at the job they’re applying for. You want to test in real-world situations, not in an isolated environment that doesn’t represent the daily aspects of the job.\n\n# Less Algorithms, More Demos\n\nSpeaking of representing a job in a more realistic light: think about the last time you had a ticket in your backlog that required discussion of tree reversal (or similar algorithm). Now think of the last time you asked a question like that in your interviews. See where I’m going here? I’m not implying that algorithm questions are inherently bad for every position, but in this industry they’ve been used as a stop-gap for more relevant questions.\n\nMany engineers can attest to being asked algorithmic questions in an interview - only to be working with styling and application state management in their day jobs. The usage of complex algorithms are far-and-few between - especially in front-end engineering. \n\nEven when algorithms ***are\\*** relevant, there’s usually a team to discuss with, research to be done, and benchmarking to verify the usage of a given algorithm for key application logic. These discussions can take significantly longer than an hour long interview.\n\nNot only are these questions rarely representative of the actual job, they’re also easy to cheat with someone with enough free-time to dedicate towards algorithm memorization. Googling “interview algorithm questions” provides over 17 million results. Even the first page of results promises to teach you how to instantly solve dozens of common algorithm questions.\n\nNot only is possible cheating unhelpful in reflecting a candidate’s problem solving skills, it actively biases your results towards those who’ve put more time into interview prep (which may discourage those who’ve been long-term employees for a single employer). It actively harms those with children or other time constraints that limit their ability to continually practice algorithm questions.\n\nEven with all of this, I’m only scratching the surface of the [issues with algorithm-based “whiteboarding” interviews that’ve been written about before](https://coderpad.io/blog/whiteboard-interview-guide/).\n\n## Fixing the Problem\n\nThat said, interview questions are important, so what should we be replacing these algorithm questions with technical assessments?\n\nIdeally, we should be asking questions based in the real-world. For example, if you’ve got an older class-style React codebase that is being rewritten into functional hooks components, let them do that for the interview!\n\nIn other scenarios, where styling is important to the role, you might want to provide a functioning app and ask the candidate to match an existing design.\n\nWhile real-world code samples provide many upsides, setting up a real-world example may take a candidate a little longer to read through the code and orient themselves. How can we reduce the dead-air for interviewers and candidates alike?\n\n# Take-Homes\n\nWe at CoderPad are ***strong\\*** advocates of take-home interviews for technical assessments. While [we’ve written about many of the benefits of take-homes before](https://coderpad.io/blog/hire-better-faster-and-in-a-more-human-way-with-take-homes/), we’ll touch on some of the advantages here:\n\n- Lower stress environment for candidate\n  - We’ve heard a lot from the autistic community and those with anxiety that this helps a lot\n- More flexibility and creativity in candidate solutions\n- Removes biases\n- Kills dead air while candidate is doing initial thought process of a problem\n\n## Level the Playing Field\n\nAs mentioned previously, time isn’t the same for everyone. Some folks look for work while they’re still working full-time for another employer. Those same people may have kids or other priorities in their lives. This makes time a rare commodity for some.\n\nA good solution of this can be setting a time limit for take-home projects. However, if a time-limit is softly set and on the honor system, engineers may feel the pressure to go outside of that time-range to add “polish” in order to compete with other candidates. This places us back at the original problem without much done.\n\nCoderPad allows you to limit the amount of time a candidate is able to spend in assessment. the interview pad Once the timer is done, the candidate is removed from the take-home and their work is submitted.\n\n![The timer you can set for CoderPad take-homes](./take_home_timer.png)\n\nI encourage you to keep the time limit to 2 hours max. Any longer and you risk alienating the candidates without that much time to do assessments. Keep in mind - you’re likely not the only role that candidate has applied for.\n\n# Find Their Speciality\n\nNot only do take-homes improve the balance of “stress” vs “capabilities” you look for in an interview, they also allow candidates with specialties focus on their strengths and show you what they’re most capable of.\n\nThink about it this way: You’re hiring for a team - ideally a team should have a good balance of skills. Even in small-scale applications, there are lots of jobs to do: styling, internal documentation to write, code organization, boilerplate writing, application logic, testing, etc.. While it’s possible to have someone capable of doing more than one of these - it’s impossible to be a true universal expert at all of them at once. Engineers are likely to lean more in some directions than others. Don’t discourage this - it’s what allows a team of diverse people to build a better product through combined individual expertise.\n\n# Wrap Up\n\nMost of these tips are meant to make your technical interviews more representative of real-world experiences and enable a more diverse pool of candidates to succeed in your process. I hope these tips help give you better insights into your candidates and enable a team that’s more well-rounded, ultimately bringing more value to your company and teams.\n\nHungry for more interviewing tips? Check out CoderPad's blog about [3 other tips for technical interviewing](https://coderpad.io/blog/technical-interviewing-3-actionable-tips-to-hire-well/).\n",
		},
		{
			title: "CSS Fundamentals",
			description:
				"A beginners course for CSS box model, HTML defaults, flexbox layout, gridbox layout, responsive design, selectors, units, and variables.",
			published: "2022-01-18T20:08:26.988Z",
			authors: ["ljtech"],
			tags: ["css", "design"],
			attached: [],
			license: {
				id: "cc-by-4",
				footerImg: "https://i.creativecommons.org/l/by/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by/4.0/",
				name: "Attribution 4.0 International (CC BY 4.0)",
				displayName: "Creative Commons Attribution 4.0 International License",
			},
			originalLink: "https://ljtech.ca/posts/css-fundamentals",
			slug: "css-fundamentals",
			locale: "en",
			authorsMeta: [
				{
					id: "ljtech",
					name: "Landon Johnson",
					firstName: "Landon",
					lastName: "Johnson",
					description:
						"Hello there, my name is Lj. I am a full stack developer.",
					socials: {
						twitter: "ljtechdotca",
						github: "ljtechdotca",
						twitch: "ljtechdotca",
						website: "https://ljtech.ca",
					},
					pronouns: "he",
					profileImg: "./ljtechdotca.png",
					color: "#7b61ff",
					roles: ["author"],
					profileImgMeta: {
						height: 500,
						width: 500,
						relativePath: "./ljtechdotca.png",
						relativeServerPath: "/content/data/ljtechdotca.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\ljtechdotca.png",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "CSS Fundamentals",
				description:
					"A beginners course for CSS box model, HTML defaults, flexbox layout, gridbox layout, responsive design, selectors, units, and variables.",
				published: "2022-01-18T20:08:26.988Z",
				authors: ["ljtech"],
				tags: ["css", "design"],
				attached: [],
				license: "cc-by-4",
				originalLink: "https://ljtech.ca/posts/css-fundamentals",
			},
			contentMeta:
				'\n## Introduction\n\nThis course will guide you through the fundamentals of CSS with a few of my own personal recommendations for further learning.\n\nKeep in mind that some concepts or principles laid out here are broad and may not be accurate or reliable for every situation.\n\n> 💡 This tutorial assumes basic knowledge of HTML and CSS\n\nThis tutorial will cover the following items in order:\n\n- **[Box Model](#box-model)**\n- **[HTML Defaults](#html-defaults)**\n- **[Flexbox Layout](#flexbox-layout)**\n- **[Gridbox Layout](#grid-box-layout)**\n- **[Positioning](#positioning)**\n- **[Where do I use Flexbox, Gridbox or Positioning?](#flex-grid-position)**\n- **[Responsive Design](#responsive-design)**\n- **[CSS Selectors](#css-selectors)**\n- **[Units & Value Types](#units-&-value-types)**\n- **[CSS Variables](#css-variables)**\n\n---\n\n## Box Model\n\n![box-model.svg](./box-model.svg)\n\nThe box model is a representation of a documents element through a set of boxes with the following properties:\n\n- **Margin** - Wraps any border, padding, and content as white space.\n- **Border** - Wraps any padding and content.\n- **Padding** - Wraps any contents as white space.\n- **Content** - Contains text, imagery, videos, etc.\n\nEvery element on the browser has a box model. You can inspect them using browser developer tools. Understanding the box model layers will help you identify element boundaries.\n\n> 📚 [Learn More About Developer Tools](https://developer.mozilla.org/en-US/docs/Glossary/Developer_Tools)\n\n---\n\n## HTML Defaults\n\nNearly every HTML element has some default browser styles. These styles are called HTML defaults. These defaults may change depending on the browsers rendering engine.\n\n> 🤓 Not every browser supports every CSS property! For up-to-date browser support I suggest checking out [Can I Use?](https://www.google.com/search?q=caniuse&rlz=1C1CHBF_enCA963CA963&oq=caniuse&aqs=chrome.0.69i59j69i60l3.1776j0j4&sourceid=chrome&ie=UTF-8)\n\nEvery HTML element has a place and a purpose. Some HTML elements are strictly used for grouping content and are generally referred to as containers, while other HTML elements are used for text, images and more.\n\nHere are some examples of HTML container elements:\n\n```html\n<aside>\n\t<!-- Represents anything indirectly related to the documents content -->\n</aside>\n\n<body>\n\t<!-- There can only be one body. It contains all the documents content -->\n</body>\n\n<div>\n\t<!-- A pure container as it does not inherently represent anything -->\n</div>\n\n<footer>\n\t<!-- Footers represent the last child of a given container -->\n</footer>\n\n<header>\n\t<!-- Headers represent the first child of a given container -->\n</header>\n\n<main>\n\t<!-- Contains the primary content inside a body container -->\n</main>\n\n<nav>\n\t<!-- Contains links for navigating to current or related documents -->\n</nav>\n\n<section>\n\t<!-- Contains a stand-alone piece of content -->\n</section>\n\n<ul>\n\t<!-- Represents a list of items -->\n</ul>\n```\n\nContaining elements are very useful for styling as they allow developers to target groups of content easily through class, ID, and type selectors.\n\n> ⚡ [Live Code Example: HTML Defaults](https://codesandbox.io/s/html-defaults-5lkjb)\n\nIt is important to know about HTML defaults and so you can work with them and not against them when styling a document.\n\n> 📚 [Learn More About HTML](https://developer.mozilla.org/en-US/docs/Web/HTML)\n\n---\n\n## Flexbox Layout\n\nThe CSS property `display: flex` is also known as flexbox. Flexbox is used for creating one-dimensional layouts on a column (up and down) or row (left and right) direction.\n\n#### Flex-Direction\n\n```css\nflex-direction: column;\n```\n\n![flex-column.svg](./flex-column.svg)\n\n```css\nflex-direction: row;\n```\n\n![flex-row.svg](./flex-row.svg)\n\nAdding `display: flex` to a container will cause any immediate descendants to become flex items. Using a few additional CSS properties we can align, justify, and space these same flex items inside the container.\n\n#### Placement Methods\n\nThese placement methods are used to distribute both flex and gridbox items:\n\n- [`place-content`](https://developer.mozilla.org/en-US/docs/Web/CSS/place-content) - shorthand property for [`align-content`](https://developer.mozilla.org/en-US/docs/Web/CSS/align-content) and [`justify-content`](https://developer.mozilla.org/en-US/docs/Web/CSS/justify-content)\n- [`place-items`](https://developer.mozilla.org/en-US/docs/Web/CSS/place-items) - shorthand property for [`align-items`](https://developer.mozilla.org/en-US/docs/Web/CSS/align-items) and [`justify-items`](https://developer.mozilla.org/en-US/docs/Web/CSS/justify-items)\n- [`place-self`](https://developer.mozilla.org/en-US/docs/Web/CSS/place-self) - shorthand property for [`align-self`](https://developer.mozilla.org/en-US/docs/Web/CSS/align-self) and [`justify-self`](https://developer.mozilla.org/en-US/docs/Web/CSS/justify-self)\n\n> 🤓 These are some godly CSS properties that everyone should know about\n\n#### Align-Items\n\n```css\nalign-items: center;\n```\n\n![align-center.svg](./align-center.svg)\n\n```css\nalign-items: flex-end;\n```\n\n![align-end.svg](./align-end.svg)\n\n```css\nalign-items: flex-start;\n```\n\n![align-start.svg](./align-start.svg)\n\n> 🤓 Keep everything inline with align-items\n\n---\n\n#### Justify-Content\n\n```css\njustify-content: center;\n```\n\n![justify-center.svg](./justify-center.svg)\n\n```css\njustify-content: flex-end;\n```\n\n![justify-end.svg](./justify-end.svg)\n\n```css\njustify-content: flex-start;\n```\n\n![justify-start.svg](./justify-start.svg)\n\n```css\njustify-content: space-around;\n```\n\n![justify-around.svg](./justify-around.svg)\n\n```css\njustify-content: space-between;\n```\n\n![justify-between.svg](./justify-between.svg)\n\n```css\njustify-content: space-evenly;\n```\n\n![justify-evenly.svg](./justify-evenly.svg)\n\n> 🤓 Space your content out with justify-content\n\nHere is a list of CSS properties used to control flexbox properties: \n\n- [`flex-direction`](https://developer.mozilla.org/en-US/docs/Web/CSS/flex-direction) - controls flexbox direction\n- [`flex-grow`](https://developer.mozilla.org/en-US/docs/Web/CSS/flex-grow) - controls a flex items grow factor\n- [`flex-shrink`](https://developer.mozilla.org/en-US/docs/Web/CSS/flex-shrink) - controls a flex items shrink factor\n- [`flex-basis`](https://developer.mozilla.org/en-US/docs/Web/CSS/flex-basis) - controls the initial size of a flex item\n- [`flex-wrap`](https://developer.mozilla.org/en-US/docs/Web/CSS/flex-wrap) - controls flex items wrapping onto multiple lines\n\n> ⚡ [Live Code Example: Flexbox Layout](https://codesandbox.io/s/flexbox-layout-p4cy8?file=/styles.css)\n\n---\n\n## Gridbox Layout\n\nThe CSS property `display: grid` is commonly referred to as gridbox. Unlike flexbox, it is capable of creating two-dimensional layouts using intersecting columns and rows.\n\n#### Grid-Template-Areas & Grid-Template-Columns\n\n```css\ngrid-template-areas:\n  "a a"\n  "b c";\ngrid-template-columns: 1fr 1fr;\n```\n\n![grid-columns.svg](./grid-columns.svg)\n\n---\n\n#### Grid-Template-Rows\n\n```css\ngrid-template-rows: 1fr 2fr 1fr;\n```\n\n![grid-rows.svg](./grid-rows.svg)\n\nAdding `display: grid` to a container will cause any immediate descendants to become grid items. Similar to flexbox, we can use placement methods to help align, justify, and space grid items inside the container.\n\n---\n\n#### Place-Items\n\n```css\nplace-items: center center;\n```\n\n![center-center.svg](./center-center.svg)\n\n```css\nplace-items: end end;\n```\n\n![place-items-end-end.svg](./end-end.svg)\n\n```css\nplace-items: start start;\n```\n\n![start-start.svg](./start-start.svg)\n\n> 🤓 Place-items is super effective if using gridbox\n\nHere is a list of CSS properties used to control gridbox properties:\n\n- [`grid-area`](https://developer.mozilla.org/en-US/docs/Web/CSS/grid-area) - controls a grid item\'s location\n- [`grid-template-areas`](https://developer.mozilla.org/en-US/docs/Web/CSS/grid-template-areas) - controls cells and assigns names\n- [`grid-auto-columns`](https://developer.mozilla.org/en-US/docs/Web/CSS/grid-auto-columns) - controls the track size of grid columns\n- [`grid-auto-flow`](https://developer.mozilla.org/en-US/docs/Web/CSS/grid-auto-flow) - controls the auto-placement algorithm\n- [`grid-auto-rows`](https://developer.mozilla.org/en-US/docs/Web/CSS/grid-auto-rows) - controls the track size of grid rows\n- [`grid-gap`](https://developer.mozilla.org/en-US/docs/Web/CSS/gap) - controls gaps between columns and rows\n- [`grid-template-columns`](https://developer.mozilla.org/en-US/docs/Web/CSS/grid-template-columns) - controls line names and track size of grid columns\n- [`grid-template-rows`](https://developer.mozilla.org/en-US/docs/Web/CSS/grid-template-rows) - controls line names and track size of grid rows\n\n> ⚡ [Live Code Example: Gridbox Layout](https://codesandbox.io/s/gridbox-layout-tnu5b?file=/styles.css)\n\n---\n\n## Positioning\n\nThe CSS property `position` determines an elements flow inside a document.\n\nThe CSS properties `top`, `bottom`, `left`, `right` are used on positioned elements to control an offset while `z-index` controls the elements order (bringing it to the front or back).\n\n![positioning.svg](./positioning.svg)\n\n```css\n.root {\n\tposition: relative;\n\twidth: 768px;\n    height: 272px;\n}\n\n.container {\n\tposition: absolute;\n\tleft: 224px;\n    top: 100px;\n    width: 320px;\n    height: 145px;\n    z-index: 90;\n}\n\n.item {\n\tposition: absolute;\n    bottom: 50px;\n    right: 90px;\n\twidth: 213px;\n\theight: 65px;\n    z-index: 100;\n}\n```\n\nThere are five types of element positions:\n\n- **Absolute** - The element is removed from document flow and positioned relative to the nearest `position: relative` parent\n  - Can be offset relative to the parent container and ordered\n- **Fixed** - The element is removed from document flow and positioned relative to the initial container\n  - Can be offset relative to the initial container and ordered\n- **Relative** - The element flows normally and provides relative positioning for children elements\n  - Can be offset relative to itself and ordered\n- **Static** - The default position\n  - Unaffected by offset and order\n- **Sticky** - The element flows normally and "sticks" to the nearest container\n  - A mixture between relative and fixed positions depending on the scroll mechanism\n  - Can be offset relative to the parent container and ordered\n\n> ⚡ [Live Code Example: Positioning](https://codesandbox.io/s/positioning-gzzv3?file=/styles.css)\n\n---\n\n## Where do I use Flexbox, Gridbox or Positioning?\n\n#### Flexbox:\n\n - Used in headers, lists, tags, or any other block or inline content with the correct flex-direction\n - Primary method to align and justify content in small components\n - Easy to use\n\nFor example, YouTube uses a flexbox to space out their headers children elements:\n\n![youtube.png](./youtube.png)\n\n> 🤓 Mastering the flexbox will take you very far in CSS as it is used everywhere\n\n#### Gridbox: \n\n - Used in creating complex layouts that require both columns and rows\n - Provides the easiest and shortest way to center elements\n - Verbose and powerful\n\nFor example, Spotify uses a gridbox to achieve their playlist player layout:\n\n![spotify.png](./spotify.png)\n\n#### Positioning: \n\n - Used in lightboxes, mobile menus, modal windows, and similar overlaying elements\n - Primarily used to remove elements from document flow\n\nFor example, the cookies modal on stackoverflow uses a fixed position to stay on your screen while hovering above other document elements:\n\n![stackoverflow.png](./stackoverflow.png)\n\n---\n\n## Responsive Design\n\nResponsive Design is an approach to web design where the goal is to create a layout that will render beautifully on any device or screen size.\n\n![responsive-design.png](./responsive-design.png)\n\nTo achieve this, designers can use media queries (AKA breakpoints) to add, override, and unset styles on any screen size.\n\nThe code snippet below shows how breakpoints can be used inside a `.css` file to override an existing CSS rule:\n\n```css\n.foobar {\n  border: 1px solid red;\n  color: red;\n}\n\n@media (min-width: 768px) {\n  .foobar {\n    border: unset;\n    color: orange;\n    display: flex;\n\t}\n}\n```\n\nHere is a list of popular screen size breakpoints for max- and min-width:\n\n- **320px** - Mobile S\n- **375px** - Mobile M\n- **425px** - Mobile L\n- **768px** - Tablet\n- **1024px** - Laptop\n- **1440px** - Laptop L\n\n#### Mobile First Design\n\nOne great method for responsive designing is called mobile first design. To use the mobile first method, simply use the min- prefix on your rules when applying breakpoints. This min- prefix will limit your breakpoints to a minimum screen size. This allows for smaller screens to be styled first, and exceptions made for larger devices.\n\n> ⚡ [Live Code Example: Responsive Design](https://codesandbox.io/s/responsive-design-rkrns?file=/styles.css)\n\n---\n\n## CSS Selectors\n\nCSS selectors are used inside `.css` files in order to target HTML elements and allows for CSS rules to be applied.\n\nThere are five basic CSS selectors:\n\n- **Universal ( `*` )** - Targets all elements\n- **Class (`.class`)** - Targets all with the given class\n- **ID (`#id`)** -Targets all with the given ID\n- **Type (`h1`)** - Targets all with the given type\n- **Attribute (`[type="submit"]`)** Targets all with the given attribute\n\n> 🤓 I recommend using the `.class` selector over the `#id` selector as ID attributes are unique \n\nYou can group selectors under one CSS rule using commas to share properties among multiple selectors:\n\n```css\n.foo {\n  color: red;\n}\n\n#bar {\n\tcolor: blue;\n}\n\n.foo, #bar {\n\tpadding: 1rem;\n}\n```\n\nYou can also combine selectors using a variety of syntax to target anything from descendants to siblings:\n\n```css\nsection h1 {\n\tcolor: red;\n}\n\nsection > h2 {\n  color: orange;\n}\n\nsection + h3 {\n\tcolor: yellow;\n}\n\nsection ~ h4 {\n\tcolor: green;\n}\n```\n\nSelectors can also be used to target browser pseudo-elements:\n\n```css\ninput::placeholder {\n  color: #dddddd;\n}\n```\n\nUsing this variety of combinators and selectors you can easily style any part of a web document.\n\n> ⚡ [Live Code Example: Selectors](https://codesandbox.io/s/selectors-fqw6x?file=/styles.css)\n\n> 📚 [Learn More About Selectors](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Selectors)\n\n---\n\n## Units & Value Types\n\nIn CSS there are seven absolute and eight relative length unit types. Here are the popular ones:\n\n- **px** - Pixels, absolute length unit\n- **em** - Relative to the parent size\n- **rem** - Relative to the root element size\n- **vw** - View-width, relative to the current device\n- **vh** - View-height, relative to the current device\n\nThese CSS units are used to determine the size of a property value.\n\n> 🤓 I recommend using the units `px` and `rem` units\n\nCSS property values will only accept certain syntax and types. Let\'s use `color` for example:\n\n```css\n.foobar__keyword {\n  color: red; /* Color will accept certain keywords */\t\n}\n\n.foobar__hex {\n  color: #ff0000; /* It will also take hexadecimal values */\n}\n\n.foobar__rgb {\n  color: rgb(255, 0, 0); /* As well as functional notations */\n}\n```\n\n> [📚 Learn More About CSS Types](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Types)\n\n> 📚 [Learn More About Units & Values](https://developer.mozilla.org/en-US/docs/Learn/CSS/Building_blocks/Values_and_units)\n\n---\n\n## CSS Variables\n\nCSS variables allow us to define arbitrary values for reuse across a stylesheet. For example:\n\n```css\n:root {\n  --red: #ff0000;\n}\n\n.foo {\n\tbackground-color: var(--red);\n}\n\n.bar {\n\tcolor: var(--red);\n}\n```\n\nIt is common to use CSS variables for repeated values such as colors, font-size, padding, etc.\n\n> ⚡ [Live Code Example: CSS Variables](https://codesandbox.io/s/css-variables-tx14z?file=/styles.css)',
		},
		{
			title: "Data Storage Options for React Native",
			description:
				"React Native contains multiple different ways you can persist data for your application. Let's look at the choices and their pros and cons.",
			published: "2020-04-14T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["react", "react native"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "data-storage-options-in-react-native",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Data Storage Options for React Native",
				description:
					"React Native contains multiple different ways you can persist data for your application. Let's look at the choices and their pros and cons.",
				published: "2020-04-14T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["react", "react native"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nOne of the hardest parts of any front-end application (native application or website alike) is the data layer. Where do I store information? That question alone can cause lots of headaches when dealing with large-scale applications. Well, worry not, as we'll be going over some of the different options you have at your disposal in your React Native applications today.\n\n# Key-Value Pair Storage {#default-preference}\n\nOften, while creating settings options, it can be useful to store a simple key/value pairings of serializable data (like JSON). In the web world, we'd use `localStorage.` Ideally, we'd like a simple data storage for string-based data that has a `get,` a `set,` and a `clear` method to handle data for us. Luckily for us, there is!\n\n[`react-native-default-preference`](https://github.com/kevinresol/react-native-default-preference) is an easy-to-add dependency that provides what we're looking for:\n\n```\nyarn add react-native-default-preference\n```\n\nUnder-the-hood, it utilized native methods for storing data in a key-value manner. These APIs it employs is the [`SharedPreferences` API on Android](https://developer.android.com/reference/android/content/SharedPreferences) and the [`UserDefaults` API on iOS](https://developer.apple.com/documentation/foundation/userdefaults). This native code utilization should mean that not only is the data straightforward to access, but speedy as well.\n\n# Secure Key-Value Pair Storage {#secure-key-store}\n\nThere may be an instance where you want to store a part of secure information to the device. For example, in [my mobile Git client I'm currently writing](https://gitshark.dev), I'm grabbing an access token from the GitHub API. This type of sensitive data introduces a new set of problems when it comes to storage; conventional means of storing data are easily accessed from external sources, leading to a security vulnerability with such sensitive data. That said, both major mobile platforms have solved for this problem: [iOS has its Keychain API](https://developer.apple.com/documentation/security/keychain_services) while [Android provides a KeyStore API](https://developer.android.com/reference/java/security/KeyStore). Both can be accessed using the [`react-native-secure-key-store` npm package](https://github.com/pradeep1991singh/react-native-secure-key-store#readme) :\n\n```\nyarn add react-native-secure-key-store\n```\n\nThis package provides an easy-to-use key-value pattern, not entirely dissimilar to the one we used [in the last section](#default-preference).\n\n## Local Database Usage {#sqlite-storage}\n\nThere may be times where having simple key-value storage isn't enough. Sometimes, you need the power and flexibility that a full-scale database provides. That said, not all of the data you need always requires a database to be hosted on the server. This instance is where having a local SQL database comes into play. React Native has a few different options for utilizing an on-device SQL database, but the most popular is using the [`react-native-sqlite-storage`](https://github.com/andpor/react-native-sqlite-storage) package:\n\n```\nyarn add react-native-sqlite-storage\n```\n\nThis package allows you to use full SQL syntax for querying and creating.\n\n## ORM Options {#orms}\n\nWant the power and utility of a SQL database, but don't want to play with any of the SQL syntaxes yourself? No problem, there is a myriad of options to build on top of SQLite using React Native. One of my favorites us [TypeORM](http://typeorm.io/). Useful for both TypeScript and vanilla JS usage, it provides a bunch of functionality that maps relatively directly to SQL.\n\nAlternatively, if you're looking for something with more of a framework feel, there's [WatermelonDB](https://github.com/Nozbe/WatermelonDB). WatermelonDB is utilized with [RxJS](https://rxjs.dev/) to provide an event-based fast-as-fusion alternative to more conventional ORMs.\n\n# Remote Database Usage {#serverless}\n\nWhile you're able to utilize [something like Fetch or Axios to make calls to your remote API for data](https://reactnative.dev/docs/network#using-fetch), you might want to utilize a serverless database to provide data to your apps. React Native's got you covered whether you want to use [MongoDB Stitch](https://www.npmjs.com/package/mongodb-stitch-react-native-sdk), [Firebase's Firestore or Realtime Database](https://rnfirebase.io/), or others.\n\n# Synchronized Database Usage {#realm}\n\nWhile you're more than able to cache database calls manually, sometimes it's convenient to have your data synchronized with your backend. This convenience is one of the selling points of [Realm](https://realm.io/). Realm is an unconventional database in that it's written natively and is not SQL based. You're able to [integrate with React Native as a local database](https://realm.io/docs/javascript/latest#getting-started) and connect to their [Realm Sync platform](https://docs.realm.io/sync/getting-started-1/getting-a-realm-object-server-instance) to provide a simple to use synchronization between your database backend and mobile client.\n\n> A note about RealmDB: [MongoDB acquired Realm in 2019](https://techcrunch.com/2019/04/24/mongodb-to-acquire-open-source-mobile-database-realm-startup-that-raised-40m/). While this may seem like an unrelated note to leave here, I mention it because large-scale changes are in the immediate horizon for the platform. MongoDB is open about such. They plan on integrating the platform into a larger-scoped platform _also_ (confusingly) called [Realm](https://www.mongodb.com/realm). I mention this because if you're starting a new project, you may want to be aware of what these changes will have in store for your future. It seems like they have a lot of exciting things coming soon!\n\n# Pros and Cons {#pros-and-cons}\n\n| Option                                        | Pros                                                         | Cons                                                         |\n| --------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| [Key-Value Pair Storage](#default-preference) | <ul><li>Extremely fast</li><li>Useful for simple data storing</li></ul> | <ul><li>Can only store serializable data</li><li>Not very cleanly separated</li><li>Not very secure</li></ul> |\n| [Secure Key-Value Storage](#secure-key-store) | <ul><li>Fast</li><li>A secure method of data storing</li></ul> | <ul><li>Can only store serializable data</li><li>Not very cleanly separated</li></ul> |\n| [SQLite without ORM](#sqlite-storage)         | <ul><li>Cleanly separated data</li></ul>                     | <ul><li>Difficult to maintain code and table migrations manually</li><li>Not very fast compared to key-value pairs</li></ul> |\n| [SQLite with ORM](#orms)                      | <ul><li>Cleanly separated data</li><li>Much more easy to maintain than writing SQL itself</li></ul> | <ul><li>Often slower than writing SQL by hand</li><li>More work to get setup</li></ul> |\n| [Serverless](#serverless)                     | <ul><li>Simple setup</li><li>No need to schema or migrate a database when data requirements change</li></ul> | <ul><li>Potentially difficult to cache</li><li>Not on-device</li></ul> |\n| [RealmDB](#realm)                             | <ul><li>An easy-to-sync on-device and cloud storage</li></ul> | <ul><li>A heavier requirement of investment than something more standard</li><li>Large migrations on the horizon</li></ul> |\n\n# Conclusion\n\nAs with many things in engineering, where to store data is a broad-reaching and integral question to be asking yourself while developing. I've found myself mixing many of these options for a single application, depending on the context. Each has its strengths to draw from and weaknesses to consider.\n\nIf you liked this article and want to see more React Native content, consider subscribing to our newsletter below. We have more React Native content on its way soon. We also have [a community Discord](https://discord.gg/FMcvc6T) if you have questions or comments that you'd like to discuss with us!\n",
		},
		{
			title: "Debugging NodeJS Applications Using Chrome",
			description:
				"Learn how to interactively debug your NodeJS applications using a GUI-based debugger built into Chrome.",
			published: "2020-01-21T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["node", "chrome"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "debugging-nodejs-programs-using-chrome",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Debugging NodeJS Applications Using Chrome",
				description:
					"Learn how to interactively debug your NodeJS applications using a GUI-based debugger built into Chrome.",
				published: "2020-01-21T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["node", "chrome"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				'\nDebugging is one of the most difficult aspects of development. Regardless of skill level, experience, or general knowledge, every developer finds themselves in an instance where they need to drop down and start walking through the process. Many, especially those who are in complex environments or just starting on their developmental path, may utilize `console.log`s to help debug JavaScript applications. However, there is a tool for developers using Node.JS that makes debugging significantly easier in many instances.\n\nThe tool I\'m referring to is [the Node Debugger utility](https://nodejs.org/api/debugger.html). While this utility is powerful and helpful all on its own, _it can be made even more powerful by utilizing the power of the Chrome debugger_ to attach to a Node debuggable process in order to _provide you a GUI for a debugging mode_ in your Node.JS applications.\n\nLet\'s look at how we can do so and how to use the Chrome debugger for such purposes.\n\n# Example Application {#example-code}\n\nLet\'s assume we\'re building an [Express server](https://expressjs.com/) in NodeJS. We want to `GET` an external endpoint and process that data, but we\'re having issues with the output data. Since it\'s not clear where the issue resides, we decide to turn to the debugger.\n\nLet\'s use the following code as our example Express app:\n\n```javascript\n// app.js\nconst express = require("express");\nconst app = express();\nconst request = require("request");\n\napp.get(\'/\', (req, res) => {\n  request("http://www.mocky.io/v2/5e1a9abe3100004e004f316b", (error, response, body) => {\n    const responseList = JSON.parse(body); \n    const partialList = responseList.slice(0, 20);\n    const employeeAges = partialList.map(employee => {\n      return employee.employeeAge;\n    });\n    console.log(employeeAges);\n  });\n});\n\napp.listen(3000);\n```\n\nYou\'ll notice that we\'re using the dummy endpoint http://www.mocky.io/v2/5e1a9abe3100004e004f316b. This endpoint returns an array of values with a shape much like this:\n\n```json\n[\n    {\n        "id": "1",\n        "employee_name": "Adam",\n        "employee_salary": "12322",\n        "employee_age": "23",\n        "profile_image": ""\n    }\n]\n```\n\nOnce you run the `app.js` file in Node, however, you\'ll see the `console.log`s of:\n\n```javascript\n[ undefined ]\n```\n\nInstead of the ages of the employees as we might expect. We\'ll need to dive deeper to figure out what\'s going on, let\'s move forward with setting up and using the debugger.\n\n> You may have already spotted the error in this small code sample, but I\'d still suggest you read on. Having the skillsets to run a debugger can help immeasurably when dealing with large-scale codebases with many moving parts or even when dealing with an unfamiliar or poorly documented API.\n\n# Starting the Debugger {#starting-the-debugger}\n\nWhereas a typical Express application might have `package.json` file that looks something like this:\n\n```json\n{\n  "name": "example-express-debug-code",\n  "version": "1.0.0",\n  "main": "app.js",\n  "dependencies": {\n    "express": "^4.17.1",\n    "request": "^2.88.0"\n  },\n  "scripts": {\n    "start": "node ./app.js"\n  }\n}\n```\n\nWe\'ll be adding one more `scripts` item for debug mode:\n\n```json\n{\n  "name": "example-express-debug-code",\n  "version": "1.0.0",\n  "main": "app.js",\n  "dependencies": {\n    "express": "^4.17.1",\n    "request": "^2.88.0"\n  },\n  "scripts": {\n    "start": "node ./app.js",\n    "debug": "node --inspect ./app.js"\n  }\n}\n```\n\nOnce you add in this flag, you can simply run `npm run debug` to start the debuggable session.\n\n> A quick sidenote:\n> Some folks like to use [the `nodemon` tool](https://nodemon.io/) in order to get their application to reload upon making changes to their source file.\n> That doesn\'t mean you can\'t join in the debugger fun! Just replace `node` with `nodemon` for the following `package.json`:\n>\n> ```json\n> {\n>   "name": "example-express-debug-code",\n>   "version": "1.0.0",\n>   "main": "app.js",\n>   "dependencies": {\n>     "express": "^4.17.1",\n>     "request": "^2.88.0"\n>   },\n>   "devDependencies": {\n>     "nodemon": "^2.0.2"\n>   },\n>   "scripts": {\n>     "start": "nodemon ./app.js",\n>     "debug": "nodemon --inspect ./app.js"\n>   }\n> }\n> ```\n\nOnce you start your debuggable session, you should be left with a message similar to the following:\n\n```\nDebugger listening on ws://127.0.0.1:9229/ffffffff-ffff-ffff-ffff-ffffffffffff\nFor help, see: https://nodejs.org/en/docs/inspector\n```\n\nAt this point, _it will hang and not process the code or run it_. That\'s okay though, as we\'ll be running the inspector to get the code to run again in the next step.\n\n# The Debugger {#the-debugger}\n\nIn order to access the debugger, you\'ll need to open up Chrome and go to the URL `chrome://inspect`. You should see a list of selectable debug devices, including the node instance you just started.\n\n![A list of inspectable devices from Chrome](./chrome_inspect.png)\n\nThen you\'ll want to select `inspect` on the node instance.\n\nDoing so will bring up a screen of your entrypoint file with the source code in a window with line numbers. \n\n![The aforementioned code screen](./initial_debugger.png)\n\nThese line numbers are important for a simple reason: They allow you to add breakpoints. In order to explain breakpoints, allow me to make an analogy about debug mode to race-car driving.\n\nThink about running your code like driving an experimental race-car. This car has the ability to drive around the track, you can watch it run using binoculars, but that doesn\'t give you great insight as to whether there\'s anything wrong with the car. If you want to take a closer inspection of a race-car, you need to have it pull out to the pit-stop in order to examine the technical aspects of the car before sending it off to drive again.\n\nIt\'s similar to a debug mode of your program. You can evaluate data using `console.log`, but _to gain greater insight, you may want to pause your application_, inspect the small details in the code during a specific state,  and to do so you must pause your code. This is where breakpoints come into play: they allow you to place "pause" points into your code so that when you reach the part of code that a breakpoint is present on, your code will pause and you\'ll be given much better insight to what your code is doing.\n\nTo set a breakpoint from within the debugging screen, you\'ll want to select a code line number off to the left side of the screen. This will create a blue arrow on the line number. \n\n> If you accidentally select a line you didn\'t mean to, that\'s okay. Pressing this line again will disable the breakpoint you just created\n\n![The blue arrow being added to line 7 of the app.js file](./breakpoint_add.png)\n\nA race-car needs to drive around the track until the point where the pit-stop is in order to be inspected; _your code needs to run through a breakpoint in order to pause and give you the expected debugging experience_. This means that, with only the above breakpoint enabled, the code will not enter into debug mode until you access  `localhost:3000` in your browser to run the `app.get(\'/\')`  route.\n\n> Some applications may be a bit [quick-on-the-draw](https://en.wiktionary.org/wiki/quick_on_the_draw) in regards to finding an acceptable place to put a breakpoint. If you\'re having difficulties beating your code running, feel free to replace the `--inspect` flag with `--inspect-brk` which will automatically add in a breakpoint to the first line of code in your running file. \n>\n> This way, you should have the margins to add in a breakpoint where you\'d like one beforehand.\n\n# Using The Debugging Tools {#using-debug-tools}\n\nOnce your code runs through a breakpoint, this window should immediately raise to focus (even if it\'s in the background).\n\n![A breakpoint paused on line 7 at the JSON parsing line](./breakpoint_paused.png)\n\n> If you don\'t see the `Console` tab at the bottom of the screen, as is shown here, you can bring it up by pressing the `Esc` key. This will allow you to interact with your code in various ways that are outlined below.\n\nOnce you do so, you\'re in full control of your code and its state. You can:\n\n- _Inspect the values of variables_ (either by highlighting the variable you\'re interested in, looking under the "scope" tab on the right sidebar, or using the `Console` tab to run inspection commands à la [`console.table`](https://developer.mozilla.org/en-US/docs/Web/API/Console/table) or [`console.log`](https://developer.mozilla.org/en-US/docs/Web/API/Console/log)):\n\n\t![A screenshot of all three of the mentioned methods to inspect a variable\'s value](./inspect_variable_value.png)\n- _Change the value of a variable:_\n  ![A screenshot of using the Console tab in order to change the value of a variable as you would any other JavaScript variable](./change_variable_value.png)\n- _Run arbitrary JavaScript commands_, similar to how a code playground might allow you to:\n  ![A screenshot of indexing the body using "body.slice(0, 100)"](./arbitrary_js.png)\n\n## Running Through Lines {#running-through-lines}\n\nBut that\'s not all! Once you make changes (or inspect the values), you\'re also able to control the flow of your application. For example, you may have noticed the following buttons in the debug window:\n\n![A red circle highlighting the "play" and "skip" buttons in the debugger](./breakpoint_paused_buttons.png)\n\nBoth of these buttons allow you to control where your debugger moves next. _The button to the left_ is more of a "play/pause" button. Pressing this _will unpause your code and keep running it_ (with your variable changes intact) _until it hits the next breakpoint_. If this happens to be two lines down, then it will run the line in-between without pausing and then pause once it reached that next breakpoint.\n\nSo, if we want to see what happens after the `body` JSON variable is parsed into a variable, we could press the "next" button to the right to get to that line of code and pause once again.\n\n![A screenshot of the JSON being parsed into a few variables with some console logs to prove it did really parse and run the line above it](./next_line.png)\n\nKnowing this, let\'s move through the next few lines manually by pressing each item. The ran values of the variables as they\'re assigned should show up to the right of the code itself in a little yellow box; This should help you understand what each line of code is running and returning without `console.log`ging or otherwise manually.\n\n![A screenshot showing ran lines until line 12 of the "console.log". It shows that "employeeAges" is "[undefined]"](./next_few_lines.png)\n\nBut oh no! You can see, `employeeAges` on line `9` is the one that results in the unintended `[undefined]`. It seems to be occurring during the `map` phase, so let\'s add in a breakpoint to line `10` and reload the `localhost:3000` page (to re-run the function in question).\n\nOnce you hit the first breakpoint on line `7`, you can press "play" once again to keep running until it hits the breakpoint on line `10`.\n\n![Two breakpoints on line 7 and 10, currently paused on line 10](./press_run_twice.png)\n\nThis will allow us to see the value of `employee` to see what\'s going wrong in our application to cause an `undefined` value.\n\n![A show of the "employee" object that has a property "employee_age"](./inspect_employee.png) \n\nOh! As we can see, the name of the field we\'re trying to query is `employee_age`, not the mistakenly typo\'d `employeeAge` property name we\'re currently using in our code. Let\'s stop our server, make the required changes, and then restart the application.\n\nWe will have to run through the breakpoints we\'ve set by pressing the "play" button twice once our code is paused, but once we get through them we should see something like the following:\n\n![Showing that the console log works out the way expected once the map is changed](./working_ran_debugger_code.png)\n\n\n\nThere we go! We\'re able to get the expected "23"! That said, it was annoying to have to press "play" twice. Maybe there\'s something else we can do in similar scenarios like this?\n\n## Disabling Breakpoints {#disabling-breakpoints}\n\nAs mentioned previously in an aside, you can disable breakpoints as simply as pressing the created breakpoint once again (pressing the line number will cause the blue arrow to disappear). However, you\'re also able to temporarily disable all breakpoints if you want to allow code to run normally for a time. To do this, you\'ll want to look in the same toolbar as the "play" and "skip" button. Pressing this button will toggle breakpoints from enabling or not. If breakpoints are disabled, you\'ll see that the blue color in the arrows next to the line number will become a lighter shade.\n\n![Showcasing the lighter shade with a red arrow over the mentioned button](./disabled_breakpoints.png)\n\nWhereas code used to pause when reaching breakpoints, it will now ignore your custom set breakpoints and keep running as normal.\n\n## Step Into {#debugger-step-into}\n\nIn many instances (such as the `map` we use in the following code), you may find yourself wanting to step _into_ a callback function (or an otherwise present function) rather than step over it. For example, [when pressing the "next" button in the previous section](#running-through-lines), it skipped over the `map` instead of running the line in it (line 10). This is because the arrow function that\'s created and passed to `map` is considered its own level of code. To dive deeper into the layers of code and therefore **into** that line of code, instead of the "next line" button to advance, you\'ll need to press the "step into" button.\n\n![A showcase of a breakpoint on line 9 currently paused and a circle around the step into button](./step_inside.png)\n\nLet\'s say you\'re on line `9` and want to move into the `map` function. You can press the "step into" to move into line `10`.\n\n![The after effects of pressing the "step into" button after the screenshot above](./step_inside_part_2.png)\n\nOnce inside the `map` function, there\'s even a button _to get you outside of that function and back to the parent caller\'s next line_. This might if you\'re inside of a lengthy `map` function, have debugged the line you wanted to inspect, and want to move past the `map` to the next line (the `console.log`). Doing so is as simple as "stepping in" a function, you simply press the "step outside" button to move to the next line\n\n![The "step outside" button being highlighted with a circle with the line 12 console log being paused](./step_outside.png)\n\n> While the example uses a callback in `map`, both of these "step into" and "step out of" also work on functions that are called. For example, assume the code was written as the following:\n>\n> ```javascript\n> const getEmployeeAges = partialList => {\n>   const ageArray = [];\n>   for (employee of partialList) {\n>     ageArray.push(employee.employee_age);\n>   }\n>   return ageArray;\n> };\n> \n> app.get(\'/\', (req, res) => {\n>   request(\'http://www.mocky.io/v2/5e1a9abe3100004e004f316b\', (error, response, body) => {\n>     const responseList = JSON.parse(body);\n>     const partialList = responseList.slice(0, 20);\n>     const employeeAges = getEmployeeAges(partialList);\n>     console.log(employeeAges);\n>   });\n> });\n> ```\n>\n> You would still be able to "step into" `getEmployeeAges` and, once inside, "step outside" again in the same manor of the `map` function, as shown prior.\n\n# Saving Files {#editing-files-in-chrome}\n\nOne more feature I\'d like to touch on with the debugger before closing things out is the ability to edit the source files directly from the debugger. Using this feature, it can make the Chrome debugger a form of lite IDE, which may improve your workflow. So, let\'s revert our code to [the place it was at before we applied the fix we needed](#example-code) and go from there.\n\n![The screenshot of the debugger with the original code](./initial_debugger.png)\n\nOnce this window is open, you\'re able to tab into or use your cursor to select within the text container that holds your code. Once inside, it should work just like a `textarea`, which _allows you to change code as you might expect from any other code editor_. Changing line `10` to `return employee.employee_age` instead of `return employee.employeeAge` will show an asterisk (`*`) to let you know your changes have not yet been applied. _Running your code in this state will not reflect the changes made to the code content on the screen_, which may have unintended effects.\n\n![Showing the asterisk once changes made but not saved](./edited_but_not_saved.png)\n\nIn order to make your changes persist, you\'ll need to press `Ctrl + S` or `Command + S` in order to save the file (much like a Word document). Doing so will bring up a yellow triangle instead of an asterisk indicating _your changes are not saved to the source file but your changes will now take effect_. Re-running the `localhost:3000` route will now correct the behavior you want, but if you open `app.js` in a program like Visual Studio Code, it will show the older broken code.\n\n![A screenshot showing the yellow triangle once this occurs](./temporarily_saved.png)\n\nNot only does VS Code not recognize your changes, but once you close your debugging window, you won\'t know what you\'d changed in order to get your code to work. While this may help in short debugging sessions, this won\'t do for a longer session of code changes. To do that, you\'ll want your changes to save to the local file system.\n\n## Persisting Changes {#chrome-as-ide-persist-changes}\n\nIn order to save the changes from inside the Chrome to the file system, you need to permit Chrome access to read and write your files. To do this, you\'ll want to press the "Add folder to workspace" button off to the left of the code screen.\n\n![A red rectangle around "Add folder to workspace" button](./add_folder_to_workspace.png)\n\nSelecting the folder your `app.js` is present in will bring up the dialog to give Chrome permission to view the files and folders within. You\'ll need to press "Allow" in order to save your saves to your file system.\n\n![A screenshot showing the "Allow"/"Deny" dialog](./allow_fs_usage.png)\n\nOnce done, you should now see a list of the files and folders in the parent folder. It should automatically have highlights over the `app.js` file and remove the yellow triangle in favor of another asterisk.\n\n![A screenshot as described in the previous paragraph](./fs_permitted_not_saved.png)\n\nAs I\'m sure you\'ve guessed, the asterisk indicates that you\'ll need to save the file again. Once done (using the key combo), the asterisk should disappear.\n\nIt\'s not just JavaScript files you\'re able to edit, though! You can click or use your keyboard to navigate the file tree of the parent folder. Doing so will allow you to edit and save changes to _any_ file in the filesystem. This would include the `package.json` file in the folder.\n\n![A screenshot of the package json file being edited](./package_json.png)\n\n# Conclusion\n\nWhile we\'ve covered a lot of functionality present within the Chrome debugger, there\'s still more to cover about it! If you\'d like to read more about it, you may want to take a look at [the extensive blog series by the Chrome team](https://developers.google.com/web/tools/chrome-devtools/javascript) that offers a much deeper dive into all of the debugging tools present within Chrome. Luckily, the skills that you gain while debugging Node.JS applications carries over to debugging front-end JavaScript, so hopefully this article has helped introduce you to the myriad of tools that Chrome has to offer.\n\nLeave a comment down below if you have a question or comment, or feel free to join [our Discord](https://discord.gg/FMcvc6T) to have a direct line to us about the article (or just general tech questions).\n',
		},
		{
			title: "Docs, Where Can We Do Better?",
			description:
				"My personal approach to writing docs, mainly aimed at frameworks and the like.",
			published: "2021-11-13T05:12:03.284Z",
			authors: ["maisydino"],
			tags: ["documentation"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			originalLink: "https://likesdinosaurs.com/posts/first-post",
			slug: "docs-where-can-we-do-better",
			locale: "en",
			authorsMeta: [
				{
					id: "maisydino",
					name: "Maisy Dinosaur",
					firstName: "Maisy",
					lastName: "Dinosaur",
					description:
						"I do a lot of stuff sometimes. Part-time fullstack, full time dog petter.",
					socials: {
						twitter: "rodentman87",
						github: "rodentman87",
						website: "https://likesdinosaurs.com",
					},
					pronouns: "she",
					profileImg: "./maisydino.jpg",
					color: "#FDF6E3",
					roles: ["author", "community"],
					profileImgMeta: {
						height: 330,
						width: 330,
						relativePath: "./maisydino.jpg",
						relativeServerPath: "/content/data/maisydino.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\maisydino.jpg",
					},
					rolesMeta: [
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "she",
						they: "she",
						them: "her",
						their: "her",
						theirs: "hers",
						themselves: "herself",
					},
				},
			],
			frontmatterBackup: {
				title: "Docs, Where Can We Do Better?",
				description:
					"My personal approach to writing docs, mainly aimed at frameworks and the like.",
				published: "2021-11-13T05:12:03.284Z",
				authors: ["maisydino"],
				tags: ["documentation"],
				attached: [],
				license: "cc-by-nc-sa-4",
				originalLink: "https://likesdinosaurs.com/posts/first-post",
			},
			contentMeta:
				"\nI've been programming for about 10 years now and by far the worst thing to navigate has been documentation. There's plenty of good books, tutorials, blog posts, etc. out there, but it seems like almost everyone forgets to make the docs good too.\n\n# So why should I care about docs?\n\nPicture this, you're browsing reddit when someone posts about the hot new library that they think is wonderful and everyone needs to check it out. They link to a blog post about it and so far everything seems great, the blog is showing all the wonderful and amazing things you can do with this hot new lib. So you think to yourself \"I really need to check this out.\" You click the GitHub link in the article and start to read the README. You see that there isn't much to it, just a couple small showcases and install instructions, so you click the docs link hoping to find more.\n\nWhat you come across is a list of modules, each with a list of objects in them. You aren't quite sure where to start, so you click around, hoping to find a quick start guide, but you come up empty-handed.\n\nYou've now spent about 30 minutes on this, and all you have so far is the name of a project and a few cool example pictures. Where do you go from here? You could spend the next hour or two looking at source code for some examples (probably uncommented/poorly commented) and asking around online until you find someone who understands it, or you could hunker down and start reading through type definitions until you understand the project inside and out.\n\nTo me, this leaves a sour taste in my mouth. There's now been a lot of time used trying to even know where to start when I could have been already working on my first project. To put this in perspective, if 100 devs did this exact same thing, and spent 2 hours each trying to even get started with this library, that's now 200 hours that could have been spent making software just trying to get their bearings.\n\n---\n\n# So what _should_ docs be like?\n\nWell, there's many possible answers to this, and my method is in no way the only option, nor is it necessarily the best option for every project. This method is more focused around web development and related libraries since that's what I use every day.\n\nMy method has four parts: Explain, Define, Exemplify, Integrate. Lets dive into each of these parts and take a look at what they are.\n\n---\n\n## 1. Explain\n\nStart each page with a small explanation of what it is. Is this an object that represents a specific thing? Is this a utils class with functions for handling dates? No need to be specific here, just enough so that the person navigating the docs knows if they're in the right place or not.\n\nLets try an example with an imaginary project, we'll say that this is an API wrapper for [Discord's API](https://discord.com/developers/docs/intro) written in TypeScript and right now we're writing the docs page for the Guild object.\n\n```txt\nA Guild represents a server and stores all the Channels, Roles, and Members of that server within it.\n```\n\n---\n\n## 2. Define\n\nThis is the raw type definition for this object and its properties and methods. Not much to talk about here, the only thing to keep in mind is to have these be readable and easily navigable. Make the names of the properties and methods stand out so that when a user is scrolling through they can scan for the one they're looking for.\n\nFor example:\n\n<h3>getMember(id: string): Member | null</h3>\nReturns the Member object for the user with the given id, or null if they aren't in the Guild.\n\n---\n\n## 3. Exemplify\n\nThe first thing you'll want to do is give one or more abstract examples, this will be here solely to show how to use the API in a vacuum. These are quick examples that someone can look at if all they want to know is how to use the API.\n\nApplying this to our example, we get this:\n\n**Get a member from the guild**\n\n```ts\nconst member = this.client\n\t.getGuild(\"110373943822540800\")\n\t.getMember(\"152566937442975744\");\n```\n\n---\n\n## 4. Integrate\n\nThis may not be possible or necessary if your library is simply a utility library, but if you're a framework or the like, this part is very important. Here you use an example project to show how this API would integrate into a real world project. Generally it's best to use one project across the entirity of the docs, but sometimes that may not be possible. If you can keep one project across the docs, this will vastly help readers to create a mental model of your library.\n\nIn our example here, we could show using it in a command context:\n\nHere we use the guild in our user info command\n\n```ts\n  //...\n  execute(context, args) {\n    const member = context.guild.getMember(args[0]);\n    return context.say({\n      embed: {\n        title: member.user.tag(),\n        body: member.roles.map(r => r.toMention()).join(\", \"),\n      }\n    })\n  }\n  //...\n```\n\n---\n\n# So how do I put these pages together?\n\nThis method works best when you have two views for your docs. One that shows the full pages, organized by topic rather than by package. The other shows just the type definitions and examples, all organized by package for easily finding them when you've already learned the library and just need a quick reference.\n\n# Conclusion\n\nDocs today aren't terrible, but there's definitely a lot to improve on. My method certainly isn't the best, and certainly needs refining. There's also definitely a lot of good examples out there already.\n\n- [Nest.js has some wonderful docs](https://docs.nestjs.com/)\n- [React is great as well](https://reactjs.org/docs/context.html).\n\nI only have these two examples for now, but message me on Discord `Rodentman87#8787` with some other good docs so that I can add them to the list. The better the docs, the better software we can build.\n",
		},
		{
			title: "A Better Way To Code: Documentation Driven Development",
			description:
				"Test Driven Development is often taught to improve a your workflow; I present Documentation Driven Development as an alternative approach.",
			published: "2022-01-18T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["documentation", "testing", "opinion"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "documentation-driven-development",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "A Better Way To Code: Documentation Driven Development",
				description:
					"Test Driven Development is often taught to improve a your workflow; I present Documentation Driven Development as an alternative approach.",
				published: "2022-01-18T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["documentation", "testing", "opinion"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nIf you've spent much time in software development, you've undoubtedly heard the expression “test-driven development” or \"TDD\" for short.\n\nThe idea behind TDD is that you should write tests before programming an implementation. For example, say you want to implement a function called `calculateUserScore` based on a user's K/D in a video game. According to TDD, you should start by writing unit or integration tests to validate the input to an expected set of outputs.\n\nStarting with tests can be a great help to ensure that your program runs the way it's intended when all is said and done. One downside, however, is that tests are still a form of coding; Yes, even when you follow good testing practices by [hardcoding values and avoiding complex logic](https://unicorn-utterances.com/posts/five-suggestions-for-simpler-tests/#dont-include-logic). It's still software development, and your tests still need to pass at the end of the day.\n\nMaking sure tests pass can be challenging to handle with the unknowns of implementation detail. After all, if you expect `parseInt` to act one way and it behaves another, you will likely have to rewrite all tests that worked off that assumption.\n\nAs a result, many choose to start implementing a function as a proof-of-concept, then adding tests incrementally alongside implementation: A TDD-lite, so to speak.\n\nThe problem is that, by doing so, you lose one of the most significant benefits of test-driven development: Its ability to force you to confront your API ahead of time.\n\n# APIs are hard\n\nYou're working at an indie game company. A small top-down shooter that you've written [in JavaScript with Phaser](https://phaser.io/). Your bass has asked you to implement a user score.\n\n> \"No problem, `calculateUserScore` is going to be super simple - no need to overthink it.\"\n\nYou think, typing out a basic implementation:\n\n```javascript\nfunction calculateUserScore({kills, deaths}) {\n    return parseInt(kills / deaths, 10)\n}\n```\n\nBut wait! What about assists? Do those count? Surely they should. Let's treat them as half of a kill.\n\n```javascript\nfunction calculateUserScore({kills, deaths, assists}) {\n    const totalKills = kills + (assists / 2);\n    return parseInt(totalKills / deaths, 10)\n}\n```\n\nOh, but some kills should give bonus points. After all, who doesn't love a good 360 no-scope? While `kills` was simply a number before, let's change it to an array of objects like so:\n\n```javascript\nconst killsArr = [\n     {\n          additionalPoints: 3\n     }\n]\n```\n\nNow we can change out the function implementation for this:\n\n```javascript\nfunction calculateUserScore({killsArr, deaths, assists}) {\n    const kills = killsArr.length;\n    const additionalPoints = killsArr.reduce((prev, k) => k.additionalPoints, 0);\n    const totalKills = kills + (assists / 2);\n    return parseInt((totalKills / deaths) + additionalPoints, 10);\n}\n```\n\nWhile we've seen the function change, remember that your game may be making this calculation in multiple parts of the codebase. On top of this, maybe your API *still* isn't perfect for this function. What if you want to display the special kills with additional points after a match?\n\nThese drastic refactors mean that each iteration requires additional refactor work, likely delaying the time to ticket completion. This can impact releases dates or other scheduled launches.\n\nLet's take a step back. Why did this happen?\n\nThese problems tend to happen because of miscommunication of scope. This miscommunication can be introduced between teams, from individual to individual, or even simply within your internal monolog.\n\n# Testing is hard\n\nOne way that many suggest working around this problem is by following TDD. TDD can help force you to address your API ahead of time by adding in a feedback loop.\n\nFor example, before implementing the `calculateUserScore` function into your codebase, you might test against the first implementation, add a `test.todo` to add in assists, and realize you should update your API before moving forward.\n\nHowever, while TDD forces you to address your API, it doesn't help you distinguish scope. This limitation of understanding of your scope may then, in turn, impact your API.\n\nLet me explain:\n\nLet's say that the ability to track special kills after the fact isn't possible to display on the match end until later in the development cycle. You know this and have decided to stop at the second implementation where `kills` is still a number. However, because the function is used repeatedly in the codebase, you'll need to do a larger refactor at a later date.\n\nHad you spoken with other engineers, you may have realized that developments in the match-end screen were completed sooner than expected. Unfortunately, it's only caught now in code review after you've made the implementation, forcing a refactor immediately.\n\n# Getting to the point\n\nOkay, okay, I'll get to the point: There's a better way to address this \"API shift\" problem better than TDD. This \"better way\" is \"Documentation driven development.\"\n\n![Drake looking away from \"Test Driven Development\" but a thumbs up for \"Documentation Driven Development\"](./drake.png)\n\nWriting docs first can help you iron out implementation details ahead of time before making tough calls about implementing a design. Even reference APIs can help you make a lot of designs.\n\nLet's loop back to the older example of `calculateUserScore`. Just like before, you called a short meeting to gather the requirements from the team. This time though, you start by writing documentation instead of starting with the code.\n\nYou include a mention of what the API should look like based on these requirements:\n\n```javascript\n/**\n * This function should calculate the user score based on the K/D of the\n * player.\n *\n * Assists should count as half of a kill\n *\n * TODO: Add specialty kills with bonus points\n */\nfunction calculateUserScore(props: {kills: number, deaths: number, assists: number}): number;\n```\n\nYou also decide to showcase some usages in your docs:\n\n```javascript\ncaluculateUserScore({kills: 12, deaths: 9, assists: 3});\n```\n\nWhile working through these docs, you decide to quickly sketch out what the future API might look like when bonus points are added.\n\n```javascript\n/*\n * TODO: In the future, it might look something like this to accommodate\n * bonus points\n */\ncalculateUserScore({kills: [{killedUser: 'user1', bonusPoints: 1}], deaths: 0, assists: 0});\n```\n\nAfter writing this, you realize you should utilize an array for the kills property first rather than later on. You don't have to have bonus points, but instead, you can simply track an `unknown` user for each kill and change it in the future.\n\n```javascript\ncalculateUserScore({kills: [{killedUser: 'unknown'}], deaths: 0, assists: 0});\n```\n\nWhile this might seem obvious to us now, it may not be so clear at the moment. This is the benefit of Documentation-Driven Development: It forces you to go through a self-feedback cycle on your APIs and the scope of your work.\n\n# Refining the process\n\nOK, I get it. Documentation is seen as a chore. While I could go on about \"your medicine is good for you,\" I've got good news for you: Documentation doesn't mean what you think it means.\n\nDocumentation can be found in many forms: design mockups, API reference docs, well-formed tickets, future plan writeups, and more.\n\nEssentially, anything that can be used to communicate your thoughts on a topic is documentation.\n\nIn fact, this _includes_ tests. 😱 Tests are a good way of conveying API examples for your usage. TDD itself may be enough on its own to convey that information for future you, while other times, it may be a good companion alongside other forms of documentation.\n\nIn particular, if you're good about [writing primarily integration tests](https://kentcdodds.com/blog/write-tests), you're actually writing out usage API docs while writing testing code.\n\nThis is particularly true when writing developer tooling or libraries. Seeing a usage example of how to do something is extremely helpful, especially with a test to validate its behavior alongside it. \n\n-------\n\nAnother thing \"documentation-driven development\" does not prescribe is \"write once and done.\" This idea is a myth and may be harmful to your scope and budgets - time or otherwise.\n\nAs we showed with the `calculateUserScore` example, you may need to modify your designs before moving forward for the final release: that's okay. Docs influence code influence docs. The same is true for TDD.\n\n--------\n\nDDD isn't just useful for developing code for production, either. In interviews, some good advice to communicate your development workflow is to write code comments and **then** write the solution. This allows you to make mistakes in the documentation phase (of writing comments) that will be less time-costly than if you'd made a mistake in implementation.\n\nBy doing this, you can communicate with your interviewer that you know how to work in a team and find well-defined goals. These will allow you to work towards an edgecase-free* implementation with those understandings.\n\n# Bring it back now y'all\n\nI realize this article already has more twists than an M. Night Shyamalan film, but here’s one more; documentation driven development, as we’ve explored today, is an established concept. It’s simply called by other names:\n\n- [Behavioral Driven Development (BDD)](https://en.wikipedia.org/wiki/Behavior-driven_development)\n- [Acceptance Test-Driven Development (ATDD)](https://en.wikipedia.org/wiki/Acceptance_test%E2%80%93driven_development)\n\nEach of these refers to a form of validating the functionality of code behind user behavior. Each encourages a stronger communication method that often includes documentation in the process. \"DDD\" is just another form of this type of logic.\n\n# Conclusion\n\nI've been using documentation-driven development as a concept to drive my coding on some projects. Among them was my project [`CLI Testing Library`](https://github.com/crutchcorn/cli-testing-library), which allowed me to write a [myriad of documentation pages](https://github.com/crutchcorn/cli-testing-library/tree/main/docs) as well as [verbose GitHub issues](https://github.com/crutchcorn/cli-testing-library/issues/2). \n\nBoth of these forced me to better refine my goals and what I was looking for. The end-product, I believe, is better as a result.\n\nWhat do you think? Is \"DDD\" a good idea? Will you be using it for your next project?\n\nLet us know what you think, and [join our Discord](https://discord.gg/FMcvc6T) to talk to us more about it! \n",
		},
		{
			title: "Why I prefer Vue over Angular: DOM Pollution",
			description:
				'Angular differs from Vue in some keys ways, including its "Incremental rendering". This shift introduces something I call "DOM Pollution"; its why I prefer Vue over Angular.',
			published: "2022-06-06T10:08:00.000Z",
			edited: "2022-06-06T10:08:00.000Z",
			authors: ["splatkillwill"],
			tags: ["webdev", "angular", "vue"],
			attached: [],
			license: {
				id: "cc-by-nc-nd-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "https://creativecommons.org/licenses/by-nc-nd/4.0/",
				name: "Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) License",
			},
			slug: "dom-pollution-why-i-prefer-vue-over-angular",
			locale: "en",
			authorsMeta: [
				{
					id: "splatkillwill",
					name: "William (Will) Lohan",
					firstName: "William",
					lastName: "Lohan",
					description: "",
					socials: {
						github: "william-lohan",
						twitch: "splat_killwill",
						website: "https://gatimus.com/",
						linkedIn: "william-lohan-b202637a",
					},
					pronouns: "they/themselves",
					profileImg: "./splatkillwill.jpg",
					color: "#BF00FF",
					roles: ["author"],
					profileImgMeta: {
						height: 512,
						width: 512,
						relativePath: "./splatkillwill.jpg",
						relativeServerPath: "/content/data/splatkillwill.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\splatkillwill.jpg",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Why I prefer Vue over Angular: DOM Pollution",
				description:
					'Angular differs from Vue in some keys ways, including its "Incremental rendering". This shift introduces something I call "DOM Pollution"; its why I prefer Vue over Angular.',
				published: "2022-06-06T10:08:00.000Z",
				edited: "2022-06-06T10:08:00.000Z",
				authors: ["splatkillwill"],
				tags: ["webdev", "angular", "vue"],
				attached: [],
				license: "cc-by-nc-nd-4",
			},
			contentMeta:
				'\nOne of the reasons I prefer front end frameworks like Vue and React over Angular, is what I like to call DOM Pollution.\n\nUnlike Vue and React, which use a virtual DOM, Angular today uses incremental rendering. Each has its pros and cons, but without a virtual DOM the components need to be represented in the browser\'s “real” DOM. Kind of like a trail of breadcrumbs, this lets the renderer know how to get back to what it’s updating.\n\nWith a renderer like the one used by Angular, breaking down your UI into reusable components comes at a cost; or at least with a side effect to be aware of. Every component adds another tag to the DOM that otherwise wouldn\'t be there, unless you made one big ugly monolith component. This can cause some problems:\n\n- Complicates CSS selectors\n- Makes SEO crawlers jobs harder\n- Can make the markup harder to read when debugging\n- Can be limiting when trying to wrap an element that needs to be a direct child of another element\n\nTo illustrate, take the following example in Vue:\n\n<iframe src="https://codesandbox.io/embed/async-leftpad-gjxmqv?codemirror=1&fontsize=14&hidenavigation=1&module=%2Fsrc%2FApp.vue&theme=dark&highlights=1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21"\n  style="width:100%; height:500px; border:0; border-radius: 4px; overflow:hidden;"\n  title="A properly formatted table with \'category\' and \'amount\' headers to your data."\n  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"\n></iframe>\n\nThen if you tried the same in Angular:\n\n<iframe src="https://codesandbox.io/embed/cranky-shadow-frukfg?codemirror=1&fontsize=14&hidenavigation=1&module=%2Fsrc%2Fapp%2Fapp.component.html&theme=dark&highlights=2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24"\n  style="width:100%; height:500px; border:0; border-radius: 4px; overflow:hidden;"\n  title="A malformed table that shows all data, including headers, horizontally instead of in a grid"\n  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"\n></iframe>\n\nWhat happened? Lets compare the custom components.\n\n`MyTextCell.vue`\n<iframe src="https://codesandbox.io/embed/async-leftpad-gjxmqv?codemirror=1&fontsize=14&hidenavigation=1&module=%2Fsrc%2Fcomponents%2FMyTextCell.vue&theme=dark&view=editor"\n  style="width:100%; height:500px; border:0; border-radius: 4px; overflow:hidden;"\n  title="MyTextCell.vue"\n  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"\n></iframe>\n\n`text-cell.component.ts`\n<iframe src="https://codesandbox.io/embed/cranky-shadow-frukfg?codemirror=1&fontsize=14&hidenavigation=1&module=%2Fsrc%2Fapp%2Ftext-cell.component.ts&theme=dark&view=editor"\n  style="width:100%; height:500px; border:0; border-radius: 4px; overflow:hidden;"\n  title="text-cell.component.ts"\n  sandbox="allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts"\n></iframe>\n\nThey both look like they are just wrapping table detail (cell) tags but they render completely diffrent.\n\nVue output:\n\n```html\n<table>\n    <!-- ect -->\n    <tr>\n        <td data-v-5fa58eab="">IT</td><!-- see here -->\n        <td data-v-451cbf87="" style="color: red;">5.27</td>\n    </tr>\n    <!-- ect -->\n</table>\n```\n\nAngular output:\n```html\n<my-table _ngcontent-rbt-c270="" _nghost-rbt-c271="">\n    <table _ngcontent-rbt-c271="">\n        <!-- ect -->\n        <my-row _ngcontent-rbt-c270="" _nghost-rbt-c272="">\n            <tr _ngcontent-rbt-c272="">\n                <!-- ect -->\n                <my-text-cell _ngcontent-rbt-c270="" _nghost-rbt-c274=""><!-- see here -->\n                    <td _ngcontent-rbt-c274="">IT</td>\n                </my-text-cell>\n                <!-- ect -->\n            </tr>\n        </my-row>\n        <!-- ect -->\n    </table>\n</my-table>\n```\n\nSo much more going on. This is because, even though the components look like they are doing the same thing, the renderer has, and must, output extra tags. Now this isn\'t how I\'d make a table in Angular and there are ways to address this like using `display: table-cell` and `role` attributes on the host but it could still be a hindrance.\n\nThis doesn\'t mean Angular is all that bad. Actually, the reason Angular components are written this way is to closely resemble a proposed standard; Web Components. \n\nSpeaking of that checkout [Corbin](/unicorns/crutchcorn)\'s [series on Web Components](/collections/web-components-101) and also [Angular elements](https://angular.io/guide/elements).\n',
		},
		{
			title: "Doomsday Rule",
			description:
				"In this blog I talk about the Doomsday Rule, how it works, how to put it into code then how to make a program that tests you.",
			published: "2022-02-10T22:12:03.284Z",
			authors: ["SkyHawk_0"],
			tags: ["python", "math"],
			attached: [],
			license: {
				id: "cc-by-4",
				footerImg: "https://i.creativecommons.org/l/by/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by/4.0/",
				name: "Attribution 4.0 International (CC BY 4.0)",
				displayName: "Creative Commons Attribution 4.0 International License",
			},
			slug: "doomsday-rule",
			locale: "en",
			authorsMeta: [
				{
					id: "SkyHawk_0",
					name: "Joshua Hawkins",
					firstName: "Joshua",
					lastName: "Hawkins",
					description:
						"I am a high school student who focuses on python. Most of my scripts I have made where just for fun or to work something out that I couldn't.",
					socials: {},
					pronouns: "he",
					profileImg: "./goofy.png",
					color: "#18BBC9",
					roles: ["author"],
					profileImgMeta: {
						height: 2048,
						width: 2048,
						relativePath: "./goofy.png",
						relativeServerPath: "/content/data/goofy.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\goofy.png",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Doomsday Rule",
				description:
					"In this blog I talk about the Doomsday Rule, how it works, how to put it into code then how to make a program that tests you.",
				published: "2022-02-10T22:12:03.284Z",
				authors: ["SkyHawk_0"],
				tags: ["python", "math"],
				attached: [],
				license: "cc-by-4",
			},
			contentMeta:
				'\n# What is the doomsday rule?\n\nBefore I get to how my program works, I should probably explain what the doomsday rule is. The doomsday rule is an algorithm that determines the day of the week for a given date in the Gregorian calendar. For example, without looking at a calendar, I know that the 18th of March, 1898 is a Friday. I can\'t think when you would use this in everyday life, but it\'s a cool party trick to show off with.\n\nThe algorithm was invented by John Conway in 1973. You may know some of his work, like Conway\'s game of life. Here\'s a nice little fact: the dates that Conway was born and died on were both doomsdays. We\'ll explain what doomsdays are later. The algorithm is simple enough that it can be calculated mentally. Conway could do this in a couple of seconds, and to improve his speed, he created a program that gave him ten random dates every time he logged on to his computer.\n\n# things you should know before the numbers\n\nI gathered this information from the [Wikipedia page, which can be found here](https://en.wikipedia.org/wiki/Doomsday_rule).\n\n## What is MOD?\n\nIf you didn\'t know already, when you get the MOD of something, you divide the first number by the second number, but the answer is the remainder. For example, 70 MOD 12 is 10, as 70 / 12 is 5 with a remainder of 10.\n\n## The days of the week\n\nThe days of the week have numbers, I have put ways of remembering them in brackets:\n```  \n0 = Sunday (Noneday)  \n1 = Monday (Oneday)  \n2 = Tuesday (Twosday)  \n3 = Wednesday (Treblesday)  \n4 = Thursday (Foursday)  \n5 = Friday (Fiveday)  \n6 = Saturday (Six-a-day)  \n```\nThis makes it very easy to add numbers to them.\n\n## Anchor Days\n\nThe Wikipedia page doesn\'t actually explain what an anchor day actually is, but it helps work out what the doomsday is for that year.\n\n## Doomsdays\n\nThe rule is called Doomsday Rule for a reason; that reason is it relies on days that are called doomsdays.\n\nI have mentioned these a lot, but what are they? They are dates of a year that fall on the same day of the week.\n\nFor examples of this, let\'s use the 18th of March 1898 for reference. To start, let\'s note that all of the following dates fall on a Monday:\n\n- 4th of April\n- 6th of June\n- 8th of August\n- 10th of October \n- 12th of December\n\nThere is one for every month, but I have only listed the 4th, 6th, 8th, 10th, and 12th months; This leaves January, February, March, May, July, September, and November, or the 1st, 2nd, 3rd, 5th, 7th, 9th and 11th month. I say the numbers and will from now on as it helps with the calculations later on.\n\nFor the 1st month, it depends if it\'s a leap year or not. To work this out, you divide the year by 4, and if it is a whole number, it\'s a leap year. So if it\'s a leap year, it\'s the 4th; if it\'s not, it\'s the 3rd. An easy way of remembering this is if it\'s the fourth year (so a leap year), it\'s the 4th. So for the 18th of March 1898, as 1898 is not divisible by 4. Because of this, the doomsday in January is the 3rd.\n\nFor the 2nd month, it also depends if it\'s a leap year; this time, the doomsday is always the last day of the month. So if it were a leap year, it would be the 29th, but if it weren\'t, it would be the 28th. So like in the paragraph above, because 1898 is not divisible by 4, the doomsday in February is the 28th.\n\nFor the 3rd month, the doomsday is Pi day. Yep, Pi day is a doomsday. So using the example, Pi day is a Monday for the 18th of March 1898.\n\nFor the 5th month, the 9th is a doomsday. An easy way of remembering it is "working 9 to 5". This mnemonic has a second half to it, but that\'s for another month. As you may have noticed (if you write your dates with the month first then day, I\'m British, so for me, it\'s day then month), the mnemonic is the wrong way round; this is because it works the other way round as well, for the 9th month the 5th is a doomsday.\n\nNow it’s just the 7th month and the 11th month. This is where the rest of the mnemonic comes. For the 7th month, the 11th is a doomsday, and the same the other way, for the 11th month, the 7th is a doomsday. So the full mnemonic is "working 9 to 5, at 7-11"\n\nList of all doomsdays (written is day/month):   \n\n- 3/1 or 4/1\n- 28/2 or 29/2\n- 14/3\n- 4/4\n- 5/9\n- 6/6\n- 7/11\n- 8/8\n- 9/5\n- 10/10\n- 11/7\n- 12/12\n\n## What about decimals?\n\nYou throw away the decimals; you don\'t round down as well, so, for example, the answer for 70 / 12 is 5.83, but for us, we only care about the whole number, so it would be 5.\n\n# How does it work?\n\nTo explain how it works I will be using an example along with the explanation. I will be using the date Apollo 11 landed on the moon: July 20, 1969.\n\nFirst, you get the anchor day for the century. The way you work this out is you get the first 2 digits of the year. Then do `5 × (century MOD 4) MOD 7 + Tuesday`.\n\nSo, for our example, `19 MOD 4` is 3; as a result, the calculation now looks like this:\n\n`5 x 3 MOD 7 + Tuesday`\n\nBecause of BIDMAS, we do `5 x 3`, which gives us 15. Then get `15 MOD 7` - which is 1 - then add Tuesday (2) to our previous multiplication, giving us 3.\n\nIf we remember back to our date/number lookup chart, `3` is associated with Wednesday. So, from our calculation, we know that the anchor day for the 1900s is a Wednesday.\n\nNow we need to find the years offset. We do this with three calculations, then adding the total together. I will label the first calculation "a", the second "b" and the third "c".\n\nThe calculations are:\n\n```\na = (last two digits of the year) / 12\n\nb = (last two digits of the year) MOD 12\n\nc = b / 4\n```\n\nAfter these calculations, you finally do:\n\n`a + b + c = offset`\n\nThen you get the MOD of offset. Think of MOD as if you were to add 7 to Wednesday (3), then run MOD over that new number (10), you are back to Wednesday. (3)\n\nSo using the example you would do:\n```\na = 69 / 12\n\na = 5\n\nb = 69 MOD 12 \n\nb = 9\n\nc = 9 / 4\n\nc = 2\n\nSo, 5 + 9 + 2 = 16\n```\nThen get the MOD which is, 2.\n\nSo we now know that the year offset is 2, and we know that the anchor day for the century is Wednesday, or 3. We add the two numbers together to get 5 and match that to our date chart, so for 1969, the doomsday is Friday.\n\nNow we need to think about the closest doomsday to July 20th. Which is the 11th of July. So from the above calculation, we know that the 11th of July is a Friday. Then we work out the difference between the date we need to figure it and the doomsday, so here it would be `20 - 11 = 9`. Then we MOD this by 7 like we did to find the offset.\n\nSo this would be 2.\n\nThen we add this to the doomsday. So `5 + 2 = 7`. But there isn\'t a 7 in our chart, but remember, `7 MOD 7` is 0. and 0 is Sunday. So we now know that the day of Apollo 11\'s landing was on a Sunday.\n\n# The fun part, Coding!\n\n## The Solver\n\nI wrote the script using functions so that it would be easy to edit the code.\n\n### Coding part 1 *The backbone of this project*\n\nFirst, I thought it would be good to start with the harder bit, which is the actual solver; But what is the first part you need for the calculations? Inputs. Let\'s build a script to generate those inputs.\n\nThe script needs to output three inputs: a day, month, and year. We will call them their respective names, so it will look like this:\n\n```python\nday = int(input("What day do you want? (number needed) "))\nmonth = int(input("What month do you want? (number needed) "))\nyear = int(input("What year do you want? "))\n```\n\nWe put `int` there to tell the program that whatever the input is, it\'s an integer not a string.\n\nNow we need the script to work out the anchor day for the century. Unfortunately, while I was making the script, whenever I tried to do the `century MOD 4` calculation, it would be incorrect. Luckily, Wikipedia has a different way of working out the anchor day, which is:\n\n`5 * (Century MOD 4) MOD 7 + 2`\n\nThe way you work out the century is:\n\n`year / 100`\n\nUnless the year ended in 00, the output of this division would be a decimal, but we need a non-decimal number. To solve for this, we can write the following in our code:\n\n`int(year / 100)`\n\nSo under the inputs we put:\n\n```python\nCentury = int(year / 100)\n\nanchor = 5 * (Century % 4) % 7 + 2\n```\n\n> The percentage sign (%) is python\'s MOD\n\nThe program now can get the anchor day. The next step is to work out the doomsday for the year. To do this, we must tell the program how to get the last 2 digits of the year. We\'ll tell the script to convert the year to a string, then tell it to get the 3rd and 4th character. That code looks like this:\n\n```python\nEndTwo = str(year)\nEndTwo = EndTwo[2:4]\n```\n\nSo going back to the a, b and c calculations they would look like this:\n\n```python\nA = int(int(EndTwo) / 12)\n\nB = int(EndTwo) % 12\n\nC = int(B / 4)\n```\n\nThen add them together and MOD the sum. After that you want to add the anchor. So in code this would look like:\n\n```python\nDoomsday = ((A + B + C) % 7) + anchor\n```\n\nThen just get the MOD of `Doomsday`:\n\n```python\nDoomsday = Doomsday % 7\n```\n\nSo far the script looks like:\n```python\nday = int(input("What day do you want? (number needed) "))\nmonth = int(input("What month do you want? (number needed) "))\nyear = int(input("What year do you want? "))\n\nEndTwo = str(year)\nEndTwo = EndTwo[2:4]\n\nCentury = int(year / 100)\n\nanchor = 5 * (Century % 4) % 7 + 2\n\nA = int(int(EndTwo) / 12)\n\nB = int(EndTwo) % 12\n\nC = int(B / 4)\n\nDoomsday = ((A + B + C) % 7) + anchor\n\nDoomsday = Doomsday % 7\n```\n\nNow we need the script to find the doomsday in the chosen month. But the script doesn\'t know what a doomsday is, so we will create a 2D list that contains the doomsday every month. We will put the list just after the inputs to keep the script structured. The list will be written as:\n\n```python\nDoomsdayList = [[4, 4], [6, 6], [8, 8], [10, 10], [12, 12], [9, 5], [5, 9], [14, 3], [7, 11], [11, 7], [4, 1], [29, 2]]\n```\n\nNow that the script knows what the doomsdays are, loop through all 12 items in the list. Then we can check if `month` is the same as `a` (declared in the loop). However, since it is a 2D list, we also need to tell it to look in the second column. As a result, the code looks like this:\n\n```python\nfor a in range(len(DoomsdayList)):\n    if DoomsdayList[a][1] == month:\n        location = a\n```\nBut this causes a problem; `DoomsdayList` has only the dates for a leap year. But what if it\'s not a leap year? We can solve this problem by adding an if statement after our check. This if statement should check if `year MOD 4` is greater than or equal to 1. If this statement is true, set the 10th item of the list to `[3, 1]` and the 11th item to `[28, 2]`.\n\n```python\nif year % 4 >= 1:\n    DoomsdayList[10] = [3, 1]\n    DoomsdayList[11] = [28, 2]\n```\n\n### Quick summary\nJust summarizing what we have done so far, we have three inputs: year, month, and day. The script calculates the anchor day for the century. It gets the last two digits of the year then uses the a, b and c calculations. Once this is done, it adds them together, gets the MOD 7 of that then adds the anchor. Next, it receives the MOD 7 of that answer. The answer for the last MOD is the doomsday. We have a `DoomsdayList` which contains the doomsdays. We have an if statement that changes the 10th and 11th item if it\'s not a leap year. Then we have a loop that looks for the location of the doomsday in the picked month.\n\nThe code should look like this now:\n```python\nday = int(input("What day do you want? (number needed) "))\nmonth = int(input("What month do you want? (number needed) "))\nyear = int(input("What year do you want? "))\n\nDoomsdayList = [[4, 4], [6, 6], [8, 8], [10, 10], [12, 12], [9, 5], [5, 9], [14, 3], [7, 11], [11, 7], [4, 1], [29, 2]]\n\nif year % 4 >= 1:\n    DoomsdayList[10] = [3, 1]\n    DoomsdayList[11] = [28, 2]\n\nEndTwo = str(year)\nEndTwo = EndTwo[2:4]\n\nCentury = int(year / 100)\n\nanchor = 5 * (Century % 4) % 7 + 2\n\nA = int(int(EndTwo) / 12)\n\nB = int(EndTwo) % 12\n\nC = int(B / 4)\n\nDoomsday = ((A + B + C) % 7) + anchor\n\nDoomsday = Doomsday % 7\n\nfor a in range(len(DoomsdayList)):\n    if DoomsdayList[a][1] == month:\n        location = a\n```\n\n### Coding part 2 *Doomsday and printing the right day of the week*\n\nThe most difficult bit is now done. Now, we only need to worry about the day of the month. After all, the script now knows the location of the closest doomsday. But this is only half true; we haven\'t told it to get the item in that location, which is luckily pretty easy to do:\n\n```python\nClosestDoomsday = DoomsdayList[location]\n```\nNow we need the difference of day and `ClosestDoomsday[0]`, we put the zero there as that is the day of the month.\n\n```python\ndifference = day - ClosestDoomsday[0]\n```\n\nAfter this we need to get MOD 7 of difference:\n\n```python\ndifference = difference % 7\n```\n\nThen we can add `Doomsday` to `difference`:\n\n```python\nDayOfWeek = Doomsday + difference\n```\n\nafter this we get MOD 7 of `DayOfWeek`:\n\n```python\nDayOfWeek = DayOfWeek % 7\n```\n\nThen we can just output the number:\n```python\nprint("This date falls on a", DayOfWeek)\n```\n\nBut this just would print out a number, so we will create another list called `weekList` we put this just above `DoomsdayList`:\n```python\n#            0         1         2          3            4           5         6\nweekList = ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"]\n```\n\nThen we can change the output command to:\n```python\nprint("This date falls on a", weekList[DayOfWeek])\n```\n\nFinally, the completed script should look like this:\n```python\nday = int(input("What day do you want? (number needed) "))\nmonth = int(input("What month do you want? (number needed) "))\nyear = int(input("What year do you want? "))\n\n#            0         1         2          3            4           5         6\nweekList = ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"]\n\nDoomsdayList = [[4, 4], [6, 6], [8, 8], [10, 10], [12, 12], [9, 5], [5, 9], [14, 3], [7, 11], [11, 7], [4, 1], [29, 2]]\n\nif year % 4 >= 1:\n    DoomsdayList[10] = [3, 1]\n    DoomsdayList[11] = [28, 2]\n\nEndTwo = str(year)\nEndTwo = EndTwo[2:4]\n\nCentury = int(year / 100)\n\nanchor = 5 * (Century % 4) % 7 + 2\n\nA = int(int(EndTwo) / 12)\n\nB = int(EndTwo) % 12\n\nC = int(B / 4)\n\nDoomsday = ((A + B + C) % 7) + anchor\n\nDoomsday = Doomsday % 7\n\nfor a in range(len(DoomsdayList)):\n    if DoomsdayList[a][1] == month:\n        location = a\n\nClosestDoomsday = DoomsdayList[location]\n\ndifference = day - ClosestDoomsday[0]\n\ndifference = difference % 7\n\nDayOfWeek = Doomsday + difference\n\nDayOfWeek = DayOfWeek % 7\n\nprint("This date falls on a", weekList[DayOfWeek])\n```\n\n## The Tester\n\nWith the hardest bit now out of the way and put into functions, we can now relax. Make a new file but keep the old when as you can look back at it to see how it works and even modify it. We built it to be used to understand what our logic should do and can be used as a template for other programs that will use it: like the tester.\n\nI built the tester using `randint` from the module `random`. This should be your first line of code:\n```python\nfrom random import randint\n```\n### Coding part 1: *The functions*\n\nIn the previous program, we made three inputs: Year, Month, Day. We still need to pass these to the doomsday program, but we need to do it randomly. To keep our code\'s structure, we will use functions.\n\n#### Random Year\n\nTo get a random year, we will just make a function that has two arguments: `StartYear` and `EndYear`. These will be in a `randint` line:\n\n```python\ndef randomYear(StartYear, EndYear):\n    return randint(StartYear, EndYear)\n```\n\nSo when ever `randomYear` is called it will pick a random number between `StartYear` and `EndYear`. This is only called once in the code but it keeps the code neat and you know what does what.\n\n#### Random Month\n\n`randomMonth` is the easiest out of the three. We don\'t need any arguments just a line that picks a random number between one and twelve. As there are 12 months in a year:\n```python\ndef randomMonth():\n    return randint(1, 12)\n```\n\n#### Random Day\n\n`randomDay` is the hardest out of the three, as there 4 possibilities that can come out of the function. `31`, `30`, `29` and `28`\n\nwe need two arguments which will be the `month` and `Year`. We need the month to see how many days there are in the month. but if it\'s a leap year (That\'s why we need the year) and it is February we need to know if its 28 days or 29 days the code looks like this for starters:\n```python\ndef randomDay(Month, Year):\n    IsLeap = Year % 4 == 0\n\n    if Month == 1 or Month == 3 or Month == 5 or Month == 7 or Month == 8 or Month == 10 or Month == 12:\n        DaysInMonth = 31\n    elif Month == 4 or Month == 6 or Month == 9 Month == 1:\n        DaysIMonth = 30\n    elif IsLeap == True and Month == 2:\n        DaysInMonth = 29\n    elif IsLeap == False and Month == 2:\n        DaysInMonth = 28\n```\nAfter we have done this all we need to do is get a random number between 1 and `DaysInMonth`:\n```python\nDay = randint(1, DaysInMonth)\n```\nThen we just return `Day`:\n```python\nreturn Day\n```\n\nso altogther the `randomDay()` function should look like this:\n```python\ndef randomDay(Month, Year):\n    IsLeap = Year % 4 == 0\n\n    if Month == 1 or Month == 3 or Month == 5 or Month == 7 or Month == 8 or Month == 10 or Month == 12:\n        DaysInMonth = 31\n    elif Month == 4 or Month == 6 or Month == 9 Month == 1:\n        DaysIMonth = 30\n    elif IsLeap == True and Month == 2:\n        DaysInMonth = 29\n    elif IsLeap == False and Month == 2:\n        DaysInMonth = 28\n\n    Day = randint(1, DaysInMonth)\n\n    return Day\n```\n\n#### making the Finder a function\n\nSo now we have a random day, month and year. We can now make a function from The solver segment code, we need to change it slightly, like getting rid of the inputs and putting a `return` at the end. We will have three arguments and so we don\'t need to go through and change the variable names we will call them `day`, `month` and `year`. Then we need to put a `return` at the end that returns the day of the week.\nAs I have already talked about how this code works I will just give you the whole function:\n```python\ndef Finder(day, month, year):\n    #            0         1         2          3            4           5         6\n    weekList = ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"]\n\n    DoomsdayList = [[4, 4], [6, 6], [8, 8], [10, 10], [12, 12], [9, 5], [5, 9], [14, 3], [7, 11], [11, 7], [4, 1], [29, 2]]\n\n    if year % 4 >= 1:\n        DoomsdayList[10] = (3, 1)\n        DoomsdayList[11] = (28, 2)\n\n    EndTwo = str(year)\n    EndTwo = EndTwo[2:4]\n\n    Ce = int(year / 100)\n\n    anchor = 5 * (Ce % 4) % 7 + 2\n\n    A = int(int(EndTwo) / 12)\n\n    B = int(EndTwo) % 12\n\n    C = int((int(EndTwo) % 12) / 4)\n\n    Doomsday = ((A + B + C) % 7) + anchor\n\n    Doomsday = Doomsday % 7\n\n    for a in range(len(DoomsdayList)):\n        if DoomsdayList[a][1] == month:\n            location = a\n\n    rightDoomsday = DoomsdayList[location]\n\n    difference = day - rightDoomsday[0]\n\n    difference = difference % 7\n\n    DayOfWeek = Doomsday + difference\n\n    DayOfWeek = DayOfWeek % 7\n\n    return weekList[DayOfWeek]\n```\n\n### Coding Part 2 *Making the question code __almost there__*\n\nWe will start by making a variable called `questions`. This will simply just be to see how many questions the user wants:\n```python\nquestions = int(input("How many questions? "))\n```\n\nthen we will have a `for` loop that repeats for how many questions the user wants:\n```python\nfor a in range(questions):\n```\nUntil I say, all the code from now on will be inside this loop.\n\nWe want to get random `Year`, `Month` and `Day` first:\n```python\n    Year = randomYear(1800, 2200)\n    Month = randomMonth()\n    Day = randomDay(Month, Year)\n```\nSo this will get a random year between 1800 and 2200, a random month, then a random day using the data from Month and Year.\n\nWe then want the code to figure out the correct day, this is easy as we have a function that we just built that does this:\n```python\n    DayOfWeek = Finder(Day, Month, Year)\n```\n\nSo even before the question is asked the code already knows the answer.\n\nThen we ask the user what the day is:\n```python\n    print(a+1, ". What day is ", Day, "/", Month, "/", Year, sep="", end="    ", flush=True)\n```\nThis will show the question number (The `+1` is there as the loop starts on 0) then the date, then will add space for the input.\n\nWe then need to get the input. Very easy. We will then convert the string to uppercase so that if they put `Monday`, `monday` or `mOnday` it would just set it to `MONDAY`:\n```python\n    guess = input()\n    guessUpper = guess.upper()\n```\nWe also want to do this to the answer that the code got as well:\n```python\n    DayOfWeekUpper = DayOfWeek.upper()\n```\n\nThen we can find out if the user was right using a `if` statement:\n```python\n    if guessUpper == DayOfWeekUpper:\n        Correct = True\n    else:\n        Correct = False\n```\n\nThen we need the code to do something if they got it right we can have another `if` statementL\n```python\n    if Correct:\n        print("That is correct.")\n        score += 1\n    else:\n        print("That is incorrect. The correct answer is", DayOfWeek)\n```\nHere we have used a variable called `score` which we haven\'t set anywhere so just above the `for` loop we will put:\n```python\nscore = 0\n```\nWe put it outside the loop as if it was in the loop it would set `score` back to zero, after each question so it would only be 1 or 0.\n\nSo now outside the `for` loop we will show the percentage of correct answers:\n```python\nprint("Your percentage is", (score / questions) * 100)\n```\n\nAnd thats it! I will put the whole code here so that you can check errors and stuff:\n# If you just want the code and don\'t care how it works, look here!\n```python\nfrom random import randint\n\ndef randomYear(StartYear, EndYear):\n    return randint(StartYear, EndYear)\n\ndef randomMonth():\n    return randint(1, 12)\n\ndef randomDay(Month, Year):\n    IsLeap = Year % 4 == 0\n\n    if Month == 1 or Month == 3 or Month == 5 or Month == 7 or Month == 8 or Month == 10 or Month == 12:\n        DaysInMonth = 31\n    elif Month == 4 or Month == 6 or Month == 9 Month == 1:\n        DaysIMonth = 30\n    elif IsLeap == True and Month == 2:\n        DaysInMonth = 29\n    elif IsLeap == False and Month == 2:\n        DaysInMonth = 28\n\n    Day = randint(1, DaysInMonth)\n\n    return Day\n\ndef Finder(day, month, year):\n    #            0         1         2          3            4           5         6\n    weekList = ["Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"]\n\n    DoomsdayList = [[4, 4], [6, 6], [8, 8], [10, 10], [12, 12], [9, 5], [5, 9], [14, 3], [7, 11], [11, 7], [4, 1], [29, 2]]\n\n    if year % 4 >= 1:\n        DoomsdayList[10] = (3, 1)\n        DoomsdayList[11] = (28, 2)\n\n    EndTwo = str(year)\n    EndTwo = EndTwo[2:4]\n\n    Ce = int(year / 100)\n\n    anchor = 5 * (Ce % 4) % 7 + 2\n\n    A = int(int(EndTwo) / 12)\n\n    B = int(EndTwo) % 12\n\n    C = int((int(EndTwo) % 12) / 4)\n\n    Doomsday = ((A + B + C) % 7) + anchor\n\n    Doomsday = Doomsday % 7\n\n    for a in range(len(DoomsdayList)):\n        if DoomsdayList[a][1] == month:\n            location = a\n\n    rightDoomsday = DoomsdayList[location]\n\n    difference = day - rightDoomsday[0]\n\n    difference = difference % 7\n\n    DayOfWeek = Doomsday + difference\n\n    DayOfWeek = DayOfWeek % 7\n\n    return weekList[DayOfWeek]\n\nquestions = int(input("How many questions? "))\nscore = 0\nfor a in range(questions):\n    Year = randomYear(1800, 2200)\n    Month = randomMonth()\n    Day = randomDay(Month, Year)\n\n    DayOfWeek = Finder(Day, Month, Year)\n\n    print(a+1, ". What day is ", Day, "/", Month, "/", Year, sep="", end="    ", flush=True)\n\n    guess = input()\n    guessUpper = guess.upper()\n\n    DayOfWeekUpper = DayOfWeek.upper()\n\n    if guessUpper == DayOfWeekUpper:\n        Correct = True\n    else:\n        Correct = False\n\n    if Correct:\n        print("That is correct.")\n        score += 1\n    else:\n        print("That is incorrect. The correct answer is", DayOfWeek)\n\nprint("your percentage is", (score / questions) * 100)\n```\n',
		},
		{
			title: "Draw under the Android NavBar Using React Native",
			description:
				"Android allows you to draw content under the navigation bar. It's a neat effect! Let's add that to our React Native apps.",
			published: "2020-04-16T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["android", "react native"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "draw-under-navbar-using-react-native",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Draw under the Android NavBar Using React Native",
				description:
					"Android allows you to draw content under the navigation bar. It's a neat effect! Let's add that to our React Native apps.",
				published: "2020-04-16T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["android", "react native"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				'\n\nWhile working on [my React Native mobile app](https://gitshark.dev), [the super-talented designer for the project](/unicorns/edpratti) raised an interesting question to me:\n\n> "Are we able to draw under the navigation bar and status bar? [Google officially recommends new apps to do so](https://youtu.be/Nf-fP2u9vjI).\n\nThe idea of drawing under the navbar intrigued me. After lots of research, I was finally able to implement it in my app, but not without struggles. Let\'s walk through how to do it manually and what I ended up doing to solve the issue myself.\n\nFeel free to follow along with the code samples, but if you\'re looking for the easiest solution, [you might want to read to the bottom to see how to easily integrate it into your app without all of the manual work](#react-native-immersive-bars).  \n\n# The Wrong Way {#flag-layout-no-limits}\n\nAfter doing some initial research, I found myself presented with various StackOverflows and official documentation pointing towards a Window flag [`FLAG_LAYOUT_NO_LIMITS`](https://developer.android.com/reference/android/view/WindowManager.LayoutParams#FLAG_LAYOUT_NO_LIMITS) to, quote:\n\n> Window flag: allow window to extend outside of the screen.\n\nThis seemed perfect to me! Being able to draw content outside the edges of the screen would surely allow me to draw under the navbar, right? I looked for the `MainActivity.java` file that loads the project initially to make the configuration:\n\n```\nandroid > app > src > main > java > yourpackagepath > MainActivity.java\n```\n\nAnd added the respective flag to initialize once the app started:\n\n```java\nimport android.os.Bundle;\nimport android.view.Window;\nimport android.view.WindowManager;\n\n// ...\n\n@Override\nprotected void onCreate(Bundle savedInstanceState) {\n    Window w = getWindow();\n    w.setFlags(\n        WindowManager.LayoutParams.FLAG_LAYOUT_NO_LIMITS,\n        WindowManager.LayoutParams.FLAG_LAYOUT_NO_LIMITS\n    );\n    super.onCreate(savedInstanceState);\n}\n```\n\nOnce this was done, I loaded my app and "et voilà"!\n\n![The FAB is placed under the navbar as expected](./flag_layout_no_limits.png)\n\n\n\n"Success," I\'d thought to myself. Since the FAB was drawn under the navbar, I thought the goal had been achieved! However, once I tried [the `safe-area-context` package](https://github.com/th3rdwave/react-native-safe-area-context) to draw margins and paddings (to move the FAB above the navbar), I faced difficulties.\n\nWhen I utilized the following code:\n\n```jsx\nimport {useSafeArea} from "react-native-safe-area-context";\n\n// ...\n\nconst insets = useSafeArea();\n\n// ...\n\nreturn <Text style={styles.headingText}>Repositories {insets.bottom}</Text>\n\n```\n\nI was expecting to see the text to read out the height of the navbar. Then, I\'d be able to use the `bottom` property to position the FAB properly.\n\n![The titlebar of the previous screenshot reads "Repositories 0"](./flag_layout_no_limits_insets_display.png)\n\nHowever, as you can see, it returned a height of `0`, which clearly wasn\'t the size of the navbar.\n\nAfter some research, [I found out that the `safe-area-context` package does not work properly when using this flag](https://github.com/th3rdwave/react-native-safe-area-context/issues/8). It doesn\'t work because of [the underlying APIs that the library uses for Android detection](https://github.com/th3rdwave/react-native-safe-area-context/blob/master/android/src/main/java/com/th3rdwave/safeareacontext/SafeAreaViewManager.java) ([InsetsAPI](https://medium.com/androiddevelopers/windowinsets-listeners-to-layouts-8f9ccc8fa4d1)), does not support the `FLAG_LAYOUT_NO_LIMITS.` This was an automatic no-go for my app: I didn\'t want the contents of the app to be stuck under the navbar without a way to access it. I had to start over from the drawing board.\n\n# Translucent Bars {#translucentcy}\n\nAfter even further research, I\'d found myself with a potential alternative: Translucent bars! I knew that the ability to draw under navbars was often accompanied with translucent bars in previous versions of Android! If we revert changes to the `MainActivity.java` file back to how they were initially, and simply update our `styles.xml` file located at:\n\n```\nandroid > app > src > main > res > values > styles.xml\n```\n\nAnd added the translucent flags, maybe that would work:\n\n```xml\n<resources>\n    <!-- Base application theme. -->\n    <style name="AppTheme" parent="Theme.AppCompat.Light.NoActionBar">\n        <!-- Customize your theme here. -->\n        <item name="android:textColor">#000000</item>\n        <!-- Add these two new items -->\n        <item name="android:windowTranslucentStatus">true</item>\n        <item name="android:windowTranslucentNavigation">true</item>\n    </style>\n</resources>\n```\n\nAfter making the changes and restarting my app, I was greeted with the following:\n\n![The correct number drawn but the bars aren\'t fully transparent](./translucent_bars.png)\n\nFantastic! It\'s not only drawing under the navbar, but it\'s also registering the correct `inset.bottom` height we wanted to display in the titlebar! That said, I was still hoping for a fully transparent navbar. I knew it was possible. Maybe if I added explicit code to make the navbar transparent, that would work:\n\n```xml\n<item name="android:statusBarColor">@android:color/transparent</item>\n<item name="android:navigationBarColor">@android:color/transparent</item>\n<item name="android:windowTranslucentStatus">true</item>\n<item name="android:windowTranslucentNavigation">true</item>\n```\n\nUnfortunately for me, there was nothing brought about by this testing.\n\n## Further Tests to no Avail {#fitsSystemWindows}\n\nBefore giving up on the `styles.xml` file, I tried two more flags that I thought might have helped.\n\n```xml\n <!-- Boolean internal attribute to adjust view layout based on system windows such as the status bar.\n    If true, adjusts the padding of this view to leave space for the system windows. API Level 1-->\n<item name="android:fitsSystemWindows">true</item>\n<!-- Flag indicating whether this Window is responsible for drawing the background for the system bars. API level 21-->\n<item name="android:windowDrawsSystemBarBackgrounds">true</item>\n```\n\nOddly enough, not only did this not solve the problem, but it made the bottom bar a solid color!\n\n![The bottom bar from before but now a solid color](./fits_system_translucent.png)\n\nDrats! We\'ll have to start all over again.\n\n# The Right Way\n\nAfter re-reading some of the resources I was looking at, I realized the answer was in [the initial GitHub issue I was first looking into when `FLAG_LAYOUT_NO_LIMIT` didn\'t work](https://github.com/th3rdwave/react-native-safe-area-context/issues/8). It suggested using [a View flag called `SYSTEM_UI_FLAG_LAYOUT_HIDE_NAVIGATION`](https://developer.android.com/reference/android/view/View#SYSTEM_UI_FLAG_LAYOUT_HIDE_NAVIGATION). After reading the documentation for the flag, I knew it was a step in the right direction:\n\n> View would like its window to be laid out as if it has requested `SYSTEM_UI_FLAG_HIDE_NAVIGATION`, even if it currently hasn\'t.\n\nWe\'d also likely want to apply [the `SYSTEM_UI_FLAG_LAYOUT_STABLE` flag as well](https://developer.android.com/reference/android/view/View#SYSTEM_UI_FLAG_LAYOUT_STABLE):\n\n> When using other layout flags, we would like a stable view of the content insets given to `fitSystemWindows`\n\nWhile this might be a bit confusing, it\'s essentially saying that not only would it draw under the navbar, but it would do so consistently, allowing us to draw under the navbar, just like we wanted!\n\nFor good measure, let\'s add in explicitly transparent navbars and status bar codes:\n\n```java\n// MainActivity.java\nimport android.graphics.Color;\nimport android.os.Bundle;\nimport android.view.View;\nimport android.view.Window;\n\n// ...\n\n@Override\nprotected void onCreate(Bundle savedInstanceState) {\n    Window w = getWindow();\n    w.setStatusBarColor(Color.TRANSPARENT);\n    w.setNavigationBarColor(Color.TRANSPARENT);\n    w.getDecorView().setSystemUiVisibility(View.SYSTEM_UI_FLAG_LAYOUT_HIDE_NAVIGATION | View.SYSTEM_UI_FLAG_LAYOUT_STABLE);\n    super.onCreate(savedInstanceState);\n}\n```\n\n![The bottom bar is now fully transparent](./transparent.png)\n\nThat\'s done it! Not only is the button being drawn under the navbar fully transparently, but the number at the top of the screen indicates that the Inset API is registering the height of the navbar still! This behavior is exactly what we were hoping for!\n\n> If your bottom bar is still a solid color like the one here:\n> ![The bottom bar in solid white](./fits_system_transparent.png)\n>\n> Then you\'ve forgotten to remove the `fitsSystemWindows` flag that we added in our `styles.xml` flag previously. Once that (and the `windowDrawsSystemBarBackgrounds` flag) was removed, it worked for me\n\n# Other API Versions {#api-versions}\n\nWhile the code I\'ve mentioned thus far works, it only really works _well_ on Android O (API Level 26) and above. That\'s only about 60% of Android devices out there! Why does this only work well on Android O? Well, if you have a light background, it only makes sense to have dark buttons in the navigation bar. That functionality has only existed since [Android introduced the `SYSTEM_UI_FLAG_LIGHT_NAVIGATION_BAR` Vew flag in API 26](https://developer.android.com/reference/android/view/View#SYSTEM_UI_FLAG_LIGHT_NAVIGATION_BAR). To edge-case this, we\'ll need to add some conditional logic to draw our own dark translucent bar for versions lower than this:\n\n```java\nif ( Build.VERSION.SDK_INT <= Build.VERSION_CODES.O) {\n\tw.setNavigationBarColor(Color.parseColor("#50000000"));\n} else {\n\tw.setNavigationBarColor(Color.TRANSPARENT);\n}\n```\n\nLikewise, [the support for dark status bar icons has only been present since API Level 23 (Android M)](https://developer.android.com/reference/android/view/WindowManager.LayoutParams#SYSTEM_UI_FLAG_LIGHT_STATUS_BAR). This too will need to be edge-cased:\n\n```java\nif (Build.VERSION.SDK_INT <= Build.VERSION_CODES.M) {\n\tw.setStatusBarColor(Color.parseColor("#50000000"));\n} else {\n\tw.setStatusBarColor(Color.TRANSPARENT);\n}\n```\n\nWhen viewing the app on older versions of Android (like M), you\'ll see the respective bars as a semi-transparent bar:\n![The statusbar is transparent while the navbar is translucent](./transparent_m.png)\n\n# The Easy Method {#react-native-immersive-bars}\n\nLet\'s not sugar coat it: It\'s tedious to make changes to native Android code in order to support all of the various API levels there are, the various forms of OEM issues that could arise. Likewise, if your app implements a dark mode, there\'s now another level of challenge: You have to toggle the light and dark navigation buttons yourself! \n\nFear not, fellow developer! I\'ve taken my learnings from implementing this into [my mobile Git Client](https://gitshark.dev) and created a package for you to utilize!\n\nhttps://github.com/crutchcorn/react-native-immersive-bars\n\nIt\'s as simple to add as:\n\n```\nyarn add react-native-immersive-bars\n```\n\n```jsx\nimport {changeBarColors} from \'react-native-immersive-bars\';\n\n// ...\n\nReact.useEffect(() => {\n    changeBarColors(isDarkMode);\n}, [isDarkMode]);\n```\n\nIt supports dark mode switching, as many API levels as React Native does, and much more!\n\n<video src="./android_10.mp4" title="A working dark switch with transparent navbar"></video>\n\n# Conclusion\n\nThis feature was not a trivial one for me to implement. Not often is it that such a short article reflects how long I\'d spent debugging and researching this issue. I want to make sure to thank [James Fenn](/unicorns/fennifith) and [Sasi Kanth](https://github.com/msasikanth) for helping me debug and research for this. I\'m happy I did so, though. I think it adds a nice level of polish to my app, and I think you\'ll find the same in your app as well. Hopefully, the package I made is able to ease the process for you. If you have any comments or questions regarding the package, please refer to the GitHub issues for said project.\n\nOtherwise, if you have comments or questions about the article, you can leave them in the comments down below. We also have a newsletter that you can subscribe to for more articles like this: I plan on writing much more about React Native as I develop my app.\n\n',
		},
		{
			title: "Write Simpler Tests - 5 Suggestions for Better Tests",
			description:
				"Writing tests is a big skill for any engineer, but we often over-complicate them. Let's simplify our tests for better testing overall!",
			published: "2020-05-26T05:12:03.284Z",
			authors: ["crutchcorn", "skatcat31"],
			tags: ["testing", "jest"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "five-suggestions-for-simpler-tests",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
				{
					id: "skatcat31",
					name: "Robert Mennell",
					firstName: "Robert",
					lastName: "Mennell",
					description:
						"A fullstack engineer who loves learning new things, playing video games, and his wife.\nIf you can learn it, you can do it.\nIf you can do it well, you've learned it.",
					socials: { github: "skatcat31", linkedIn: "rnmennell" },
					color: "#ba68c8",
					profileImg: "./hello.png",
					pronouns: "he",
					roles: ["author", "community"],
					profileImgMeta: {
						height: 2048,
						width: 2048,
						relativePath: "./hello.png",
						relativeServerPath: "/content/data/hello.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\hello.png",
					},
					rolesMeta: [
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Write Simpler Tests - 5 Suggestions for Better Tests",
				description:
					"Writing tests is a big skill for any engineer, but we often over-complicate them. Let's simplify our tests for better testing overall!",
				published: "2020-05-26T05:12:03.284Z",
				authors: ["crutchcorn", "skatcat31"],
				tags: ["testing", "jest"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nWriting tests is a part of programming and the skills that allow for good test writing are deviant from the typical programming skillset. This isn't to say that programming and writing tests are entirely separated from one another, but that writing tests requires a different mindset when approaching them. One of the primary differences between most programming and writing tests is that it tends to benefit your application by writing simpler tests.\n\nWe’ve collected five methods for simplifying your tests while making them easier to write, understand, and debug.\n\nYou may notice that our code samples use various libraries from [the Testing Library suite of libraries](https://testing-library.com/). This is because we feel that these testing methodologies mesh well with the user-centric testing that the library encourages.\n\n> Keep in mind that Jest (and furthermore, Testing Library) is not exclusive to \n> any specific framework or toolset. This article is meant just as general advice for testing.\n>\n> That said if you're looking to include Jest and Testing Library into your Angular app,\n> but don't know where to start, [we wrote a guide on how to do just that](/posts/writing-better-angular-tests/)\n\n# Don't Include Application Logic in Tests {#dont-include-logic}\n\nI'd like to make a confession: I love metaprogramming. Whether it's typings, complex libraries, babel plugins, it's all joyous for me to write.\n\nThe problem that I face is that I find it's often not joyous for others to read (or debug, for that matter). This is especially pronounced in my testing: when I don't keep things simple my tests tend to suffer.\n\nTo demonstrate this point, let's use an example component: A table component. This component should have the following functionality:\n\n- Optional pagination\n- When pagination is disabled, list all items\n- Display a row of various sets of data\n\nWe could use a `for` loop to make sure that each row contains each set of data. This would keep our logic somewhat centralized and able to be quickly customized:\n\n```javascript\nimport { screen, getByText } from '@testing-library/dom';\nimport moment from 'moment';\n\nconst rows = [{\n\t// ... A collection of objects that contains a name, phone number, and date of birth\n}]\n\n  rows.forEach((row, index) => {\n      const domRow = screen.getByTestId(`row-${index}`);\n      expect(getByText(domRow,row.name)).toBeInTheDocument();\n      expect(getByText(domRow, moment(row.dob).format(formatDate))).toBeInTheDocument();\n      expect(getByText(domRow, row.phone)).toBeInTheDocument();\n    });\n```\n\nWhile this code is relatively easy to read through, it's not immediately clear what content we're looking to see on-screen.\n\nFor example, how many items am I expecting to be rendered?\n\nI would much rather see the following code instead:\n\n```javascript\nconst person1 = row[0];\nconst person2 = row[1];\nconst person3 = row[2];\n\nexpect(screen.getByText(person1.name)).toBeInTheDocument();\nexpect(screen.getByText(moment(person1.dob).format(formatDate))).toBeInTheDocument();\nexpect(screen.getByText(person1.phone)).toBeInTheDocument();\n\nexpect(screen.getByText(person2.name)).toBeInTheDocument();\nexpect(screen.getByText(moment(person2.dob).format(formatDate))).toBeInTheDocument();\nexpect(screen.getByText(person2.phone)).toBeInTheDocument();\n\nexpect(screen.getByText(person3.name)).toBeInTheDocument();\nexpect(screen.getByText(moment(person3.dob).format(formatDate))).toBeInTheDocument();\nexpect(screen.getByText(person3.phone)).toBeInTheDocument();\n```\n\nThis code is much more repetitive, and it's not the perfect code example (we'll continue to make it more and more readable and simple as we go through the article), but it reflects some of the simplicity we're looking for. It more immediately tells us what screen is being requested to be read, how many times we're looking for people's text, and so much more.\n\nWhen bringing up this point to a coworker, they reminded me of the expression \"Write code for your audience.\" In this case, your audience is Junior developers on your team working on debugging why a test is failing, QA engineers who might not be familiar with your programming language, and yourself when in the middle of deploying something integral to production when your tests unexpectedly fail. Each of these scenarios directly benefits from simpler, easier to parse, less utility-driven tests.\n\nFurthermore, there's another advantage to writing code simpler: Error messages. When using `for` loops, when an error is thrown, it's not known what piece of data is not rendering. You only know that _something_ isn't being rendered, but not what data, in particular, is missing. If I dropped the third row in its entirety, the error message in the `for` loop will not indicate what row was throwing the error. However, removing them from the for loop, it will immediately be clear which row, in particular, is throwing the error.\n\n# Hardcode Your Testing Data {#hardcode-data}\n\nWhile we started our example previously by removing for loops, this can be difficult to do without doing this step first. Hard-coding data is one of the most important things you can do to simplify your tests and reduce potential errors in your tests.\n\nLet's take the following code that was used to generate data:\n\n```javascript\nconst faker = require('faker');\n\nconst generatePerson = () => ({\n  name: faker.name.findName(),\n  dob: faker.date.past(),\n  phone: faker.phone.phoneNumber(),\n});\n\n// Generate an array of 20 random people\nconst data = Array.from({length: 20}, () => generatePerson());\n```\n\nWhile this enables us to quickly change how many people's random data is generated, it makes our tests much harder to read. Let's take a look at two parts of code, and see which one is easier to read:\n\n```javascript\nconst person1 = row[0];\n\nexpect(screen.getByText(person1.name)).toBeInTheDocument();\nexpect(screen.getByText(moment(person1.dob).format(formatDate))).toBeInTheDocument();\nexpect(screen.getByText(person1.phone)).toBeInTheDocument();\n```\n\nNow, is the above code easier to read, or would you prefer reading this?\n\n```javascript\nexpect(screen.getByText('Jadyn Larson')).toBeInTheDocument();\nexpect(screen.getByText('2020/01/14')).toBeInTheDocument();\nexpect(screen.getByText('964.170.7677')).toBeInTheDocument();\n```\n\nThe second test has some other advantages that might not seem immediately clear. For one, not only is it readable and more debuggable exactly _what_ isn't showing on the screen, but when you remove your code one step further away from implementation, it might highlight bugs with said implementation. For example, you notice that we were using `moment` in the first code sample. Since we're hardcoding data in the second code sample, if there's a bug in how we display our dates, then it'll be picked up whereas it might not be found when using `moment`.\n\nThis leads to another rationale for hardcoding data and simplifying tests in general: Debugging code sucks, debugging testing code doubly so. When you hardcode data, the worst a bug can get is a mistyped string. When not using hardcoded data, there could be any number of bugs in the implementation of the runtime randomization.\n\nSo, the question remains, how do you generate large quantities of random data without manually writing them in?\n\nWell, you're able to do them programmatically just as you did before. You just want to do so once on your local development machine and commit it as its own file. For example, if you save the following file to a JS file:\n\n```javascript\n const faker = require('faker')\n const fs = require('fs')\n\n const generatePerson = () => ({\n  name: faker.name.findName(),\n  dob: faker.date.past(),\n  phone: faker.phone.phoneNumber(),\n});\n\nconst data = Array.from({length: 20}, () => generatePerson());\n\nconst rows = JSON.stringify(genRows(20), null, 2)\n\nfs.writeFileSync('mock_data.js', `module.exports = ${rows}`);\n```\n\nYou can then run `const mockData = require('./mock_data.js')` inside of your test file. Now, you should be able to hardcode your data, knowing what the first, second, and third index are.\n\n# Keep Tests Focused {#seperate-tests}\n\nWhile working on tests, it can be easy to group together actions into a single test. For example, let's say we want to test our table component for the following behaviors:\n\n\nShows all of the column data on users\nMake sure a user on page 2 does not show when looking at page one\n\nWe could easily combine these two actions into a single `it` test:\n\n```javascript\nit('should render content properly', () => {\n\t// Expect page 1 person to be on screen\n\texpect(screen.getByText('Jadyn Larson')).toBeInTheDocument();\n\texpect(screen.getByText('2020/01/14')).toBeInTheDocument();\n\texpect(screen.getByText('964.170.7677')).toBeInTheDocument();\n\n\t// Expect page 2 person not to be on screen\n\texpect(screen.getByText(Joe Hardell)).not.toBeInTheDocument();\n\texpect(screen.getByText('2010/03/10')).not.toBeInTheDocument();\n\texpect(screen.getByText('783.879.9253')).not.toBeInTheDocument();\n})\n```\n\nHowever, when you look at your failing tests, the message that's displayed is vague and harder to debug. Furthermore, it clutters your tests and makes your intentions less clear.\n\nI would alternatively suggest separating them out and displaying them as two separate tests:\n\n```javascript\nit('should render all columns of data', () => {\n\texpect(screen.getByText('Jadyn Larson')).toBeInTheDocument();\n\texpect(screen.getByText('2020/01/14')).toBeInTheDocument();\n\texpect(screen.getByText('964.170.7677')).toBeInTheDocument();\n})\n\nit('should not render people from page 2 when page 1 is focused', () => {\n\texpect(screen.getByText(Joe Hardell)).not.toBeInTheDocument();\n\texpect(screen.getByText('2010/03/10')).not.toBeInTheDocument();\n\texpect(screen.getByText('783.879.9253')).not.toBeInTheDocument();\n})\n```\n\nWhile this may cause slower tests as a result of duplicating the `render` function's actions, it's worth mentioning that most of these tests should run in milliseconds, making the extended time minimally impact you.\n\nEven further, I would argue that the extended time is worth the offset of having clearer, more scope restricted tests. These tests will assist with debugging and maintainability of your tests.\n# Don't Duplicate What You're Testing  {#dont-duplicate}\n\nThere's yet another advantage of keeping your tests separated by `it` blocks that I haven't mentioned yet: It frees you to reduce the amount of logic you include in the next test. Let's take the code example from before:\n\n```javascript\nit('should render all columns of data', () => {\n\texpect(screen.getByText('Jadyn Larson')).toBeInTheDocument();\n\texpect(screen.getByText('2020/01/14')).toBeInTheDocument();\n\texpect(screen.getByText('964.170.7677')).toBeInTheDocument();\n})\n\nit('should not render people from page 2 when page 1 is focused', () => {\n\texpect(screen.getByText(Joe Hardell)).not.toBeInTheDocument();\n\texpect(screen.getByText('2010/03/10')).not.toBeInTheDocument();\n\texpect(screen.getByText('783.879.9253')).not.toBeInTheDocument();\n})\n```\n\nWhile this test seems reasonable at first, I would prose that the tests contain duplicated testing logic: We already know that the table should render all of the contents on-screen, why do we need to double-check that _all_ of the items in the table are hidden?\n\nThis might be a bad example. Maybe you want to demonstrate that all of your columns are un-rendering properly. Fair enough! Let's take a look at another example.\n\nLet's say that I want to make sure that when my table has pagination disabled that we want to see every single person in the table. We could write our tests one of two ways:\n\n```javascript\nit('should render all columns of data', () => {\n\texpect(screen.getByText('Jadyn Larson')).toBeInTheDocument();\n\texpect(screen.getByText('2020/01/14')).toBeInTheDocument();\n\texpect(screen.getByText('964.170.7677')).toBeInTheDocument();\n})\n\nit('should render all of the users', () => {\n\texpect(screen.getByText('Jadyn Larson')).toBeInTheDocument();\n\texpect(screen.getByText('2020/01/14')).toBeInTheDocument();\n\texpect(screen.getByText('964.170.7677')).toBeInTheDocument();\n\n\texpect(screen.getByText(Joe Hardell)).toBeInTheDocument();\n\texpect(screen.getByText('2010/03/10')).toBeInTheDocument();\n\texpect(screen.getByText('783.879.9253')).toBeInTheDocument();\n})\n```\n\nOr, we could write our test like this:\n\n\n```javascript\nit('should render all columns of data', () => {\n\texpect(screen.getByText('Jadyn Larson')).toBeInTheDocument();\n\texpect(screen.getByText('2020/01/14')).toBeInTheDocument();\n\texpect(screen.getByText('964.170.7677')).toBeInTheDocument();\n})\n\nit('should render all of the users', () => {\n\t// Expect the first person to render\n\texpect(screen.getByText('Jadyn Larson')).toBeInTheDocument();\n\n\t// Expect the last person to render\n\texpect(screen.getByText(Joe Hardell)).toBeInTheDocument();\n})\n```\n\nIn this example, I would prefer the second test. It's closer to how I would manually check if all of the data was rendered, and it reduces the size of my tests. We already know that the columns are all being rendered, why not trust your first test and separate what logic you're testing for the next test? This makes debugging easier as well. If your phone number column isn't rendering, it will only fail one test, not two. This makes it easier to pinpoint what's gone wrong and how to fix it.\n\nUltimately, when writing tests, a good rule to follow is \"They should read like simple instructions that can be run, tested, and understood by a person with no technical knowledge\"\n\n# Don’t Include Network Logic in Your Render Tests  {#seperate-network-logic}\n\nLet's say in a component we want to include some logic to implement some social features. We’ll follow all the best practices and have a wonderful looking app with GraphQL using ApolloGraphQL as our integration layer so we don’t need to import a bunch of APIs and can hide them behind our server. Now we’re writing out tests and we have a _ton_ of mocked network data services and mock providers. Why do we need all of this for our render?\n\n```javascript\n// ConnectedComponent.spec.tsx\nit(\"renders\", async () => {\n  const { findByText, getByText } = render(\n    <MockedProvider mocks={mocks} addTypename={false}>\n      <Component />\n    </MockedProvider>\n  );\n\n  expect(getByText(\"Loading component...\")).toBeInTheDocument();\n  waitForElement(() => expect(getByText(“Element”)).toBeInTheDocument());\n  expect(getByText(\"FirstName\")).toBeInTheDocument();\n});\n```\n\nWe have a `MockedProvider`, `mocks`, extra logic for loading states, and then finally what our tests really care about with how things get rendered to the screen. We’ve taken our wonderful, strong tests and made them fragile and dependent on this specific implementation. How do we make it so that if we swap out our data layer we can make sure our tests and components will still work just fine with minimal updates?\n\nThankfully the answer to that is pretty easy. Taking a cursory glance at our component we see a data layer and some logic for the data layer.\n\n```javascript\n// ConnectedComponent.tsx\nexport default () => {\n  const { data } = userQueryHook();\n  const { user } = data?.user; \n  \n  return !user\n    ? <span>Loading component…</span>\n    : <><span>Element</span><span>{user.first}</span></>\n```\n\nHere the component will mount into the DOM and then go and fetch some user data to store in the state. This isn’t necessarily a bad thing. It does mean that the tests would need a way to test the component and the network layer logic.\n\nWe don’t want our tests doing that as now our component and the test is directly tied into how the exact component was implemented and is closer to an integration test instead of a unit test in regards to what we render. Instead, we need to remove that logic so that the component can just render. We can do this in several ways, but the easiest and fastest method with a simple component like this one is to extract the data fetch to a layer higher and simply receive the data as a prop.\n\n```javascript\n// ConnectedComponentRender.tsx\nexport default ({ user }:{ user: UserType }) => {\n  return !user\n    ? <span>Loading component…</span>\n    : <><span>Element</span><span>{user.first}</span></>\n}\n```\n\n```javascript\n// ConnectedComponent.tsx\nexport default () => {\n  const { data } = userQueryHook();\n  const { user } = data?.user; \n\n  return <ConnectedComponentRender user={ user } />\n}\n```\n\nNow the tests for the rendered component look much simpler\n\n```javascript\n// ConnectedComponent.spec.tsx\nit(\"renders without data\", async () => {\n  const { findByText, getByText } = render(<ConnectedComponentRender />);\n\n  expect(getByText(\"Loading component...\")).toBeInTheDocument();\n});\n\nit(\"renders with data\", async () => {\n  const { findByText, getByText } = render(<ConnectedComponentRender user={ first: ‘FirstName’ } />);\n\n  expect(getByText(“Element”)).toBeInTheDocument();\n  expect(getByText(\"FirstName\")).toBeInTheDocument();\n});\n```\n\nThe tests get drastically simplified and we can write tests with mocks for our specific network layer logic separately in the integration tests.\n\nWhen using large amounts of network data that you'd like to mock, be sure to [hardcode that data using mock files](#hardcode-data).\n\n# Conclusion {#conclusion}\n\nUsing these methods, tests can be simplified, often made faster, and typically shorten the length of a testing file. While this may sound straightforward on a surface level, writing tests is a skill that's grown like any other. Practice encourages growth, so don't be discouraged if your tests aren't as straightforward as you'd like to first.\n\nIf you have any questions about testing, or maybe have a test you're unsure how to simplify, be sure to join [our Discord Server](https://discord.gg/FMcvc6T). We engage in tons of engineering discussions there and even live pair-program solutions when able. \n",
		},
		{
			title: "GitHub Copilot Breaks Bad Interviews",
			description:
				"GitHub Copilot is a huge step forward for tech. Luckily, it improves our lives. Unfortunately, it will break your interviews. Here's why.",
			published: "2021-07-22T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["interviewing", "opinion", "copilot"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/github-copilot-breaks-bad-interviews/",
			slug: "github-copilot-breaks-bad-interviews",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "GitHub Copilot Breaks Bad Interviews",
				description:
					"GitHub Copilot is a huge step forward for tech. Luckily, it improves our lives. Unfortunately, it will break your interviews. Here's why.",
				published: "2021-07-22T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["interviewing", "opinion", "copilot"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/github-copilot-breaks-bad-interviews/",
			},
			contentMeta:
				"\n[GitHub Copilot](https://copilot.github.com/) was recently announced! In the past few years, we’ve seen artificial intelligence (AI) revolutionize aspects of technology such as image recognition, recommendation algorithms, and more. With Copilot, GitHub is hoping to add “code generation” to that list of items. In this article, we’ll explain what GitHub Copilot is, why some people are concerned with allowing its usage in technical interviews, and how to build your interviews to be better in general and therefore more resilient to auto-generated code.\n\n## What is GitHub Copilot?\n\nGitHub Copilot is a VSCode extension that’s able to autocomplete code snippets. While we've had some form of code completion for some time now, they've been relatively limited in one way or another. Usually, they tend to rely on existing code in your files or can only suggest a tiny amount of code per suggestion. Other times, code completion can be no more than a predefined snippet of code without considering any additional context.\n\nCopilot offers the ability to suggest multi-line and contextually aware code suggestions - powered by AI. GitHub says this tool is available for most programming languages and can implement entire functions off of their names alone.\n\nThey’re not alone in this endeavor, however. GitHub is working in collaboration with OpenAI, the company behind the extremely powerful GPT-3 AI tool. Between the training dataset consisting of GitHub’s public source code and OpenAI’s expertise in AI generation, it has the potential to provide impressive results.\n\nTaking an example from their website, it’s able to generate an implementation of a date utility from nothing more than the function name.\n\n![img](./copilot_hero_img.png)\n\nIt’s incredible that given the simple input of:\n\n```javascript\nfunction calculateDaysBetweenDates(date1, date2) {\n```\n\nIt’s able to generate the following code which functions how you might expect:\n\n```javascript\nfunction calculateDaysBetweenDates(date1, date2) {\n  var oneDay = 24 * 60 * 60 * 1000;\n  var date1InMillis = date1.getTime();\n  var date2InMillis = date2.getTime();\n  var days = Math.round(Math.abs(date2InMillis - date1InMillis) / oneDay);\n  return days;\n}\n```\n\nWhile every new tech has its naysayers, and even some on our team are skeptical of its true utility, it’s undoubtedly a powerful tool that will, for some, change the way they write code. \n\nGitHub’s not alone in this venture of AI-powered code generation, either! Other companies, such as [Kite](https://www.kite.com/) or [TabNine](https://www.tabnine.com/) are working hard at this problem space as well! Whether we want it to or not, AI-generated code helpers are here to stay.\n\n## How does Copilot Threaten Tech Interviews?\n\nIn the current tech interview landscape, algorithms reign as the leading method of technical assessment. While we’ve touched on [why this shouldn’t be the case](https://coderpad.io/blog/5-tips-for-tech-recruiting/) before, Copilot in particular breaks algorithm questions in significant ways by being able to rapidly generate solutions to algorithmic problems.\n\nLet’s see how Copilot interacts with some common interview questions.\n\nOne common question that’s a favorite of interviewers hoping to quickly glean mathematical competency is a function to check if a given number is prime or not.\n\nWell, it’s been a few years since I’ve refreshed my math skills, so they might be a little shakey. I should be able to figure it out all the same. \n\nLet’s open VSCode and start implementing the function.\n\n<video src=\"./gh_copilot_is_prime.mp4\" title=\"GitHub Copilot generating a complete implementation of 'isPrime' from nothing more than the function name\"></video>\n\nWow! I hadn’t even had a chance to add the parameters to the “isPrime” function before Copilot had already made a suggestion!\n\nLooking through the suggested code, it seems clean and functions as expected!\n\n```javascript\nfunction isPrime(n) {\n    if (n < 2) return false;\n    for (var i = 2; i < n; i++) {\n        if (n % i == 0) return false;\n    }\n    return true;\n}\n```\n\nSure, we could change the `var` to a `const`, but this is code that I wouldn’t blink twice at in a code review!\n\nWhile this may seem like an outlier, Copilot seems to excel in these algorithm-based questions. \n\nBut surely `isPrime` would be too trivial for a *real* interview question, right? Perhaps, but watch what happens when a popular coding YouTuber attempts to utilize Copilot to solve Leetcode interview questions\n\nhttps://www.youtube.com/watch?v=FHwnrYm0mNc\n\nWithout fail, Copilot is able to generate usable code for each difficulty level of algorithms given to it. Further, the solutions are all more performant than the average of submissions. For the permutation question, it’s able to be faster than 88% of other submissions!\n\n“Given how predominant these types of interview questions are, we could be in big trouble if some candidates are less-than-forthcoming with their usage of Copilot in coding exercises.”\n\nWhile this may be true for some interviews, if your interviews are susceptible to collapse with Copilot in the picture, you’re already facing this problem whether you’re aware of it or not.\n\n## Algorithms Are Breaking Your Interviews\n\nOn paper, algorithm based interview questions sound like a great way to assess a candidate's skills. They can help give guidance on a candidate's understanding of logic complexity, how efficient (or inefficient) a specific solution is, and is usually an insight into a candidate’s ability to think in abstract manners. \n\nHowever, in practice algorithm questions tend to go against the grain of real-world engineering. Ideally, an interview process should act as a way to evaluate a candidate’s ability to do the same kind of engineering they’d be using in their projects at your company. While a developer may, with resources, implement an algorithm once in a while, they’re more than likely doing things like refactoring significantly more often.\n\nWe’ve written more about how [algorithms aren’t often effective as interview questions in the past.](https://coderpad.io/blog/5-tips-for-tech-recruiting/#less-algorithms-more-demos)\n\nBut more than being unrepresentative of the job, algorithm questions are often easy to cheat - without the use of GitHub Copilot. Because most algorithm questions are significantly similar to each other, there’s often a small selection of tips and tricks a candidate can memorize in order to drastically improve their output in these styles of interviews.\n\n\nThere’s even the potential for a candidate to be able to output an algorithm verbatim. There are hundreds of sites that will give a candidate one algorithm question after another in the hopes of improving their understanding of these algorithms.\n\nBut with GitHub Copilot, the propensity for cheating on an algorithm question rises significantly. As we’ve demonstrated previously in the article, it’s capable of generating significant portions of code at a time. In fact, Copilot is so proficient at algorithm questions that a [non-trivial number of algorithm questions we asked it to solve were done](https://github.com/CoderPad/github-copilot-interview-question) before we could even finish the function signature. All it takes is a candidate to give Copilot the name of the function and paste the results into their assessment editor.\n\nFurther, folks wanting to cheat have had the ability to do something similar for some time now in the form of forum questions. Simply lookup any algorithm on a code forum or site like [StackOverflow](http://stackoverflow.com/) and you can find hundreds of answers at your disposal. \n\nIn fact, many have pointed out that Copilot’s process of looking up code based on its expected constraints is similar to one that a developer might experience by searching StackOverflow for code snippets. Funnily, some thought the idea so similar they decided to build an alternative VSCode plugin to Copilot that simply [looks up StackOverflow answers as suggestions](https://github.com/hieunc229/copilot-clone).\n\nRegardless of how the question is answered, a candidate’s skill at these types of questions might not reflect their capabilities in other aspects of the codebase. That’s why, in order to access candidates properly, it might be the right move to move away from these questions.\n\n## How to Fix Your Interviews\n\nWhile you *could* simply require candidates to use a non-VSCode IDE for your technical assessments, there are no guarantees that your take-homes will be spared the same fate. Further, while VSCode is the launch platform for Copilot, it’s more than likely to gain plugins for other IDEs in the future as well.\n\nBut what of it? Let’s say your company doesn’t do take-homes ([even though you totally should](https://coderpad.io/blog/hire-better-faster-and-in-a-more-human-way-with-take-homes/)), what of it? Well, even if restricting VSCode would work to avoid Copilot for a while, you ideally want to be able to standardize your IDE platform for all candidates. \n\nPlus, as we touched on in the previous section, algorithm-based interview questions are still able to be manipulated - with or without Copilot.\n\nThe solution to fixing your interviews should be two-fold:\n\n1. More representative questions of the job\n   - Require more thought process than memorization\n2. Better communication with candidates\n\nFor the first, make sure your questions are examples of real-world challenges you’ve seen in your project’s codebase. Some great examples of this might be “setting up a backend endpoint [connected to your database](https://coderpad.io/resources/docs/full-stack-databases/)” or “[refactor this React component to be unidirectional](https://coderpad.io/blog/master-react-unidirectional-data-flow/#challenge)”.\n\n> If you’re using CoderPad, we have a [great selection of questions available in our Question Bank that you can personalize to fix the unique needs of your team](https://coderpad.io/resources/docs/question-bank/example-questions/)\n\nThe second point might sound obvious, but look at it this way: Engineering often utilizes more “soft” skills than we usually credit. In any engineering team you’ll need to do code review, create technical documentation, and communicate with others on your team. Being able to program is well and good, but without soft skills your ability to leverage those skills goes flat.\n\nEven if a candidate does end up using Copilot to generate a non-trivial portion of a candidates’ submitted code, you should be able to ask them what their review process of the generated code looked like. Does it follow their code standards? What alternatives did it suggest and why did they choose that one? How maintainable is said code? Are there edge-cases not yet covered?\n\n## Conclusion\n\nGitHub Copilot is a remarkable piece of technology. It will be interesting to watch as it continues to develop and see how developers will utilize it in their day-to-day. As it becomes more and more relevant, we need to make sure our interviews are structured to handle(and prevent) its capabilities.\n\nIn fact, we’ve created [a GitHub repo to showcase a wide range of interview questions that Copilot has been able to successfully generate](https://github.com/CoderPad/github-copilot-interview-question), given little input.\n\n[![The GitHub Copilot interview questions GitHub repo](copilot_questions_github_repo.png)](https://github.com/CoderPad/github-copilot-interview-question)\n\nFeel free to open a PR if you find a question that you think should be present. If you’re worried about your interview question being susceptible to Copilot, maybe drop by the repo and see if it’s in the list.\n",
		},
		{
			title: "GitHub Copilot is Amazing - It Won't Replace Developers",
			description:
				"GitHub Copilot is an amazing tool that I think will drastically improve the way that I code. But it won't replace me. Here's why.",
			published: "2021-10-04T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["opinion", "tools", "copilot"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "github-copilot-wont-replace-devs",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "GitHub Copilot is Amazing - It Won't Replace Developers",
				description:
					"GitHub Copilot is an amazing tool that I think will drastically improve the way that I code. But it won't replace me. Here's why.",
				published: "2021-10-04T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["opinion", "tools", "copilot"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nI recently touched on how [GitHub Copilot](https://copilot.github.com/), an AI-powered code generation tool from GitHub and OpenAI, [is going to shift the way we’ll need to do interviews](/posts/github-copilot-breaks-bad-interviews/). Copilot frankly is astonishing in its abilities to generate complex algorithm implementations from nothing more than a function name. This makes sense given it's training data of GitHub's publicly hosted community code ([a controversial decision](https://twitter.com/eevee/status/1410037309848752128)).\n\nSome have taken these advanced algorithm assessment capabilities as a warning sign that developers will soon be fully automated using tech similar to Copilot, I’m not sold on that idea.\n\n# Copilot Isn't An Engineer\n\nAutomation is amazing. Some would argue the whole point of programming is to automate as much as possible.\n\nBut when you automate things you often lose a fair amount of nuance within the problem-space you're trying to automate. This is true for any industry and any problem you run into: Especially so with programming. \n\nWe all know the meme: The junior engineer asks a question and the senior mentor answers \"it depends\"\n\n![A joke off of an O' Reilly programming book. \"It depends, the answer to every programming question ever conceived - The definitive guide\". Credit: @thePracticalDev](./it_depends.jpg)\n\nBut there's a reason for this \"joke\" having such prevalence: it's true. A lot of software engineering requires a lot of context be kept in mind.\n\nKnowing this, can an AI take on the required nuance and act an additional engineer to the team?\n\nOn first glance, GitHub Copilot may appear to walk the \"I'm an Engineer replacement\" walk, and it may even talk the talk from time-to-time: but it falters in some key areas.\n\n## Architecture\n\nLet’s first remember what the job of an engineer or developer is. While on the surface, yes, developers do type code into their IDE - the real work is done in the developer’s mind. To code something is to consider a problem’s expected outcome, its constraints, edge cases, and to take those into account to decide on an implementation.\n\nWhile Copilot is highly capable of generating *a* solution, it doesn’t know your engineering constraints. This is where architecture decisions come into play. Sure, you may know that you want a sorting algorithm - but *which* sorting algorithm may be more important than being able to implement it. After all, if you are wanting to implement a complex sort on a large dataset with limited memory, your biggest problems are likely to stem from knowing where to store your data in an [external sort](https://en.wikipedia.org/wiki/External_sorting) as opposed to the specific code syntax you’ll utilize to make that a reality.\n\nThat said, not every engineer is at or needs to be at an architectural level. Some of us are most comfortable when we can focus within our IDEs as opposed to meeting rooms where those constraints often come to light. However, there is a skill that every developer will need to develop as they code: Debugging.\n\n## Bugs\n\nEven when assisted by a tool like Copilot, bugs are inevitable in any system. Even if your code is perfection itself captured in text, we still have to rely on others code in upstream dependencies. Knowing how to work through finding the root cause and solving a bug is integral to development. Oftentimes, I find myself spending more time debugging complex issues than building a significant portion of fresh code.\n\nRegardless of if you use the debugger or print statements (which, we all do at some point, be honest), Copilot isn’t able to automate that process for you.\n\n## Refactors\n\nLikewise, a common task in an existing codebase is to refactor it in order to be more secure, efficient, fast, readable, or otherwise better. While Copilot is able to glean context from the current file you’re presently in, refactors can often span multiple files as you modify the underlying abstractions in a codebase. Even then, while [GitHub says they’re adding support for full project-based context in the future](https://copilot.github.com/#faq-what-context-does-github-copilot-use-to-generate-suggestions), automated refactors would be extremely difficult to attain. \n\n> When I'm talking about automated refractors, I'm *not* talking about [codemods](https://www.sitepoint.com/getting-started-with-codemods/) powered by AST manipulation to, say, migrate from one version of a library to another. Codemods like those rely on consistent information existing for both versions of the library code being migrated. Further, these codemods don’t come for free and libraries must usually engineer specifically with automated migrations in mind.\n>\n\nIn order to automate refactors, Copilot would not only need to know how things *were* done, but what the newer method of doing things is. After all, the previous code exists for a reason, what is it doing, why is it doing what it is, and how are we able to improve it? When application-wide refactors occur, a team often sits down and discusses the advantages of standards and sets a level of consistency to strive for. However, refactors often have hidden levels of complexity within. When actually diving into a refactor, there may be constraints in the new technology that may not have been known previously. When this occurs, the team must make decisions based on many parameters. A machine simply isn’t up for the task.\n\n## Code Review\n\nWhen GitHub Copilot first launched, there was a lot of discussion about how good its generated code would be in the end. Can Copilot understand the nuances in `useEffect`? Does it know that you need a consistent memory reference to avoid triggering change detection?\n\nMaybe, but you can’t be certain it will get it right every time. However, the same can be said for others: you can’t be certain another person on the team will get it right every time.\n\nThis nuance brings another point against the concept of developers being fully automated by Copilot: Code review. \n\nIdeally, you shouldn't be allowing developers to push code directly to production on a regular basis. While there will always be emergency scenarios where this doesn't apply, it's dangerous to ignore the code review stage. This isn't to say that you shouldn't trust your developers, but we're only human after all. If [Google can make a single-character typo to wipe every ChromeOS laptop with a certain update installed](https://www.androidpolice.com/2021/07/20/a-new-chrome-os-91-update-is-breaking-chromebooks-like-a-bull-in-a-china-shop/), it's not impossible your team may make a similar mistake.\n\nDuring this process of code review, your team may discover bugs, realize that an experience is impacted by planned implementation, or even point out a more optimized or easier-to-read implementation. Having this team environment allows for a more diverse pooled perspective on the code that's being contributed towards a codebase and results in a better product. \n\n\n\n\n# GitHub Copilot’s Strengths\nNone of this is to say that Copilot as a tool isn’t advantageous. Copilot is often able to make suggestions that impress me. In particular, if I have a somewhat repetitive task or are simply exploring a commonly implemented function, Copilot can fill in the blanks for me with only the name.\n\nAll of these utils are generated with Copilot using only the function name as an argument passed in:\n\n```javascript\nconst reverseString = str => {\n  return str.split('').reverse().join('');\n}\n\nconst normalizePath = path => {\n  return path.replace(/\\/+/g, '/');\n}\n\nconst stripBOM = str => {\n  return str.replace(/^\\uFEFF/, '');\n}\n\nconst usageOfChar = (str, char) => {\n  return str.split(char).length - 1;\n}\n```\n\n![GitHub copilot making the code suggestions shown above with only a function name](./utils-suggestions.png)\n\nWhile there may be _faster_ implementations of some of these, they're undoubtedly extremely readable and maintainable  - they're how I'd implement these functions myself! \n\n\n\nThis isn't to say that GitHub Copilot is simply limited to small-scale utility functions, either. I recently wanted to make an implementation of a binary search tree. I was barely a class name into implementing when Copilot made the following suggestion:\n\n```javascript\n// Only typed `class Node` to get this suggestion\nclass Node {\n    constructor(data) {\n        this.data = data;\n        this.left = null;\n        this.right = null;\n    }\n}\n\n// Copilot suggested all of this without any help whatsoever\nclass BinarySearchTree {\n    constructor() {\n        this.root = null;\n    }\n\n    insert(data) {\n        if (!this.root) {\n            this.root = new Node(data);\n        } else {\n            this._insert(this.root, data);\n        }\n    }\n```\n\nThis isn't all that was suggested by Copilot, either - [it generated a full implementation of a depth-first binary tree](https://github.com/CoderPad/github-copilot-interview-question/blob/main/questions/javascript/binary-depth-search.js)!\n\n![Showcasing GitHub Copilot generating the binary file from a single class name](./binary.png)\n\nThis is an impressive range of capabilities for an automated code generation tool. While I would likely want to customize or otherwise modify this exact implementation, this is a very valid base of a binary tree that I could take an expand into something production-ready. \n\n## Invisible Helper \n\nI've read a lot of conversations about GitHub Copilot. Participated in a lot of them too. Something that often comes up is how distracting Copilot can be at times.\n\nI'd be lying if I said I hadn't encountered this myself. I got access to Copilot very early on and when first using it my editor would be **flooded** with irrelevant suggestions. Oftentimes, these suggestions would even be a few words repeating until the generated code limit.\n\nDespite this argument, over time I've come around and started to enjoy having Copilot around in daily development.\n\nWhile I wasn't a developer when traditional autocomplete tools (such as Intellisense) came into play of daily development, I'm certain there were arguments from some against using. I'm sure the first time someone went to type a method name they'd memorized the dropdown of seemingly irrelevant method names seemed obtuse and distracting.\n\nHowever, once used to tools like Intellisense, it can become easy to ignore it when working in environments that don't suit it well. I regularly find myself not even looking at code suggestions - especially when dealing with minified code I'm debugging. And I think that's the key: **developer tools do best when they become invisible**. Copilot is able to do that quite well and gets out of your way when you don't need it\n\nFor a start, while I had significant problems with Copilot going overboard with suggestions early on, I've since noticed two things:\n\n1) It's gotten a **lot** better since then. Undoubtedly due to it being an AI and learning from it's usage and some tweaks made by the GitHub team\n2) This only _really_ occurs when I sit still in my editor for extended periods of time with an incomplete variable typed out\n\nThe first point feels fairly self-explanatory, but let's stop and explore the practical side-effect of the second point being made. When I am programming, I am often doing one of three things:\n\n1) Thinking of what code is doing or how to move forward next\n2) Actively typing something I have thought of\n3) Making small changes and waiting to see if the compiler/linter is angry at me (it usually is)\n\nFor my workflow in particular, I tend to pause for extended periods of time before actually typing something in my main IDE file. It's only really when dealing with unfamiliar codebases, concepts, or naming conventions that I pause in significant level of frequency in the middle of typing something. Oftentimes, this is because I'm trying to remember how to do something by memory or looking at some documentation/reference APIs I have pulled up elsewhere.\n\nThis leaves me with pausing typing on unfinished variables realistically only when I'm starting a new project or waiting to see my autocomplete's results. As a result, I often completely ignore Copilot until a fair amount of scaffolding of a project has been created - often as a result of it wanting to overzealously generate boilerplate I'm not looking for.\n\nIt's once deep within a project that Copilot stops begging for attention and can sneakily seep into average development. I honestly have a hard time telling when a code suggestion is made from traditional code analyzation and when it's coming from a smarter Copilot from time-to-time. However, as much as it sounds like one: This isn't an insult, it's a good thing!\n\nBecause Copilot can grok more complex implementation details, it's often able to make the same type of single-property name suggestions in my editor without the multi-line codegen we've come to expect from many of its demos. These suggestions aren't just extremely helpful and get less in the way, but they help me as a developer feel more in control as to what's happening.\n\nThis capability is so good at the \"transparent tools that get out of your way\" test that while [streaming on my Twitch](https://twitch.tv/crutchcorn), I was confident I didn't have Copilot enabled and had to check after a particularly clever suggestion, hours after starting work.\n\nhttps://clips.twitch.tv/TacitFitIcecreamTriHard-KgJCKYYIEPqxe4dQ\n\n\nIt's this transparency that I feel is Copilot's _true_ strength. It's important to remember that even GitHub isn't poising Copilot as a replacement to developers of any kind - simply a tool that developers can utilize to make their jobs easier.\n\n## Learning Tool\n\nI recently saw a tweet that showcased Copilot generating the following JavaScript:\n\n```javascript\nconst range = (start, size) => Array.from({length: size}, (_, i) => start + i)\n```\n\nAnd remarking \"I didn't know you could make an array this way\".\n\nWhile I couldn't find that tweet again after searching for it later, it stuck out in my mind. I had learned of the trick only by scrolling through WebDev Twitter one day. Had I been on vacation that day or even decided not to check Twitter, I would have not likely learned for a long time afterwards.\n\nI distinctly remember learning that method from Twitter because I was so surprised about how it worked that I did some research and read more. That day I learned a lot about [JavaScript's implementation about Iterators](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators) and the fact that, in JavaScript, [arrays are objects under-the-hood](https://stackoverflow.com/a/5048482). One step closer to understanding JavaScript primitives: A concept I struggled with in my early days of WebDev.\n\nAfter all, when I am learning how to program something new, it's always been useful for me to see an implementation of how it's done elsewhere. I remember being in my first programming job as a Junior and learning so much simply by seeing how others in the team wrote similar code.\n\nNow, my early career was somewhat formed by what I'd seen others do in codebases I was adjacent to. Because I was assigned tasks, the things I learned about tended to pertain specifically to those tasks. Further, I found it somewhat tricky to find symbols like `!.` After all, [Google search is not kind to many symbols we use in programming](https://stackoverflow.com/a/3737197).\n\nBut honestly, I was lucky to've been taken on as a Junior so early on into my code learning experience; Not everyone is so privileged. \n\nThis is why that Tweet stuck out so much in my mind. Would I have learned code as quickly if I was doing independent study without a such in-depth reference point to others' code? Likely not.\n\nSure, theoretically a new developer could jump into any number of open source projects and gain experience that way. But **how many of those projects are able to provide 1:1 mentorship** and code review on every PR? As it stands open-source maintainers are regularly overworked and unpaid for their efforts.\n\nMoreover: how does a new developer's confidence play into that? I started with Angular as my first web framework, didn't have a formal education, and saw Google as an infallible agent of raw engineering in my first year. **Terms like \"Dependency injection\" and \"Ahead-of-time compiler\" scared me into feeling as if it were \"unsafe\" to read through any of the project's source code until I had found out that [I was rewriting it's source code without knowing it](https://unicorn-utterances.com/posts/angular-templates-start-to-source/#directive-same-name-input)**.\n\nEven today, a developer of 7 years professionally - having written compilers and apps with millions of users - I am still oftentimes intimidated to read through large project's codebase. **I regularly have to psyche myself out and reassure myself that it's okay to explore before diving into big source projects.**\n\nThe beauty (and, unfortunately, again, [controversy](https://twitter.com/eevee/status/1410037309848752128)) of **GitHub Copilot in this instance is that it doesn't tell you where large chunks of its generated code comes from**. You're able to find new ways to do things and want to learn and research more without all the self-imposed stress I mentioned. \n\nI've seen code generated by Copilot that could easily pass for logic within any major framework or application I've ever read through.\n\nBut **I don't just see Copilot as an opportunity for newcomer developers to learn**. For example, I'm familiar with binary search trees. I have written implementations before. But I won't lie: It's been a long time. Further, the last time I saw a tree in a production codebase, it was significantly more complex than an early implementation with only the core concepts exposed.\n\nBeing able to generate a decent implementation to a tree in my IDE is helpful for me to compare-and-contrast methods done there vs. what I would instinctually think of doing.\n\n## Documentation\n\n\"Types are not documentation\". If you've heard me say it once, you've probably heard me say it a dozen times. It's sorta a mantra for me.\n\n> Here, I'll say it again: \"Types are not documentation\"\n\nUnfortunately for me: My mantras don't define the outcome of a popular library's state of documentation. While making an upstream PR is almost always the way-to-go to solve this problem long-term - it can be a long process to figure out how something works without any usage examples to go off of.\n\nWhile Copilot is far from _solving_ this problem, it can help. Having GitHub's projects as a reference point, it may suggest usages of non-documented APIs that it's seen elsewhere.\n\nHonestly though? The number of external codebases that are not documented at all that I'm working in nowadays is fairly low.\n\nMore often than not, I'm working in a codebase like Vue that has a massive surface area, good docs, but I'm not always sure where to look.\n\nWhile it's no replacement to a helpful community (which Vue absolutely has) or some masterful [GoogleFu](https://www.urbandictionary.com/define.php?term=google-fu), Copilot can often help guide me towards what I'm looking for by that same \"teaching by reference\" principle I outlined earlier.\n\n# Conclusion\n\nGitHub Copilot is an innovative tool. With many forms of innovation, there's a lot of uncertainty on how useful a tool is. Copilot isn't perfect by any means, but for many use-cases it can potentially speed up development.\n\nAlso similar to other innovative ideas, there's a lot of \"what if in the future\" being merged with \"it is this way today\". While Copilot (or other AI-powered code generators) has the potential to go a long distance in lowering the barrier to entry and making development easier and smoother, it's not at the stage of \"robot uprising\" today.\n\nGCP, I love your work, but I don't think your suggestion that [humans need not apply](https://www.youtube.com/watch?v=7Pq-S557XQU) isn’t quite here yet. At least not for developers.\n\nAfter all, GitHub’s tool is called “Copilot”, not “Autopilot”\n\nWhat do you think? Let us know [on Twitter](https://twitter.com/UnicornUttrncs) or [join our Discord](https://discord.gg/FMcvc6T) and start a conversation with us! We're an open-source community ran project with no ads, no spam.\n\nWe'd love to hear your thoughts!\n\n",
		},
		{
			title: "A Guide to Python's Secret Superpower: Magic Methods",
			description: "",
			published: "2022-06-08T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["python"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/development/guide-to-python-magic-methods/",
			slug: "guide-to-python-magic-methods",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "A Guide to Python's Secret Superpower: Magic Methods",
				description: "",
				published: "2022-06-08T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["python"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/development/guide-to-python-magic-methods/",
			},
			contentMeta:
				'\r\nPython has a secret superpower with a similarly stupendous name: Magic Methods. These methods can fundamentally change the way you code with Python classes and introduce code that seems ✨ magical ✨ to handle complex logic. They’re more powerful than [list comprehensions](https://coderpad.io/blog/development/python-list-comprehension-guide/) and more exciting than any new [PEP8](https://peps.python.org/pep-0008/) linter.\r\n\r\nToday, we’ll be talking about a few things:\r\n\r\n- What magic methods are\r\n- Some simple introductory magic method usage\r\n- How to programmatically manage class properties\r\n- How to overwrite operator symbol functionality\r\n- How to make your classes iterable\r\n\r\nWe also have a cheat sheet for utilizing these magic methods quicker within your projects:\r\n\r\n> [Download the related Magic Methods Cheat Sheet](https://coderpad.io/python-magic-methods-cheat-sheet/)\r\n\r\nWithout further ado, let’s dive in!\r\n\r\n## What are magic methods?\r\n\r\nMagic methods are methods that Python calls on your behalf in specific circumstances. These methods are named in a particular way to quickly distinguish them from other Python methods: they’re preceded and followed by two underscores.\r\n\r\n```python\r\nclass Speaker:\r\n    # This is a magic method\r\n    def __init__(self):\r\n        print("Hello, world!")\r\n# This will call __init__ and print "Hello, world!"\r\ninstance = Speaker()\r\n```\r\n\r\n> This is why magic methods also called “dunder methods,” which is a shorthand for “Double underscore methods.”\r\n\r\nIn the above code you can see what I’m talking about: Python calls the `__init__` dunder method on your behalf when a new class instance is created.\r\n\r\nThis barely scratches the surface when it comes to the power that magic methods provide. Let’s dive into their usage.\r\n\r\n## Simple magic method usage\r\n\r\nIf you’ve ever created a class, you’re likely familiar with the following method:\r\n\r\n`__init__(self, …args)` - `ClassName()`\r\n\r\nIt’s probably the best-known magic method, Python’s __init__ acts as a class constructor. You can use this to pass initial arguments to a Python class.\r\n\r\nFor example, take the following:\r\n\r\n```python\r\nclass Speaker:\r\n    message = ""\r\n    def __init__(self, val):\r\n        self.message = val\r\n       \r\n    def sayIt(self):\r\n        print(self.message)\r\n\r\ninstance = Speaker("Hello, world!")\r\ninstance.sayIt()\r\n```\r\n\r\nHere, whenever the `Speaker` class is initialized, it will assign `self.message` to the passed value. We’re then able to use a custom “sayIt” method that utilizes `self.message`.\r\n\r\n### Clean up class instantiation with `del`\r\n\r\nIn addition to a class initializer, there’s also a class deletion handler:\r\n\r\n`__del__(self)` - `del instance`\r\n\r\nThis method will run any time you call `del` on a class instance. This is particularly useful whenever you have an I/O operation in the constructor in order to cleanup said I/O operations.\r\n\r\n```python\r\nimport os\r\n\r\nclass Test:\r\n    def __init__(self):\r\n        f = open("temp.csv", "w")\r\n        f.write("data,more data,testing")\r\n        f.close()\r\n    def __del__(self):\r\n        os.remove(\'temp.csv\')\r\n        print("Cleanup done!")\r\n\r\nfirstItem = Test()\r\n\r\ndel firstItem\r\n```\r\n\r\nThis type is cleanup is integral to ensure your applications are deterministic on each run, which in turn increases general application stability. After all, if you leave remnants of your cache, they’re likely to be picked up by subsequent runs and cause havoc with your application logic.\r\n\r\n## How to programmatically manage class properties\r\n\r\nStuff like class constructors and cleanup are par for the course when it comes to class management. Ready for the weird stuff?\r\n\r\nWhat about declaring attributes that don’t exist? `__getattr__` has you covered.\r\n\r\n`__getattr__(self, key)` - `instance.property` (when `property` doesn’t exist)\r\n\r\nSimply check what the lookup key is (in this case with the `__name` property) and return a value if you want to create a new property programmatically:\r\n\r\n```python\r\nclass Test:\r\n    number = 1\r\n\r\n    def __getattr__(self, __name: str):\r\n        if __name == "string":\r\n            return "Test"\r\n        pass\r\n\r\n\r\ntest = Test()\r\nprint(test.number) # Will print `1`\r\nprint(test.string) # Will print `"Test"`\r\n```\r\n\r\nThere also exists a slightly different __getattribute__ built-in:\r\n\r\n`__getattribute__(self, key)` - `instance.property` (regardless of if `property` exists)\r\n\r\n```python\r\nclass Test:\r\n    number = 1\r\n\r\n    def __getattribute__(self, __name: str):\r\n        if __name == "string":\r\n            return "Test"\r\n        pass\r\n\r\n\r\ntest = Test()\r\nprint(test.number) # `None`\r\nprint(test.string) # `"Test"`\r\n```\r\n\r\nNotice how instead of `test.number` returning the expected `1` value, it returns a `None`.\r\n\r\nThis is because while `__getattr__` will resolve the existing variables and fallback to the special method when nothing is found, `__getattribute__` runs first and doesn’t fall back to existing values in the class instance.\r\n\r\nIn order to have `__getattribute__` to have the same behavior as `__getattr__`, we need to explicitly tell Python not to get stuck in the `__getattribute__` trap we’ve set up.\r\n\r\nTo do this, we can call `super().__getattribute__`:\r\n\r\n```python\r\nclass Test:\r\n    number = 1\r\n\r\n    def __getattribute__(self, __name: str):\r\n        """\r\n        We need a "try/except" here, otherwise it will fail during\r\n        lookup of an invalid key\r\n        """\r\n        try:\r\n            existingVal = super().__getattribute__(__name)\r\n            if existingVal:\r\n                return existingVal\r\n        except:\r\n            if __name == "string":\r\n                return "Test"\r\n        pass\r\n\r\n\r\ntest = Test()\r\nprint(test.number) # Will print `1`\r\nprint(test.string) # Will print `"Test"`\r\n```\r\n\r\n### Customize class property dictionary lookup\r\n\r\nWhile `__getattr__` and `__getattribute__` both work wonders for adding in keys programmatically, there’s a problem with that method. When using [the `dir` built-in method](https://docs.python.org/3/library/functions.html#dir), it won’t show the new keys.\r\n\r\nLet’s show you what I’m talking about with a code sample. Take the following:\r\n\r\n```python\r\nclass Test:\r\n    number = 1\r\n\r\n    def __getattr__(self, __name: str):\r\n        if __name == "string":\r\n            return "Test"\r\n        pass\r\n\r\n\r\ntest = Test()\r\nprint(dir(test))\r\n```\r\n\r\nThis `print` statement will output all of these keys:\r\n\r\n```\r\n[\'__class__\', \'__delattr__\', \'__dict__\', \'__dir__\', \'__doc__\', \'__eq__\', \'__format__\', \'__ge__\', \'__getattr__\', \'__getattribute__\', \'__gt__\', \'__hash__\', \'__init__\', \'__init_subclass__\', \'__le__\', \'__lt__\', \'__module__\', \'__ne__\', \'__new__\', \'__reduce__\', \'__reduce_ex__\', \'__repr__\', \'__setattr__\', \'__sizeof__\', \'__str__\', \'__subclasshook__\', \'__weakref__\', \'number\']\r\n```\r\n\r\nThis list of keys includes other magic methods, which muddies the output a bit for our needs. Let’s filter those out with the following logic:\r\n\r\n```python\r\ndef simpledir(obj):\r\n    return [x for x in dir(obj) if not x.startswith(\'__\')]\r\n```\r\n\r\nNow, when we run `simpledir(test)`, we only see:\r\n\r\n```python\r\n[\'number\']\r\n```\r\n\r\nBut where is our `’string’` field? It doesn’t show up.\r\n\r\nThis is because while we’ve told Python how to look up the overwritten values, we’ve not told Python which keys we’ve added.\r\n\r\n\r\nTo do this, we can use the `__dir__` magic method.\r\n\r\n`__dir__(self)` - `dir(instance)`\r\n\r\n```python\r\nclass Test:\r\n    number = 1\r\n\r\n    def __dir__(self):\r\n        originalList = super().__dir__()\r\n        originalList.append("string")\r\n        return originalList\r\n   \r\n    def __getattr__(self, __name: str):\r\n        if __name == "string":\r\n            return "Test"\r\n        pass\r\n```\r\n\r\nCustomizing `dir` behavior like this will now enable us to treat our dynamic properties as if they existed normally. Now all we’re missing is a way to set values to those properties…\r\n\r\n### Set programmatically created keys\r\n\r\nWhile we’re now telling Python which keys we’re programmatically creating and how to lookup the value of those keys, we’re not telling Python how to store those values.\r\n\r\nTake the following code:\r\n\r\n```python\r\nclass Test:\r\n    number = 1\r\n \r\n    def __getattr__(self, __name: str):\r\n        print("Test");\r\n        if __name == "string":\r\n            return "Test"\r\n        pass\r\n \r\ntest = Test()\r\n \r\ntest.string = "Value"\r\nprint(test.string)\r\n```\r\n\r\nHere, we might expect the `print(test.string)` to output "Test" as well as "Value", since `getattr` should be called. But, if we look at the log, we only see the following:\r\n\r\n```python\r\n"Value"\r\n```\r\n\r\nThis is because, once we assign `test.string`, it no longer calls `getattr` the way we expect it to.\r\n\r\nTo solve this problem, we need to use the `__setattr__` magic method to “listen” for property assignment.\r\n\r\n`__setattr__(self, key, val)` - `instance.property = newVal`\r\n\r\n```python\r\nclass Test:\r\n    updateCount = 0\r\n    valid = 1\r\n\r\n    def __setattr__(self, key, val):\r\n        super().__setattr__("updateCount", self.updateCount + 1)\r\n        pass\r\n\r\n\r\ntest = Test()\r\ntest.valid = 12\r\nprint(test.updateCount)\r\n```\r\n\r\n> Notice our usage of `super().__setattr__`. We need to do this similarly to how we utilized the `super()` method in `__getattribute__`, otherwise `self.updateCount += 1` would trigger an infinite loop of calls to `__setattr__`.\r\n\r\n### Clean up programmatic property instanciation\r\n\r\nJust as we can hook into the setting and getting behavior of an attribute, we can also hook into the `del` behavior of an attribute using `__delattr__`.\r\n\r\nFor example, what if we wanted to create a class that acted like a dictionary. For each key created in this dictionary we’d want to automatically create a temporary file. Then, on cleanup (using `del`), let’s remove that file with `os.remove`:\r\n\r\n`__delattr__(self, key)` - `del instance.property`\r\n\r\n```python\r\nimport os\r\n\r\nclass FileDictionary:\r\n    def __setattr__(self, filename, val):\r\n        f = open(filename, "w")\r\n        f.write(val)\r\n        f.close()\r\n   \r\n    def __delattr__(self, filename):\r\n        os.remove(filename)\r\n\r\nfileDictionary = FileDictionary()\r\n\r\nfileDictionary.README = "Hello"\r\ndel fileDictionary.README\r\n```\r\n\r\nRemember, if you’re not cleaning up your side effects, it may cause havoc with future usage of your app. This is why it’s so important to add in `__delattr__` when relevant.\r\n\r\n### Convert programatic lookups to index properties\r\n\r\nIn our most recent `FileDictionary` example, we created a class called “FileDictionary”, but then accessed the child values with the dot accessor:\r\n\r\n```python\r\nfileDictionary.README = "Hello"\r\n```\r\n\r\nHowever, this dot syntax causes some minor headache: it’s not consistent with how you access properties from a dictionary. The reason we’re not using the standard dictionary syntax is because if you do the following:\r\n\r\n```python\r\nfileDictionary[\'README\'] = "Hello"\r\n```\r\n\r\nWe would quickly get an error from Python:\r\n\r\n```\r\n> TypeError: \'FileDictionary\' object is not subscriptable\r\n```\r\n\r\nTo solve this problem, we need to migrate away from `__setattr__`, which only supports dot notation, to `__setitem__`, which only supports the dictionary-style notation.\r\n\r\n\r\n- `__getitem__(self, key)` - `instance[property]`\r\n- `__setitem__(self, key, val)` - `instance[property] = newVal`\r\n- `__delitem__(self, key)` - `del instance[property]`\r\n\r\n```python\r\nimport os\r\n\r\nclass FileDictionary:\r\n    def __setitem__(self, filename, val):\r\n        f = open(filename, "w")\r\n        f.write(val)\r\n        f.close()\r\n\r\n    def __delitem__(self, filename):\r\n        os.remove(filename)\r\n\r\nfileDictionary = FileDictionary()\r\n\r\nfileDictionary[\'README\'] = "Hello"\r\ndel fileDictionary[\'README\']\r\n```\r\n\r\nAs a wonderful side effect, you’re now able to add in a file extension to the `fileDictionry`. This is because bracket notation supports non-ASCII symbols while the dot notation does not.\r\n\r\n```python\r\nfileDictionary[\'README.md\'] = "Hello"\r\ndel fileDictionary[\'README.md\']\r\n```\r\n\r\n## How to replace operator symbol functionality with custom logic\r\n\r\nThere’s nothing more Pythonic than the simplicity of using simple mathematical symbols to represent mathematic actions.\r\n\r\nAfter all, what could more clearly represent the sum of two numbers than:\r\n\r\n```python\r\nsum = 2 + 2\r\n```\r\n\r\nMeanwhile, if we have a wrapper around a number:\r\n\r\n```python\r\nsum = numInstance.getNumber() + numInstance.getNumber()\r\n```\r\n\r\nIt gets a bit harder to read through.\r\n\r\nWhat if we could utilize those symbols to handle this custom class logic for us?\r\n\r\n```python\r\nsum = numInstance + numInstance;\r\n```\r\n\r\nLuckily we can!\r\n\r\n\r\nFor example, here’s how we can make the `+` symbol run custom logic:\r\n\r\n- `__add__(self, other)` - `instance + other`\r\n\r\n```python\r\nclass Test:\r\n    __internal = 0\r\n    def __init__(self, val):\r\n        self.__internal = val\r\n    def __add__(self, other):\r\n        return self.__internal + other.__internal\r\n \r\n\r\nfirstItem = Test(12)\r\nsecondItem = Test(31)\r\n\r\n# This will call "__add__" instead of the traditional arithmetic operation\r\nprint(firstItem + secondItem)\r\n```\r\n\r\nThere’s also other math symbols you can overwrite:\r\n\r\n- `__sub__(self, other)` - `instance - other`\r\n- `__mul__(self, other)` - `instance * other`\r\n\r\n### Manage comparison symbol behavior\r\n\r\nAddition, subtraction, and multiplication aren’t the only usages for operator overloading, however. We can also modify the comparison operators in Python to run custom logic.\r\n\r\nLet’s say we want to check if two strings match, regardless of casing:\r\n\r\n- `__eq__(self, other)` - `instance == other`\r\n\r\n```python\r\nclass Test():\r\n    str = ""\r\n\r\n    def __init__(self, val):\r\n        self.str = val\r\n\r\n    def __eq__(self, other):\r\n        return self.str.lower() == other.str.lower()\r\n\r\nfirstItem = Test("AB")\r\nsecondItem = Test("ab")\r\n\r\nprint(firstItem == secondItem)\r\n```\r\n\r\nYou can also have different logic for `==` and `!=` using `__ne__`.\r\n\r\n- `__ne__(self, other)` - `instance != other`\r\n\r\nHowever, if you don’t provide a `__ne__`, but **do** provide a `__eq__`, Python will simply negate the `__eq__` logic on your behalf when `instance != other` is called.\r\n\r\nThere’s also a slew of magic methods for customizing other comparison operators:\r\n\r\n- `__lt__(self, other)` - `instance < other`\r\n- `__gt__(self, other)` - `instance > other`\r\n- `__le__(self, other)` - `instance <= other`\r\n- `__ge__(self, other)` - `instance >= other`\r\n\r\n### Overwrite a class’s type casting logic\r\n\r\nPython, like any other programming language, has the concept of data types. Similarly, you’re able to convert easily from any of those types to another type using built-in methods of type-casting data.\r\n\r\n\r\nFor example, if you call `bool()` on a string, it will cast the truthy value to a Boolean.\r\n\r\n\r\nWhat if you could customize the behavior of the `bool()` method? You see where we’re going with this…\r\n\r\n- `__bool__(self)` - `bool(instance)`\r\n\r\n```python\r\nfrom os.path import exists\r\n\r\nclass File:\r\n    file_path = ""\r\n   \r\n    def __init__(self, file_path):\r\n        self.file_path = file_path\r\n          # This method should return `True` or `False`\r\n    def __bool__(self):\r\n        return exists(self.file_path)\r\n\r\nfile = File("temp.txt")\r\n\r\n# Will return True or False depending on if file exists\r\nprint(bool(file))\r\n```\r\n\r\nThere’s also other type casts logic you can customize:\r\n\r\n- `__int__(self)` - `int(instance)`\r\n- `__str__(self)` - `str(instance)`\r\n\r\n\r\n## How to make your classes iterable\r\n\r\nLet’s say that we’ve used a custom class to build a replacement for a List:\r\n\r\n```python\r\nclass ListLike:\r\n    length = 0\r\n\r\n    def __getitem__(self, key):\r\n        return self.__getattribute__(str(key))\r\n\r\n    def __setitem__(self, key, val):\r\n        self.__setattr__(str(key), val)\r\n\r\n    def __delitem__(self, key):\r\n        self.__delattr__(key)\r\n\r\n    def append(self, val):\r\n        self[str(self.length)] = val\r\n        self.length += 1\r\n\r\nlistLike = ListLike()\r\nprint(listLike.length) # 0\r\nlistLike.append("Hello")\r\nlistLike.append("World")\r\nprint(listLike.length) # 2\r\nprint(listLike[0]) # "Hello"\r\n```\r\n\r\nThis appears to work amazingly at first glance, until you try to do the following:\r\n\r\n```python\r\n[x for x in listLike]\r\n```\r\n\r\nOr any other kind of iteration on the ListLike. You’ll get the following confusingly named error:\r\n\r\n```python\r\n\'ListLike\' object has no attribute \'2\'\r\n```\r\n\r\nThis is because Python doesn’t know *how* to iterate through your class, and therefore attempts to access a property in the class. This is where `__iter__` comes into play: It allows you to return an iterable to utilize anytime Python might request iterating through the class, like in [a list comprehension](https://coderpad.io/blog/development/python-list-comprehension-guide/).\r\n\r\n- `__iter__(self)` - `[x for x in instance]`\r\n\r\n```python\r\nclass ListLike:\r\n    length = 0\r\n \r\n    def __getitem__(self, key):\r\n        return self.__getattribute__(str(key))\r\n \r\n    def __setitem__(self, key, val):\r\n        self.__setattr__(str(key), val)\r\n \r\n    def __delitem__(self, key):\r\n        self.__delattr__(key)\r\n \r\n    def __iter__(self):\r\n        isMethod = lambda x: type(x).__name__ == \'method\'\r\n        # Only return non-method keys that are not "length"\r\n        return iter([x for x in dir(self) if not x.startswith(\'__\') and x != \'length\' and not isMethod(self[x])])\r\n \r\n    def append(self, val):\r\n        self[str(self.length)] = val\r\n        self.length += 1\r\n \r\nlistLike = ListLike()\r\n \r\nlistLike.append("Hello")\r\nlistLike.append("World")\r\n \r\n[print(x) for x in listLike]\r\n```\r\n\r\n> Notice that we’re having to return a real list wrapped in the `iter` method for the `__iter__` return value: This is required by Python. \r\n>\r\n> If you don\'t do this, you\'ll get the error:\r\n>\r\n> ```\r\n> iter() returned non-iterator of type \'list\'\r\n> ```\r\n\r\n### Check if an item exists using the “in” keyword\r\n\r\nThe `__iter__` magic method isn’t the only way to customize traditionally list-like behavior for a class. You can also use the `__contains__` method to add support for simple “is this in the class” checks.\r\n\r\n- `__contains__(self, item)` - `key in instance`\r\n\r\n\r\nSomething to keep in mind is that if `__contains__` isn\'t defined, Python will use the information provided by `__iter__` to check if the key is present. However, `__contains__` is a more optimized method, since the default `__iter__` checking behavior will iterate through every key until it finds a match.\r\n\r\n## Python magic method cheat sheet\r\n\r\nPython magic methods can level up your application logic by reducing the amount of boilerplate required to do specific actions, but that’s not its only usecase. Othertimes, you might want to use magic methods to provide an API with a nicer development experience for consuming developers.\r\n\r\nThat said, we know that with so many magic methods it can be difficult to remember them all. This is why we made a cheat sheet that you can download or print out to reference when writing code. \r\n\r\n> [Download the related Magic Methods Cheat Sheet](https://coderpad.io/python-magic-methods-cheat-sheet/)\r\n',
		},
		{
			title: "Hard grids & baselines: How I achieved 1:1 fidelity on Android",
			description:
				"Testing the limits of `firstBaselineToTopHeight` and `lastBaselineToBottomHeight` to deliver a perfect result.",
			published: "2019-10-07T22:07:09.945Z",
			edited: "2020-02-02T22:07:09.945Z",
			authors: ["edpratti"],
			tags: ["android", "design"],
			attached: [],
			license: {
				id: "cc-by-nc-nd-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "https://creativecommons.org/licenses/by-nc-nd/4.0/",
				name: "Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) License",
			},
			slug: "hard-grids-and-baselines-android-design-fidelity",
			locale: "en",
			authorsMeta: [
				{
					id: "edpratti",
					name: "Eduardo Pratti",
					firstName: "Eduardo",
					lastName: "Pratti",
					description:
						"UI designer and developer wannabe. Cares about negative space, layout grids and Bloodborne challenge runs.",
					socials: { twitter: "edpratti", website: "http://pratti.design" },
					pronouns: "he",
					profileImg: "./edpratti.jpg",
					color: "#FF3300",
					roles: ["designer", "author"],
					profileImgMeta: {
						height: 960,
						width: 959,
						relativePath: "./edpratti.jpg",
						relativeServerPath: "/content/data/edpratti.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\edpratti.jpg",
					},
					rolesMeta: [
						{ id: "designer", prettyname: "Designer" },
						{ id: "author", prettyname: "Author" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Hard grids & baselines: How I achieved 1:1 fidelity on Android",
				description:
					"Testing the limits of `firstBaselineToTopHeight` and `lastBaselineToBottomHeight` to deliver a perfect result.",
				published: "2019-10-07T22:07:09.945Z",
				edited: "2020-02-02T22:07:09.945Z",
				authors: ["edpratti"],
				tags: ["android", "design"],
				attached: [],
				license: "cc-by-nc-nd-4",
			},
			contentMeta:
				'\n# Testing the limits of `firstBaselineToTopHeight` and `lastBaselineToBottomHeight` to deliver a perfect result.\n\n_**I really care about implementation.**_ I obsess over it. I’m constantly thinking about it.\n\nWhenever I’m designing an app, I always try to focus on how a UI can be created optimally and how well the composition inside a design tool can translate to platform components and paradigms.\n\nYou’ve probably been through the same thing at one point: you make mockups, detailed descriptions, and spreadsheets; and in the end, the result is not what you wanted it to be. In that case, you’d ask yourself whether those details matter to someone other than yourself. And your answer would be “No.”\n\nBut that doesn’t help it. Deep down, you still care. It’s still wrong. It almost makes it worse; you’re the only one that knows it’s wrong, but you can’t push yourself to bug your developers about it and waste time that could be spent on “better things” or “more features.” That’s certainly the case for me.\n\nSo today I’m going to talk about Android’s `TextViews`; how they behave in comparison to design tools, and how to take full control of them, **as a designer.**\n\n<blockquote class="bigBlock">The goal is to ensure the implementation is perfect without taking time off feature development.</blockquote>\n\nIn this post, I’ll walk you through how to make text components for Figma that can be easily implemented on Android, with code snippets and explanations. This post is also helpful for developers to understand [**why they should move that button `3px` to the left.**](https://library.gv.com/why-you-should-move-that-button-3px-to-the-left-c012e5ad32f7)\n\nIf all you need is to quickly ensure that text sits within a baseline grid without knowing the exact values or whether they match the mockups, there are alternatives to this method!\n\n_[Plaid’s `BaselineGridTextView` library](https://github.com/android/plaid/blob/master/core/src/main/java/io/plaidapp/core/ui/widget/BaselineGridTextView.java)_\n\n<ul role="list" style="list-style: none; padding: 0; margin: 0;">\n<li role="listitem">✔ Applies proper baseline alignment automatically</li>\n<li role="listitem">✔ Ensures a precise line height</li>\n</ul>\n\n**If this isn’t good enough for you and you’d rather have control over every aspect of the UI, then come along.**\n\n# Introduction\n\nAndroid has two main `TextView`s; one of them is `AppCompatTextView`, which has been available for quite a while, and `MaterialTextView` (which extends `AppCompatTextView`). They are identical, with the latter allowing a line-height attribute to be set in a `textAppearance` (if you don’t know what that means, no worries). _**Go with `MaterialTextView`**._\n\nWith Android 9.0 Pie, Google introduced 3 new attributes for `TextView`s: `firstBaselineToTopHeight`, `lastBaselineToBottomHeight` and `lineHeight`. These control everything you’d need to build a UI with.\n\nShortly after, Google removed those API restrictions by backporting those features to [`AppCompatTextView`](https://developer.android.com/reference/androidx/appcompat/widget/AppCompatTextView) and subsequently, [`MaterialTextView`](https://developer.android.com/reference/com/google/android/material/textview/MaterialTextView?hl=en). This means these attributes can now be used across all supported versions of Android!\n\nHowever, if you seek fidelity, you’ll find that `lineHeight` on Android differs from other platforms and most design tools.\n\n# How is it any different?\n\nLet us take a look at some examples; one with a single line, then two lines, then three lines with line height set to `24pt/sp`.\n\n![A side-by-side comparison of the differences in line-height between the Figma design tool (which reflect the web and Sketch as well) and Android. Shows how a single line string is "24pt" on the web while it\'s rounded to "19sp" on Android, it shows how a string that splits two lines is "48pt" on Figma while "43sp" on Android and finally how a three-line string is "72pt" on Figma while "67sp" on Android](line_height_difference.png "A comparison between Figma and Android line-heights")\n\nAs you can probably tell, Android `TextViews` are always smaller than the ones given to a developer from a design tool and those implemented on the web. In reality, Android’s `lineHeight` is not line-height at all! **It’s just a smart version of line-spacing.**\n\n![A side-by-side comparison of line-spacing on Figma and Android. Figma provides equal spacing above and belong to text string to align them with space around while Android is a space between with no spacing on the top for the first item or spacing on the bottom for the last](under_the_hood_01.png "A comparison between Figma and Android line-spacing")\n\n![A further comparison of the above image\'s demo of spacing around on Figma and spacing between on Android](./under_the_hood_02.png "Another comparison between Figma and Android line-spacing")\n\nNow you might ask yourself, “*How can I calculate the height of each `TextView`, then?*”\n\nWhen you use a `TextView`, it has one parameter turned on by default: **`includeFontPadding`**. `includeFontPadding` increases the height of a `TextView` to give room to ascenders and descenders that might not fit within the regular bounds.\n\n![A comparison between having "includeFontPadding" on and off. When it\'s off the height is "19sp" and when it\'s on it is "21.33sp". It shows the formula "includeFontPadding = TextSize * 1.33"](includefontpadding.png "A comparison of having the \'includeFontPadding\' property enabled")\n\nNow that we know how Android’s typography works, let’s look at an example.\n\nHere’s a simple mockup, detailing the spacing between a title and a subtitle. It is built at `1x`, with Figma, meaning line height defines the final height of a text box — not the text size. (This is how most design tools work)\n\n![A spec file of a phone dailing application](./specs.png)\n\n![A mockup with spec lines enabled of a call log app](./implementation.png )\n\n*Of course, because it’s Android, the line height has no effect on the height of the `TextView`, and the layout is therefore `8dp` too short of the mockups.*\n\nBut even if it did have an effect, the problems wouldn’t stop there; the issue is more complex than that.\n\n# What designers want, and what developers can do\n\nDesigners, like myself, like to see perfect alignment. We like consistent values and visual rhythm.\n\n![A showcase of the differences in line spacing between a mockup and an implementation in Android](./designers_want_designers_get.png)\n\nUnfortunately, translating values from a design tool wasn’t possible. You had the option to either pixel nudge (pictured above, right), or forget about alignment altogether, thus leading to an incorrect implementation that would, yet again, be shorter than the mockups.\n\n## …Until now!\n\n_`firstBaselineToTopHeight`_ and _`lastBaselineToBottomHeight`_ are powerful tools for Android design. They do as the name suggests: If _`firstBaselineToTopHeight`_ is set to `56sp`, then that’ll become the distance between the first baseline and the top of a `TextView`.\n\n![A subtitle block showing "56sp" height despite the text visually being much shorter](56sp.png)\n\nThis means that designers, alongside developers, can force the bounds of a `TextView` to match the design specs and open the door to perfect implementations of their mockups.\n\nThis is something I’ve personally tested in an app I designed. [**Memoire**, a note-taking app](http://tiny.cc/getmemoire) for Android, is a 1:1 recreation of its mockups — for every single screen. This was made possible due to these APIs — *and because [**@sasikanth**](https://twitter.com/its\\_sasikanth) is not confrontational* — since text is what almost always makes baseline alignment and hard grids impossible to implement in production.\n\n<video src="./memoire_bounds_and_baselines.mp4" title="Near-perfect duplication of guidelines against Memoire\'s mockups and actual app"></video>\n\n*Memoire’s TextViews are all customized using these APIs.*\n\n# What is the purpose of firstBaselineToTopHeight and lastBaselineToBottomHeight?\n\nIn reality, the new attributes were actually made to be used when creating layouts: you want to make sure the baseline is a certain distance from another element, and it also helps to align the first and lastBaseline to a `4dp` grid. This mirrors the way iOS layouts are built.\n\n![A showcase of "firstBaselineToTopHeight" being used to create top-padding from an image and lower text on a card, "lastBaselineToBottomHeight" to create bottom padding against the card edge, and "lineHeight" to set the text spacing](intended_use.png "A showcase of the various props to size this card")\n\n**However, there’s one giant flaw: You can’t align a `TextView`’s `firstBaseline` to another `TextView`’s `lastBaseline`.** So a problem immediately arises due to this limitation:\n\n<blockquote class="bigBlock"><i>What if there’s more than one <code class="language-text">TextView</code>?</i></blockquote>\n\nAs you might imagine, **if we want to keep our text aligned to a baseline grid, we need to ensure that the height of each `TextView` is a multiple of 4 while doing so.** This means we must apply first and lastBaseline attributes to both / all of the stacked TextViews — and that becomes hard to maintain.\n\n![A comparison table of Dos and Donts that matches the below table](./dos_donts.png)\n\n|✅ Good|🛑 Bad|\n|--|--|\n|Applying `firstBaseline` and `lastBaseline` in styles allows you to know exactly what the distance between baselines is, without having to set them one by one to ensure they properly align to a `4dp` grid. | Without applying `firstBaseline` and `lastBaseline` in styles, you can’t detect what the default values are, so you are forced to apply these one by one to every `TextView` to ensure they align to a `4dp` grid. |\n\n<video src="./ios_vs_android.mp4" title="A comparison of how text spacing is applied on iOS and Android"></video>\n\nThe solution is to apply them in your `styles.xml` so that, when themed, the `TextView` is given the right text size, height, font, and baseline properties.\n\n**It is important to note that these values should not be overridden within layouts.**\n\n<blockquote class="bigBlock">Ultimately, <strong>overriding first and lastBaseline in layouts also causes major issues</strong> if you want to change a font style or text size in the future.</blockquote>\n\nThe overrides will take precedence to whatever value you set in your **`styles.xml`**, requiring you to hunt down occurrences until you can find a layout that was broken due to the change. Let’s look at an example:\n\n<video src="./dont_override.mp4" title="Allowing margin changes instead will let the text grow to it\'s expected sie without having issues with the baseline not being centered"></video>\n\nImplementing margins instead of overriding values also matches the way layouts work within Android Studio and design tools like Sketch and Figma. It also ensures that your layouts can scale well to different font sizes.\n\n# So, how can you adapt your TextViews? Design goes first.\n\nIt’s actually pretty simple. Let’s walk through how to adapt one of Material Design’s standard type sizes: Headline 6 — used inside AppBars and dialog titles.\n\n**Step 1: Place a text box of the text style you’d like to adapt — in this case, Headline 6.**\n\n![A headline 6 within Figma showing "32pt" height](./figma_textbox_size.png "Text box within Figma")\n\n*Text box within Figma.*\n\nHere we can see that the text box has a height of `32`. This is inherited from the line height set in Figma, but we need to know the minimum height on Android. We can easily calculate the minimum height in production using *includeFontPadding*.\n\n> Headline 6 = `20` (text size) `* 1.33` (`includeFontPadding`) = `26.667sp`\n\n![An image showcasing the headline height mentioned above](./android_textview_size.png "TextView on Android")\n\n*`TextView` on Android.*\n\nNow resize your Figma text box to `26.6` — *it will round it to `27`, but that’s fine.*\n\n**Step 2: With the resized text box, align its baseline with the nearest `4dp` breakpoint in your grid.**\n\n![Baseline now sits on the "4dp" grid.](./step_01.png)\n\n*Baseline now sits on the `4dp` grid.*\n\n**Step 3: Measure the distance between the baseline and the top and bottom of the text box.**\n\n![Showcasing the above effect by having \'firstBaselineToTopHeight\' set to 20.66 and \'lastBaselineToBottomHeight\' to 6.0](step_02.png)\n\n*`firstBaselineToTopHeight`: `20.66` | `lastBaselineToBottomHeight`: `6.0`*\n\n**Step 4: Now right click the text box and select Frame Selection.**\n\n![The right-click dialog hovering over Frame Selection, key binding Ctrl+Alt+G](./step_03.png "The right-click dialog hovering over Frame Selection")\n\n*When created from an object, a frame’s dimensions are dependent on the content inside it.*\n\n**Step 5: While holding Ctrl / Command, drag the frame handles and resize it so that the top and bottom align with the nearest baselines beyond the minimum values.**\n\n![The moving of the baseline by holding the key commands](./step_04.png)\n\n![Another view of the same adjustment](./step_05.png)\n\n**NOTE: Keep in mind we must not resize the text box with it. Holding Ctrl / Command is very, very important.**\n\nIn the example above, we stretched the frame so that the distance between the top of the frame and the baseline of the text box would be bigger than `20.66` (the minimum), therefore, **`24sp`**.\n\nThe same thing was done to the last baseline and the bottom; we changed it from `6sp` to **`8sp`**, which was the closest multiple of 4 larger than 6.\n\n**Step 6: Select the text box inside the frame, and set the text to Grow Vertically.**\n\n![A view of the image aligning tool with the tooltip enabled for "Grow Vertically"](./step_06.png "You can recreate the margin vertical grow functionality by selecting this")\n\nThis will cause the text box to return to its original height of `32sp` — inherited from the line height.\n\n![A showcase of the text box being "1sp" down from the frame](./step_07.png)\n\n*The text box is 1sp down from the frame, but that’s normal. We no longer care about the text box height.*\n\n**Step 7: With the text box selected, set its constraints to *Left & Right* and *Top & Bottom*.**\n\n![A view of the constraints dialog in Figma on the headline](./step_08.png)\n\n*Now your text box will resize with your frame. This is essential when using the text components.*\n\nYou would need to find these values for every text style in your app, but if you’re taking the Material Design Type Spec as a base for your own, I have already measured and picked the right values for each! _**Resources at the end.**_\n\n![A showcase of what the headings and text should look like at the end](./headline_text_size_showcase.png)\n\n# How to implement these values (as a developer)\n\nAll of them follow the same template.\n\nWe first set up a `TextAppearance` — which your app probably already has —  and then create another style that encapsulates the `TextAppearance` alongside the `firstBaseline` and `lastBaseline` attributes.\n\n```xml\n<!-- **TEXT_STYLE** -->\n    <style name="TextAppearance.**APP_NAME**.**TEXT_STYLE**" parent="TextAppearance.MaterialComponents.**TEXT_STYLE**">\n        <item name="lineHeight">**LINE_HEIGHT**</item>\n        <item name="android:textSize">**TEXT_SIZE**</item>\n        <item name="android:letterSpacing">**LETTER_SPACING**</item>\n    </style>\n\n    <style name="TextStyle.**APP_NAME**.**TEXT_STYLE**">\n        <item name="android:textAppearance">@style/TextAppearance.**APP_NAME**.**TEXT_STYLE**</item>\n        <item name="firstBaselineToTopHeight">**FIRST_BASELINE_VALUE**</item>\n        <item name="lastBaselineToBottomHeight">**LAST_BASELINE_VALUE**</item>\n    </style>\n<!-- **TEXT_STYLE** -->\n```\n\n\nLet’s use Memoire once again as an example.\n\n![An example of the Memoire codebase showing the headline of 4](./memoire_headline_4_code.png)\n\n## Each has a different function:\n\n**`TextAppearance`:** Applied in styles to theme Material Components globally.\n\nMaterial Components are themed with `textAppearanceTEXT\\_STYLE` attributes that are then applied to all components that inherit it.\nFor example, _**`textAppearanceCaption`**_, _**`textAppearanceBody1`**_, etc.\n\n**`TextStyle`:** Applied to `TextView`s in layouts, to ensure `4dp` alignment.\n\n![A display of code styling when "TextStyle" is properly applied. See \'styles.xml\' at the bottom of the post for an example](text_style_applied_properly.png "A display of code styling when TextStyle is properly applied")\n\n*What happens to a `TextView` when a `TextStyle` is properly applied.*\n\n# And now, a couple of warnings\n\n## Loss of vertical padding\n\nWhen setting a style to a `TextView`, keep in mind that `firstBaseline` and `lastBaseline` are designed to replace vertical padding. This means that, whenever set, a `TextStyle` will nullify all vertical padding values.\n\n## Do not apply `TextStyle` to Material Components. Use `TextAppearance` for those instances instead.\n\nApplying a `TextStyle` to a component — instead of a `TextAppearance` — causes serious issues.\n\n![A showcase of a "button" component not having the text align to the height of the component](./textstyle_buttons.png)\n\n*Uh-oh…*\n\nThis happens because Material Components already have padding that _**IS NOT**_ overridden by `firstBaseline` and `lastBaseline` values. Buttons, in particular, have a **maximum height *and* padding**, meaning we’re effectively trying to fit a large text box into a very narrow container, causing the text to shrink as a result.\n\nAs far as other issues, I haven’t been able to find any.\n\n# Resources, resources, resources!\n\nNow that you’ve scrolled all the way down without reading a single word, here’s all the stuff you’ll need:\n\n![A preview of the Figma document with code and layout samples](./preview.png)\n\n*Figma document with code and layout samples.*\n\n## For designers: [Figma Document](https://www.figma.com/file/F1RVpdJh73KmvOi06IJE8o/Hard-Grid-—-Text-Components/duplicate)\n\nDocument containing:\n\n* A slight introduction\n\n* All the text components\n\n* A small tutorial on how to use them effectively\n\n* Prebuilt layout examples to get you started\n\n* Customizable code blocks for each style in a text box, so you can change each depending on your theme and hand it to developers\n\n## For developers: [styles.xml](./styles.xml)\n\nA styles.xml file containing:\n\n* All the `TextAppearance`s that can be used with Material Components\n\n* All the `TextStyle`s to theme `TextView`s accordingly\n\n',
		},
		{
			title: "How Computers Speak: Assembly to AST",
			description:
				"Have you wondered how programming languages are able to be ran on your hardware? This article explains how your code is processed and ran",
			published: "2020-08-25T04:45:30.247Z",
			edited: "2020-08-25T04:45:30.247Z",
			authors: ["crutchcorn", "reikaze"],
			tags: ["hardware", "javascript", "computer science"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "how-computers-speak",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
				{
					id: "reikaze",
					name: "Kevin Mai",
					firstName: "Kevin",
					lastName: "Mai",
					description:
						"Hello! I'm Kevin Phong Mai, aka Reikaze or RockmanDash12, a Computer Engineering Student and Freelance Writer passionate about Tech, Anime, Visual Novels and much more. I'm the Owner of RockmanDash Reviews Blog, and I write for the AniTAY & FuwaNovel blogs.",
					socials: { twitter: "Reikaze0", github: "Reikaze" },
					pronouns: "he",
					profileImg: "./reikaze.jpg",
					color: "#ba68c8",
					roles: ["author"],
					profileImgMeta: {
						height: 718,
						width: 718,
						relativePath: "./reikaze.jpg",
						relativeServerPath: "/content/data/reikaze.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\reikaze.jpg",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "How Computers Speak: Assembly to AST",
				description:
					"Have you wondered how programming languages are able to be ran on your hardware? This article explains how your code is processed and ran",
				published: "2020-08-25T04:45:30.247Z",
				edited: "2020-08-25T04:45:30.247Z",
				authors: ["crutchcorn", "reikaze"],
				tags: ["hardware", "javascript", "computer science"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				'\nDuring my time learning programming, I found myself lacking foundational knowledge about how a computer worked under-the-hood. It wasn\'t until much later in my career that I started learning about how certain puzzle pieces fit together and had a more holistic image of how computers worked. I feel that having this insight made me a better developer and shifted my thinking during debugging to reflect more accurately what was happening.\n\nIn this article, we\'re going to introduce you to various concepts to helping you understand how computers are able to parse and understand common programming languages and process the instructions you pass to it.\n\nWe\'ll ask and answer the following questions:\n\n- [What is "source code"?](#source-code)\n- [What are the major components of a computer, and how do they tie together?](#computer-hardware)\n- [What language does the computer speak natively?](#assembly-code)\n\n- [Why do I need a custom program to run some programming languages?](#compiled-vs-runtime)\n- [How does a computer turn letters and symbols into instructions that it knows how to run?](#lexer)\n- [Why do some programming languages have different rules and look different from one another?](#parser)\n- [Why can\'t we simply give the computer English instructions and have it run those with a special program?](#english-vs-ast)\n\n>  I\'m writing this article as a starting point to a developer\'s journey or even just to learn more about how computers work under-the-hood. I\'ll make sure to cover as many of the basics as possible before diving into the more complex territory. That said, we all learn in different ways, and I am not a perfect author. If you have questions or find yourself stuck reading through this, drop a comment down below or [join our Discord](https://discord.gg/FMcvc6T) and ask questions there. We have a very friendly and understanding community that would love to explain more in-depth.\n\n# Source Code {#source-code}\n\nIf you\'ve spent any time with developers, you\'ll likely have heard of the term "source code." Source code simply refers to the text that programmers type  to make their programs. Take the following text:\n\n```javascript\nconst magicNumber = 185;\n\nconsole.log(magicNumber);\n```\n\nIf you\'re not familiar with what that code does,  we\'ll explain it in a bit. Right now, it\'s just important to focus on what\'s being typed. If you opened Notepad, you\'d be able to type this in using a typical QWERTY keyboard.\n\n**This type of file, regardless of the file name, is known as a "plain text" file**. Plain text files are those that contain only the alpha-numeric values that you\'re able to type. There are other types of files - such as **"binary" files - that contain special encoding that, were you to open them in Notepad, humans would not be able to easily read**.\n\n> Notice that I mention using Notepad instead of a program like Microsoft Word. This is because Word actually includes special formatting in its files that would break any source code stored within a file created in Word\n\nThe mention of "regardless of file name" might seem like an odd thing to mention until you consider [the file extension](/posts/what-do-files-extensions-do/) is part of the file name.\nThis means that you can store source code in a `.txt` file and still have it run if executed properly. Most programming languages have their own file extensions, which they tell your computer they own. Still, even  if you change a file\'s extension, [the contents of the file are exactly the same, just the file name (ala extension) is different](/posts/what-do-files-extensions-do/).\n\nLet\'s assume that we\'ve stored the `magicNumber` code inside of a text file. Go ahead and open Notepad, copy+paste that code, and save it to `/User/Destop/code.js`. Now, download [NodeJS](https://nodejs.org/). NodeJS is a program that runs JavaScript source code files. [Not all programming languages are run this way](#compiled-vs-runtime), but JavaScript is.\n\nOnce NodeJS is downloaded, open your terminal (also known as CMD in Windows), go to your desktop, and run `node code.js`, it will output the number `185` so that you can see it.\n\n![](./cmd.png)\n\nThis same behavior would happen even if you called the file `code.txt`. While understanding what a source code file is, it does lend itself to a question:\nHow does your computer understand what to do when running a programming language? Why do some languages, like JavaScript, need another program to run its code while others don\'t?\n\nThe answer to all of these involves an understanding of how hardware works, and one of the best ways to learn programming is to learn how a computer works in the first place.\n\n# How A Computer Works {#computer-hardware}\n\n> This section won\'t be a complete "Computers 101" course. While we _will_ be writing material that dives deeper into these subject matters, this is meant as a short description to supplement explanations later on in the article. If you\'d like to see that type of content in the future, be sure to [sign up for our newsletter](https://newsletter.unicorn-utterances.com/)\n\nYour computer is comprised of many components, but today we\'ll be focusing on five of the primary ones:\n\n- Motherboard\n- Long Term Storage ("HDD" or "SSD")\n- Graphics Processing Unit ("GPU")\n- Central Processing Unit ("CPU")\n- Random Access Memory ("RAM")\n\nThese are used to connect each of these parts together, make up the "brains" of your computer. Whenever you take an action on your computer, these components launch into action to bring you the output you\'d expect. Be it auditory, visual, or some other form of output, these components will do the "thinking" required to make it happen.\n\n## Motherboard {#mobo}\n\n**A motherboard is the platform in which all other components connect together and communicate through**. There are various integrated components to your motherboard, like storage controllers and chipsets necessary for your computer to work. Fancier motherboards include additional functionality like high-speed connectivity (PCI-E 4.0) and Wi-Fi. \n\nWhen you turn on your computer, the first that will happen is your motherboard will do a "POST"; a hardware check to see if everything connected is functioning properly. Then the motherboard will start the boot sequence; which starts with storage\n\n## Long Term Storage {#hdd}\n\n**There are 2 primary types of storage in computers; Solid State Drives (SSD), and Hard Disk Drives (HDD)**. When the boot sequence hits storage, your drive will scan the very first bit of its disk ([also known as the "boot sector"](https://en.wikipedia.org/wiki/Boot_sector)) to find the installed operating system. Once your storage is done finding the relevant files, your computer reads the rest of the information off of the drive to load your system. This includes configuration files that you\'ve updated by setting up your computer (like your username, wallpaper, and more) and the system files set up when you installed your operating system (like Windows). Moreover, this is also where your documents live. If you\'ve written a document in Microsoft Word, downloaded a song from iTunes, or anything in between, it lives on your hard drive.\n\n## Memory {#ram}\n\n**While SSDs and HDDs are fantastic for long-term file storage, they\'re too slow (in terms of reading speeds) to store data needed to run your computer**. This is why we have memory in the form of Registers and Random Access Memory (RAM).  **Registers are the closest memory to your processor and are extremely fast, but they are extremely small.** System Memory, or RAM, is outside of the processor but allows us to store entire programs in a responsive manner.  Everything from your operating system to your video player utilizes memory to store data while processing. We\'ll see how the computer utilized registers and RAM in programs [later in the article](#assembly-code).\n\n**While this information is magnitudes faster to access than hard-drives, it\'s volatile.** That means that when you turn off your computer, the data stored in RAM is lost forever. Memory is also much more expensive than Storage. This is why we don\'t store our files to RAM for long-term access.\n\n## GPU {#gpu}\n\nComputers are a marvel, but without some ability to interact with them, their applications are limited. For many, that interaction comes through their computer screens - seeing the results of an action they\'ve taken. **Your computer\'s "graphics processing unit" (GPU) is the hardware used to calculate the complex maths required to draw things on-screen.** The GPUs\' complex mathematics prowess can also be utilized for things other than graphics (data analytics, cryptocurrency mining, scientific computation).\n\n## CPU {#cpu}\n\nYour CPU is what does all of the computation needed to perform tasks you do on your computer. **It does the math and logic to figure out what the other components need to be doing, and it coordinates them.** An example of this is telling the GPU what to draw. While your GPU does the calculations for what\'s to be drawn, the command to do such comes from the CPU. If your interaction requires data to be stored, it\'s the one that dispatches those actions to your HDD or RAM.\n\nYou can think of these components working together similarly to this:\n\n![](./hardware_devices.svg)\n\n> For those unaware, the visual cortex is the part of the brain that allows us to perceive and understand the information provided to us by our eyes. Our eyes simply pass the light information gathered to our brains, which makes sense of it all. Likewise, the GPU does the computation but does not display the data it processes; it passes that information to your monitor, which in turn displays the image source to you.\n\n\n# Assembly: What\'s that? {#assembly-code}\n\nAt the start of this article, one of the questions I promised to answer was, "What language does the computer speak natively?". The answer to this question is, as you may have guessed from the section title, assembly.\n\nWhen [introducing CPUs](#cpu), I mentioned that they contain the logic to do maths, instruct other components to execute operations, and more. To support a wide range of operations needed to run a computer, **CPU manufacturers implement an "instruction set."** This instruction set handles everything from basic arithmetic to basic memory handling. Once an instruction set is settled upon, **the CPU hardware is built around the instruction set**. That\'s right: Processors are built with their instructions (code) in mind first, and hardware is meant to backup that code.\n\nThese instructions often map very plainly to a sequence of bits (ones and zeros). For example:\n\n```\n100001 # addu\n101011 # sw\n100100 # and\n```\n\nWhile [understanding binary can be a task all on its own](/posts/non-decimal-numbers-in-tech/), suffice it to say that the processor hardware is built to understand the order of `1`s and `0`s, and which command they map to. Because of the direct one-to-one match between instruction and assembly code, this is considered the closest a programming language can get to the hardware.\n\n> Because of this close proximity to hardware, each type of CPU has a different flavor of assembly. Because of this, the actual assembly code isn\'t particularly important, nor is it particularly accurate. Keep that in mind as we go forward.\n>\n> For record-keeping purposes: we\'ll be trying our best to stick to the [MIPS instruction set](http://www.mrc.uidaho.edu/mrc/people/jff/digital/MIPSir.html) with [Pseudoinstructions assembler macros](https://en.wikibooks.org/wiki/MIPS_Assembly/Pseudoinstructions)\n\nSince assembly is the closest to hardware that any programming can get, **all programming languages end up as assembly instructions at one stage or another (we\'ll touch on how that conversion takes place later on)**. Because of this, we\'d like to show you how to do some basic programming using assembly to help connect some dots.\n\nLet\'s assume we want to do the math `180 + 5`. A fairly straightforward example, let\'s evaluate how we might go about doing so in MIPS assembly.\n\nWhen you and I do math, we need to keep the concepts of the numbers `180` and `5` in our minds separately to combine them. Likewise, the computer needs to store both of these hardcoded values in [registers (remember, we touched on what registers are in the "memory section")](#ram) before they can be added together.\n\nLet\'s assume that we have two (2) registers. We can use `$1` as shorthand for "register 1," while `$2` will be shorthand for "register 2".\n\n```\nli      $1,180     # Loads "180" into register 2\nli      $2,5       # Loads "5" into register 2\n```\n\n> The `li` command stands for "load immediate".\n\nNow that we have that data loaded into registers, we can now do the `addu` instruction to combine these numbers and store the final value back in register 1\n\n```\naddu    $1,$2,$1   # Add (+) data from registers 1 and 2, store the result back into register 1\n```\n\nFinally, if you were to inspect the value within register 1, you\'d find a value representing the number `185`. \n\nThis works well, but what happens if we want to add 3 numbers together? We don\'t have enough registers to store all of these values at once!\n\nThis is where RAM comes into play. To store items into RAM, we can use `sw` instruction (short for "Store word") to store register values into RAM with a "tag" of sorts. This "tag" then can read and write values into RAM for you.\n\n> The method in which these values are stored is into [a Stack](/posts/virtual-memory-overview/#stack). For simplicity\'s sake, we won\'t review that here, but it\'s suggested you read the [related article](/posts/virtual-memory-overview/#stack) that covers the topic\n\n```\n# Saving "180" to RAM w/ tag "8"\n\nli      $1,180     # Loads "180" into register 1\nsw      $1,8($fp)  # Store data in register 1 into RAM (with the tag "8")\n\n# Saving "5" to RAM w/ tag "8"\n\nli      $1,5       # Loads "5" into register 1\nsw      $1,12($fp) # Stores data in register 1 into RAM (with the tag "12")\n\n# Saving "20" to RAM w/ tag "16"\n\nli      $1,20      # Loads "20" into register 1\nsw      $1,16($fp) # Stores data in register 1 into RAM (with the tag "16")\n\nlw      $1,8($fp)  # Load RAM tag 8 data into register 1\nlw      $2,12($fp) # Load RAM tag 12 data into register 2\naddu    $1,$2,$1   # Add (+) data from register 1 and 2, store the result back into register 1\n\n# Register 1 now contains the value "185"\n\nlw      $2,12($fp) # Load RAM tag 16 data into register 2\n\n# Remember, register 2 now contains the value "20"\n\naddu    $1,$2,$1   # Add (+) data from register 1 and 2, store the result back into register 1\n\n# Register 1 now contains the value "205"\n```\n\n> Editors note: There\'s a way to add the numbers together without using RAM. We\'re only doing things this way to demonstrate how you use RAM in assembly. If you can figure out how this is done (hint: move some lines around), leave a comment! 😉\n\n# This (code) Keeps Lifting me Higher {#introducing-c-code}\n\nAs efficient as assembly code is, you may have noticed that it\'s not particularly readable. Further, for larger projects, it\'s impossible to manage a project of that scale without some abstractions that higher-level languages provide. This is where languages like C or JavaScript come into play.\n\nWhile in-memory "tags" are useful for storing data into RAM using assembly, the numbers spit out from the stack are hardly memorable. Remembering what value is present in RAM spot #16 is tricky on its own, and only grows more and more complex the larger the application is. As such, **higher-level languages have the concept of "variables."** They\'re an abstraction around storing values in RAM, but instead of number "tags," you can make them alpha-numeric human-readable values. For example, the following code in C:\n\n```c\nvoid main() {\n   int magicNumber = 185;\n}\n```\n\nMight map to something like this:\n\n```\nli      $1,185\nsw      $1,8($fp)\n```\n\nWithout the comments in the assembly, it\'s much easier to tell what the C code is doing. This is made more dramatic when using more than a single value. Let\'s take the three number addition from before:\n\n```c\nint main() {\n\tint magicNumber = 180;\n\tint number2 = 5;\n\tint thirdNumber = 20;\n\n\treturn magicNumber + number2 + thirdNumber;\n}\n```\n\n## Portability {#compilation}\n\nWhile the previous example already demonstrates the readability that higher-level languages hold over assembly, when it comes to code complexity, there\'s no contest: High-level languages make I/O like printing something on-screen readily available.\n\nTake the following:\n\n```c\n#include <stdio.h>\n\nint main() {\n    int magicNumber = 185;\n    \n    printf("%d", magicNumber);\n}\n```\n\nThis code simply says, "print the number 185 to the screen so the user can see it". **To do the same in assembly requires a massive amount of knowledge about the system** you\'re intending to run code on, due to the lack of portability granted by higher-level languages.\n\nWhat do I mean by portability? Well, let\'s say you want to write code that runs on both low-end Chromebooks and high-end Desktops alike, you need to adapt your code to run on their respective processors. Most low-end Chromebooks use a type of CPU called "ARM", while most high-end Desktops run "x86_64" processors. **This difference in CPU architecture means an entirely different instruction set, which requires a different set of assembly instructions to be written to do the same thing in both**.\n\nMeanwhile (with a few exceptions), simple C code will run both platforms equally with some minor changes. This is because of C\'s _compiler_. \n\nWhat is a compiler?\n\n**A compiler is a program that converts a given programming language into instructions that the computer can understand and run**. With the above example, you can use a compiler like [GCC](https://gcc.gnu.org/) in order to convert that into the assembly instructions for x86 or ARM. Simply save the code to a file `code.c`, then run the command:\n\n```\ngcc -S code.c\n```\n\nIt should output a `code.s` file. This contains the assembly code that\'s generated from the relevant C code. Here\'s the `code.s` file generated from the C example targeting MIPS (for familiarity):\n\n```\nmain:\n\taddiu\t$sp,$sp,-40\n\tsw\t$31,36($sp)\n\tsw\t$fp,32($sp)\n\tmove\t$fp,$sp\n\tlui\t$28,%hi(__gnu_local_gp)\n\taddiu\t$28,$28,%lo(__gnu_local_gp)\n\t.cprestore\t16\n\tli\t$2,185\t\t\t# 0xb9\n\tsw\t$2,28($fp)\n\tlw\t$5,28($fp)\n\tlui\t$2,%hi($LC0)\n\taddiu\t$4,$2,%lo($LC0)\n\tlw\t$2,%call16(printf)($28)\n\tmove\t$25,$2\n\t.reloc\t1f,R_MIPS_JALR,printf\n1:\tjalr\t$25\n\tnop\n\n\tlw\t$28,16($fp)\n\tmove\t$2,$0\n\tmove\t$sp,$fp\n\tlw\t$31,36($sp)\n\tlw\t$fp,32($sp)\n\taddiu\t$sp,$sp,40\n\tjr\t$31\n\tnop\n```\n\nThere\'s a lot there that\'s not familiar to us. That\'s okay. There\'s a lot of Vudu that the compiler does to make sure your code is efficient and compatible with as many computers (of the same CPU type) as possible. You\'ll still likely recognize the `addiu`, `li`, and `sw` instructions [from before](#assembly-code).\n\nFurther, some abstractions make higher-level languages easier to build and scale than assembly, which doesn\'t have trivial 1:1 mappings. This is why compilers are so complex: there are many tricks up a compiler\'s sleeve to convert code to run and even internally "rewrite" your code to be more efficient - All without know knowing.\n\nThis is why to run your C code, you need to run the compiler to convert your source code into an executable file to run your program.\n\n## Compiled vs. Runtime {#compiled-vs-runtime}\n\nAt [the start of this section](#introducing-c-code), we mentioned that languages like C or JavaScript are higher-level languages than assembly. However, long-time developers will be quick to remind that these two languages are drastically different. The most significant difference between these being that C is a "compiled" language while JavaScript is a dynamic "runtime" language.\n\nIf you download [NodeJS](https://nodejs.org/en/) for your computer and run the `node` command from a computer terminal, you can write JavaScript and have it executed right then and there, without having to have compiled your source code ahead-of-time (also known as A.O.T. compilation)\n\nHow are these runtime languages able to run without compiling beforehand?\n\n**That\'s because they utilize a program (known as the runtime) to compile the code while running it**. While this gives the advantage of even more portable code, it comes at the cost of having to download a separate program (the runtime) to run your programs. Instead of having to port your entire codebase to support a new operating system or CPU flavor, you port the runtime the language runs on. Once this is done, you can run all programs written in that language on the new platform.\n\nBecause the compilation on these languages happens during runtime (this method of compilation is called J.I.T compilation - "just in time compilation"), **it is a common misconception that these languages are not compiled**. This is not true.\n\nSimply because a language is compiled at run-time does not mean that there is a lack of optimizations. The compilers for these J.I.T languages can be just as complex (if not more so) than those for pre-compiled languages. Typically, **J.I.T compilers are able to "warm-up" and increase speed as they optimize the code they\'re running**, due to repetitions in execution cycles.\n\nIn fact, many J.I.T languages - like Python - contain a way to optimize your code by **running your code through a pre-compiler to generate what\'s known as "bytecode."** This bytecode is often closer in resemblance to your instruction set, while not going so far as to compile all the way down to assembly. **You can think of this pre-optimization as pre-heating the oven** - you\'ll be faster to cook your food if much of the prep work is already handled. As such, you still need the runtime to run this optimized code, but because you\'ve done the early optimization, the code will load much faster. In Python, once you [precompile your code](http://effbot.org/zone/python-compile.htm), it gets turned into a `.pyc` file, which is faster to run on first load.\n\n# Introducing the AST {#ast}\n\nWhile we\'ve talked about compiled languages (A.O.T. and J.I.T. alike), we haven\'t yet talked about how computers can convert high-level language source code into assembly. How does it know what commands to map to which instructions?\n\nI\'m glad you asked! Inside of **every compiler** is a piece of software that **turns your source code into something called an "Abstract Syntax Tree" (AST)**. An AST takes the human-readable text and turns it into machine-understandable data using a rigid set of rules. Once in this state, an AST is easier to map and match to the related instructions.\n\nLet\'s take the following JavaScript variable assignment:\n\n```javascript\nconst magicNumber = 185;\n```\n\nWhile this code sample is extremely trivial (and doesn\'t do anything on its own), it contains enough complexity in how the computer understands it to use as an introductory example.\n\n## The Lexer {#lexer}\n\nThere are (typically) two steps to turning source code into something that the computer can transform into assembly instruction sets.\n\nFirst, the computer goes through a _"lexer."_ **The lexer is what turns individual characters into collections of characters called _"tokens."_** These tokens can either be a single character or a collection of characters. Both the lexer and the token identifiers are programmed into the language compiler. Taking the code snippet, we can see that 5 tokens are generated:\n\n![](./lexer_1.svg)\n\n> These lexer demos are a general approximation of how a lexer might work. This particular example isn\'t based on any specific JavaScript lexer\n\nWhile these tokens\' collective functions may seem obvious to you and me, the computer does not yet understand that we want to assign a variable, despite the "ASSIGN" name of the `=` token. **At this stage of tokenization, syntax errors do not exist yet, code logic does not exist yet**, simply characters and tokens.\n\nWhat do I mean by that? Let\'s take the following intentionally incorrect example:\n\n```javascript\nconst magicNumber = = 185;\n```\n\nTo a developer, this is obviously a syntax error. However, the lexer is not in charge of finding syntax errors, simply assigning tokens to the characters it\'s been taught to recognize. As such, running the above through a lexer would likely yield us something like this:\n\n![](./lexer_2.svg)\n\nIt\'s not until later (with the parser) that the computer recognizes that there is a syntax error, at which point it will throw an error:\n\n```\nUncaught SyntaxError: Unexpected token \'=\'\n```\n\nNotice how it reports "Unexpected token"? That\'s because the lexer is converting that symbol into a token before the parser recognizes that it\'s an invalid syntax.\n\n## The Parser {#parser} \n\nNow that we\'ve loosely touched on the parser at the end of the last section let\'s talk more about it!\n\nAfter the lexer has converted the code into a series of tokens (complete with metadata about the tokens, like the line number and column start/end), the parser is ready to convert the tokens into a tree for further computing.\n\n> A tree is a kind of memory structure that represents a hierarchy of information related to one another. While [we touched on this concept in our "Understanding the DOM" article](/posts/understanding-the-dom/), here\'s a quick chart from that article to show an example tree:\n>\n> ![](../understanding-the-dom/dom_tree.svg)\n>\n> Once a set of data is turned into a tree, the computer knows how to "walk" through this tree and utilize the data (and metadata of their relationships) to take actions. In this case, the tree that is created by the parser is traversed to compile the code into instruction sets.\n\n\nOnce the tokenized code is ran through the parser, we\'re left with the "syntax tree" of the code in question. For example, when run through Babel\'s parser (A JavaScript parser that\'s written itself in JavaScript), we\'re left with something like the following:\n\n![](./parser_1.svg)\n\nWhile the above chart represents the code in a flat manner, it\'s anything but:\n\n![](./ast_1.svg)\n\nAs you can see, there\'s a top-down view of the AST for the expected code. However, that\'s not all I\'m able to provide. Because Babel\'s parser is implemented in JavaScript itself, I\'m able to show the AST in the shape of a JavaScript object:\n\n```javascript\n{\n  type: "File",\n  program: {\n    type: "Program",\n    body: [\n      {\n        type: "VariableDeclaration",\n        declarations: [\n          {\n            type: "VariableDeclarator",\n            id: {\n              type: "Identifier",\n              name: "magicNumber",\n            },\n            init: {\n              type: "NumericLiteral",\n              value: 185,\n            },\n          },\n        ],\n        kind: "const",\n      },\n    ],\n  },\n};\n```\n\n> This is not the exact output of the Babel Parser. There is a great deal more metadata that has been stripped for the sake of simplicity\n\nThis showcases how much metadata is stored during the parsing process. Everything from operator order to variable naming is stored during this process. Because of this, the conversion to instructions is made possible.\n\nWhether you\'re using a compiled language or a runtime language, you\'re using an A.S.T. at some point in using the language.\n\n## Why Not English? {#english-vs-ast}\n\nAn A.S.T. seems like it\'s a lot of work just to convert code into other code. Wouldn\'t it make development simpler if we were to cut out the middle-man and build computers that can understand English (or some other human native tongue)?\n\nWhile this may seem like a logical progression of tech, there are some extreme limitations with the idea that prevent it from being executed in practice.\n\nLet\'s start with the biggest problem that even humans face when communicating with language: Ambiguity.\n\nTake the following sentence:\n\n> "I wonder what time it will happen."\n\nThis sentence is complete but lacks the proper context required to fully understand what the sentence is saying. This would cause massive problems when trying to convert our language to operable instructions. This is exacerbated by homonyms like "fish" that change meaning depending on context:\n\n> "I fish for fishy fish."\n\nWhile humans have grown to parse this type of language, doing so for computers is an extreme challenge. This is because of both the massive amounts of complexity in the English language and the looseness of the rules that apply to the language. While computer programming languages are more strict, they contain their own grammar; this grammar simply fits computers better than our native tongues.\n\nI\'ll make my point by presenting you an extremely confusing grammatically correct sentence:\n\n>  ["Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo."](https://simple.wikipedia.org/wiki/Buffalo_buffalo_Buffalo_buffalo_buffalo_buffalo_Buffalo_buffalo)\n\nYes, that\'s a complete and valid English sentence. Have fun writing a parser for that one.\n\n### The Future {#AI}\n\nWhile writing a parser for the English language is near-impossible to do perfectly, there is some hope for using English in the programming sphere in the future. This hope comes in the form of AI, natural language processing. \n\nAI has been used for years to help computers understand our language. If you\'ve ever used a Google Home, Amazon Alexa, or Apple\'s Siri, you\'ve utilized an AI that tries its best to parse your language into instructions pre-determined by the parent company\'s developers.\n\nLikewise, there are projects such as [OpenAPI\'s GPT-3.0](https://beta.openai.com/) that make some moonshot ideas closer to reality. \n\nSome folks have even been able to write [React code using GPT-3.0](https://twitter.com/sharifshameem/status/1284807152603820032).\n\nOnly time travelers will know precisely how AI will play out with using English for our programming in the future, but there are many obstacles to overcome before it becomes the norm.\n\n# Conclusion {#conclusion}\n\nWhile computers can be incredibly complex, most of their foundation can be understood. We\'ve touched on a lot in this article: a bit about hardware, some language design, even some linguistical parsing! This is both the blessing and the curse when it comes to a field as large as computer science: there are so many avenues to go down. If the path you\'re looking for is more in-depth explanations of how languages are parsed and understood by the computer, be sure to sign up for our newsletter down below! We\'re wanting to write an article explaining what "grammars" languages can follow.\n\nIf you have any questions about the article or CS in general, drop a comment down below or [join our community Discord](https://discord.gg/FMcvc6T).\n',
		},
		{
			title: "How to ask better questions",
			description:
				"We all ask questions from time to time, so here are some of my favourite tips when it comes to how to improve the quality of your questions.",
			published: "2022-07-20T20:10:03.000Z",
			authors: ["alexchadwick"],
			tags: ["opinion"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "how-to-ask-good-questions",
			locale: "en",
			authorsMeta: [
				{
					id: "alexchadwick",
					name: "Alex Chadwick",
					firstName: "Alex",
					lastName: "Chadwick",
					description:
						"I'm a full-stack web developer in the UK (but born in sunny Spain!) \n I spend too much time reading articles on clean code and not enough refactoring 🤣",
					socials: {
						twitch: "alexchadwicc",
						twitter: "TheAlexChadwick",
						github: "AlexChadwickP",
						linkedin: "alexchadwickp",
						website: "https://alexchadwick.com",
					},
					pronouns: "he",
					profileImg: "./alexchadwick.jpg",
					color: "",
					roles: ["author", "translator"],
					profileImgMeta: {
						height: 2316,
						width: 2315,
						relativePath: "./alexchadwick.jpg",
						relativeServerPath: "/content/data/alexchadwick.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\alexchadwick.jpg",
					},
					rolesMeta: [
						{ id: "author", prettyname: "Author" },
						{ id: "translator", prettyname: "Translator" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "How to ask better questions",
				description:
					"We all ask questions from time to time, so here are some of my favourite tips when it comes to how to improve the quality of your questions.",
				published: "2022-07-20T20:10:03.000Z",
				authors: ["alexchadwick"],
				tags: ["opinion"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\n\n## Introduction\n\nIn this day and age, the programming ecosystem has become so rich and complex that asking questions is inevitable for any developer, regardless of what stage of their career they find themselves in.\n\nHowever, it is not always easy to ask a question, and often you'll see StackOverflow questions being downvoted or taken down because of a sense of confusion around the question itself.\n\nAsking the best possible questions is essential to getting help quickly, as whoever is reading your question will have immediate access to most of the information they need to come up with an answer that could potentially answer your doubts.\n\nSo in this article, I wanted to cover the basics on how to improve your questions, in order to get good answers.\n\nNote: Most of these concepts could also apply to opening issues on OSS projects, or to give feedback to different pieces of software\n\n## Define the exact problem you're facing\n\nNow whilst this sounds simple, there are many people who struggle to define their problem. If you're not able to identify the problem you've got, how do you expect other people to be able to identify it for you?\n\nThe most basic way to define your problem is to explain what the expected behaviour is, and what the actual behaviour is. For example:\n\n> *I've written a function `sum` that is meant to return the sum of 2 numbers. When I do `sum(1, 1);` I'm expecting it to return 2, however it's returning 1.*\n\nNow whoever is reading my question knows what I'm trying to achieve and what is currently happening.\n\nI see a lot of questions where people describe their expected behaviour but omit their current behaviour, or the other way around.\n\nAlso, feel free to share screenshots if whatever you're working on has graphics, however, **always try to avoid using screenshots for code, output, or errors that may display on the command line**. Most people prefer that you copy and paste them instead, as it ensures it remains accessible for people with disabilities and translatable for people that speak different languages. Only use images when you need to if possible.\n\n## Share your problematic code\n\nIf you can pinpoint the problematic code, then it's important that you share it. If it's too large to share directly, introduce a link to a pastebin or github repository and explain what you're linking to so people know where to find your code. Remember not to link your entire repository as people don't have the time to be searching through your code to find the problem.\n\nIn my previous example I would do the following:\n\n> *This is where `sum` is defined and how I'm calling `sum`:*\n> \n> ```javascript\n> function sum(a, b) {\n>     return a * b;\n> }\n> \n> \n> const result = sum(1, 1); // result == 1?\n> ```\n\nIt also helps to introduce some comments if you don't have them already. These can add notes, explain a complex piece of code, or describe a function that is defined elsewhere.\n\n## Share what you have tried\n\nJust to save everyone some time, and also get a better understanding of the entire problem, share what you have already tried. If you haven't tried anything yet, try googling for similar problems, and at least attempt to brainstorm a solution. Do your best to try something before asking someone else.\n\nSharing what you've tried helps people to rule out anything you've already tried and they can concentrate on thinking of another solution that might work. Following my basic example:\n\n> *I've also tried to pass in 2 and 2 and that seemed to work, but then if I passed in 3 and 2 I would get 6.*\n> \n> \n> \n> *Finally I've tried to do sum like the following but that also didn't work:*\n> \n> ```javascript\n> function sum(a, b) {\n>     return b * a;\n> }\n> ```\n\n\n\n## Other tips for asking questions\n\nThose are the main tips that are applicable to any programming question, regardless of  where / when you're asking the question. But there are other tips that may apply to more specific situations that I want to talk about in this section:\n\n* ###### Choose the right time and the right person\n  Are you asking someone at work or in your household? Firstly make sure that it's a good time for them. If they're busy working away then you might want to try to find a different time to ask your question.\n\n* ###### Do some research\n  Are there any terms you're unsure of that are relevant to your question? Look around first and make sure *you* know the entire problem before expecting other people to.\n\n* ###### If something's not clear then ask about it\n  It's easy to feel bad when someone explains something to you and you still don't fully understand and need to ask again. There is no shame in asking someone to be clearer as long as you're being respectful about it. They're already helping you which means they're probably happy to give away some of their time to help you out!\n\n* ###### Be understanding of other people's time\n  Most clearly defined questions can be solved in 15 minutes or less. If you find that a problem is taking longer than that, or you notice the person helping you is taking longer to reply, it's okay to ask for continued help for another time! You could simply ask them when is a more convenient time for you two to have another go at it? Something like:\n  \n  > *\"This is taking more time than it thought it would, is it OK if I asked you if we could give it another go maybe when you've got a bit more time?\"*\n  \n  Most times people will be happy to!\n\n* ###### Finally, asking \"bad\" questions from time to time is fine\n  Don't feel bad if you've asked a question that you're worried is low quality. It's easy to forget that sometimes Google exists and you ask a coworker something that could've been answered faster by the internet! Similarly, don't lash out when someone asks you a bad question. Instead, kindly teach them how to ask better questions for future reference!\n\n## Conclusion\n\nAsking questions is easy, and asking *good questions* can also be easy if you follow the general rules described in this article. But most importantly of all, remember that people answering your questions are often giving up their time for you, so don't forget to be polite, grateful and happy that they're giving you a helping hand.\n\nSimilarly, if you're answering a question, make sure to always be polite as well! It only takes a couple people to answer a question rudely or patronisingly to put someone off asking questions and clearing their doubts. We were all beginners once, and many of us still are!\n\nThanks for the time you've dedicated to reading this article, I really appreciate it. Have a good one!\n\n\n",
		},
		{
			title: "How to get started with .NET",
			description:
				"Did you know that 35% of developers are using .NET? This is a great article to read to get started with .NET.",
			published: "2022-01-18T19:20:19.000Z",
			authors: ["bobrossrtx"],
			tags: ["dotnet", "csharp"],
			attached: [],
			license: {
				id: "cc-by-4",
				footerImg: "https://i.creativecommons.org/l/by/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by/4.0/",
				name: "Attribution 4.0 International (CC BY 4.0)",
				displayName: "Creative Commons Attribution 4.0 International License",
			},
			originalLink:
				"https://dev.to/bobrossrtx/how-to-get-started-with-net-50bh",
			slug: "how-to-get-started-with-net",
			locale: "en",
			authorsMeta: [
				{
					id: "bobrossrtx",
					name: "Bobrossrtx",
					firstName: "Owen",
					lastName: "Boreham",
					description:
						"I have over 1000 years of software development experience, do not underestimate me!",
					socials: {
						twitter: "bobrossrtx",
						github: "bobrossrtx",
						website: "https://www.owenboreham.tech",
					},
					pronouns: "he",
					profileImg: "./bobrossrtx.jpg",
					color: "#b7e11e",
					roles: ["developer", "author"],
					profileImgMeta: {
						height: 2316,
						width: 2316,
						relativePath: "./bobrossrtx.jpg",
						relativeServerPath: "/content/data/bobrossrtx.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\bobrossrtx.jpg",
					},
					rolesMeta: [
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "How to get started with .NET",
				description:
					"Did you know that 35% of developers are using .NET? This is a great article to read to get started with .NET.",
				published: "2022-01-18T19:20:19.000Z",
				authors: ["bobrossrtx"],
				tags: ["dotnet", "csharp"],
				attached: [],
				license: "cc-by-4",
				originalLink:
					"https://dev.to/bobrossrtx/how-to-get-started-with-net-50bh",
			},
			contentMeta:
				'\nI am very new to blogging, so I thought I would write a little bit about myself. I am a software developer, programming since October 2020.\nI have worked on a number of projects, ranging from small to large scale, and I have been working on a number of different languages.\nThe reason I am writing this blog is to share my experiences with the .NET platform, and how you can get started with it too!\n\nI\'m not a professional programmer, I just like to write code and learn new things. The approach I took to learning to code was average,\nI had been playing with HTML and CSS, then I moved to JavaScript, then I started playing with React. I have learned a lot of things since then,\nranging from Low level programming in C to modern JavaScript, to the latest frameworks like React. I had always struggled to get started with .NET and\nC#. It had always felt like a daunting task, mainly because I had never worked with C# before, and the people I have seen using it were amazing.\n\nAfter I finally decided to learn C#, I was able to get started with it. I was able to write a simple program in Visual Studio, and I was able to\nget it to run. I felt a great sense of accomplishment, but also disappointment, I was thinking about how I could have done better, started earlier.\nIt was no different to learning another language, like Python, JavaScript, or even C. Now I am going to take you through the process of getting started with\n.NET.\n\n# How to get started with .NET\n\nFirst of, we are going to start with something extremely simple. We are going to create a simple Console Application. There is just one small, but important\nstep we must take before we can start writing code. Now unfortunately, if you use a Linux based system, you will need to install the .NET Core SDK, which can\nbe tedious. You can download the SDK from the following link: https://www.microsoft.com/net/core\n\nOn Windows or MacOS, you can install Visual Studio, which comes with the .NET Core SDK already installed. You can download Visual Studio from the following\nlink: https://visualstudio.microsoft.com/downloads\n\nThis article is directed at windows users, but you can also use Visual Studio on MacOS. If you are using Linux, you will need to use another IDE/Text Editor\nand the dotnet CLI. You can download the dotnet CLI from the following link: https://dotnet.microsoft.com/download\n\n# Creating a project\n\nIn Visual Studio, you can create a new project by clicking new->project. You can also create a new project by right clicking on the solution explorer, and\nthen clicking new->project. You will be prompted to select the type of project you want to create, pick the Console Application, and then you will be prompted\nto name the project, and choose the location where you want to save it. Once you have created the project, you will be able to start writing code.\n\nYou should be greeted with the following code:\n\n```csharp\nusing System;\n\nnamespace BoilerPlateConsoleApp\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            Console.WriteLine("Hello World!");\n        }\n    }\n}\n```\n\nThe code you see above is called boilerplate code. This is code that is automatically generated by Visual Studio when you create a new project. You can\nrun the project, and it will run the code you see above. The will then see "Hello World!" printed to the console. Good job! You have just created your\nfirst .NET project!\n\n# Writing Code\n\nI know what you are probably thinking, why haven\'t we written any code yet? Well, the answer is that we haven\'t needed to. First we need to decide what\nwe want out code to do. I will show you how to write a small program that will print a list of films. This will include the title, the year, and the director.\n\nWe will create a new class called Film, and then we will create a new method called `PrintFilmInfo` which will print the title, year, and director of the film.\nWe will also create a List of films, and then we will add a few films to the list.\n\nLets get started with writing code:\n\n```csharp\nusing System;\nusing System.Collections.Generic;\n\nnamespace BoilerPlateConsoleApp\n{\n    class Film\n    {\n        public string Title { get; set; }\n        public int Year { get; set; }\n        public string Director { get; set; }\n\n        public void PrintFilmInfo()\n        {\n            Console.WriteLine($"Title: {Title}");\n            Console.WriteLine($"Year: {Year}");\n            Console.WriteLine($"Director: {Director}");\n        }\n    }\n\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            List<Film> films = new List<Film>();\n            films.Add(new Film() { Title = "The Shawshank Redemption", Year = 1994, Director = "Frank Darabont" });\n            films.Add(new Film() { Title = "The GodFather Part II", Year = 1974, Director = "Francis Ford Coppola" });\n            films.Add(new Film() { Title = "The Dark Night", Year = 2008, Director = "Christopher Nolan" });\n\n            foreach (var film in films)\n            {\n                film.PrintFilmInfo();\n            }\n        }\n    }\n}\n```\n\nThis is the complete code for the film list. You can run the code to see the output. Might I also mention that I have used the `foreach` loop to print out\nthe films. This is a very common loop in C#, and it is very easy to use. You can use it to loop through a list of items, and then print out the items.\nThe `List<Film>` is a data structure that is used to store a list of items. The `Film` class is a class that we created to store information about a film.\nInside of the `Film` class, we have three properties, `Title`, `Year`, and `Director`. Properties are like variables, and they are used to store information.\n\nI\'m not going to go into nitty gritty details about what is going on here, as I expect you to be familiar with some of the concepts already. I really recommend\nreading up on the C# language, and reading the documentation, at https://docs.microsoft.com/dotnet/csharp to get a better understanding of what is going on here.\n\nI fully understand that dotnet can be a bit confusing at first, but I hope that this article will help you get started with .NET. I hope you enjoyed the article!\n\n# Contact\n\nIf you have any questions, comments, or concerns, feel free to contact me at https://www.owenboreham.tech/contact\n',
		},
		{
			title: "How to Interview Frontend Engineers",
			description:
				"Interviewing for frontend engineering positions can be difficult. Let's walk through some things you should focus on while interviewing.",
			published: "2021-05-28T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["interviewing", "web", "javascript"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/how-to-interview-frontend-engineers/",
			slug: "how-to-interview-frontend-engineers",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "How to Interview Frontend Engineers",
				description:
					"Interviewing for frontend engineering positions can be difficult. Let's walk through some things you should focus on while interviewing.",
				published: "2021-05-28T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["interviewing", "web", "javascript"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/how-to-interview-frontend-engineers/",
			},
			contentMeta:
				"\nInterviewing for frontend engineering positions can be difficult. There’s a lot to keep in mind for any interview, but frontend interviews always seem to have so many things to be cognizant of. \n\nWhile we’ve discussed [5 tips for tech recruiting](https://coderpad.io/blog/5-tips-for-tech-recruiting/), let’s take a look at some of the things we feel are more specific to a frontend technical screening.\n\n# JavaScript Baseline\n\nWhether you’re using a JavaScript framework or simply adding logic to a vanilla JS website, good frontend candidates need to know some basics of JavaScript in order to create business logic.\n\nSome codebases may follow OOP principles while others will heavily utilize functional programming paradigms. Make sure you ask frontend candidates questions that are relevant to your project. If your app extensively utilizes classes in JavaScript, you might ask about prototype inheritance or focus on the `this` keyword. Likewise, if you’re primarily using functional coding, you might check if they’re familiar with functions-as-values - asking them to make generic functions that utilize callbacks or returned functions.\n\nRegardless of the code style you utilize, you may want to ask about JavaScript basics like variable scoping between `var`, `let`, or `const` and when each is appropriate. That said, try to avoid asking questions about niche specifics in a language. Unless you’re hiring for engineering work on a JavaScript runtime, your candidate doesn’t need to know the engine level specifics of things like “[Temporal Dead Zone](https://2ality.com/2015/10/why-tdz.html)”. \n\nLikewise, “gotcha” questions specifically designed to be confusing or obtuse are unhelpful in gauging real-world problem-solving in any technical interview.\n\n# Design Focus\n\nAs a frontend engineer, being able to build an app to match designs is important. If your interview process includes a design for your candidate to build, check to see how consistent their implementation is to your design. While minor changes in element sizing can be easily glossed over, they can impact a user’s view of the product. Ideally, you want to include a way to analyze the provided design for the engineer to check the values of padding and other measurements. Oftentimes in technical interviews, the only provided design is a screenshot - having to guess-and-check the pixel values proves a frustrating candidate experience.\n\nIf your exercise doesn’t include a design to utilize, I wouldn’t evaluate their skills based on the UX or UI. Unless the role you’re hiring for is a mixture of designer and engineering, keep in mind - engineers don’t necessarily need to have design skills.\n\n## Different Screens\n\nWith mobile devices becoming more and more predominant in today’s society, it’s important to know that your candidate can scale the application’s UI to non-desktop devices. Even if a design isn’t provided, ask your candidate to include a view for smaller screens as well.\n\n\nWhile JavaScript is more than able to conditionally render logic based on screen size, it’s suggested to utilize CSS’s media queries whenever possible. This allows your app to adjust to various-sized screens (and often helps with SEO).\n\n# Frameworks\n\nMost modern frontend applications are written with a framework like React or Vue. Luckily for engineers looking to switch roles, the core concepts of many of these frameworks are similar in nature.\n\nYou may want lead engineer or senior developer candidates to have in-depth knowledge of the specific framework you're utilizing to help other team members. For example, understanding `useMemo` or `useCallback` in React can be critical for ensuring your app has high performance. However, mid or entry-level developers can usually learn the framework's specifics on the job if they have a strong foundation of the core concepts from other experience.\n\nBecause of this, there are some things you can ask of a candidate that may have had more experience in a different frameworks.\n\n## Lifecycles\n\nEven frameworks that have recently moved away from highlighting lifecycle methods (such as React with Hooks), most frameworks have some concept of a lifecycle. Being able to have a candidate explain when and why a component will do its initial data capture, re-render, and un-render can help accentuate their core framework knowledge.\n\n## Unidirectionality\n\nWhile frameworks like Vue or Angular allow you to bubble events up from a child component to a parent, it’s generally accepted that keeping your application architecture unidirectional is the best practice. We’ve [written a bit about what that means in practice](https://coderpad.io/blog/master-react-unidirectional-data-flow/), but it’s something to be cognizant of when evaluating a candidate’s code submission.\n\n# Empathy\n\nA major part of collaborating within a team effectively is a candidate’s empathy for others. Remember, engineering often utilizes significantly more interpersonal skills than most give credit. It’s important that your engineers are able to communicate with one another effectively. Great engineers will even consider users in their daily work and raise concerns or thoughts when they see something that misaligns with the user’s experience in your app.\n\n## Accessibility\n\nPart of a front-end engineer’s role is to make sure that the application they’re building is usable by all users. Making sure that users with screen-readers, color blindness, or other impairments are able to use your application as easily as other users is important. \n\nThis could mean bringing up problems with color contrasts in a provided design, making sure that the candidate is using semantic HTML, or even that they’re utilizing the right `aria` attributes. Don’t forget that CSS can impact screen-reader support through properties like flexbox’s “[order](https://developer.mozilla.org/en-US/docs/Web/CSS/order)”\n\n## Documentation\n\nEmpathy isn’t just something that should be expressed to users. After all, communication within a team is extremely important and much more frequent. One way that communication can be increased within a codebase is documentation. While many tend to think of documentation as dedicated docs pages shared with engineers, documentation can take many forms.\n\nFor example, code comments that explain how a particular bit of code can be a form of documentation. If you’re using a typed programming language like TypeScript in an interview, maybe explicit typings can be a form of documentation. Both of these can be demonstrated through a representative [Take-Home](https://coderpad.io/blog/hire-better-faster-and-in-a-more-human-way-with-take-homes/). Maybe the candidate is able to provide comments to a particularly confusing bit of code or add typing interfaces where `unknown` or `any` might’ve otherwise sufficed.\n\n\nIn other scenarios, creating example projects that showcase component’s design can help be a bridge of communication between designers, engineers, and product managers. You can help encourage candidates to add a development route that acts as a showcase of their UI components.\n\n# Ignore Style Differences\n\nWhile most of this article has been focused on things ***to\\*** do and look for in an interview, let’s look at something that shouldn’t be focused on: code style. While there are certainly instances where `for` loops make more sense than `forEach`, or `function() {}` declarations are required instead of `() => {}` functions, most of the time they shouldn’t be taken as a positive or negative indicator of code quality. Some engineers might prefer newer syntaxes such as object destructuring but other engineers might have experience prior to the introduction of those syntax introductions.\n\nThere are exceptions to this - using a single `for` loop may be more performant than multiple. Maybe code maintenance and readability is more important than performance for parts of your application.\n\nRegardless of code preferences, make sure to communicate expectations with your candidate ahead of time. There’s nothing worse than shifting goalposts when working on a project - especially during an interview\n\n# Conclusion\n\nWhile we feel that these points provide a good baseline of evaluation for technical screenings, interviews are dynamic and change from company to company. What are the things you look for during a frontend interview? Let us know [on Twitter](https://twitter.com/coderpad) or [on our community Slack](https://bit.ly/coderpad-slack) - we’d love to see you there!\n",
		},
		{
			title: "How to Pick Tech Stacks For New Projects",
			description:
				'I often get asked "How do you pick a tech stack for your projects?". The answer is: outline what questions you should be asking early on.',
			published: "2020-03-02T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["opinion"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "how-to-pick-tech-stacks-for-new-projects",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "How to Pick Tech Stacks For New Projects",
				description:
					'I often get asked "How do you pick a tech stack for your projects?". The answer is: outline what questions you should be asking early on.',
				published: "2020-03-02T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["opinion"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nI talk to engineers; I talk to a lot of engineers. I've spoken to engineers from various backgrounds and various skillsets. We all have had to face the same thing at some point: \"What tools do you pick for the job?\". It's a question that was phrased perfectly by [Lindsay Campbell](https://www.linkedin.com/in/lindsaycampbelldeveloper/) on [the public Unicorn Utterances Discord server our community use to chat](https://discord.gg/FMcvc6T):\n\n_\"When you start a new project, how do you go about planning it? How do you know what features you want? How do you even start do you figure out frameworks, libraries you will use for those different features? What do you do to also make sure that all the different technologies you will be using will work together nicely in your application? Thanks!\"_\n\n> Side note, Lindsay is an excellent engineer. You should [check out her profile](https://www.linkedin.com/in/lindsaycampbelldeveloper/) and give her a follow\n\nThe answer is ironically a lot less about the solution to a given problem as much as it is discovering the root of the problem itself.\n\nFor example, let's look at a project I've been debating on spinning up with a few folks:\n\nAn online-first Bootcamp system with interactive quizzes, live-streamed content (like video sessions), a large set of hosted video, and other education-related features.\n\nThe first thing I do, _before looking at any tech whatsoever is think about it from a business perspective_.\n\n- \"Who is this for?\"\n- \"What do they want?\"\n- \"What's most important to have done first?\"\n- \"What are my stretch goals/holistic vision/defining drive?\"\n- \"What is the profit model?\" (if that matters to that project)\n- \"What's my budget?\" (_Budget means more than just finances_, if you're talking about a side project, the budget is the time you have to work on the project).\n\nThese are all of the questions I layout before even thinking about coding. I first start by white-boarding these things, explaining them to both myself and my partners, and generally doing my due-diligence concerning project planning.\n\n# Wholistic Vision {#whats-your-vision}\n\nMy holistic vision would consist of:\n\n- Simple-to-use UI\n\n- Lots of full-filled content, such as video courses or pictures to serve alongside their written content\n\n- A single place to host a course for someone\n- An independent creator feeling comfortable enough to host content here without having to make their landing page in a separate service. As such, we'll need to provide a lightweight customization of a page to showcase their own brand/course.\n- Focus on groups rather than single courses. Subscribing to a single content group/creator rather than \"React course #1\" which has no clear distinction from another \"React course #1\"\n\nWhile the first point doesn't inform us of much at this early stage (we'll touch on UI tooling selection later), we can glean from the second point that we'll have to maintain some kind of storage layer. This will be something we'll need to keep in mind as we structure our goals.\n\n# Target Audience {#who-are-you-targetting}\n\nIn this case, the groups of people I would want to appeal to are:\n\n- Students looking for a place to learn remotely\n- Independent teachers looking for a unified platform to publish through\n- Bootcamps looking to have an organized, content-focused site to host their courses\n\nThis potentially broad appeal might be able to drive a lot of business, but without a focused plan and a solid profit model, the project would fall flat.\n\n# Profit Model {#layout-your-profit-model}\n\nWe'd plan to drive revenue by using the following profit model:\n\n- We'd focus on a B2B type solution where you could pay for a pro account that would make promoting your courses and stuff to other students easier.\n- No students would pay for accounts but might pay for a subscription to course content\n- We'd likely take a cut of the subscription or charge for course features in some way\n\n# Budget {#define-your-budget}\n\nFinally, none of this can be done without resources. These resources should be budgeted upfront, so what have we got? We have:\n\n- Myself, maybe a few other folks local to my area working on this project\n- This project would be a second job or side project for all of us\n- Additionally, I'd be working on this project on top of working on other UU content and other side projects\n\nOur limited budget tells us that we will have to be hyper-focused when it comes time to planning out our MVP. We'll need to keep our goals well defined, and if we intend to make it profitable, we'll need to _keep those goals closely aligned with our profit model's requirements define_.\n\nNow that we have a more precise goal of what the problem space we're entering is, we can more clearly define our goals (next part)\n\n# Goals {#mvp}\n\nNow that we're onto setting goals, I like to start thinking about \"What is the bare minimum we need to show this to someone to spark a conversation.\" _This is often called the \"minimum viable product\" or \"MVP\" for short_.\n\nLooking at what we need to do from the previous section, I can say that we could probably get away with the following to reach that \"MVP\":\n\n- User account creation. We'll keep only one type of user for now, but we do need to be aware that users will have different permission roles in the future\n\n- Organizations creation/viewing (we can manually assign users to organizations using the database for now, but we'll want to structure data to support many users per organization)\n\n- This org will need courses, so creation/view of those (no need to manage permissions, that'd be a future feature)\n\n- Courses will need content, so a way to upload/view content on courses\n\nWhile thinking about these features, I want to keep the implementation details to a minimum, just enough to suffice with our resources by ignoring the nuances of certain permission features. However, notice how, despite thinking about the features minimally, *I'm also mentally mapping how the data should be structured and thinking about long-term implications* in such a way that we can add them later without refactoring everything. This balance during architecture can be tough to achieve and becomes more and more natural with experience.\n\n# Requirements {#data-requirements}\n\nFinally, I look at the data requirements and features and start thinking about what code requirements I'll run into to implement those data requirements.\n\n- I need to upload/download files\n\n  Speaking from experience, doing this with GraphQL is tricky, so I'll stick with REST for the MVP\n\n- My data isn't likely to change structure very much\n\n\tAs a result, I'd feel comfortable using SQL for something like this.\n\n- I need user authentication\n\n\tI don't like rolling my own auth solution, so I'll probably use [passport](https://www.npmjs.com/package/passport) since it's been well tested and stable. If I want to enable users to sign in from their Google accounts or something in the future, I should keep that in mind even if I'm not building that functionality right away\n\n- I am going to be focusing on per-user UI (achievements, dashboards, etc.)\n\n\tAs such, my use of something like [Gatsby](https://www.gatsbyjs.org/) for static site generation (SSG) isn't realistically beneficial. We could go with server-side rendering (SSR) with something like [Next.JS](https://nextjs.org/), but due to using a lot of media (video/picture), I'd argue there's not much of a return-on-investment (ROI) by building SSR-first since the content has to be loaded by the DOM regardless.\n\n- I'm not likely to have many forms in my application - primarily focusing on viewing rather than form creation\n\n\tSometimes it's important to know what an application is and _isn't_ going to be using. If we were highly focused on forms, I might advocate for [Angular](https://angular.io/) to be used in the front-end (since I have found their form system to be quite robust). However, since I know my team is not as familiar with Angular as other options and we have a limited budget, we likely won't be moving forward with it\n\n- However, we'll be hoping to have a lot of live-streamed user content in the future\n\n\tStuff like \"live quizzes,\" live streaming/playback of video, anything that requires tracking of time/etc is all a great use case for event-based programming. One of the most prominent implementations of this in JavaScript is [RxJS](https://github.com/ReactiveX/rxjs).\n\nSo there we have it - a non-Angular, REST API, Passport authenticated, SQL DB, non-SSR, RxJS powered application\n\nNow, this doesn't give us the whole idea, but from here we can start doing further research (next part)\n\n# Extra Pieces\n\nFrom here, things start becoming a lot more subjective and a lot more social.\n\nWhile I personally prefer Vue, after talking with my team, it became clear that they're much more comfortable with React. Because React has a large ecosystem with a sturdy backing, I'm not against using it since I feel it can sustain our product's growth over time.\n\nMoving onto CSS was more of the same: It was less \"what can support this specific use-case\" and more \"what is familiar and can sustain our growth?\".  \n\nThis example is where things get really tricky because you often are not just picking a framework or library, but often a philosophy of CSS as well. After a long-form discussion with my (front-end focused) team about this, we decided to go with Styled Components and Material UI. These tools were decided on due to their flexibility, general A11Y support (for MUI), themability, and our comfort with the tools. The size and stability also took a role in this discussion.\n\nSmaller decisions of libraries for me often boil down to a formula-of-sorts:\n\n- What's their community support like? (can I ask a question and have an answer within a few days)\n- What's the size of their community? (typically judged by questions I can find on StackOverflow, their community site/forum or even npm downloads)\n- How stable is the tool?\n- When was it last updated?\n- Does it handle my edge-cases?\n- What's the performance of the tool?\n\nEach tool and usage will weigh these questions differently. If I'm looking for a simple timer component library and come across two options, I may be more likely to pick a small library over a larger one, depending on the context. For example, _if that smaller library has clean, easily readable code, but only has seven stars on GitHub, that's likely better for my project than a more bloated alternative because I know I can maintain it if all else fails._ However, I personally wouldn't likely go with something like IO.js (now defunct alternative to Node.js) for a larger project regardless of how clean the code is because I'd be unable to maintain the much more complex tool if I ever needed to.\n\n# Conclusion\n\nTo recap, it's a mixture of:\n- Proper planning (focusing on features and experience rather than tech)\n    - This point should take double priority, as understanding what to start building after picking the tech is important\n- Expertise\n    I knew that SQL would suffice for our data thanks to my experience scaffolding various applications with SQL and NoSQL alike\n- Research\n    The only reason I knew that working with binary data over GQL is due to research I did ahead of time before even writing any product code\n- Communication\n    This one is often overlooked but is **critical** - especially within teams. _Leverage each other's strengths and weaknesses and be open and receptive to suggestions/concerns_\n\nThat's by **no** means an easy feat to do, despite reading as if they were. Don't worry if you're not able to execute these skills flawlessly - goodness knows I can't! I'm sure a lot of the decisions I made here, even with the group I spoke to, could have been better guided in different ways. These are the skills that I think I value the most in seniors developer, especially communication. _Communication becomes critical when working with medium/larger teams (or really, groups of any size) since reasonable minds may differ on toolsets that they might see strengths/weaknesses in_.\n\nHave a similar question to the one Lindsey asked? Like conversations like this? Have something to add? [Join us in our Discord server](https://discord.gg/FMcvc6T) to jump into the community and engage in conversations like this! We wouldn't have the quality of our content without our community! \n",
		},
		{
			title: "How to Upgrade to React 18",
			description:
				"React 18 introduces some awesome features that I'm sure you can't wait to try! Here's how you can get started with React 18 today!",
			published: "2022-01-07T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["react", "webdev"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink: "https://coderpad.io/blog/how-to-upgrade-to-react-18/",
			slug: "how-to-upgrade-to-react-18",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "How to Upgrade to React 18",
				description:
					"React 18 introduces some awesome features that I'm sure you can't wait to try! Here's how you can get started with React 18 today!",
				published: "2022-01-07T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["react", "webdev"],
				attached: [],
				license: "coderpad",
				originalLink: "https://coderpad.io/blog/how-to-upgrade-to-react-18/",
			},
			contentMeta:
				'\r\nReact 18 is the latest in a long line of major releases of React. With it you gain access to: [new features for Suspense](https://reactjs.org/docs/concurrent-mode-suspense.html), new [useId](https://github.com/reactwg/react-18/discussions/111), [useSyncExternalStore](https://github.com/reactwg/react-18/discussions/86), and [useDeferredValue](https://github.com/reactwg/react-18/discussions/100) hooks, as well as the new [startTransition](https://github.com/reactwg/react-18/discussions/100) API.\r\n\r\nWhile React 18 is not yet a stable release, testing out your application can be useful. \r\n\r\nLike with previous major releases of React, React 18 is a fairly easy migration for most apps.\r\n\r\nWhile [Strict Mode has received some changes](https://github.com/reactwg/react-18/discussions/19) that may impact your app, and [automatic batching](https://github.com/reactwg/react-18/discussions/21) may introduce some new edge cases, they only impact apps that don’t [follow the Rules of React properly](https://reactjs.org/docs/hooks-rules.html).\r\n\r\n\r\nOutside of those considerations, let’s upgrade!\r\n\r\n## Installation\r\n\r\nFirst, start by installing React 18:\r\n\r\n```\r\nnpm i react@18.0.0-rc.0 react-dom@18.0.0-rc.0\r\n```\r\n\r\nOr, if you use `yarn`:\r\n\r\n```\r\nyarn add react@18.0.0-rc.0 react-dom@18.0.0-rc.0\r\n```\r\n\r\nIf you’re using Create React App, you may also want to [upgrade to the newest v5](https://github.com/facebook/create-react-app/releases/tag/v5.0.0) as well using:\r\n\r\n```\r\nnpm i react-scripts@5\r\n```\r\n\r\nOr\r\n\r\n```\r\nyarn add react-scripts@5\r\n```\r\n\r\nThen, make sure to upgrade any dependencies that might rely on React.\r\n\r\nFor example, upgrade [React Redux to v8](https://github.com/reduxjs/react-redux/releases/tag/v8.0.0-beta.2) or [SWR to 1.1.0](https://github.com/vercel/swr/releases/tag/1.1.0)\r\n\r\n## Update `render` method\r\n\r\nAfter you install React 18, you may receive an error when your app is running:\r\n\r\n> Warning: ReactDOM.render is no longer supported in React 18. Use createRoot instead. Until you switch to the new API, your app will behave as if it\'s running React 17. Learn more:[ https://reactjs.org/link/switch-to-createroot](https://reactjs.org/link/switch-to-createroot)\r\n\r\nThis is because previously, in React 17 and before, you’d have a file - usually called `index.js` or `index.ts` - that included the following code:\r\n\r\n```\r\nconst rootElement = document.getElementById("root");\r\nReactDOM.render(<App />, rootElement);\r\n```\r\n\r\nWhile this code will continue to function for this release, it will not allow you to leverage most of the new features of React 18. Further, it’ll be removed in a future release of React.\r\n\r\nTo fix this issue, replace this code with the following:\r\n\r\n```\r\nconst rootElement = document.getElementById("root");\r\nReactDOM.createRoot(rootElement).render(\r\n  <App />\r\n);\r\n```\r\n\r\nWhen finished, you should be able to verify the version of React you’re using with `{React.version}`\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=200107" loading="lazy"></iframe>\r\n\r\n## Conclusion\r\n\r\nAs promised, the update to React 18 is fairly straightforward! Most applications should be able to upgrade without too many problems. \r\n\r\nIf you run into issues during your migration and you’re using `StrictMode`, try temporarily removing it to see if you run into any issues. [React 18 introduced some changes that may impact some apps.](https://github.com/reactwg/react-18/discussions/19)\r\n\r\nWe hope you enjoy the new [React concurrent features](https://github.com/reactwg/react-18/discussions/4) and happy hacking!\r\n',
		},
		{
			title: "WebDev 101: How to use npm and Yarn",
			description:
				"You've heard a lot about Node, NPM, and Yarn - but aren't sure what they are. Let's introduce them in-depth and answer questions about them!",
			published: "2021-04-05T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["webdev", "javascript", "node"],
			attached: [],
			license: {
				id: "cc-by-4",
				footerImg: "https://i.creativecommons.org/l/by/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by/4.0/",
				name: "Attribution 4.0 International (CC BY 4.0)",
				displayName: "Creative Commons Attribution 4.0 International License",
			},
			slug: "how-to-use-npm",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "WebDev 101: How to use npm and Yarn",
				description:
					"You've heard a lot about Node, NPM, and Yarn - but aren't sure what they are. Let's introduce them in-depth and answer questions about them!",
				published: "2021-04-05T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["webdev", "javascript", "node"],
				attached: [],
				license: "cc-by-4",
			},
			contentMeta:
				'\nIf you\'re new to web development, it can be difficult to figure out when (and how) to use the package manager most commonly used to install app dependencies and utilities: `npm`. Likewise, if you\'ve looked into projects that are already established, you may find yourself looking at instructions to use `yarn`.\n\nIn this article, we\'ll outline what Node and npm are, how to use both `npm` and `yarn` to install dependencies for your project, and point out some "gotcha\'s" that are good to keep in mind while using them.\n\n# What\'s Node and `npm`, anyway? {#what-are-they}\n\nIf you\'re new to web development - well, firstly, welcome! - you may wonder what Node and `npm` are. Great questions!\n\n## Node {#whats-node}\n\nLet\'s start with Node. Node is a [JavaScript runtime](/posts/how-computers-speak/#compiled-vs-runtime) that allows you to run JavaScript code on your machine without having to run your JavaScript in a browser. This means that you can write JavaScript that interacts with your computer in ways your browser cannot. For example, you can host a REST web server from Node, write files to your hard drive, interact with operating system APIs (like notifications), and more!\n\n> You can [learn more about what a runtime is and how they work from our article that introduces the concept](/posts/how-computers-speak/#compiled-vs-runtime)\n\nNode also comes with an advantage over browsers for running JavaScript: you can interface with lower-level programming languages such as C via [Node\'s N-API](https://nodejs.org/api/n-api.html#n_api_node_api). This means that libraries you rely on can build on top of this N-API to provide a way to do things like send native desktop notifications, show something particular in your taskbar, or any other action that would require lower-level access to your local machine than JavaScript typically provides.\n\n## `npm` {#whats-npm}\n\nAny sufficiently useful programming language needs an ecosystem to rely on. One of the primary elements for an ecosystem is a collection of libraries that you can use to build out your own libraries and applications.\n\n> A library is a snippet of code that other people have written that you can easily import into your own code and use yourself - often with a single line of code\n\n`npm` is a combination of two things:\n\n1) The registry - the servers and databases that host the packages with their specific named packages. \n2) The client-side CLI utility - the program that runs on your computer in order to install and manage the packages on your local disk\n\nWhen, say, Facebook wants to publish a new version of `react`, someone from the React team (with publishing credentials) will setup and build the production version of the React source code, open the client-side utility in order to run the command `npm publish`, which will send the production code to the registry. From there, when you install `react` using the `npm` command on your device, it will pull the relevant files from the registry onto your local machine for you to use.\n\nWhile the registry is vital for the usage of the CLI utility, most of the time we say `npm` in this article, we\'re referring to the CLI tool. We\'ll make sure to be explicit when talking about the registry itself\n\n# Setting Up Node {#setup-node}\n\nBefore we explain how to install Node, let\'s explain something about the release process of the software. \n\nWhen it comes to install options there are two: \n\n1) LTS\n\n2) Current\n\nThe "LTS" release stands for "long-term support" and is considered the most "stable" release that is recommended for production usage. This is because LTS releases will receive critical bug fixes and improvements even after a new version comes along. LTS releases often see years of support.\n\nThe "current" release, on the other hand, usually sees new features of JavaScript implemented that may not be present in the LTS release. This is often used to experiment and tests new features and functionality before the next LTS release.\n\nNodeJS switches back and forth between LTS and non-LTS stable releases. For example, Node 12 and 14 were LTS releases, but Node 13 and 15 were not. You can [read more about their release cycle on their website](https://nodejs.org/en/about/releases/)\n\n## Installing Node {#installing-node}\n\nYou can find pre-built binaries ready-to-install from [NodeJS\' website](https://nodejs.org/en/download/). Simply download the package you want and install it. \n\n> If you\'re unsure which version of Node to go with, stick to the LTS release\n\nNode installs come pre-packaged with their own version of `npm`, so don\'t worry about having to install that seperately.\n\nHowever, the process of upgrading and changing version of NodeJS can be difficult. This is why I (and many others) recommend using NVM to manage your Node versions.\n\n### NVM {#nvm}\n\nWhile Node has a fairly stable API (and their LTS releases are often supported for many years at a time), there may be instances where it\'s benificial to have the ability to quickly upgrade and change the currently installed Node versions.\n\nFor example, some webdev projects only work on specific versions of Node, while other times specific JavaScript features are only available on new versions of Node.\n\nWindows, macOS, and Linux all have versions of a program called `nvm`, which allows you to change the installed version of node based on a single CLI command:\n\n```\nnvm use --lts\n```\n\nAdditionally, you can (and, in order to use `nvm`, **must** use `nvm` to do so) install new versions of node using `nvm` . To do this, simply type:\n\n```\nnvm install --lts\n```\n\n#### Switching Node Versions {#nvm-switch-node-ver}\n\nNVM is a useful tool to switch Node versions, but there is something that should be noted before you do so. When you switch Node versions, it also resets the globally installed packages. This means that if you ran:\n\n```\nnpm i -g create-react-app\n```\n\nOn Node 12, when you switch to Node 14, and attempt to run a `create-react-app` command, you\'ll find yourself with a "cannot find that package" message.\n\nIt\'s also worth noting that some packages (like `sass`) have native dependencies. This means that they need to run specific commands on install depending on the version of Node you have installed. Because of this, if you switch from Node 12 to Node 14, you may need to re-run `npm i` on your packages before you attempt to re-run your applications.\n\n#### Windows NVM {#windows-nvm}\n\nIt\'s worth noting that the Windows variant of `nvm` does not support the same commands as the macOS and Linux variants. As such, when you find instructions for `nvm` online, you may have to find the alternative versions of those commands for the Windows version\n\nFor example, the previously mentioned `lts` command does not work on Windows. Instead, you\'ll have to lookup the newest LTS release of Node (from their website) and install it as such:\n\n```\nnvm install 12.16.3\n```\n\nThen, simply declare it as your main version of node:\n\n```\nnvm use 12.16.3\n```\n\n### Upgrading NPM {#upgrading-npm}\n\nThe version of `npm` that\'s shipped with Node is typically good enough for 99.99% of use-cases. Like any other software, however, bug fixes and features are added to new versions of `npm`. You can follow [the official `npm` blog](https://blog.npmjs.org/) to read about new features and bug fixes the versions introduce.\n\nIronically enough, the method of upgrading `npm` is by using `npm` itself:\n\n```\nnpm i -g npm@latest\n```\n\n> Keep in mind that if you switch Node versions using `nvm`, you will need to re-run this command on every version of installed Node, as switching Node also switches the installed version of `npm`.\n\n## Yarn {#yarn}\n\n`npm` isn\'t the only game in town when it comes to installing packages for use in webdev. One of the biggest alternatives to `npm` is the `yarn` package manager.\n\nYarn does not host it\'s own registry. Because of this, when you install a library using yarn, you\'re using the NPM registry and the `yarn` CLI tool. It\'s the method of how the packages are extracted, maintained, and handled on your local system that are changed when you use `yarn` over `npm` - not the package\'s contents or functionality.\n\nBecause of this, if you run into a library that tells you to run:\n\n```\nyarn add library-name\n```\n\nBut your project utilizes the `npm` CLI instead, you can safely replace that command with:\n\n```\nnpm i library-name\n```\n\nAnd vice-versa to retrieve the same package\'s contents.\n\nHowever, the ways `npm` and `yarn` install packages on your local machine are different enough that, for some projects specifically built around Yarn\'s functionality, you cannot simply replace `yarn` for `npm` without some re-engineering. The differences between `npm` CLI and `yarn` are numerous and nuanced. While most projects can get by with `npm`, if a project instructs you to use `yarn` to setup your development environment, there are usually good engineering reasons for it.\n\n> Want to learn the differences between `npm` and `yarn` yourself? We\'re working on an article that covers that exact topic in-depth, both for newcomers and experiences devs alike. Be sure to subscribe to our update emails (at the bottom of the page right above the comments) to catch when that article lands!\n\n## Installing Yarn {#install-yarn}\n\nOnce you have node and npm installed, installing yarn is as simple as:\n\n```\nnpm i -g yarn\n```\n\nIt\'s worth noting that, just like `npm` and any other globally installed packages, [when you change Node version using `nvm`, you\'ll need to re-run this command](#nvm-switch-node-ver). However, if you\'re able to natively install `yarn`, you can sidestep this issue and have `yarn` persist through `nvm` version changes.\n\n### macOS {#yarn-mac}\n\nIf you\'re using macOS and want to utilize `nvm`, you can also use Homebrew (a third party package manager for Macs) to install `yarn` natively:\n\n```\nbrew install yarn\n```\n\n> There are other methods to install Yarn on macOS if you\'d rather. [Look through `yarn`\'s official docs for more](https://classic.yarnpkg.com/en/docs/install/#mac-stable)\n\n### Windows {#yarn-windows}\n\nJust as there\'s a method for installing `yarn` natively on macOS, you can do the same on Windows using [the same third-party package manager we suggest using for installing and maintaining Windows programs on your machine, Chocolatey](https://unicorn-utterances.com/posts/ultimate-windows-development-environment-guide/#package-management):\n\n```\nchoco install yarn\n```\n\n\n> There are other methods to install Yarn on Windows if you\'d rather. [Look through `yarn`\'s official docs for more](https://classic.yarnpkg.com/en/docs/install/#windows-stable)\n\n\n# Using Node {#using-node}\n\nNow that you have it setup, let\'s walk through how to use Node. First, start by opening your terminal.\n\n> On macOS, you can find your terminal by opening finder (Meta+Space) and typing "Terminal".\n>\n> For Windows usage, there are a few more options. We suggest reading through [our article that outlines those options and explains how to setup and use your terminal correctly.](https://unicorn-utterances.com/posts/ultimate-windows-development-environment-guide/#terminal-usage)\n\nOnce you have your terminal open, run the following command:\n\n```\nnode\n```\n\nOnce this is done, you should see a cursor that indicates where in the terminal:\n\n```\n>\n```\n\nFrom here, you can type in JavaScript code, and hit "enter" to execute:\n\n```javascript\n> console.log("Hello")\n```\n\n![Windows Terminal showing the console output](./hello-js.png)\n\nThis view of Node - where you have an interactive terminal you can type code into - is known as the REPL.\n\n## Executing JS Files {#node-run-file}\n\nWhile Node\'s REPL is super useful for application prototyping, the primary usage of Node comes into effect when running JavaScript files.\n\nTo show how this works, create a file in an empty folder called "index.js". Then, place valid JavaScript in that file:\n\n```javascript\n// index.js\n\nconst randomNumber = Math.random() * 100;\n\nif (randomNumber > 75) {\n    console.log("You got really lucky and won 100 points!");\n} else if (randomNumber > 50) {\n    console.log("You got pretty lucky and won 50 points!");\n} else if (randomNumber > 25) {\n    console.log("You got 25 points!");\n} else {\n    console.log("You got unlucky and gained no points");\n}\n```\n\nThen, in your terminal, `cd` into the directory the `index.js` file is and run `node index.js`. It will run the code and execute a `console.log` and exit immediately after.\n\n![Windows Terminal showing the program output](./output-js.png)\n\nThis particular program will automatically exits Node once it\'s completed running, but not all do. Some programs, like the following, may run until manually halted: \n\n```javascript\n// index.js\n\nvar points = 0;\n\nfunction checkNumber() {\n    const randomNumber = Math.random() * 100;\n\n    if (randomNumber > 75) {\n        console.log("You got really lucky and won 100 points!");\n        points += 100;\n    } else if (randomNumber > 50) {\n        console.log("You got pretty lucky and won 50 points!");\n        points += 50;\n    } else if (randomNumber > 25) {\n        console.log("You got 25 points!");\n        points += 25;\n    } else {\n        console.log("You got unlucky and gained no points");\n    }\n\n    console.log("You now have " + points + " points");\n}\n\nsetInterval(checkNumber, 2000);\n```\n\nSome other programs that may run continually includes servers (REST, GraphQL),  file watchers, or background programs. It is worth mentioning that [unless you change the default behavior with a library](#nodemon), programs that do not have an exit condition pre-programmed need to be manually restarted in order to see changes to your code executed properly.\n\nThis means that if you change the interval at-which the `checkNumber` function is ran:\n\n```javascript\nsetInterval(checkNumber, 3000);\n```\n\nYou\'ll need to re-start Node to catch that update.\n\nThe way you restart a Node process is the same on Windows as it is on macOS - it\'s the same way you stop the process. simply type Ctrl+C in your terminal to stop the process running. Then, re-run your Node command.\n\n### Hot Reload on File Edit {#nodemon}\n\nNode being able to run JavaScript files is useful once you have a finished product ready-to-run. However, while you\'re actively developing a file, it can be frustrating to manually stop and restart Node every time you make a change. I\'ve had so many instances where I\'ve Googled "NodeJS not updating JavaScript file" at some point in my debugging, only to realize that I\'d forgotten to restart the process.\n\nIntroducing `nodemon`: a library (installable via `npm`) that listens for your file changes and restarts the process whenever any of your dependencies change.\n\nTo install `nodemon`, use `npm`:\n\n```\nnpm i -g nodemon\n```\n\nThen, simply replace your `node index.js` command with `nodemon index.js`.\n\n# Using NPM/Yarn {#using-pkg-manager}\n\nWith basic Node usage established, we can expand our abilities by learning how to use `npm`/`yarn` efficiently.\n\nLet\'s start by explaining what the `package.json` file is.\n\nWhen you `clone` a project, you might see a file in the root called `package.json`, it might look something like this:\n\n```json\n{\n  "name": "unicorn-utterances-site",\n  "description": "Learning programming from magically majestic words",\n  "version": "0.1.0",\n  "bugs": {\n    "url": "https://github.com/unicorn-utterances/unicorn-utterances/issues"\n  },\n  "scripts": {\n    "start": "node index.js",\n  },\n  "dependencies": {\n    "classnames": "^2.1.3"\n  },\n  "devDependencies": {\n    "prettier": "^1.19.1"\n  }\n}\n```\n\nThis is how `npm` is able to track what versions of what libraries for your project, as well as keeping a consolidated list of what commands you\'d like to have a shorthand for, and other project metadata. We\'ll explain what each of these sections does in sub-sections.\n\nYou\'re able to generate a fresh `package.json` file for your project using either:\n\n```\nnpm init\n```\n\nOr:\n\n```\nyarn init\n```\n\n## Dependencies {#deps}\n\nMost projects you\'ll run into will have at least one dependency. A dependency is a library that your project depends on for it\'s functionality. For example, if I use the [`classnames` library](https://www.npmjs.com/package/classnames) to generate CSS-friendly class names from a JavaScript object:\n\n```javascript\nconst classNames = require(\'classnames\');\nconst classes = classNames({ foo: true, bar: false });\nconsole.log({classes});\n```\n\nI would need to make sure that `classnames` is installed before running this code. Otherwise, I\'d run into an error like this:\n\n```\ninternal/modules/cjs/loader.js:985\n  throw err;\n  ^\n\nError: Cannot find module \'classnames\'\n```\n\nIn order to fix this error, we need to make sure that `classnames` is in our dependency object in `package.json` and that we\'ve ran `npm i` or a `yarn install` to install the package.\n\nIf your `package.json` already has the dependency listed:\n\n```\n"dependencies": {\n  "classnames": "^2.1.3"\n},\n```\n\nThen it should be as easy as `npm i` or `yarn install` to tell it "Install the packages listed as dependencies". However, if you\'re starting with a fresh `package.json` file without any dependencies (or simply want to add a new dependency), you can do so with a single command.\n\nIf you\'re using `npm`, you can add a new dependency using:\n\n```\nnpm install classnames\n```\n\nOtherwise, if you\'re using `yarn`, the command is:\n\n```\nyarn add classnames\n```\n\n> Just because using `classnames` as an example here, doesn\'t mean you have to. You can use the name of whatever dependency you\'re wanting to add.\n\n### Semantic Versioning {#semver}\n\nFor each dependency listed, there is a number with three dots associated with it. These numbers represent the version of the library to install when running commands like `npm i`.\n\nWhile you can use these numbers arbitrarily, most projects follow [a standard called "Semantic versioning"](https://semver.org/) (aka "SemVer" for short).\n\nThe basics of semantic versioning can be broken down into three parts:\n\n1) The major version\n2) The minor version\n3) The patch version\n\nIn SemVer, a package version might look something like `MAJOR.MINOR.PATCH`. A package with `2.1.3` has a "**major** version" of `2`, a "**minor** version" of `1`, and a "**patch** version" of `3`.\n\nWhat are major, minor, and patch versions?\n\nThey describe what changes were made in each release. Let\'s start from the bottom and work our way up.\n\nA patch release might contain documentation updates, bug fixes, security patch, or anything else that doesn\'t add functionality or breaking changes (more on that later).\n\nA minor release is usually a feature update. This release added some new functionality to the library without any breaking changes.\n\nA major release is a change to the library that requires a change (any change) in the consuming code. These changes, which may require dependants to rewrite sections of their code to utilize, are called **breaking changes**. In large libraries, breaking changes are often withheld from smaller releases and grouped together to create a major release, complete with documentation for how to change your code to reflect these changes.\n\nBecause minor and patch releases do not contain breaking changes (when following SemVer), you can safely update dependencies that utilize SemVer without having to check the changelog for every minor/patch release.\n\nAgain, this isn\'t the _only_ way to version a library, but it is an increasingly common method for making sure that new versions won\'t break your project\'s functionality.\n\n#### SemVer Setting {#package-json-semver}\n\nHow can we leverage SemVer in our `package.json`? If you looked at the `dependencies` object in our example previously, you may have noticed an odd character that\'s not a number: `^`.\n\n```\n"dependencies": {\n  "classnames": "^2.1.3"\n},\n```\n\nThis is a character that\'s understood by `npm` to mean "you may install any version of `classnames` that\'s a minor version above `2.1.3`"\n\nFor example, `classnames` has had the following releases:\n\n- `2.1.2`\n- `2.1.3`\n- `2.1.4`\n- `2.2.0`\n- `2.2.1`\n- `...`\n- `2.2.6`\n\nIf we set our version to include the caret (`^`) of `2.1.3`(`^2.1.3`), the following versions are allowed to be installed:\n\n```diff\n- 2.1.2\n+ 2.1.3\n+ 2.1.4\n+ 2.2.0\n+ ...\n+ 2.2.6\n- 3.0.0\n```\n\n> A `-` means that this version is out-of-range and should not be installed, while `+` means that this version is in-range and is able to be installed by your package manager.\n\nThis allows us to set a bare-minimum version that we rely the functionality of without worrying about breaking changes from a major release.\n\nHowever, `^` isn\'t the only character you can use to tell your package manager which version to install. You can also use `~` like `~2.1.3` to indicate that you\'d like to install patch releases, but not minor releases.\n\n```diff\n- 2.1.2\n+ 2.1.3\n+ 2.1.4\n- 2.2.0\n- ...\n- 2.2.6\n- 3.0.0\n```\n\nThis can be useful when a package isn\'t following SemVer and instead includes breaking changes in minor releases.\n\nThere are other modifiers you can use such as version ranges that cross-over major releases, pre-release versions, and more. To learn more about these additional modifiers and to experiment with the tilde and caret modifiers, [NPM has setup a website that teaches you and lets you visually experiment with the modifiers](https://semver.npmjs.com/).\n\n### Dev Dependencies {#dev-deps}\n\nLet\'s take a closer look at the `package.json` we were using as an example.\n\n```json\n{\n  "dependencies": {\n    "classnames": "^2.1.3"\n  },\n  "devDependencies": {\n    "prettier": "^1.19.1"\n  }\n}\n```\n\nAdditional to `dependencies`, `devDependencies` also contains it\'s own list of libraries. What are dev dependencies? When are they useful? After all, they both get installed when you run `npm i`/`yarn install` in the project\'s root.\n\nWhile `dependencies` list out the libraries you use in your project\'s code, `devDependencies` list out the libraries you use for your development environment. For example, you might use [`prettier`](https://prettier.io/) to keep a consistent code style for all of your JavaScript files, but your code does not rely on `eslint` to function. Tools like `webpack`, `babel`, `typescript`, and more would belong here.\n\nWhile less important for applications, the distinction is extremely important for libraries. When a library is shipped to NPM\'s registry, you include your `package.json`. When your library is eventually installed in a project as a dependency (dev or otherwise), it will also install all of your `dependencies` on the user\'s machine.\n\nIf you include `prettier` and other tools you use to develop the library, it bloats the install size of the library\'s installation. However, if you list those tools in `devDependency`, it will not install them alongside your library on a user\'s machine.\n\n**`devDependency` allows you to keep a list of tools you\'ll utilize when developing, but which your code itself does not rely on to run.**\n\n### Peer Dependencies {#peer-deps}\n\nWhile dependencies are incredibly useful, if you\'re using a framework like React, having every dependency in your project install a separate version of React would potentially cause issues. Each dep would have a different version, which may act differently, and your `node_modules` would be bloated.\n\nAs such, the concept of `peerDependencies` is to allow client projects to have a single version of a dependency installed that is shared other deps. For example, a library built using JSX might have a `package.json` that looks like this:\n\n```json\n{\n  "dependencies": {\n    "classnames": "^2.1.3"\n  },\n  "peerDependencies": {\n    "react": "^17.0.2"\n  }\n}\n```\n\nThis would allow you to have `react` installed on your project and able to share the dependency with anything that requests the peer dep.\n\nIt\'s worth noting in that in `npm 6`, you used to have to install these yourselves. However, `npm 7` made the change such that peer deps are installed automatically. If you see an error from a package saying that your peer dep doesn\'t match, find the project and make a pull request to add the correct versions of the peer deps. These warnings were not significant with `npm 6`, but with `npm 7`, these matter substantially more.\n\n## Ignoring `node_modules ` {#gitignore}\n\nOnce you have your packages installed (either by using `yarn` or `npm`), **it\'s important that you _do not commit_ your `node_modules` folder** to your code hosting. By commiting `node_modules`, you:\n\n- Bloat the size of your repository codebase\n- Slow down cloning of your project\n- Making it difficult/impossible to do analytics on the code you\'re using\n- Remove the potential to install security updates with semver ranges in your package.json\n- Break CI/CD systems that plan on running `npm i`\n\nTo avoid these problems (and more), be sure to exclude your `node_modules` folder from being tracked in Git. To do this, create a file called `.gitignore`. Then, place the following inside:\n\n```\nnode_modules/\n```\n\nWorried that your dependencies might not resolve the same version on systems like CI where having replicable stable dependency installs matter a lot? That\'s where lock files comes into play\n\n## Lock Files {#package-lock}\n\nOnce you run `npm i` on a project with dependencies, you\'ll notice a new file in your root folder: `package-lock.json`. This file is called your **"lockfile"**. **This file is auto-generated by `npm` and should not be manually modified.** \n\n> If you\'re using `yarn`, you\'ll notice instead this file is called `yarn.lock`. It serves the same purpose as `package-lock.json` and should be treated similarly\n\nWhile your `package.json` describes which versions you\'d _prefer_ to be installed, your lockfile nails down exactly which version of the dependency (and sub dependencies) were resolved and installed when it came time to install your packages. This allows you to use commands like `npm ci` to install directly from this lockfile and install the exact same version of packages you had installed previously.\n\nThis can be incredibly helpful for debugging package resolution issues as well as making sure your CI/CD pipeline installs the correct versions of deps. \n\nWhile it\'s imperative not to track your `node_modules` folder, you **want to commit your `package-lock` file in your git repo**. This ensures that things like CI pipelines are able to run the same versions of dependencies you\'re utilizing on your local machine.\n\n> Something to keep in mind is that different major versions of `npm` use slightly differently formatted lock files. If part of your team is using `npm 6` and the other part uses `npm 7`, you\'ll find that each team replaces the lockfile every single time `npm i` is installed. To avoid this, make sure your team is using the same major version of `npm`.\n\n## Scripts {#npm-scripts}\n\nYou\'ll notice that the above `package.json` has a `start` script. When `npm run start` or `yarn start` is ran, it will execute `node index.js` to run the file with Node. While `node` usage is common, you\'re also able to leverage any command that\'s valid on your machine. You could have:\n\n```json\n"scripts": {\n  "start": "gatsby build",\n}\n```\n\nTo reference an `npm` package script, or even a system command like:\n\n```\n"scripts": {\n  "start": "ls",\n}\n```\n\nYou\'re not limited to a single command, either. Most projects will have "scripts" for things like building your project for production, starting development servers, running linters, and much more:\n\n```json\n"scripts": {\n  "build": "gatsby build",\n  "develop": "gatsby develop",\n  "lint": "eslint ./src/**/*.{ts,tsx}",\n  "start": "npm run develop",\n  "test": "jest"\n}\n```\n\n# Conclusion\n\nWhile there\'s always more to learn when it comes to developmental tooling, this has been an introduction to `npm`, `yarn`, and `node`! With this information, you should have more context when it comes to how dependency management and basic JavaScript usage are utilized in web projects. We suggest taking a look through some open-source projects on GitHub to see how they\'re doing things.\n\nRun into any questions along the way? We have [a community Discord](https://discord.gg/FMcvc6T) where you can ask us any questions you might find along your development journey. We wish you the best along this journey! 😊 Just remember, this is only the start - don\'t be discouraged by potential hiccups along the way, and never be afraid or embarrassed to ask for help from others.\n',
		},
		{
			title: "Integrating Native Android Code in Unity",
			description:
				"Have you ever wanted to run native Java and Kotlin code from your mobile game written in Unity? Well, you can! Let's see how.",
			published: "2020-01-04T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["unity", "android", "csharp", "java"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "integrating-android-code-in-unity",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Integrating Native Android Code in Unity",
				description:
					"Have you ever wanted to run native Java and Kotlin code from your mobile game written in Unity? Well, you can! Let's see how.",
				published: "2020-01-04T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["unity", "android", "csharp", "java"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				'\nWorking on mobile games with Unity, you may come across some instances where you\'ll want to run native code. Whether it be to access specific sensors, run code in the background, or other closer-to-hardware mobile-specific actions, knowing how to call native code from within your Unity\'s C# environment can be a great boon to your developmental efforts.\n\nLuckily for us, Unity has a system of "plugins" that allow us to do just that. Unity contains the ability to map code between C# and Java by using in-house-developed helper classes to cross-talk between the two languages. This article will outline [how to set up a development environment](#set-up-a-development-environment), [how to manage Android dependencies in Unity](#android-dependencies), and finally [how to call Android-specific code from C#](#call-android-from-c-sharp). Without further ado, let\'s dive in! 🏊‍♂️\n\n> ⚠️ Be aware that this information is based on Unity 2018 versions. While this might be relevant for older versions of Unity, I have not tested much of this methodology of integration with older versions.\n\n# Setting up Development Environment {#set-up-a-development-environment}\n\n[Unity supports using either Java files or Kotlin source files as plugins](https://docs.unity3d.com/Manual/AndroidJavaSourcePlugins.html). This means that you\'re able to take Android source files (regardless of if they\'re written in Java or Kotlin) and treat them as callable compiled library code. Unity will then take these files and then include them into its own Gradle build process, allowing you — the developer — to focus on development rather than the build process.\n\n> For anyone who may have experimented with doing so in older versions of Unity in the past will note that this is a massive improvement — it used to be that you\'d have to compile to AAR files and include them manually.\n\nThat said, the editor you may be using may not be best suited for editing Android code, and it would be great to have a powerful development experience while working with. For this purpose, it would be great to edit code using [the official IDE for Android development: Android Studio](https://developer.android.com/studio/).\n\nUnfortunately, I\'ve had difficulties getting the same Android Studio development environment to sync with the "source file" interoperability that Unity provides. For this reason, I tend to have two folders:\n\n- One of these folders lives at the root of the project (directly under `Unity/ProjectName`) called `AndroidStudioDev` that I open in Android Studio.\n\n- The other folder is one that lives under `Assets` called `AndroidCode`, which contains copied-and-pasted files from `AndroidStudioDev` that are only the related source files I need to call.\n\n![Showcase of the filesystem as described by the previous paragraph](./android_code_fs_layout.png)\n\nOnce the copying of the files from the Android Studio environment to `Assets` has finished, you\'ll need to mark it as being included in the Android build within Unity\'s inspector window that comes up when you highlight the source file.\n\n![The inspector window showing "Android" selected](./unity_inspector.png)\n\n> If you forget to do this, your class or file may not be found. This is an important step to keep in mind during debugging.\n\nThis will naturally incur a question for developers who have tried to maintain a system of duplication of any size:\n**How do you manage dependencies between these two folders?**\n\n\n## Managing Android Dependencies {#android-dependencies}\n\nLuckily for us, managing Android code dependencies in Unity has a thought-out solution from a large company: Google. [Because Google writes a Firebase SDK for Unity](https://firebase.google.com/docs/unity/setup), they needed a solid way to manage native dependencies within Unity.\n\n### Installing the Unity Jar Resolver {#installing-jar-resolver}\n\n> ℹ️ If you\'ve installed the Unity Firebase SDK already, you may skip the step of installing.\n\n[This plugin, called the "Unity Jar Resolver"](https://github.com/googlesamples/unity-jar-resolver/), is hugely useful to us for synchronizing our development environment. You can start by downloading it from [their releases tab on GitHub](https://github.com/googlesamples/unity-jar-resolver/releases).\n\n> If you have a hard time finding the download link, you\'ll want to press the three dots (or, if you\'re looking for the alt text: the "Toggle commit message" button). There will typically be a link for downloading the `.unitypackage` file.\n\nIn your project, you\'ll then want to select `Assets > Import Package > Custom Package` in order to import the downloaded plugin.\n\n![A visual of where to find that menu in the MacOS menubar](./import_custom_package.png)\n\nThen, you\'ll see a dialog screen that\'ll ask what files you want to import with your Unity Package. Ensure that all of the files are selected, then press "Import".\n\n![A screenshot of the dialog mentioned](./importing_the_plugin.png)\n\n> Your screen may look slightly different from the one above. That\'s okay — so long as all of the files are selected, pressing "Import" is perfectly fine.\n\n### Using the Jar Resolver {#using-jar-resolver}\n\nUsing the Jar resolver is fairly straightforward. Whenever you want to use a dependency in your Android code, you can add them to a file within [the `Assets/AndroidCode` folder](#set-up-a-development-environment) that adds dependencies with the same keys as the ones typically found in a `build.gradle` file for dependencies.\n\n```xml\n<!-- DeviceNameDependencies.xml -->\n<dependencies>\n\t<androidPackages>\n\t\t<androidPackage spec="com.jaredrummler:android-device-names:1.1.8">\n\t\t</androidPackage>\n\t</androidPackages>\n</dependencies>\n```\n\nThe only rule with this file structure is that your file must end with `Dependencies.xml`. You can have as many of these files as you\'d like. Let\'s say you want to separate out dependencies based on features? You can do that, just have separate files that follow that naming pattern!\n\n```xml\n<!-- LocationCodeDependencies.xml -->\n<!-- Alongside the other file -->\n<dependencies>\n\t<androidPackages>\n\t\t<androidPackage spec="com.google.android.gms:play-services-location:16.0.0">\n\t\t</androidPackage>\n\t</androidPackages>\n</dependencies>\n```\n\nAfter creating the files, in the menubar, go to `Assets > Play Services Resolver > Android Resolver > Resolve`, and it should go fetch the AAR files related to those specific libraries and download them.\n\n![The MacOS menubar showing the above path to resolve libraries](./resolve_dependencies.png)\n\nSo long as your file ends with `Dependencies.xml`, it should be picked up by the plugin to resolve the AAR files.\n\n#### Adding Support into Android Studio Environment {#add-android-studio-support}\n\nBut that\'s only half of the equation. When editing code in Android Studio, you won\'t be able to use the libraries you\'ve downloaded in Unity. This means that you\'re stuck manually editing both of the locations for dependencies. This is where a simple trick with build files comes into play.\n\nAssuming, like me, you used the built-in "Create Project" method of starting a codebase in Android Studio, you\'ll have a `build.gradle` file for managing dependencies. However, you\'ll notice that when you run the `Resolve` on the plugin in Unity, it\'ll download AAR and JAR files to `Assets/Plugins/Android`. You can tell Android Studio\'s Gradle to include them by adding the following line to your `dependencies`:\n\n```groovy\ndependencies {\n\timplementation fileTree(dir: \'../../Assets/Plugins/Android\', include: [\'*.jar\', \'*.aar\'])\n}\n```\n\nThis will take all of the AAR files and JAR files and treat them as if they were synced by Android Studio\'s Gradle sync.\n\n\n\nFor more information on how to manage your app\'s dependencies from within Unity, you may want to check out [this article created by the Firebase developers](https://medium.com/firebase-developers/how-to-manage-your-native-ios-and-android-dependencies-in-unity-like-firebase-921659843aef), who coincidentally made the plugin for managing Android dependencies in Unity.\n\n\n\n# Call Android code from C# {#call-android-from-c-sharp}\n\nIt\'s great that we\'re able to manage those dependencies, but they don\'t mean much if you\'re not able to utilize the code from them!\n\nFor example, take the following library: https://github.com/jaredrummler/AndroidDeviceNames\n\nThat library allows you to grab metadata about a user\'s device. This might be useful for analytics or bug reporters you may be developing yourself. Let\'s see how we\'re able to integrate this Java library in our C# code when building for the Android platform.\n\n## Introduction {#intro-call-android-from-c-sharp}\n\nYou must make your callback extend the type of callback that is used in the library. For example, take the following code sample from the README of the library mentioned above:\n\n```java\nDeviceName.with(context).request(new DeviceName.Callback() {\n\t@Override public void onFinished(DeviceName.DeviceInfo info, Exception error) {\n\t\tString manufacturer = info.manufacturer;  // "Samsung"\n\t\tString name = info.marketName;            // "Galaxy S8+"\n\t\tString model = info.model;                // "SM-G955W"\n\t\tString codename = info.codename;          // "dream2qltecan"\n\t\tString deviceName = info.getName();       // "Galaxy S8+"\n\t}\n});\n```\n\nWhile this example may seem straightforward, let\'s dissct what we\'re doing step-by-step here. This will allow us to make the migration to C# code much simpler to do mentally.\n\n```java\n// Create a new "DeviceName.Callback" instance\nDeviceName.Callback handleOnFinished = new DeviceName.Callback() {\n\t// Provide an implementation of the `onFinished` function in the `Callback` class\n\t// Notice that there are two parameters for this method: one for info, the other for errors\n\t@Override public void onFinished(DeviceName.DeviceInfo info, Exception error) {\n\t\t// ... Assignment logic here\n\t}\n};\n\n// Create a `DeviceName.Request` by passing the current context into the `DeviceName.with` method\nDeviceName.Request withInstance = DeviceName.with(context);\n\n// Use that request instance to pass the `DeviceName.Callback` instance from above to run the related code\nwithInstance.request(handleOnFinished);\n```\n\nYou can see that we have a few steps here:\n\n1) Make a new `Callback` instance\n\t- Provide an implementation of `onFinished` for said instance\n2) Call `DeviceName.with` to create a request we can use later\n\t- This means that we have to gain access to the currently running context to gain device access. When calling the code from Unity, it means we have to get access to the `UnityPlayer` context that Unity engine runs on\n3) Call that request\'s `request` method with the `Callback` instance\n\nFor each of these steps, we need to have a mapping from the Java code to C# code. Let\'s walk through these steps one-by-one\n\n## Create `Callback` Instance {#android-c-sharp-callback}\n\nIn order to create an instance of a `Callback` in C# code, we first need a C# class that maps to the `Java` interface. To do so, let\'s start by extending the Android library interface. We can do this by using the `base` constructor of `AndroidJavaProxy` and the name of the Java package path. You\'re able to use `$` to refer to the interface name from within the Java package.\n\n```csharp\nprivate class DeviceCallback : AndroidJavaProxy\n{\n\t// `base` calls the constructor on `AndroidJava` to pass the path of the interface\n\t// `$` refers to interface name\n\tpublic DeviceCallback() : base("com.jaredrummler.android.device.DeviceName$Callback") {}\n}\n```\n\n> [This package path can be found in the library\'s code at the following path](https://github.com/jaredrummler/AndroidDeviceNames/blob/e23b73dbb81be6cb64dfa541a3e93800ee26b185/library/src/main/java/com/jaredrummler/android/device/DeviceName.java#L17). The `DeviceName` is referring to the path of the `.java` file name.\n\nWe can then provide an implementation of the `onFinished` method of that `Callback`. Recall how we previously had two params? Well, now the implementation will require we use the `AndroidJavaObject` type for both of those params.\n\nOtherwise — if we type the function with a C# interface or class that matches the Java implementation — the method will not be called when we expect it to. This is due to function overloading expecting to get the `AndroidJavaObject` from the code Unity has developed to call mapped functions and classes.\n\nThis [`AndroidJavaObject` type has a myriad of methods that can be called to assist in gathering data from or interfacing with the Java object](https://docs.unity3d.com/ScriptReference/AndroidJavaObject.html). One of such methods is the [`Get` method](https://docs.unity3d.com/ScriptReference/AndroidJavaObject.Get.html). When called on an `AndroidJavaObject` instance in C#, it allows you to grab a value from Java. Likewise, if you intend to call a method from the Java code, you can use [`AndroidJavaObject.Call`](https://docs.unity3d.com/ScriptReference/AndroidJavaObject.Call.html).\n\n```csharp\nprivate class DeviceCallback : AndroidJavaProxy\n{\n\tpublic DeviceCallback() : base("com.jaredrummler.android.device.DeviceName$Callback") {}\n\t// These both MUST be `AndroidJavaObject`s. If not, it won\'t match the Java method type and therefore won\'t be called\n\tvoid onFinished(AndroidJavaObject info, AndroidJavaObject err)\n\t{\n\t\t// When running `AndroidJavaObject` methods, you need to provide a type for the value to be assigned to\n\t\tvar manufacturer = info.Get<string>("manufacturer"); // "Samsung"\n\t\tvar readableName = info.Get<string>("marketName"); // "Galaxy S8+"\n\t\tvar model = info.Get<string>("model"); // "SM-G955W"\n\t\tvar codename = info.Get<string>("codename"); // "dream2qltecan"\n\t\tvar deviceName = info.Call<string>("getName"); // "Galaxy S8+"\n\t}\n}\n```\n\n## Get Current Context {#get-unity-context}\n\nJust as all Android applications have some context to their running code, so too does the compiled Unity APK. When compiling down to Android, Unity includes a package called the "UnityPlayer" to run the compiled Unity code. The package path for the player in question is `com.unity3d.player.UnityPlayer`.\n\nWhile there is not a docs reference page for this Java class, [some of the company\'s code samples](https://docs.unity3d.com/530/Documentation/Manual/PluginsForAndroid.html) provide us with some useful methods and properties on the class. For example, that page mentions a static property of `currentActivity` that gives us the context we need to pass to `DeviceName.with` later on:\n\n```csharp\nvar player = new AndroidJavaClass("com.unity3d.player.UnityPlayer");\nvar activity = player.GetStatic<AndroidJavaObject>("currentActivity");\n```\n\nWe can then gain access to the `DeviceName` Java class. If we look at [the related Java code from the previous section](#call-android-from-c-sharp), we can see that we\'re calling `DeviceName.with` without making a new instance of `DeviceName`:\n\n```java\nDeviceName.Request withInstance = DeviceName.with(context);\n```\n\nThis means that `with` must be a static method on the `DeviceName` class. In order to call static Java methods, we\'ll use the `AndroidJavaClass.CallStatic` method in C#.\n\n```csharp\nvar jc = new AndroidJavaClass("com.jaredrummler.android.device.DeviceName");\nvar withCallback = jc.CallStatic<AndroidJavaObject>("with", activity);\n```\n\nFinally, we can add the call to `request` with an instance of the `DeviceCallback` class.\n\n```csharp\nvar deviceCallback = new DeviceCallback();\nwithCallback.Call("request", deviceCallback);\n```\n\n## Complete Code Example {#android-c-sharp-code-sample}\n\nLine-by-line explanations are great, but often miss the wholistic image of what we\'re trying to achieve. The following is a more complete code sample that can be used to get device information from an Android device from Unity.\n\n```csharp\npublic class DeviceInfo {\n\tpublic string manufacturer;  // "Samsung"\n\tpublic string readableName;  // "Galaxy S8+"\n\tpublic string model;         // "SM-G955W"\n\tpublic string codename;      // "dream2qltecan"\n\tpublic string deviceName;    // "Galaxy S8+"\n}\n\nclass DeviceName : MonoBehaviour {\n\tprivate class DeviceCallback : AndroidJavaProxy {\n\t\t// Add in a field for us to gain access to the device info after the callback has ran\n\t\tpublic DeviceInfo deviceInfo;\n\t\tpublic DeviceCallback() : base("com.jaredrummler.android.device.DeviceName$Callback") {}\n\t\tvoid onFinished(AndroidJavaObject info, AndroidJavaObject err) {\n\t\t\tdeviceInfo.manufacturer = info.Get<string>("manufacturer");\n\t\t\tdeviceInfo.readableName = info.Get<string>("marketName");\n\t\t\tdeviceInfo.model = info.Get<string>("model");\n\t\t\tdeviceInfo.codename = info.Get<string>("codename");\n\t\t\tdeviceInfo.deviceName = info.Call<string>("getName");\n\t\t}\n\t}\n\n\tprivate void Start() {\n\t\tvar player = new AndroidJavaClass("com.unity3d.player.UnityPlayer");\n\t\tvar activity = player.GetStatic<AndroidJavaObject>("currentActivity");\n\t\tvar jc = new AndroidJavaClass("com.jaredrummler.android.device.DeviceName");\n\t\tvar withCallback = jc.CallStatic<AndroidJavaObject>("with", activity);\n\t\tvar deviceCallback = new DeviceCallback();\n\t\twithCallback.Call("request", deviceCallback);\n\t\tDebug.Log(deviceCallback.deviceInfo.deviceName);\n\t}\n}\n```\n\n# Calling Source Code from Unity {#call-source-from-unity}\n\nCalling native Android code can be cool, but what if you have existing Android code you want to call from Unity? Well, that\'s supported as well. Let\'s take the following Kotlin file:\n\n```kotlin\n// Test.kt\npackage com.company.example\n\nimport android.app.Activity\nimport android.util.Log\n\nclass Test() {\n\tfun runDebugLog() {\n\t\tLog.i("com.company.example", "Removing location updates")\n\t}\n}\n```\n\nAssuming you [copied it over to the `Assets/AndroidCode` folder and marked it to be included in the Android build](#set-up-a-development-environment), you should be able to use the `package` name and the name of the class in order to run the related code.\n\n```csharp\nvar testAndroidObj = new AndroidJavaObject("com.company.example.Test");\ntestAndroidObj.Call("runDebugLog");\n```\n\n# AndroidManifest.XML Overwriting {#manifest-file}\n\nMany Android app developers know how important it can be to have the ability to customize their manifest file. By doing so, you\'re able to assign various metadata to your application that you otherwise would be unable to. Luckily for us, Unity provides the ability to overwrite the default XML file.\n\nBy placing a file under `Assets\\Plugins\\Android\\AndroidManifest.xml`, you\'re able to add new values, change old ones, and much more.\n\nIf you want to find what the default manifest file looks like, you\'ll want to look for the following file:  `<UnityInstallationDirecory>\\Editor\\Data\\PlaybackEngines\\AndroidPlayer\\Apk\\AndroidManifest.xml`. This file is a good baseline to copy into your project to then extend upon. The reason I suggest starting with the default XML is that Unity requires its own set of permissions and such. After that, however, you\'re able to take the manifest and customize it to your heart\'s content.\n\n> It\'s worth mentioning that if you use Firebase Unity SDK and wish to provide your own manifest file, you\'ll need to [customize the default manifest file to support Firebase opperations](https://firebase.google.com/docs/cloud-messaging/unity/client#configuring_an_android_entry_point_activity).\n\n# Firebase Support {#firebase}\n\nLet\'s say you\'re one of the users who utilizes the Firebase SDK for Unity. What happens if you want to send data from Android native code or even use background notification listeners in your mobile app?\n\nYou\'re in luck! Thanks to the Unity Firebase plugin using native code in the background, you\'re able to share your configuration of Firebase between your native and Unity code. So long as you\'ve [configured Firebase for Unity properly](https://firebase.google.com/docs/cloud-messaging/unity/client#add-config-file) and [added the config change to Android Studio](#add-android-studio-support), you should be able to simply call Firebase code from within your source files and have the project configs carry over. This means that you don\'t have to go through the tedium of setting up and synchronizing the Unity and Android config files to setup Firebase — simply call Firebase code from your source files, and you should be good-to-go! No dependency fiddling required!\n\n# Conclusion {#conclusion}\n\nI hope this article has been helpful to anyone hoping to use Android code in their Unity mobile game; I know how frustrating it can be sometimes to get multiple moving parts to mesh together to work. Rest assured, once it does, it\'s a satisfying result knowing that you\'re utilizing the tools that Unity and the Firebase team have so graciously provided to game developers.\n\nIf you have any questions or comments, please leave them down below. Thanks for reading!\n',
		},
		{
			title: "Introduction to HTML, CSS, and JavaScript",
			description:
				"Introduction to the underlying concepts of HTML, CSS, and JavaScript and how they work together.",
			published: "2019-12-16T13:45:00.284Z",
			authors: ["MDutro"],
			tags: ["html", "css", "javascript"],
			attached: [],
			license: {
				id: "publicdomain-zero-1",
				footerImg: "https://licensebuttons.net/p/zero/1.0/88x31.png",
				licenceType: "Public Domain",
				explainLink: "https://creativecommons.org/publicdomain/zero/1.0/",
				name: "CC0 1.0 Universal (CC0 1.0) Public Domain Dedication",
				displayName: "Public Domain",
			},
			slug: "intro-to-html-css-and-javascript",
			locale: "en",
			authorsMeta: [
				{
					id: "MDutro",
					name: "Micah Dutro",
					firstName: "Micah",
					lastName: "Dutro",
					description: "A non-profit lawyer turned budding web developer.",
					socials: { github: "MDutro" },
					pronouns: "he",
					profileImg: "./mdutro.jpg",
					color: "#7C4DFF",
					roles: ["developer", "author", "community"],
					profileImgMeta: {
						height: 700,
						width: 700,
						relativePath: "./mdutro.jpg",
						relativeServerPath: "/content/data/mdutro.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\mdutro.jpg",
					},
					rolesMeta: [
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Introduction to HTML, CSS, and JavaScript",
				description:
					"Introduction to the underlying concepts of HTML, CSS, and JavaScript and how they work together.",
				published: "2019-12-16T13:45:00.284Z",
				authors: ["MDutro"],
				tags: ["html", "css", "javascript"],
				attached: [],
				license: "publicdomain-zero-1",
			},
			contentMeta:
				'\nSo you have decided to learn web development.\n\nGreat! But once you start looking around for tutorials, guides, and other resources, it\'s easy to get overwhelmed. Web development incorporates a lot of different technologies that all work together to create the internet as we know it today. Understanding how they work together is no small task, especially when you are at the beginning of your web development journey. Which ones should you learn first? What do they do? What does it all mean???\n\nUnicorn Utterances is here to help. Let\'s start at the beginning.\n\nAt a very basic level, all websites are constructed from three foundational technologies: HTML, CSS, and JavaScript. Every other concept or technology related to front-end web development is either based on or works with one of these three building blocks. Getting a firm grasp on HTML, CSS, and JavaScript is critical to understanding web development and learning how to create your own websites and web applications.\n\n# HTML\n\nHTML stands for [HyperText Markup Language](https://developer.mozilla.org/en-US/docs/Web/HTML), and the latest release is HTML5. HTML is the foundation of the modern internet. Every website you visit or web application you use is built on a structure created by an HTML document. A great way to visualize what HTML does is to think of a building under construction. All buildings have a frame, whether steel or wood, that creates the basic structure of the building from the foundation to the roof. This structure dictates the size and shape of the building. No matter what the building looks like when it is finished or the purpose it serves, everything will be built around that steel structure.\n\nHTML is the steel frame of the user\'s interaction with any given website. It is the structure that websites are built around and it tells your web browser how to construct the site you are visiting. Just like you don’t see the wooden framing of your house once it is built, the structural parts of HTML are ordinarily hidden from view. Your web browser uses it to build the site, along with CSS and JavaScript, and present it to you in the way that the developer intended.\n\nSo, HTML gives a website its structure. But how does it do that?\n\nAt its most basic level, HTML builds the structure of a webpage by using something called "elements" which are normally invisible to the casual website visitor. But even if you can\'t see them, you can usually guess where they are. That’s because elements are used to divide a web page into logical sections. When you see a navigation bar, a title, paragraphs of text, or a footer, you can be sure there is at least one HTML element associated with it.\n\nIf HTML is like the steel frame of a building, then elements are like the individual beams that make up the frame. Elements are defined by small chunks of text called ["tags"](https://developer.mozilla.org/en-US/docs/Learn/HTML/Introduction_to_HTML/Getting_started) that define where an element begins and ends. There are many different tags, and they can be organized in many ways - you can even nest tags inside each other - but the important thing to remember here is that the web browser on your computer reads these tags from the top of the HTML document to the bottom. Items on a website can be visually rearranged by CSS or JavaScript but their initial position on the page is set by their position in the HTML document itself.\n\nIf you want to see the HTML of a website, all you have to do is access the developer tools in [Chrome](https://developers.google.com/web/tools/chrome-devtools/open) or [Firefox](https://developer.mozilla.org/en-US/docs/Tools).\n\nHTML also serves as the foundation for web accessibility for people with disabilities. [Screen readers](https://www.afb.org/blindness-and-low-vision/using-technology/assistive-technology-products/screen-readers) allow people who are blind or have low vision to use the internet in a primarily audio format. They work by reading the HTML directly and are programmed to follow its structure and pick up on information included in the element tags. Practicing good [web accessibility standards](https://www.w3.org/WAI/standards-guidelines/wcag/) is important for a modern web developer and makes websites that are easier to use for everyone.\n\n# CSS\n\nCSS, or [Cascading Style Sheets](https://developer.mozilla.org/en-US/docs/Web/CSS), is what web developers use to control the look and feel of the websites they create.\n\nLet\'s think back to our building construction analogy for a moment. We have our steel frame (HTML), but what will the building look like when it is finished? Will the facade be brick, wood siding, or cut stone? Should it be painted? If so, what color? These are the kinds of questions that web developers use CSS to answer.\n\nCSS can be used to control virtually every visual aspect of a website. Take a look at the site you are reading right now. Everything on it is controlled (or "styled" as the lingo goes) by CSS. The background color, the color of the text, the size of the text, where images or videos appear on the page, the location of the navigation bar, and even some animations are set by CSS.\n\nIn modern web development, CSS is written in a separate document  called a "stylesheet" that is referenced in the HTML document with a link element. The stylesheet contains a list of HTML elements, identified by various "selectors", that the developer wants to style. Each element may contain any number of [properties](https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Properties_Reference) and property values that set up how that element will be presented to the user in the web browser. These properties have a specific mapping to various aspects of how the page is styled. For example, `font-size` dictates the size of the font of the text on the page. Exactly what appears on the screen can be a little tricky for a beginner, and I encourage you to read the excellent [tutorial in Mozilla’s documentation](https://developer.mozilla.org/en-US/docs/Learn/CSS/Building_blocks/Cascade_and_inheritance). For now, just know that CSS rules can inherit property values from each other and can even override each other in certain circumstances.\n\nCSS is a big topic, and you will very likely be learning more about it as long as you do web development. There are pre-made frameworks, preprocessors, and lots of other CSS-related goodies out there to dive into as you learn your new craft. The important thing at the outset is to learn the basics well so that you know what to expect as you write your own CSS stylesheets.\n\n# JavaScript\n\nJavaScript is the programming language of the internet and web browsers. When you are shopping online, JavaScript is happening. When you check your local weather radar, JavaScript is happening. When you use social media, JavaScript is happening. Basically, JavaScript is what gives websites and web applications the ability to actually do something.\n\nJust like CSS, JavaScript is normally written in a separate file and connected by reference to the HTML itself. JavaScript is an “interpreted” language, which means that the code is run by the browser at the time it is activated. Some JavaScript code is set to run automatically when the page loads, while some sits dormant waiting to spring into action based on user input.\n\nAs I said before, JavaScript is a for-real programming language. That means it has arrays, for loops, if-else statements, and lots of other computer science-y things going on. Despite that, the language is actually very beginner-friendly. You don’t have to have a degree in computer science or arcane mathematics to get started with a programming language. And because of the way JavaScript interacts with web browsers, you will be to do some amazing things pretty quickly.\n\nOne thing that makes JavaScript unique is [its ability to manipulate the DOM](/posts/understanding-the-dom/). The Document Object Model (or DOM) is an API (advanced programming interface) that allows JavaScript to manipulate the HTML and CSS of a website as the user navigates around the page and uses its features. Basically, the web browser can read JavaScript and make changes to the look, feel, and even the structure of the page in real-time.\n\nTo go back to our building construction analogy… well, it starts to break down at this point. Imagine if you could wave a magic wand and turn the wood siding on your building into bricks. Or change the color of the building from gray to bright blue. Remember the steel beams of HTML our building is made of on the inside? By using the DOM, JavaScript can change those too!\n\nJavaScript is a powerful tool that can be used to create everything from useful applications, to convenient shopping experiences, and even games. JavaScript is complex, and there is a lot to learn, but there are a lot of great free [resources](https://developer.mozilla.org/en-US/docs/Web/JavaScript) out there to learn the basics and get started writing code from scratch.\n\n# Conclusion\n\nNow you should have a better conceptual understanding of the primary web technologies, what they do, and how they work together to create the internet that we see and use every day. Once you learn the basics of HTML, CSS, and JavaScript, you will have a firm foundation to build on to create your own websites and applications.\n\nYou can also read more about how your browser understands and utilizes HTML and CSS in order to display content and handle user interaction under-the-hood on [another post on the site](/posts/understanding-the-dom/).\n\nFinally, you\'re always able to [join our Discord](https://discord.gg/FMcvc6T) if you have any questions or comments while you\'re learning. All are welcome!\n',
		},
		{
			title: "Introduction to Web Accessibility (A11Y)",
			description:
				"Accessibility allows as many people to use your product as possible. That, in turn, generates more profit. Here's how to improve it on web.",
			published: "2021-05-30T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["accessibility", "webdev"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/introduction-to-web-accessibility-a11y/",
			slug: "intro-to-web-accessability",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Introduction to Web Accessibility (A11Y)",
				description:
					"Accessibility allows as many people to use your product as possible. That, in turn, generates more profit. Here's how to improve it on web.",
				published: "2021-05-30T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["accessibility", "webdev"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/introduction-to-web-accessibility-a11y/",
			},
			contentMeta:
				'\nIf you’ve come across this article but haven\'t heard about web accessibility (often shortened to "A11Y") before, that\'s okay. We\'re all learning at different speeds and come across new things all the time. That said, accessibility is a critical component of any frontend engineer\'s responsibilities. We implore you to explore what that means, not just in this blog post but beyond with your teams and communities.\n\nFirst, let\'s define what "accessibility" is. Accessibility in engineering is ["the process of creating products that are usable by people with the widest possible range of abilities."](https://dl.acm.org/doi/10.1145/2596695.2596719)\n\nOne example of accessibility is the needs of blind or low-vision users. They may rely on [screen readers](https://www.afb.org/blindness-and-low-vision/using-technology/assistive-technology-products/screen-readers) or other assistive technologies, which allows them to navigate their computer with their other senses. These methods may be used in tandem with the visual experience for some or used independently to navigate their computer auditorily or tactilely.\n\nAnother example is users with limited mobility who utilize specialty hardware, such as buttons, to trigger different behaviors on their machine.\n\n> If you\'re a visual learner who would like to see some short-and-quick workflows from users like this, [one of Apple\'s ads](https://www.youtube.com/watch?v=XB4cjbYywqg) displays a few use cases that proper accessibility support can enable.\n\nSomething to keep in mind is that these disabilities may not be permanent. For instance, if you fall and break your arm, you may be only using one arm while healing. Likewise, there are situational impairments as well. If you\'re holding a cup of coffee in one hand, you\'ll only be using the other for device usage. Here\'s a chart that outlines a few more of these examples:\n\n<table>\n\t<tr>\n\t  <th></th>\n\t\t<th scope="col">Permanent</th>\n\t\t<th scope="col">Temporary</th>\n\t\t<th scope="col">Situational</th>\n\t</tr>\n\t<tr>\n\t\t<th scope="row">Touch</th>\n\t\t<td><img src="./one_arm.png" style="height: 200px"/><br/>One arm</td>\n\t\t<td><img src="./arm_injury.png" style="height: 200px"/><br/>Arm injury</td>\n\t\t<td><img src="./new_parent.png" style="height: 200px"/><br/>New parent</td>\n\t</tr>\n\t<tr>\n\t\t<th scope="row">See</th>\n\t\t<td><img src="./blind.png" style="height: 200px"/><br/>Blind</td>\n\t\t<td><img src="./cataract.png" style="height: 200px"/><br/>Cataract</td>\n\t\t<td><img src="./distracted_driver.png" style="height: 200px"/><br/>Distracted driver</td>\n\t</tr>\n\t<tr>\n\t\t<th scope="row">Hear</th>\n\t\t<td><img src="./deaf.png" style="height: 200px"/><br/>Deaf</td>\n\t\t<td><img src="./ear_infection.png" style="height: 200px"/><br/>Ear infection</td>\n\t\t<td><img src="./bartender.png" style="height: 200px"/><br/>Bartender</td>\n\t</tr>\n\t<tr>\n\t\t<th scope="row">Speak</th>\n\t\t<td><img src="./non_verbal.png" style="height: 200px"/><br/>Non-verbal</td>\n\t\t<td><img src="./laryngitis.png" style="height: 200px"/><br/>Laryngitis</td>\n\t\t<td><img src="./heavy_accent.png" style="height: 200px"/><br/>Heavy accent</td>\n\t</tr>\n</table>\n\n> Microsoft originally created this chart as part of their [Inclusive Toolkit](https://download.microsoft.com/download/b/0/d/b0d4bf87-09ce-4417-8f28-d60703d672ed/inclusive_toolkit_manual_final.pdf) manual\n\nCreating an application that\'s accessible means that you\'re making a better experience for *all* of your users.\n\nBy making your services accessible to more people, you are most importantly making them more equitable, but there is often a business case for accessibility. Opening your doors to more users may create an additional financial incentive, and many organizations have a legal requirement to meet accessibility guidelines. For instance, the U.S. Federal Government is subject to [Section 508](https://www.section508.gov/manage/laws-and-policies), which requires compliance with [Web Content Accessibility Guidelines (also known as WCAG, which we\'ll touch on later)](#wcag). Likewise, private US companies may be subject to compliance due to the "Americans with Disabilities Act" (shortened to "ADA"). The U.S. isn\'t the only country with these requirements, either. According to [WCAG\'s reference page for various legal laws](https://www.w3.org/WAI/policies/), there are at least 40 such laws in place around the world.\n\n> Please note that we are _not_ giving legal advice. This article is simply meant for educational purposes for individuals. Consult legal authorities for the appropriate jurisdiction\n\nAccessibility isn\'t a pure science, however. If you aren’t a user of assistive technology, this may be an abstract idea at first. However, think of it like this: the colors an app uses or a button\'s visual placement may convey different messages and meanings depending on their context. This same problem applies to users of screen-readers and other accessible tech as well, just with different constraints. If the screen is visually cluttered, the content may be more difficult to read. Likewise, different accessibility methods will lead to different experiences for users of assistive technology. In both of these scenarios, there may not be objectively correct answers - some may prefer a button placed visually to the left, while others might advocate for it on the right. Similarly, how something is read using a screen reader may make sense to some, but might be confusingly expressed to others.\n\n# Sensible Standards {#wcag}\n\nWhile accessibility has some levels of subjectivity, it\'s important to note that there _are_ standards surrounding web application\'s accessibility support. ["Web Content Accessibility Guidelines"](https://www.w3.org/WAI/) (shortened to "WCAG") are guidelines to follow when considering your app\'s accessibility.  These guidelines are published by a subgroup of the [World Wide Web Consortium](https://www.w3.org/) (shortened to "W3C"), the main international standards organization for the Internet. WCAG acts as the de-facto standard for accessibility guidelines.\n\nThere are different scales of accessibility as well. [WCAG includes three different levels of conformance](https://www.w3.org/WAI/WCAG2AA-Conformance):\n\n> - Level A is the minimum level.\n> - Level AA includes all Level A and AA requirements. Many organizations strive to meet Level AA.\n> - Level AAA includes all Level A, AA, and AAA requirements.\n\nMeeting AA requirements is typically seen as a good commitment to accessibility, but AAA will open more doors to your users and is the gold standard for accessible user experience. \n\nFar from a comprehensive list, A requires:\n\n- [Non-text content to have alternative text](https://www.w3.org/TR/WCAG21/#non-text-content)\n- [Automatically moving elements (such as GIFs) must be able to be paused](https://www.w3.org/TR/WCAG21/#pause-stop-hide)\n\nMeanwhile, AA covers things like:\n\n- Screen reader experience\n- [Minimum contrast guidelines](#contrast)\n- [Text resize support](#font-resize)\n- [Video captions](https://www.w3.org/TR/WCAG21/#captions-live)\n- [Basic support for keyboard navigation](#keyboard)\n\nFinally, AAA includes support for:\n\n- [Enhanced contrast](https://www.w3.org/TR/WCAG21/#contrast-enhanced)\n- [Reduced/restricted animations](https://www.w3.org/TR/WCAG21/#animation-from-interactions)\n- [Video sign language support](https://www.w3.org/TR/WCAG21/#sign-language-prerecorded)\n- [Full website functionality with keyboard](#keyboard)\n\nInterested in reading the full list? [Read the quick reference to WCAG 2.1](https://www.w3.org/WAI/WCAG21/quickref/).\n\n# Smartly using Semantic HTML Tags {#html-semantic-tags}\n\nOne of the easiest things you can do for your application\'s accessibility is to use semantic HTML tags. \n\nLet\'s say we have HTML to display fruits in a list:\n\n```html\n<!-- Inaccessible -->\n<div>\n    <div>Orange</div>\n    <div>Banana</div>\n    <div>Grapefruit</div>\n</div>\n```\n\nWhile this will display the contents, and you may be able to use CSS to add styling to make this look like a list, the browser has no way of knowing that this is a list. This is reflected in how screen readers read that HTML output.\n\n<video src="./div.mp4" width="100%" height="auto" preload="auto" title="Voiceover reading of the content above"  controls></video>\n\nLikewise, search engine crawlers won\'t know that this is a list. If you\'re only using `div` tags as far as Google\'s concerned, you have no lists, no headings, nothing. This makes the page significantly less engaging and therefore rank more poorly.\n\nLet\'s compare that to using the correct HTML tags for a list.\n\n```html\n<!-- Accessible -->\n<ul aria-label="Fruits">\n    <li>Orange</li>\n    <li>Banana</li>\n    <li>Grapefruit</li>\n</ul>\n```\n\n<video src="./semantic.mp4" width="100%" height="auto" preload="auto" title="Voiceover reading of the content above" controls></video>\n\nAs you may be able to hear, this screen reader is now able to read out that it\'s a list and its name. It makes navigation of that list easier for those users by allowing them to quickly skip to the next list item and hear the index of an item in the list.\n\nNot only does this enhance the experience of assistive technology users browsing your list, but because search engine crawlers rely on HTML tags to inform what\'s what, your site may rank better in search engine queries as well! This is a massive boon to your site\'s SEO score.\n\n# Understand `aria-` properties {#aria}\n\nIn our previous example, we used an HTML attribute [`aria-label`](https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/ARIA_Techniques/Using_the_aria-label_attribute) on our `ul`. [ARIA is collection of HTML attributes that allow you to enhance the accessibility in applications](https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA). That said, _**it is highly encouraged to use the suggested HTML tags instead of `aria` attributes whenever possible**_. Think of `aria` as a complex low level API that can enhance your experience when done properly, but drastically harm user experience when improperly utilized.\n\n> No ARIA is better than Bad ARIA\n> [WCAG WAI-ARIA Authoring Practices](https://www.w3.org/TR/wai-aria-practices-1.1/#no_aria_better_bad_aria)\n\nA super small small subsection of `aria-` attributes includes:\n\n- [`aria-labelledby`](https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/ARIA_Techniques/Using_the_aria-labelledby_attribute) — Associate the element with another element\'s text as the label \n- `aria-expanded` — A Boolean value meant to communicate when a dropdown is expanded\n- `aria-valuemin` — The minimum allowed value in a numerical input\n- `aria-valuemax` — The maximum allowed value of a numerical input\n\nAdditional to `aria` props, [the `role` property](https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/ARIA_Techniques#roles) tells the browser what an element\'s intended purpose is, thus changing its behavior with accessible tech. Again, this is a highly advanced (and often incorrectly deployed) API for complex apps. To learn more, [read through Mozilla\'s ARIA basics article.](https://developer.mozilla.org/en-US/docs/Learn/Accessibility/WAI-ARIA_basics)\n\n# Classy CSS {#css}\n\nWhile HTML relays a significant amount of information to assistive technologies like screen readers, it\'s not the only thing used to inform those tools. Certain CSS rules can change the functionality as well. After all, screen readers (and other tools) don\'t look through the source code of a website. Instead, they\'re looking at [the accessibility tree](https://developers.google.com/web/fundamentals/accessibility/semantics-builtin/the-accessibility-tree): a modified version of the DOM. The accessibility tree and the DOM are both constructed by the browser from the website\'s source code. \n\n> Want to learn more about the DOM, how the browser constructs it, and what it\'s used for internally? [This article helps explain this in detail](https://unicorn-utterances.com/posts/understanding-the-dom/).\n\nBecause the DOM is influenced by CSS, it impacts the accessibility tree as well. For example, `display: none` removes the element from the [accessibility tree](https://benmyers.dev/blog/accessibility-tree/) and from the browsers visual output. This means that screen readers won\'t read the contents of an element with that rule applied. However, `visibility: hidden`  or `width: 0px` will hide an element visually, but will still be read by screen readers.\n\nFor this reason, there\'s a frequently used CSS class used to hide elements visually but not from screen readers:\n\n```css\n.sr-only {\n\tposition: absolute;\n\twidth: 1px;\n\theight: 1px;\n\tpadding: 0;\n\tmargin: -1px;\n\toverflow: hidden;\n\tclip: rect(0, 0, 0, 0);\n\twhite-space: nowrap;\n\tborder-width: 0;\n}\n```\n\n There are many ways which CSS can influence assistive technologies. [Ben Myers covers this more in his blog post](https://benmyers.dev/blog/css-can-influence-screenreaders/).\n\n# Contrast is Cool {#contrast}\n\nWhile screen readers are imperative to frontend accessibility testing, a site\'s visuals can help provide a good experience for many users. While a certain color palette may be aesthetically pleasing, it may be difficult to read for a colorblind user. Colorblind users aren\'t the only ones impacted, however.\n\nWhile there are various reasons a user might not be able to see weakly contrasted color, everyone is different. See if you can distinguish the text from the background in the displayed image with poor contrast:\n\n<img alt="Dark gray text on a black background" src="./color_fail.png" style="max-width: 600px; width: 100%"/>\n\nNow, compare that to highly contrasting colors: \n\n<img alt="White text on a black background" src="./color_pass.png" style="max-width: 600px; width: 100%"/>\n\nThe contents are not only easier to distinguish from the background, but it\'s made easier to focus on as a result of the increased contrast.\n\nThis said, not all contrasts are the same. Per [WCAG guidelines](#wcag), you may have a different ratio of contrast for different compliance levels. These contrast ratios depend on both font size as well as compliance level.\n\n![Light grey text passing AA for large text, but not small text](./pass_aa_large.png)\n\nIn this example you can see that the text passes the WCAG AA requirements for large text, but fails the same requirements for small text.\n\n# Fantastic Fonts {#font-resize}\n\nOne of the most widely used accessibility features is font scaling. While many browsers default to a font size of `16px`, the user is actually able to change settings on their device to configure websites to use a larger font size.\n\nMany phones using iOS and Android allow users to change the font size on their mobile devices. This feature is so commonplace that it often prompts users to change this setting when the phone is being set up.\n\n<div style="display: flex; justify-content: space-around">\n    <figure>\n\t\t<img src="./ios_text_size.png"  style="height: 300px"/>            \n        <figcaption>\n            iOS font size settings screen\n        </figcaption>\n    </figure>\n    <figure>\n        <img src="./android_text_size.png"  style="height: 300px"/>\n        <figcaption>\n            Android font size settings screen\n        </figcaption>\n    </figure>\n</div>\n\nNot only do you have these settings on mobile devices, but they\'re available on desktop as well. \n\nUsing Chrome, go to [your settings page](chrome://settings/?search=font+size), and you should be able to set your font size.\n\n![Font settings in Chrome](./chrome_font_size.png)\n\nYou can do the same in Firefox in [your preferences](about:preferences#general).\n\n![Font settings in Firefox](./firefox_font_size.png)\n\n\n## Implementation {#font-rem}\n\nWhile browsers have the ability to set the font size, if you\'re using `px`, `vw`, `vh`, or other unit values for your fonts, the browser will not update these font sizes for you. In order to have your application rescale the font size to match the browser settings, you\'ll need to use the `rem` unit.\n\nYou can think of `rem` as a multiplier to apply to the default font size. When the browser\'s font size is set to `16px`:\n\n- `1rem` will be `16px` (1 * 16px)\n- `1.5rem` will be `24px` (1.5 * 16px)\n- `3rem` will be `48px` (3 * 16px)\n\nLikewise, when the browser\'s font size is set to `20px`:\n\n- `1rem` will be `20px` (1 * 20px)\n- `1.5rem` will be `30px` (1.5 * 20px)\n- `3rem` will be `60px` (3 * 20px)\n\n> Something to keep in mind is that `rem` is a _relative_ font size. It\'s relative to the root element\'s font size. _This means that you cannot set a default `px` value font size in CSS to the `<html>` tag or to the `:root` selector, as it will disable font scaling, even if the rest of your page is using `rem` values._\n\nIt\'s highly encouraged to keep body text size standardized around the `1rem` value. While this may seem like a frustrating limitation at first, see it from the user\'s perspective. Font sizes can, of course, be larger than this for things like headers or callouts, but the primary content of your site should default to this sizing.\n\nSay site "A" sets their font size to `1rem`, and site "B" sets their font size to `0.8rem`. When the user switches from "A" to "B", the font size drastically decreases, requiring the user to change their font size. Then, when they switch back to site "A", they\'re left with too large of font size. By respecting the user\'s setting of font size, you\'re ensuring that their experience jumping from site to site is more consistent and a nicer experience.\n\nWant to learn more about `rem` and font sizing? [Take a look at this in-depth blog post that covers even more](https://www.24a11y.com/2019/pixels-vs-relative-units-in-css-why-its-still-a-big-deal/).\n\n# Keyboard is King {#keyboard}\n\nJust as developers have preferences with keyboard or mouse, so too do your end-users. Some people may only be able to utilize the keyboard to navigate the digital world. Not only is keyboard navigation critical for accessibility, but it enables power users of your application to be more efficient as well.\n\nWhile you may immediately think of "keyboard shortcuts" to trigger different applications, it\'s often easy to forget about smaller interactions as well.\n\n> This isn\'t to say that keyboard shortcuts aren\'t helpful - they can serve as shorthand for operations that might otherwise take considerable more effort using only the keyboard. Do consider implementing them in your app when they make sense.\n\nConsider a site with a large number of navigation links like [The New York Times](https://www.nytimes.com/).\n\n![The initial homepage of New York Times](./nyt_initial.png)\n\nTheir site has 30+ individual items in their header that you\'d need to tab through in order to get to the main portion of the website. Safe to say that most users of the site are likely to want to access that main content quickly. Additionally, users that rely on a screen reader that aren\'t familiar with the site\'s layout wouldn\'t know when to stop tabbing without slogging through every item in the header.\n\nAs such, many sites (including New York Times) include a "Skip to Content" button that doesn\'t become visible until you\'ve tabbed into it. Unless you were navigating the site by keyboard, you wouldn\'t know it was there.\n\n![A "skip to content" button shown on the New York Times\' site](./nyt_skip.png)\n\nThis is far from the only considerations that should be made when considering a site\'s keyboard navigability, but is a prime example of a solution to a problem that might not be immediately obvious to users that primarily use the mouse.\n\n## Focus Indicators {#focus-indicator}\n\nSomething to keep in mind is that not all keyboard users use screen readers. Because of this, it\'s important to have an outline around the element you\'re currently focused on. Without this outline, how would a sighted person know where they are on the page?\n\nImagine trying to use your mouse without being able to see your cursor or hover effects on elements — it would be nearly impossible to know what you were doing!\n\nLuckily, the browser provides a default outline out-of-the-box. That said, some developers unfamiliar with accessibility requirements may disable the outline, as they "don\'t like the look of the outline when using a mouse" or "think the outline is too obtrusive visually". They often do this by adding an `outline: none` rule to the element, which breaks the behavior of the browser.\n\nInstead, it\'s suggested to either:\n\n- Style the outline to be more consistent with your project\'s visuals (similarly to how The New York times made their outline styling black to match their site)\n- Style the element in some other way to indicate focus (avoid only using colors to differentiate, as colorblind users may not be able to distinguish the differences)\n- Use JavaScript to disable the behavior when mouse-events are detected (and re-enable if keyboard events are detected)\n\nTo learn more about the focus indicator and how to work alongside it, [check out this blog post from The A11Y Project](https://www.a11yproject.com/posts/2013-01-25-never-remove-css-outlines/).\n\n# Humans Can’t Be Automated {#no-automation}\n\nThe perception for some is that accessibility is something that can be 1:1 adapted from an existing design. This is often untrue. You may want to add a "Skip to contents" button that only shows up with tabbing for some sites, while the visual order and tab order might need to be flipped for a better experience for screen-reader users. Remember, accessibility is a form of user experience that has to be crafted by hand. Each decision has nuance to it, and there are rarely objectives of which experience is better than others. Because of this, many companies will have dedicated accessibility specialists alongside their design and engineering teams.\n\nYou also need to make sure to [test your application](#testing) as you would any other part of your app. Automation is helpful here, but humans are still critical. We\'ll touch on this more in a future section.\n\nIf anyone is ever advertising to you that your inaccessible project can be made accessible (or prevent lawsuits) without any changes to your codebase, they\'re either lying to you or don\'t understand accessibility.\n\n## Assistance is Amicable {#eslint}\n\nWhile full automation will never be possible for improving a project\'s accessibility, not everyone proposing assistance in the process is trying to sell snake oil. \n\nFor example, [Deque\'s open-source Axe project](https://github.com/dequelabs/axe-core) can help identify issues such as common HTML semantic errors, contrast problems, and more. There are even libraries that help integrate Axe into your project\'s linters, such as one for React called [`eslint-plugin-jsx-a11y`](https://github.com/jsx-eslint/eslint-plugin-jsx-a11y).\n\nHowever, keep in mind that these tools are not infallible and are meant to supplement accessibility experts working with your engineering team, not replace them.\n\n# Test, Test, Test Again {#testing}\n\nTesting is a critical component of any application release. Whether using automated testing solutions or QA teams, they help ensure that your users are getting the best experience possible without regressions in an application\'s behavior.\n\nAs a developer working on the frontend, you should be regularly using an assistive technology like a screen reader to analyze your site and navigating your application [with only your keyboard](#keyboard). This will help enforce the feedback loop between building the functionality and getting it shipped to users. Make it part of your code review process — have other members of your team test with a screen reader as they would visually analyze new features.\n\nYou\'re also able to include automated tests that will help with accessibility regressions. Either using [integration tests](https://kentcdodds.com/blog/write-tests) or end-to-end tests, you can use real-world behavior such as "search for an element with this label" or "tab over to this button" to ensure your application is functioning as intended.\n\nAs mentioned in [a previous section](#no-automation), the process to make your app accessible cannot be fully automated. This extends to testing as well. While real-world automated tests are fine and well, you need someone to experience the application on a broader scale to make sure the experience is as fluid as it can be. While a specific component might be accessible by default, perhaps in specific usages, it falls flat. [Displaying an accessibility statement](https://www.w3.org/WAI/planning/statements/) while transforming your users\' reported problems into bug tickets and performing user testing with disabled users are great ways to close the loop with the real people affected.\n\n# Fantastic Features {#features}\n\nWhile there is plenty you can do to make existing functionality accessibility friendly, it\'s often forgotten that a strongly accessible app may opt to add specific functionality for its users with disabilities.\n\nSome great examples of things like this are sites with lots of user-generated content. For example, Twitter allows its users to [add alternative (alt) text to their uploaded images and GIFs](https://help.twitter.com/en/using-twitter/picture-descriptions). Likewise, YouTube has the ability to [add subtitles and captions](https://support.google.com/youtube/answer/2734796?hl=en) to uploaded videos on their platform. \n\nOftentimes, you\'ll find that these features benefit everyone, not just assistive technology users. You may want to watch a video in a crowded area; with closed captions, that\'s a much easier sell than trying to hear over others and interrupting everyone around you.\n\n# Radical Research {#further-reading}\n\nWhile we\'ve done our best to have this article act as a starting point for accessibility, there\'s always more to cover.  Let\'s talk about some of the ways you can continue learning more.\n\n## Terminology\n\nDuring your journey to learn more, you may run into terms that you\'re not familiar with. Let\'s take a look at some of the more predominant ones. We\'ll start this discussion of terminology with a common question:\n\n> What\'s "A11Y"?\n\nA11Y is [a nymeronym](https://www.a11yproject.com/posts/2017-08-26-a11y-and-other-numeronyms/) which stands for "accessibility". It\'s used as shorthand for the word in conversations about the subject.\n\nSome other terms that might helpful are:\n\n- "UI" — "User interface". The visual styling of an app\n- "UX" — "User experience". The interaction the user has with the app that defines their experience. This extends to assistive technology\n- ["WCAG"](#wcag) — "W3C Accessibility Guidelines", the standard guidelines for applications\' accessibility support\n- "W3C" — "World Wide Web Consortium", the organization that publishes WCAG\n- "ADA" — "Americans with Disabilities Act", regulations in the US for businesses and governments which prohibits discrimination based on disability\n- "Alternative text"/"Alt text" — Short text used to describe images and other non-text assets\n\n## Tools\n\nPeople in need of a screen reader have multiple options at their disposal. Just a few of them include:\n\n- [JAWS](https://www.freedomscientific.com/products/software/jaws/) — An incredibly popular paid Windows screen reader\n- [NVDA](https://www.nvaccess.org/) — A Windows screen reader\n- [VoiceOver](https://www.apple.com/accessibility/vision/)  — The screen reader for iOS and macOS\n- [TalkBack](https://support.google.com/accessibility/android/answer/6283677?hl=en) — The screen reader for Android\n\nIt\'s important to keep in mind that just as browsers may have differing behaviors for CSS or JavaScript, so too may these screen readers. Be sure to test with more than one of them as you would with different browsers.\n\nScreen readers aren\'t the only accessible tech, however. A small example of them might be:\n\n- [Braille Displays](https://www.afb.org/node/16207/refreshable-braille-displays)\n- [Switches](https://axesslab.com/switches/)\n- [Eye tracking](https://en.wikipedia.org/wiki/Eye_tracking#Assistive_technology)\n\n## Additional Resources\n\n- [Google\'s accessibility tips for web developers](https://web.dev/a11y-tips-for-web-dev/)\n- [Apple\'s accessibility guidelines](https://developer.apple.com/design/human-interface-guidelines/accessibility/overview/introduction/)\n- [WebAIM\'s website with a plethora of resources](https://webaim.org/)\n- [The A11Y Project](https://www.a11yproject.com/)\n\nAdditionally, there are a few sites that contain extensive lists of additional resources:\n\n- [A11Y project\'s list of external resources](https://www.a11yproject.com/resources/)\n- [A11Y & Me resource list](https://a11y.me/)\n\n# Conclusion {#conclusion}\n\nWe hope you\'ve enjoyed learning from our accolade-worthy alliterative headlines.\n\nThere are so many things that we wanted to include in this article but couldn\'t. Like most parts of engineering, the field of accessible design and the nuances within can be incredibly complex in fringe scenarios. Getting accessibility in a great place for your users takes active effort - just like any other part of building your app. Because of this, we encourage you to do [further research](#further-reading) on the topic. Don\'t be afraid to ask questions of community members, either! Many in the community are incredibly helpful and friendly.\n\nSpeaking of community, we\'d love to hear your thoughts on this article. Did you learn something from it? Have questions about something accessibility-related? Think we missed something? [Join our Slack community](https://bit.ly/coderpad-slack) and chat with us or [send us a Tweet](https://twitter.com/coderpad)! \n',
		},
		{
			title: "Web Components 101: Vanilla JS",
			description:
				"One of the ways web components differs from a framework is that it works right in the browser. Here's how to build them from scratch.",
			published: "2021-07-15T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["javascript", "html", "webdev"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/intro-to-web-components-vanilla-js/",
			series: "Web Components 101",
			order: 2,
			slug: "intro-to-web-components-vanilla-js",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Web Components 101: Vanilla JS",
				description:
					"One of the ways web components differs from a framework is that it works right in the browser. Here's how to build them from scratch.",
				published: "2021-07-15T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["javascript", "html", "webdev"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/intro-to-web-components-vanilla-js/",
				series: "Web Components 101",
				order: 2,
			},
			contentMeta:
				"\nMany modern web apps today are built using components. While frameworks like React exist to add an implementation, web components seek to make those practices standardized and part of your browser.\n\nIn this article, we’ll touch on what web components are, how we can build them without a framework, and some limitations to keep in mind during development. Later, in a follow-up article, we’ll show how a lightweight framework (such as Lit) can provide quality-of-life improvements for those looking to build larger scale applications.\n\n## What are Web Components?\n\nThere are a lot of misconceptions about what web components even are. While some might assume that it’s simply the ability to make custom elements with dedicated UI, style, and logic in one consolidated place (more on that later), there’s definitely more to it\n\nWeb components are a mix of 3 different web standards that, when utilized together, can offer a viable alternative to using a framework like React which offers similar functionality. These web standards consist of:\n\n1. [Custom elements](https://developer.mozilla.org/en-US/docs/Web/Web_Components/Using_custom_elements) - the ability to create new elements that will provide unique UI and app logic when the related HTML tag is added\n2. [Shadow DOM](https://developer.mozilla.org/en-US/docs/Web/Web_Components/Using_shadow_DOM) - the ability to keep specific elements segmented off from your main document DOM, allowing you to avoid document collision issues\n3. [HTML templates](https://developer.mozilla.org/en-US/docs/Web/Web_Components/Using_templates_and_slots) - elements that allow you to write HTML that is not drawn to the page, but can be used as a template for markup to reuse elsewhere\n\nWhile the Shadow DOM and HTML templates are undoubtedly useful in applications, we’ll be focusing on custom elements today, as we feel they’re the easiest place to start in introducing web components as a whole.\n\n> While these are the only official specifications part of Web Components, they’re often utilized with other JavaScript and browser features to create a cohesive development experience.\n>\n> One of these features often used is [JavaScript Modules](https://v8.dev/features/modules). While the concept of breaking your app into multiple files has been commonplace with bundlers like Webpack for a while, being built into the browser has been game changing.\n\n## What are Custom Elements?\n\nAt their core, custom elements essentially allow you to create new HTML tags. These tags are then used to implement custom UI and logic that can be used throughout your application. \n\n```\n<!-- page.html -->\n\n<!-- These are custom elements, combined to make a page -->\n<page-header></page-header>\n<page-contents></page-contents>\n<page-footer></page-footer>\n```\n\nThese components can be as simple as a styled button or as complex as an entire page of your application, complete with your business logic.\n\nWhile we tend to think of HTML tags as directly mapping to a single DOM element, that’s not always the case with custom elements. For example, the “page-header” tag in the example above might contain “nav” and “a” elements as a list of their children.\n\n![Chrome DevTools showing the page header element expand into multiple tags](./chrome.png)\n\nBecause of this, we’re able to improve an app’s organization by reducing the amount of tags visible in a single file to read with better flow. \n\nBut custom elements aren’t just made up of HTML - you’re able to associate JavaScript logic with these tags as well! This enables you to keep your logic alongside it’s associated UI. Say your header is a dropdown that’s powered by JavaScript. Now you can keep that JavaScript inside of your “page-header” component, keeping your logic consolidated.\n\nFinally, a significant improvement that components provide is composability. You’re able to use these components on different pages, allowing you to keep your header code in sync between pages. This reduces the potential for having variations in standard components - like having multiple differently sized buttons in a page - that might confuse your users. As long as you’re vigilant about utilizing your existing components, you’re able to make your app more consistent this way.\n\n## Lifecycle Methods\n\nWhile many implementations of components have differences, one concept that is fairly universal is “lifecycle methods”. At their core, lifecycle methods enable you to run code when events occur on an element. Even frameworks like React, which haved moved away from classes, still have similar concepts of doing actions when a component is changed in some way.\n\n\nLet’s take a look at some of the lifecycle methods that are baked into the browser’s implementation.\n\nCustom elements have 4 lifecycle methods that can be attached to a component.\n\n| connectedCallback        | Ran when attached to the DOM                                 |\n| ------------------------ | ------------------------------------------------------------ |\n| disconnectedCallback     | Ran when unattached to the DOM                               |\n| attributeChangedCallback | Ran when one of the web component’s attributes is changed. Must explicitly track |\n| adoptedCallback          | Ran when moved from one HTML document to another             |\n\n> While each of them has their uses, we’ll primarily be focusing on the first 3. `adoptedCallback` is primarily useful in niche circumstances and is therefore difficult to make a straightforward demo of.\n\nNow that we know what the lifecycle methods are, let’s see an example of them in action.\n\n### Connection Lifecycles\n\nThe first two lifecycle methods we’ll be talking about are typically used as a pair together: `connectedCallback` and `disconnectedCallback`\n\n`connectedCallback` is ran when a component is mounted onto the DOM. This means that when you want the element to be shown, you can change your `innerHTML`, add event listeners to elements, or do any other kind of code logic meant to setup your component.\n\nMeanwhile, `disconnectedCallback` is run when the element is being removed from the DOM. This is often used to remove event listeners added during the `connectedCallback`, or do other forms of cleanup required for the element.\n\nHere’s a simple web component that renders a header with the text “Hello world”.\n\n```javascript\nclass MyComponent extends HTMLElement {\n  connectedCallback() {\n      console.log(\"I am connecting\");\n      this.innerHTML = `<h1>Hello world</h1>`;\n  }\n\n  disconnectedCallback() {\n      console.log(\"I am leaving\");\n  }\n}\n\ncustomElements.define('my-component', MyComponent);\n```\n\n### Attribute Changed\n\nWhile there are other methods to pass data to an element (which we’ll touch on shortly), the undeniable simplicity of attributes is hard to deny. They’re widely utilized in HTML-spec tags, and most display custom elements should be able to utilize attributes to pass data from a parent trivially.\n\nWhile `attributeChangedCallback` is the lifecycle method used to detect when an attribute’s value is changed, you must tell the component which attributes to track.\n\nFor example, in this example we’re tracking the `message` attribute. If the `message` attribute value changes, it will run `this.render()`. However, any other attribute’s value changing will not trigger `attributeChangedCallback` because nothing else is marked to be tracked.\n\n```javascript\nclass MyComponent extends HTMLElement {\n  connectedCallback() {\n      this.render();\n  }\n\n   // Could also be:\n  // static observedAttributes = ['message'];\n  static get observedAttributes() {\n      return ['message'];\n  }\n\n  attributeChangedCallback(name, oldValue, newValue) {\n      this.render();\n  }\n\n  render() {\n      const message = this.attributes.message.value || 'Hello world';\n      this.innerHTML = `<h1>${message}</h1>`;\n  }\n}\n\ncustomElements.define('my-component', MyComponent);\n```\n\nYou’ll notice that the “`attributeChangedCallback`” receives the name of the attribute changed, it’s previous value, and it’s current value. This is useful for granular manual change detection optimizations.\n\nHowever, utilizing attributes to pass values to a component has its limitations. To explain these limitations, we must first start by talking about serializability.\n\n## Serializability\n\nSerialization is the process of turning a data structure or object into a format that can be stored and reconstructed later. A simple example of serialization is using JSON to encode data.\n\n```javascript\nSON.stringify([\n    {hello: 1},\n    {other: 2}\n])\n\n// \"[{\\\"hello\\\": 1}, {\\\"other\\\":2}]\"\n```\n\nBecause this JavaScript object is simple and only utilizes [primitive data types](https://developer.mozilla.org/en-US/docs/Glossary/Primitive), it’s relatively trivial to turn into a string. This string can then be saved to a file, sent over HTTP to a server (and back), and be reconstructed when the data is needed again.\n\n> This simplicity of serialization to JSON is one reason why JSON is such a popular format for transferring data over REST endpoints.\n\n### Serializing Limitations\n\n\nWhile simple objects and arrays can be serialized relatively trivially, there are limitations. For example, take the following code:\n\n```javascript\nconst obj = {\n    method() {\n        console.log(window);\n    }\n}\n```\n\nWhile this code’s behavior may seem simple to us reading it as developers, think about it from a machine’s perspective.\n\nIf we wanted to send this object to a server from a client remotely with the method intact, how should we do that?\n\n`window`, while available in the browser, is not available in NodeJS, which the server may likely be written in. Should we attempt to serialize the `window` object and pass it along with the method? What about methods on the `window` object? Should we do the same with those methods?\n\nOn the other end of the scale, while `console.log` ***is\\*** implemented in both NodeJS and browsers alike, it’s implemented using native code in both runtimes. How would we even begin to serialize native methods, even if we wanted to? *Maybe* we could pass machine code? Even ignoring the security concerns, how would we handle the differences in machine code between a user’s ARM device and a server’s x86_64 architecture?\n\n\nAll of this becomes a problem before you even consider that your server may well not be running NodeJS. How would you even begin to represent the concept of `this` in a language like Java? How would you handle the differences between a dynamically typed language like JavaScript and C++?\n\n#### Let’s Stringify Some Functions\n\nNow knowing the problems with serializing functions, you may wonder what happens if you run `JSON.stringify()` on `obj`?\n\n```javascript\nconst obj = {\n    method() {\n        console.log(this, window);\n    }\n}\n\nJSON.stringify(obj); // \"{}\"\n```\n\nIt simply omits the key from the JSON string. This is important to keep in mind as we go forward.\n\n### HTML Attribute Strings\n\n\nWhy are we talking about serialization in this article? To answer that, I want to mention two truths about HTML elements.\n\n- HTML attributes are case insensitive\n- HTML attributes must be strings\n\nThe first of these truths is simply that for any attribute, you can change the key casing and it will respond the same. According to HTML spec, there is no difference between:\n\n```html\n<input type=\"checkbox\"/>\n```\n\n\nAnd:\n\n```html\n<input tYpE=\"checkbox\"/>\n```\n\n\nThe second truth is much more relevant to us in this discussion. While it might seem like you can assign non-string values to an attribute, they’re always parsed as strings under-the-hood.\n\nYou might think about being tricky and using JavaScript to assign non-string values to an attribute:\n\n```javascript\nconst el = document.querySelector('input');\nel.setAttribute('data-arr', [1, 2, 3, 4]);\n```\n\nHowever, the attribute’s assigned value may not match your expectations:\n\n```html\n<input type=\"checkbox\" data-arr=\"1,2,3,4\">\n```\n\nYou’ll notice the lack of brackets in the attribute. This is because JavaScript is implicitly running `toString` on your array, which turns it into a string before assigning it to the attribute.\n\nNo matter how you spin it - your attribute will be a string.\n\nThis is also why when trying to use attributes for non-string values you may run into otherwise unexpected behavior. This is true even for built-in elements, such as `input`.\n\n```html\n<input type=\"checkbox\" checked=\"false\"/>\n```\n\nWithout being aware of this HTML attribute limitation, you may well expect the checkbox to be unchecked. However, when rendered, it appears checked.\n\nThis is because you’re not passing the boolean `false`, you’re passing the string `\"false\"`, which is (confusingly) truthy.\n\n```javascript\nconsole.log(Boolean(\"false\")); // true\n```\n\nSome attributes are smart enough to know when you’re intending to assign a number or other primitive value to an element via an attribute, but the implementation internally might look something like:\n\n```javascript\nclass NumValidator extends HTMLElement {\n  connectedCallback() {\n      this.render();\n  }\n\n  static get observedAttributes() {\n      return ['max'];\n  }\n\n  attributeChangedCallback(name, oldValue, newValue) {\n      this.render();\n  }\n\n  render() {\n      // Coerce \"attribute.value\" to a number. Again, attributes\n      // can only be passed as a string\n      const max = Number(this.attributes.max.value || Infinity);\n      // ...\n  }\n}\n```\n\nWhile this tends to be the extent of HTML element’s deserializing of attributes, we can extend this functionality much further.\n\n## Pass Array of Strings\n\nAs we touched on shortly, if we simply try to pass an array to an attribute using JavaScript’s `setAttribute`, it will not include the brackets. This is due to `Array.toString()`’s output.\n\nIf we attempted to pass the array ``[\"test\", \"another\", \"hello\"]`` from JS to an attribute, the output would look like this:\n\n```javascript\n<script>\n  class MyComponent extends HTMLElement {\n      connectedCallback() {\n          this.render();\n      }\n\n      static get observedAttributes() {\n          return ['todos'];\n      }\n\n      attributeChangedCallback(name, oldValue, newValue) {\n          this.render();\n      }\n\n      render() {\n          const todos = this.attributes.todos.value || '';\n          this.innerHTML = `<p>${todos}</p>`;\n      }\n  }\n\n  customElements.define('my-component', MyComponent);\n</script>\n\n<my-component id=\"mycomp\" todos=\"test,another,hello\"></my-component>\n```\n\nBecause of the output of `toString`, it’s difficult to convert the attribute value back into a string. As such, we only display the data inside of a `<p>` tag. But lists don’t belong in a single paragraph tag! They belong in a `ul` with individual `li`s per item in the list. After all, [semantic HTML is integral for an accessible website](https://coderpad.io/blog/introduction-to-web-accessibility-a11y/)!\n\n\nLets instead use `JSON.stringify` to serialize this data, pass that string to the attribute value, then deserialize that in the element using `JSON.parse`.\n\n```html\n<script>\n  class MyComponent extends HTMLElement {\n      connectedCallback() {\n          this.render();\n      }\n\n      static get observedAttributes() {\n          return ['todos'];\n      }\n\n      attributeChangedCallback(name, oldValue, newValue) {\n          this.render();\n      }\n\n      render() {\n          const todosArr = JSON.parse(this.attributes.todos.value || '[]');\n          console.log(todosArr);\n          const todoEls = todosArr.map(todo => `<li>${todo}</li>`).join('\\n');\n          this.innerHTML = `<ul>${todoEls}</ul>`;\n      }\n  }\n\n  customElements.define('my-component', MyComponent);\n</script>\n\n<my-component todos=\"[&quot;hello&quot;,&quot;this&quot;]\">\n</my-component>\n```\n\nUsing this method, we’re able to get an array in our `render` method. From there, we simply `map` over that array to create `li` elements, then pass that to our `innerHTML`.\n\n## Pass Array of Objects\n\n\nWhile an array of strings is a straightforward demonstration of serializing attributes, it’s hardly representative of real-world data structures. \n\n\nLet’s start working towards making our data more realistic. A good start might be to turn our array of strings into an array of objects. After all, we want to be able to mark items “completed” in a todo app.\n\nFor now, we’ll keep it small, and we’ll grow it later. Let’s keep track of the “name” of the todo item, and whether or not it’s been completed:\n\n```javascript\nconst data = [{name: \"hello\", completed: false}];\n```\n\nLet’s take a look at how we can display this in a reasonable manner using our custom element:\n\n```html\n<script>\n  class MyComponent extends HTMLElement {\n      connectedCallback() {\n          this.render();\n      }\n\n      static get observedAttributes() {\n          return ['todos'];\n      }\n\n      attributeChangedCallback(name, oldValue, newValue) {\n          this.render();\n      }\n\n      render() {\n          const todosArr = JSON.parse(this.attributes.todos.value || '[]');\n          const todoEls = todosArr\n              .map(todo => `\n              <li>                 \n                <!-- checked=”false” doesn’t do what you might think -->\n                <input type=\"checkbox\" ${todo.completed ? 'checked' : ''}/>\n                ${todo.name}\n              </li>\n          `)\n              .join('\\n');\n          this.innerHTML = `<ul>${todoEls}</ul>`;\n      }\n  }\n\n  customElements.define('my-component', MyComponent);\n</script>\n\n<my-component\n  id=\"mycomp\"\n  todos=\"[{&quot;name&quot;:&quot;hello&quot;,&quot;completed&quot;:false}]\">\n</my-component>\n```\n\n\n\n> Remember, checked=”false” will leave a checkbox checked. This is because “false” is a truthy string. Reference our “serializing limitations” sections for more reading.\n\nNow that we’re displaying these checkboxes, let’s add a way to toggle them! \n\n```javascript\nvar todoList = [];\n\nfunction toggleAll() {\n  todoList = todoList.map(todo => ({...todo, completed: !todo.completed}));\n  changeElement();\n}\n\nfunction changeElement() {\n  const compEl = document.querySelector('#mycomp');\n  compEl.attributes.todos.value = JSON.stringify(todoList);     \n}\n```\n\n\nNow, all we need to do is run the function “toggleAll” on a button press and it will update the checkboxes in our custom element.\n\nNow that we have a way to toggle all checkboxes, let’s look at how we can toggle individual todo items.\n\n## Pass Objects with Functions\n\nWhile there are many ways to have user input in a custom element interact with a parent’s data set, let’s store a method in each todo object and pass it into the custom element.\n\nThis pattern follows best practices for components by keeping the data passing unidirectional. In the past, we’ve touched on how to [keep your components unidirectional](https://coderpad.io/blog/master-react-unidirectional-data-flow/) for React and Web Components alike.\n\nLet’s change a todo object to reflect something similar:\n\n```javascript\ntodoList.push({\n  name: inputEl.value,\n  completed: false,\n  id: todoId,\n  onChange: () => {\n    toggleTodoItem(todoId)\n  }\n});\n```\n\nThen, we’ll simply implement our `toggleTodoItem` method using the ID to modify the related todo object:\n\n```javascript\nfunction toggleTodoItem(todoId) {\n  thisTodo = todoList.find(todo => todo.id == todoId);\n  thisTodo.completed = !thisTodo.completed;\n  changeElement();\n}\n\nfunction changeElement() {\n  const compEl = document.querySelector('#mycomp');\n  compEl.attributes.todos.value = JSON.stringify(todoList);\n}\n```\n\nWith these changes, we have all of the logic we need from our parent to handle the checkbox logic. Now we need to update our custom element to trigger the `onChange` method when the checkbox is checked. In order to bind an event listener the “input” element, we need to access the underlying [HTMLElement](https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement) reference. To do this, we’ll need to migrate away from the `innerHTML` logic we were using previously in favor of `document.createElement`.\n\n```javascript\nrender() {\n  this.clear();\n\n  // Create list element\n  const todosArr = JSON.parse(this.attributes.todos.value || '[]');\n  const todoEls = todosArr\n      .map(todo => {\n          // Use `createElement` to get access to the element. We can then add event listeners\n          const checkboxEl = document.createElement('input');\n          checkboxEl.type = \"checkbox\";\n\n          // This doesn't work, we'll explain why shortly\n          checkboxEl.addEventListener('change', todo.onChange);\n\n          checkboxEl.checked = todo.completed;\n\n          const liEl = document.createElement('li');\n          liEl.append(checkboxEl);\n          liEl.append(todo.name);\n          return liEl;\n      });\n\n  const ulEl = document.createElement('ul');\n  for (const liEl of todoEls) {\n      ulEl.append(liEl);\n  }\n\n  // Add header. This should update to tell us how many items are completed\n  const header = document.createElement('h1');\n  header.innerText = todosArr.filter(todo => todo.completed).length;\n\n  // Reconstruct logic\n  this.append(header);\n  this.append(ulEl);\n}\n```\n\nAwesome! Now we’ve made all of the changes required, let’s see if it all works together!\n\n[\n](https://app.coderpad.io/sandbox?question_id=181066)Oh… Weird… While our checkboxes seem to be updating, our `h1` is not. What’s more, if we look in our developer console, we don’t see the `console.log`s we would expect to see during a re-render.\n\nWhy is that?\n\nWell, as we mentioned in our section about serialization limitations, functions are not serializable. Because of this, when an object with methods are passed to `JSON.parse`, those keys are removed. When we’re adding our event listener, the function is `undefined`, and therefore doesn’t do anything.\n\n```javascript\ncheckboxEl.addEventListener('change', todo.onChange); // onChange is undefined\n```\n\nThe checkbox’s state visually updating without being reflected in our data is an example of a misalignment between the DOM and the data we used to build the DOM.\n\nHowever, we can verify that our code is correct outside of serialization issues. If we change that line of code to utilize the global function `toggleTodoItem` directly, it functions as expected:\n\n```javascript\ncheckboxEl.addEventListener('change', () => toggleTodoItem(todo.id))\n```\n\n> Update this line of code in the sandbox above to see the correct behavior!\n\nWhile this works for our current setup, one of the advantages of building custom elements is the ability to split out your application to multiple files in order to keep your app’s codebase organized. As soon as `toggleTodoItem` is no longer in the same scope as the custom element, this code will break.\n\nIf this isn’t a good long-term solution, what can we do to fix our issue with serialization?\n\n## Pass via Props, not Attributes\n\nAttributes provide a simple method of passing primitive data to your custom elements. However, as we’ve demonstrated, it falls flat in more complex usage due to the requirement to serialize your data. \n\nKnowing that we’re unable to bypass this limitation using attributes, let’s instead take advantage of JavaScript classes to pass data more directly.\n\nBecause our components are classes that extend `HTMLElement`, we’re able to access our properties and methods from our custom element’s parent. Let’s say we want to update `todos` and render once the property is changed.\n\nTo do this, we’ll simply add a method to our component’s class called “`setTodos`”. This method will then be accessible when we query for our element using `document.querySelector`. \n\n```javascript\nclass MyComponent extends HTMLElement {\n  todos = [];\n\n  connectedCallback() {\n      this.render();\n  }\n\n  setTodos(todos) {\n      this.todos = todos;\n      this.clear();\n      this.render();\n  }\n\n  render() {\n      // ...\n  }\n}\n\n// ...\n\nfunction changeElement() {\n  const compEl = document.querySelector('#mycomp');\n  compEl.setTodos(todoList);\n}\n```\n\nNow, if we toggle items in our todo list, our `h1` tag updates as we would expect: we’ve solved the mismatch between our DOM and our data layer!\n\nBecause we’re updating the *properties* of our custom elements, we call this “passing via properties”, which solves the serialization issues of “passing via attributes”.\n\nBut that’s not all! Properties have a hidden advantage over attributes for data passing as well: memory size.\n\nWhen we were serializing our todos into attributes, we were duplicating our data. Not only were we keeping the todo list in-memory within our JavaScript, but the browser keeps loaded DOM elements in memory as well. This means that for every todo we added, not only were we keeping a copy in JavaScript, but in the DOM as well (via attribute string).\n\n\nBut surely, that’s the only way memory is improved when migrating to properties, right? Wrong!\n\nBecause keep in mind, on top of being loaded in-memory in JS in our main `script` tag, and in the browser via the DOM, we were also deserializing it in our custom element as well! This meant that we were keeping a *third* copy of our data initialized in-memory simultaneously!\n\nWhile these performance considerations might not matter in a demo application, they would add significant complications in production-scale apps.\n\n## Conclusion\n\nWe’ve covered a lot today! We’ve introduced some of the core concepts at play with web components, how we’re able to best implement various functionality, and the limitations of the DOM.\n\nWhile we spoke a lot about passing data by attributes vs. properties today, there are pros and cons to both. Ideally, we would want the best of both worlds: the ability to pass data via property in order to avoid serialization, but keep the simplicity of attributes by reflecting their value alongside the related DOM element.\n\n\nSomething else we’ve lost since the start of this article is code readability in element creation. Originally, when we were using `innerHTML`, we were able to see a visual representation of the output DOM. When we needed to add event listeners, however, we were required to switch to `document.createElement`. Preferably, we could attach event listeners without sacrificing the in-code HTML representation of our custom element’s rendered output.\n\nWhile these features may not be baked into the web component specifications themselves, there are other options available. In our next article, we’ll take a look at a lightweight framework we can utilize to build better web components that can integrate with many other frontend stacks!\n",
		},
		{
			title:
				"Introduction to Android: Contexts, Intents, and the Activity lifecycle",
			description:
				"A basic overview of the main components of an Android app and how they interact with each other and the Android system",
			published: "2019-08-22T05:12:03.284Z",
			authors: ["fennifith"],
			tags: ["android"],
			attached: [],
			license: {
				id: "publicdomain-zero-1",
				footerImg: "https://licensebuttons.net/p/zero/1.0/88x31.png",
				licenceType: "Public Domain",
				explainLink: "https://creativecommons.org/publicdomain/zero/1.0/",
				name: "CC0 1.0 Universal (CC0 1.0) Public Domain Dedication",
				displayName: "Public Domain",
			},
			slug: "introduction-to-android-framework",
			locale: "en",
			authorsMeta: [
				{
					id: "fennifith",
					name: "James Fenn",
					firstName: "James",
					lastName: "Fenn",
					description:
						"Enjoys writing software on loud keyboards. Starts too many projects. Consumes food.",
					socials: { twitter: "fennifith", github: "fennifith" },
					pronouns: "he",
					profileImg: "./fennifith.jpg",
					color: "#0091EA",
					roles: ["developer", "author", "community"],
					profileImgMeta: {
						height: 400,
						width: 400,
						relativePath: "./fennifith.jpg",
						relativeServerPath: "/content/data/fennifith.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\fennifith.jpg",
					},
					rolesMeta: [
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title:
					"Introduction to Android: Contexts, Intents, and the Activity lifecycle",
				description:
					"A basic overview of the main components of an Android app and how they interact with each other and the Android system",
				published: "2019-08-22T05:12:03.284Z",
				authors: ["fennifith"],
				tags: ["android"],
				attached: [],
				license: "publicdomain-zero-1",
			},
			contentMeta:
				'\nThis is a basic summary of the different components of Android and what they can be used for. It\nis written with the assumption that you already have basic knowledge about Android development,\nsuch as Java programming and the basic construction of a simple Android app (e.g. `Activity`\nclasses, the `AndroidManifest.xml`, and layout files).\n\nIf you are completely new to Android development, I would recommend following through Android\'s\n["Build your first app"](https://developer.android.com/training/basics/firstapp/) tutorial before\nreading this article.\n\n# Contexts\n\nIn Android, a `Context` is a general class that... facilitates your app\'s interaction with the\nAndroid system? I\'m not sure how to best explain it, but it essentially gives you access to\neverything in your application from string resources and fonts to starting new Activites.\n\nThe `Application`, `Activity`, and `Service` classes all extend `Context`, and `View` classes\nall require an instance of one to be displayed (you can obtain this instance by using the\nView\'s `.getContext()` method). This allows you to access information such as the device\'s\nscreen orientation, locale, and obtain assets particular to this information. For example,\nlocale-specific string resources (which are commonly defined in `res/values/strings.xml`) can\nbe obtained by calling `context.getString(R.string.string_name)`, while Drawables (a type of\nimage asset) can be obtained using `context.getDrawable(R.drawable.drawable_name)`.\n\nThe `R` class that is used to obtain these resources is a collection of static identifiers\nthat is automatically generated by Android Studio at build/compile-time.\n\nFor more about translating strings, see the\n["Localize your app"](https://developer.android.com/guide/topics/resources/localization) guide\nin the Android Developer Documentation.\n\nFor more about Drawables and other image assets, see\n["Drawable resources"](https://developer.android.com/guide/topics/resources/drawable-resource.html).\n\nA general overview of app resources can be found\n[here](https://developer.android.com/guide/topics/resources/providing-resources).\n\n# Intents\n\nEvery component inside of an Android app is started by an `Intent`. Components declared in an\napp\'s manifest can typically be invoked from _anywhere in the system_, but you can define\nintent-filters to declare that they should be started by a specific type of "thing". Your app\'s\nmain activity has a filter like `android.intent.category.LAUNCHER`, which is how the home screen\nknows to display and launch _that specific activity_ when the user opens your app.\n\nAssuming that you have an active `Context`, you can start other activities inside your application\nby firing an intent that references the classes directly, like:\n\n```java\ncontext.startActivity(new Intent(context, ActivityClass.class));\n```\n\nThis call to `startActivity` sends the `Intent` to the Android system, which is then in charge of\ncreating and opening the activity that you have specified.\n\n## Starting an Unknown Activity\n\nYou do not always need to specify an explicit class to start a new activity, though. How would your\napp start an activity in another application? You don\'t know what its class name is, and if you did,\nyou likely wouldn\'t be able to reference it since it isn\'t a part of your app. This is where\nintent-filters come in: they allow you to start an activity without explicitly stating which activity\nshould be launched. Take a look at the following intent:\n\n```java\nIntent intent = new Intent();\nintent.setAction(Intent.ACTION_VIEW);\nintent.setDataAndType(Uri.parse("content://..."), "image/*");\ncontext.startActivity(intent);\n```\n\nThis intent will open any activity on the device that claims it is able to display image files from\na URI. The first (or most prominent) activity that the Android system finds with a filter that contains\nthe `android.intent.action.VIEW` action and accepts `image/*` data will be launched by the system.\nIf you want to let the user choose which activity is launched that meets the criteria, you could open\na "share menu" with `context.startActivity(Intent.createChooser(intent, "Open with..."));`. Part of the\nreason that Android\'s share menus are notorious for being\n_[so ridiculously slow](https://issuetracker.google.com/issues/68393945)_ is that in order to display\nthese lists, it has to query every single activity on the device asking "will you accept this Intent?"\nto make a list for the user to choose from.\n\n## Sending Data to Activities\n\nIn order for an Activity to have any dynamic functionality, you will need to have some way of sending\ninformation to it. When you create an Intent to a new Activity, you should _never_ have an instance of\nthe created activity, as it is created and managed separately by the system. While under normal\ncircumstances this may not present any obvious issues, there are situations where this would not be possible\n(for example, starting an activity in a different process or task hierarchy). However, you still need a\nreliable way to tell an activity what to display while abiding by the laws of the system. There are two\nmain ways of doing this, both of which have their own advantages and disadvantages:\n\n### 1. Create your own state / data provider.\n\nThis indirectly relies on having access to an instance of the activity, though it should not fail if\nit does not obtain an instance; rather than relying on the started activity being created, it acts\nas more of a general solution to managing the data or state across your application.\n\nThe [Android Architecture Components](https://developer.android.com/topic/libraries/architecture/index.html)\nsuggest to use a [LiveData](https://developer.android.com/topic/libraries/architecture/livedata)\nobservable data class for this purpose, which allows you to persist a set of information across\nyour entire application and notify other parts of your app when it is changed. While this is a\nvery robust solution that will make your application much easier to maintain in the long run,\nit can be a little bit complicated, especially if you are writing a simple application that\nonly needs to manage a small amount of information.\n\n### 2. Use Intent extras.\n\nThe other, much simpler method of transferring data between activities is to simply include the\ndata in the Intent. This data will be passed with the Intent to the Android system when it starts\nthe activity, which will then give it to the new Activity once it has been created. For example:\n\n```java\nIntent intent = new Intent(context, ActivityClass.class);\nintent.putExtra("com.package.name.EXTRA_MESSAGE", "Hello world!"); // the data to send\ncontext.startActivity(intent);\n```\n\nNow, when the new Activity is created (inside the `onCreate` method), you can obtain the provided\ndata as such:\n\n```java\nBundle extras = getIntent().getExtras();\nif (extras != null) {\n    String message = extras.getString("com.package.name.EXTRA_MESSAGE");\n    // message == "Hello World!"\n}\n```\n\nOf course, this has its restrictions; since the data is passed to the system, there is a size limit\non the amount of data that you can pass through an Intent - most primitive types and small data\nstructures / serializable classes will be fine, but I would recommend against passing heavier classes\nsuch as Bitmaps or Drawables.\n\nFor more information about Intents, there is a more descriptive summary of them in the\n[Android Developer Documentation](https://developer.android.com/reference/android/content/Intent).\n\n## Note: More about Contexts\n\nWhen your application is opened by the system, the first components to be created will be the\n`Application`, then the `Activity` - which will have a different Context from the Application\ncomponent. If you Activity contains a layout with a set of views, the context that a view has\ncan probably be cast to an Activity (like `(Activity) view.getContext()`) without any problems,\nbut it... isn\'t a very good idea to assume this, as there are weird situations where this might\nnot work.\n\nIf your app needs to have a global "thing" shared between all of its components, or if you need\nto notify the parent activity of an event occurring in a view, then it is best to put that inside\nof your app\'s `Application` class (which should be referenced from the manifest) and have your\nActivities and other parts of your application look there for the information. The Application\nclass can be obtained from any `Context` instance by calling `context.getApplicationContext()`.\n\n# Activity Lifecycle\n\nActivities are big and complicated things, and many events can occur during their use as a result\nof user interaction or just weird Android memory-saving things. However, it is important to know\nwhat state of the lifecycle your Activity is in when performing a task as things can go very wrong\nif you try to do something at the wrong time, or fail to stop at the right time.\n\nYou are probably familiar with the `onCreate()` method - this is the first event to happen in the\nActivity lifecycle. Here, you declare and inflate your Activity\'s layout and set up the UI. After\nthis, `onStart()` and `onResume()` are called once your layout becomes visible and the user\ncan interact with it. From here, a few different events can occur...\n\nLet\'s say that another Activity comes into the foreground (but this activity is still visible behind\nit; imagine a popup or something that the user will return to your app from).\n- `onPause()` called; stop doing anything significant - playing music or any continuous task not running\n    in another component (like a `Service`) should be ceased.\n\nThen, if the user returns to the activity...\n- `onResume()` called; resume whatever was paused previously\n\nIf the user leaves your activity completely, then you will get:\n- `onPause()` called; probably stop doing stuff maybe\n- `onStop()` called; okay, REALLY stop doing stuff now\n\nThen, if the user navigates back to your activity...\n- `onRestart()` called\n- `onStart()` called\n- `onResume()` called\n\nWhen the application is completely closed by the user, then you will receive:\n- `onPause()` called\n- `onStop()` called\n- `onDestroy()` called\n\nA more comprehensive overview of the Activity lifecycle can be found\n[here](https://developer.android.com/guide/components/activities/activity-lifecycle).\n\n# More...\n\nWhat about tasks that you want to exist beyond the Activity lifecycle? Maybe you want music to\nkeep playing after the user leaves the app, or you just want to perform a short action without\nopening an activity when a certain event occurs. There are two other components that can receive\nintents for this purpose: `Service` and `BroadcastReceiver`.\n\n## Services\n\nServices can run in the background without being attached to a user interface for longer periods\nof time, for tasks such as playing music, downloading large files, or other potentially lengthy\noperations that shouldn\'t be terminated when the user leaves the app.\n\nSee: [Service documentation](https://developer.android.com/reference/android/app/Service).\n\n## Broadcast Receivers\n\nA broadcast receiver can be seen as more of an "event" that occurs once and is over. They can run\nindependently from a UI, the same a Service, but only for a short period of time (I believe they are\nterminated by the system after ~10 seconds - citation needed). However, they are given a `Context`,\nand can fire an intent to start other components of the app if needed.\n\nBroadcast receivers are a little special in that they don\'t have to be declared explicitly in the\n`AndroidManifest.xml`. While Activities and Services must be declared in order to be used, broadcast\nreceivers can be registered dynamically when your application is running, and can be unregistered\nagain when they are no longer needed.\n\nSee: [BroadcastReceiver documentation](https://developer.android.com/reference/android/content/BroadcastReceiver).\n\n# Fin\n\nThat\'s all for now! This was not a very thorough overview of Android development, and I feel like\nI left a lot of holes and exceptions to what I mentioned here, but hopefully it is useful to someone.\n',
		},
		{
			title: "Introduction to TypeScript — What is TypeScript?",
			description:
				"An introduction and explanation of what TypeScript is, is not, and what it's used for",
			published: "2019-10-13T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["typescript"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "introduction-to-typescript",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Introduction to TypeScript — What is TypeScript?",
				description:
					"An introduction and explanation of what TypeScript is, is not, and what it's used for",
				published: "2019-10-13T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["typescript"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nTypeScript's popularity cannot be understated. Either you likely know someone who works with it, you've heard of it, or possibly you've been using it. As the language continues to grow and evolve, it can be helpful to jump into the language and play with it. Other times, however, having a reference for what the language is, what the language is not, and how it can be helpful can be of great resource. We're hoping that this page can be a good starting point for that resource.\n\n> If you're more of an auditory learner, there's also a podcast episode that was done on this exact subject matter with the author of this post.\n>\n> This podcast episode [can be found on one of our sponsor's pages](https://www.thepolyglotdeveloper.com/2019/10/tpdp-e32-getting-familiar-typescript-development/)\n\n# What is TypeScript? {#what}\n\n**TypeScript is a superset of JavaScript**, meaning that _all valid JavaScript is valid TypeScript, but not all TypeScript is valid JavaScript_. Think of it as JavaScript plus some goodies. These goodies _allow developers to add type information to their code that is enforced during a TypeScript to JavaScript compilation step_.\n\nThese goodies are enabled by the TypeScript compiler, which takes your TypeScript source code and output JavaScript source code, capable of running in any JavaScript environment.\n\n## Doesn't JavaScript Have Types Already? {#javascript-types}\n\nWhile JavaScript _does_ have a loose understanding of types, they're not strictly enforced.\n\nTake the following example:\n\n```javascript\nlet numberHere = 0;\nnumberHere = 'Test';\n\nconst newNumber = 10 - numberHere;\n```\n\nIn this example, we're expecting `10 - 0` but have accidentally thrown in a new line during a copy + paste session (this always happens to me) that changed the type from a number to a string. As a result of this errant line, instead of `newNumber` being a number, it's now `NaN`.\n\nWhile TypeScript does not restrict the ability to have `NaN`s and errant copy-pastes (oh how I wish it did), it can make it more obvious that mistakes like this have been made by marking `numberHere` as a number type explicitly.\n\n```typescript\nlet numberHere: number = 0;\n// 🛑 Error will be thrown during compilation:\n// Type '\"Test\"' is not assignable to type 'number'.\nnumberHere = 'Test';\n\nconst newNumber = 10 - numberHere;\n```\n\nThis point is made even more complex when dealing with how both values are handled internally in JavaScript. Especially when talking about ES6 classes, _the type-strict nature of TypeScript types and the \"types\" that are understood in JavaScript are not the same_. While [ES6 classes are syntactical sugar on top of JavaScript's prototype system](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes) and there [are only seven base-types](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures) (called _primitive types_) in JavaScript that every other value is composed of, TypeScript has a much more robust type system.\n\n> Author's Note:\n> While the above mention of _primitive types_ and _syntactical sugar_ are meant as a path for you to learn more, don't feel discouraged from learning more about TypeScript if you're unfamiliar with such concepts.\n>\n> We're going to try to go at a high-level, and while we may hint at deeper concepts or knowledge, know that we all learn at our own pace. It's more than okay to take your time feeling comfortable before diving into those topics.\n\n# Why TypeScript? {#why}\n\nYou may be asking yourself: \"Why use TypeScript if it doesn't change the runtime behavior of your code?\" There can be a few reasons you may want to integrate TypeScript in your project, such as the following.\n\n## Type Safety {#type-safety}\n\nAs mentioned before, [JavaScript may have rudimentary types, but TypeScript's are far more robust](#javascript-types). This robustness is able to lend developers to force their code inputs and outputs to strictly enforce the limitations the developer places on them. Let's look at  take the following code for example:\n\n```js\nfunction addFive(input) {\n    return input + 5;\n}\naddFive('5');\n```\n\nReading through this code quickly, you might be able to spot the problem. Because we passed in a string, rather than a number, we get the result of `'55'` rather than the (likely) expected result of `10`. _This is the kind of unintentional code safety concern that TypeScript fixes_. Using TypeScript, we are able to check the properties passed into `addFive` during compile time in order to warn a developer about these mistakes.\n\n```ts\n// test.ts\nfunction addFive(input: number) {\n    return input + 5;\n}\naddFive('5');\n```\n\nWill now output:\n\n```bash\n>tsc test.ts\ntest.ts:5:9 - error TS2345: Argument of type '\"5\"' is not assignable to parameter of type 'number'.\n5 addFive('5');\n```\n\nIn a smaller codebase, such as the given example, it can be easy to miss how important type checking is. Detecting the error in this small length of code is often trivial; however, it can be much more difficult to do so in larger, more complex codebases or when utilizing code that might not be from your project, such as a library or framework. In these use cases, it can be much easier to identify an edge case where changing a function's parameters would break another part of the codebase. Likewise, being able to quickly identify implementation errors when using a library is a significant factor in identifying problems effectively.\n\n## Developer Quality of Life {#quality-of-life}\n\nWhile it can be easy to forget in the abstract world of development, developers make the code that we interact with on a daily basis. These developers (yourself included) tend to like enjoying certain experiences while working on their code. TypeScript provides a myriad of such quality-of-life improvements.\n\nLet's go over some of the arguments in favor of TypeScript's developer quality of life improvements.\n\n### Improved Tooling Support {#tooling}\n\nHistorically, having the ability to make assumptions about code in order to provide developer niceties (such as autocomplete code suggestions) in loosely typed languages such as JavaScript has been incredibly hard to do. As time has gone on, support for these types of actions has gotten better; but due to the nature of JavaScript's type system, there will likely always be limitations on how effectively this can be done. TypeScript's syntax, however, _can provide much of the type data about your source code needed for tools to be able to provide those niceties_ that are otherwise tricky for these tools to build. _The TypeScript team even provides a tool to communicate directly to these IDEs_ so that the work on implementing this syntax data consumption is much more trivial than they otherwise would be. _This is why [many changelogs for TypeScript releases](https://www.typescriptlang.org/docs/handbook/release-notes/overview.html) mention changes to editors such as [Visual Studio Code](https://code.visualstudio.com)_.\n\n#### 3rd Party Library Support {#typing-files}\n\nBecause of JavaScript's awesome engineering diversity, many widely used projects do not use TypeScript. However, _there are ways we can still utilize TypeScript's tooling capabilities without porting the code_. If you have a good understanding of the given project's codebase and TypeScript, _you can write a definition file that sits separated from the rest of the codebase_. These definition files allow you many of the same tooling abilities native TypeScript source code allows.\n\nAn example of these typings might look something like this:\n\n```javascript\n// index.js\nfunction aNumberToAString(numProp) {\n\tif (typeof numProp !== \"number\") throw \"Only numbers are supported\";\n\treturn numProp.toString();\n}\n```\n\n```typescript\n// index.d.ts\ndeclare function aNumberToAString(numProp: number): string; // Accept a number arg, return a string\n```\n\n##### Community Hosting {#definitely-typed}\n\nAdditionally, because TypeScript has a well established and widely used install-base, **there are already many different definition files in the wild for supporting non-TypeScript supporting projects**. One of the more extensive collections of these typings lives at the [DefinitelyTyped repository](https://github.com/DefinitelyTyped/DefinitelyTyped), which publishes the package's community typings under the package names `@types/your-package-name` (where `your-package-name` is the name of the project you're looking for typings of) that you can look for on your package manager.\n\n### Documented Types {#typing-doc-references}\n\nAnother way TypeScript can help with the workflow while coding is in regard to gaining references to APIs and code.\n\nWhen working on projects with objects that contain many properties that are used variously across files and functions, it can be difficult to track down what properties and methods are available to you without having to refer to the documentation of that scope in your application. With types present in your code, you're often able to reference that type (_often with a \"jump to declaration\" shortcut feature that is present in many IDEs_) to quickly refer to the properties and methods present on a given value or class.\n\n## Type Information {#reflect-metadata}\n\nHowever, developer quality of life changes and type safety aren't the only positive for utilizing TypeScript in your projects!\n\nAlthough it's a much more complex and highly experimental feature of TypeScript, _you are also able to use the typing data from your program to do other operations without explicitly duplicating the type data._\n\nWhat do I mean by this? Take the following code:\n\n```typescript\nfunction HandleUserInput(inputProp: number, functionToHandle: Function): string {\n...\n}\n```\n\nWhat if you had a way to mutate or modify this function? What if this way of mutating this function allowed you the ability to see that the first parameter is a number, the second is a function, and the return type is a string? **While this may not seem to have any immediate advantages, this meta-type info allows us to do powerful things.** It can be used in a situation where you might want to generate a JSON schema based on a class declaration in a TypeScript file or when using ORMs and mapping TypeScript types to the databases' native type. _By doing something like this with your ORM, you could preserve both the database typing and the TypeScript compile type within the same file so that you don't have to do duplicate checks against either._\n\n> Author's note:\n> An ORM is an \"Object Relational Model\". An ORM is a library that helps developers keep database schemas mapped in their code, often by having classes reflect the shape of their (typically) SQL server schema.\n>\n> As always, feel free to search more on them (the terms \"JavaScript ORM\" might help) and always know that not knowing a thing is always okay 🤗\n\nHere's an example [from a library built to do just that](https://typeorm.io/#/) that allows you to preserve the TypeScript type to save data in specified field types in your database:\n```typescript\nimport {Entity, PrimaryGeneratedColumn, Column} from \"typeorm\";\n\n@Entity()\nexport class User {\n\n    @PrimaryGeneratedColumn()\n    id: number;\n\n    @Column()\n    firstName: string;\n\n    @Column()\n    lastName: string;\n\n    @Column()\n    age: number;\n}\n```\n\nAnd this feature doesn't have an API dissimilar to standards-based APIs; [it's being built with and on top of features proposed for a future version of JavaScript (commonly referred to as ESNext).](https://www.typescriptlang.org/docs/handbook/decorators.html#metadata)\n\n# What isn't TypeScript {#misconceptions}\n\nNow that we've covered a bit of what TypeScript _is_, it might be a good idea to quickly synopsis what it _isn't_. After all, to know what something is not is oftentimes just as powerful as knowing what something _is_.\n\n## It's Not the Tower You Think It Is {#typescript-is-not-babel}\n\nOne of the things TypeScript is not is a transpiler. What this means is that TypeScript (alone) _will not take TypeScript source code that contains syntax from newer JavaScript versions (ES6+) and output older versions of JavaScript (ES5) in order to improve browser compatibility (IE11)_.\n\nFor anyone who's used TypeScript, this may confuse you, as there are various flags and config options for the output version of JavaScript it compiles to. What's really happening under-the-hood is that TypeScript hands off your source code to Babel after it compiles down to JavaScript. [With Babel 7 this is even harder to notice](https://devblogs.microsoft.com/typescript/typescript-and-babel-7/), but be aware that any transpilation you expect to occur when using TypeScript may force you to use and understand Babel tools.\n\nHowever, this does mean that you can utilize the entire arsenal of Babel tooling to your disposal, [such as Babel plugins](https://babeljs.io/docs/en/plugins/).\n\n## Logic != Typings {#typings-are-not-logic}\n\n_TypeScript will not find all your typing errors on its own_. This is because TypeScript is only as useful as your typings are. [Let's look back at an earlier example](#type-safety):\n\n```javascript\nfunction addFive(input) {\n    return input + 5;\n}\n```\n\nIf you keep `addFive`'s `input` parameter without an explicit type, it will try to do its best to detect the type based on the operations you run on the value. **While these inferred types are often very useful, it often has difficulty doing so in an accurate manner**. _This is why manually assigning types is almost always preferred to leaving them as inferred_. If it couldn't properly detect a type for the value in this example, it does nothing to prevent strings from being passed as the parameter value.\n\nAlthough examples like this are simple, strict typings can also become fairly complex to maintain maximum type strictness. See the [Advanced section of the official handbook](https://www.typescriptlang.org/docs/handbook/advanced-types.html) for examples that illustrate this.\n**Also, because typings do nothing to test against the logic of your program, they should not be seen as a replacement for testing, but rather a companion to them.** _With strict typings and proper testing, regressions can be severely limited and improve code quality of life._\n\n##### Typing Mishaps Happen {#typings-can-be-wrong-too}\n\nRemember, because typings are kept separately from the project's logic code, typings can be misleading, incomplete, or otherwise incorrect. While this can also happen with TypeScript logic code, it tends to be more actively mitigated as a project's ability to compile (and therefore distribute) relies on that typing information. This isn't to say that you should immediately mistrust typings, but this is simply a reminder that they too may have their flaws — just as any other part of a codebase.\n\n## Don't Forget To Document {#typescript-is-not-documentation}\n\nJust as typings shouldn't replace tests, typings should also not replace documentation or comments. Typings can help understand what inputs and outputs you're expecting, but just the same as with testing; _it doesn't explain what the logic does or provide context as to why the data types have specific properties_, what the properties are used for, and so forth. Additionally, typings often do little to help explain how to contribute in the larger scale when talking about documentation. For example, in a large-scale application, there may be come complex data patterns or order-of-operations that are required to do a task. Typings alone will not effectively communicate these design principles that are integral to the usage of the code.\n\nEssentially, I just want to make sure to iterate that while there may be tools that can let you auto-document the properties and the property type from TypeScript annotations, hand-done documentation is still extremely important.\n\n# Conclusion\n\nAnd with that, we have a better understanding of what TypeScript is! I hope this has been informative and helpful for those that may be new to the language in particular. What'd you learn, let us know!\n\nNow that you're more familiar with TypeScript, maybe you'd like to play around with one of their more experienced functionality: [Type generics](/posts/typescript-type-generics/)? We have a whole post around that concept as well, [you can find that here](https://unicorn-utterances.com/posts/typescript-type-generics/).\n\nThanks for reading! Leave any questions or feedback in the comments below.\n",
		},
		{
			title: "JavaScript Fundamentals: Functions Are Values",
			description:
				"JavaScript functions are widely used in web development... but do you KNOW them? Let's explore the fundamentals and how they can be used in unorthodox ways",
			published: "2022-07-28T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["webdev", "javascript"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/development/what-you-never-learned-about-javascript-functions/",
			series: "JavaScript Fundamentals",
			order: 1,
			slug: "javascript-functions-are-values",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "JavaScript Fundamentals: Functions Are Values",
				description:
					"JavaScript functions are widely used in web development... but do you KNOW them? Let's explore the fundamentals and how they can be used in unorthodox ways",
				published: "2022-07-28T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["webdev", "javascript"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/development/what-you-never-learned-about-javascript-functions/",
				series: "JavaScript Fundamentals",
				order: 1,
			},
			contentMeta:
				'\n**Functions are weird**. Consider the following code:\n\n```javascript\nfunction sayHello() {\n  console.log("Hello");\n}\n\nsayHello();\n```\n\nSeems straightforward enough, right? We\'re creating a function `sayHello`, then immediately calling it.\n\nNow, what about the following code:\n\n```javascript\nfunction sayHello() {\n  console.log("Hello");\n}\nconst greeting = sayHello;\ngreeting();\n```\n\nThis “intuitive” code comes loaded with assumptions and processes that we regularly take for granted:\n\n- Why are we able to assign a function to a variable?\n- What is this doing under the hood?\n- Are we able to utilize functions in potentially unexpected ways?\n\nWhile you *could* get away with never knowing the answers to these questions, being a great developer often involves understanding how the tools we use actually work – and JavaScript functions are no exception.\n\nFor example, do you know what “function currying” is and why it’s useful? Or do you know how `[].map()` and `[].filter` are implemented?\n\nFret not, dear reader, as we will now take a look at all these questions.\n\n# Why are we able to assign a function to a variable?\n\nTo understand why we\'re able to assign a function to a variable, let\'s analyze what happens when *anything* is assigned to a variable.\n\n## How memory works\n\nInside of your computer, there\'s something called "memory," AKA RAM,[which allows your computer to store short-term memory that it can quickly reference later.](https://unicorn-utterances.com/posts/how-computers-speak#ram)\n\nWhen we create a variable, what we\'re doing is storing values inside of this memory.\n\nFor example, take the following code:\n\n```javascript\nconst helloMessage = "HELLO";\nconst byeMessage = "SEEYA";\n```\n\nThis will create two sections of memory that your compiler will keep around for reference when you use those variables. Each of these sections of memory will be just big enough to store 5 characters of the string.\n\nThis might be visually represented like so:\n\n![A big block called "memory" with two items in it. One of them has a name of "helloMessage" and is address `0x7de35306` and the other is "byeMessage" with an address of `0x7de35306`.](./memory_block.png)\n\nIt\'s important to remember that the memory address itself doesn\'t store the name, your compiler does. When you create blocks of memory via variables, the compiler gets back a number that it can use to look up the variable\'s value inside of a "stack" of memory.\n\nYou can *loosely* think of this memory stack as an array that the compiler looks through in order to get the data based on an index. This number can be huge because your computer likely has multiple gigabytes of RAM. Even 16GB is equivalent to 1.28e+11 bytes. Because of this, memory addresses are often colloquially shortened to [hexadecimal representations](https://unicorn-utterances.com/posts/non-decimal-numbers-in-tech).\n\nThis means that our *0x7de35306* memory address is associated with bit number 2112049926, or just over the 0.2GB mark.\n\n> This explanation of memory is a very generalized explanation of how memory allocation works. [You can read more about memory stacks here.](https://en.wikipedia.org/wiki/Stack-based_memory_allocation)\n\nWhen your browser compiles the following code:\n\n```javascript\nconst helloMessage = "HELLO";\nconst byeMessage = "SEEYA";\n\nconsole.log(helloMessage);\nconsole.log(byeMessage);\n```\n\nThe browser\'s compiler will replace the variable names with memory addresses:\n\n```javascript\nmemoryBlocks[0x7de35306] = "HELLO";\nmemoryBlocks[0x7de35307] = "SEEYA";\n\nconsole.log(memoryBlocks[0x7de35306]);\nconsole.log(memoryBlocks[0x7de35307]);\n```\n\n> This code is simply pseudocode and will not actually run. Instead, your computer will compile down to ["machine code" or "assembly code"](https://unicorn-utterances.com/posts/how-computers-speak#assembly-code), which will in turn run on "bare metal". What\'s more, this is a drastic oversimplification of how your browser\'s JIT compiler and your system\'s memory management*actually* works under-the-hood.\n\n## How does this relate to function storage?\n\nRemember that functions in JavaScript have two different syntaxes:\n\n```javascript\nfunction sayHello() {\n  console.log("Hello");\n}\n\nsayHello();\n```\n\nIs roughly equivalent to:\n\n```javascript\nconst sayHello = () => {\n  console.log("Hello");\n}\n\nsayHello();\n```\n\nAs you might correctly assume, this means that both of these syntaxes allow a function to be stored in memory. \n\nUsing our pseudocode again, this might look like:\n\n```javascript\nmemoryBlocks[0x9de12807] = () => {\n    console.log("Hello");\n}\n\nmemoryBlocks[0x9de12807]();\n```\n\n## Why does it matter that functions are stored as memory addresses?\n\nThe reason I\'ve gone on to show you that functions are stored as memory addresses is to help reinforce the idea that **functions are values** and can be treated like such. For example, you can do the following with numbers in JavaScript:\n\n```javascript\nconsole.log(1 + 2);\n```\n\nWithout having to assign each number to a variable:\n\n```javascript\nconst one = 1;\nconst two = 2;\nconsole.log(one + two);\n```\n\nLikewise, you can use functions without assigning them to a variable.\n\nThis means the the following `sayHello` function:\n\n```javascript\nconst sayHello = () => {\n    console.log("Hello");\n}\nsayHello();\n```\n\nCan be used without a variable to assign the function:\n\n```javascript\n(() => console.log("Hello"))();\n```\n\nThis is just the start of what\'s possible with functions. Think of all the interactions you can have with a non-function variable like integers and strings. You can have those same interactions with functions as well.\n\n# Can you pass a function to another function?\n\nOne very popular use of functions is passing in values as properties. For example:\n\n```javascript\nfunction sayThis(message) {\n    console.log(message);\n}\n\nsayThis("Hello");\n```\n\nHere, we\'re passing a string as a property to the `sayThis` function. \n\nJust like you can pass in integers, strings, or arrays to a function, you might be surprised to know you can also pass in functions into a function:\n\n```javascript\nfunction doThis(callback) {\n    callback();\n}\n\nfunction sayHello() {\n    console.log("Hello");\n}\n\ndoThis(sayHello);\n```\n\nThis will output the same "Hello" as our previous`sayThis` usage.\n\nNot only can you call these functions that are passed as parameters, but you can pass parameters to *those* functions as well.\n\n```javascript\nfunction callThisFn(callback) {\n    // Remember, `callback` is a function we\'re padding\n    // `console.log` specifically\n    return callback(\'Hello, world\');\n}\n\ncallThisFn(console.log);\n```\n\nTo walk through this step-by-step, we:\n\n- Pass `console.log` to `callThisFn` through an argument\n- `callThisFn` assigns that property as `callback`, which remains a function\n- We then call `callback` with a parameter of it\'s own: \'Hello, world\'\n\nIn case this isn\'t clear, let\'s do our previous trick of calling a function without assigning it to a variable.\n\n```javascript\n(callback => callback(\'Hello, world!\'))(console.log);\n```\n\n# What about returning a function from another function?\n\nAs a function’s input, parameters are only half of the story of any function\'s capabilities – just as any function can output a regular variable, they can also output another function: \n\n```javascript\nfunction getMessage() {\n  return "Hello";\n}\n\nconst message = getMessage();\nconsole.log(message);\n// Equivalent to\nconsole.log(getMessage());\n```\n\nIf you\'ve done much coding in JavaScript, this will look familiar. We\'re "calling"`getMessage` and storing the return value to `message` variable. We can then do anything else we might expect with this `message` variable - including passing it to other functions as a parameter.\n\nThis too, is possible with a function as a return value:\n\n```javascript\nfunction getMessageFn() {\n    return () => {\n        console.log("Hello");\n    }\n}\n\nconst messageFn = getMessageFn();\nmessageFn();\n// This can be simplified to\ngetMessageFn()();\n```\n\nThis code block is an extension on the "returned value" idea. Here, we\'re returning*another* *function* from `getMessageFn`. This function is then assigned to `messageFn` which we can then in turn call itself.\n\nMeta, right?\n\nFunnily enough, you can even combine this with the ability to return within the inner function.\n\n```javascript\nfunction getMessageFn() {\n    return () => {\n        return "Hello";\n    }\n}\n\nconst messageFn = getMessageFn();\nconst message = messageFn();\nconsole.log(message);\n// This can be simplified to\nconsole.log(getMessageFn()());\n```\n\n# Let\'s combine concepts by accepting and returning a function from another function\n\nKnowing that we can both accept a function as a property and return a different function as a value, we can combine these both to create the following logic:\n\n```javascript\nfunction passFunctionAndReturnFunction(callback) {\n    return () => {\n        callback("Hello, world");\n    }\n}\n\nconst sayHello = passFunctionAndReturnFunction(console.log);\nsayHello(); // Will log "Hello, world"\n```\n\n# How do you pass data from one function to another? A pipe function!\n\nThe concepts we\'ve spoken about today are commonly utilized when programming in a style called "functional programming." Functional programming is a style of programming - similar to["Object Oriented Programming" (OOP)](https://www.educative.io/blog/object-oriented-programming) - that utilizes functions as a method to pass, change, and structure data. \n\nFunctional programming relies heavily on the properties of functions that we\'ve looked at today: passing functions to other functions, returning functions from functions, and more.\n\nIf you spend much time looking at functional programming libraries, [such as Ramda](https://ramdajs.com/), you might run into [a function called a "Pipe"](https://ramdajs.com/docs/#pipe).\n\nTraditionally, a `pipe` function takes a list of other functions to call them and return a final value.\n\nFor example, you might run:\n\n```javascript\nconst finalVal = pipe([\n  () => 1,\n  // Pass `1` to `v`\n  v => v + 1\n]);\n\nconsole.log(finalVal); // 2\n```\n\nThis is useful when you need to chain a list of actions together and get the final output.\n\nLuckily, `pipe` is an easy function to implement:\n\n```javascript\nfunction pipe(fns) {\n    let val = undefined;\n    for (let fn of fns) {\n        val = fn(val)\n    }\n    return val;\n}\n```\n\nSo when is this useful? Let\'s assume that we want to clamp the values between two numbers.\n\n```javascript\nclamp({min: 0, max: 10, val: 5}); // 5\nclamp({min: 0, max: 10, val: 15}); // 10\nclamp({min: 0, max: 10, val: -10}); // 0\n```\n\nThinking about this problem, we can break up our logic into three different parts:\n\n1. Check if smaller than minimum\n2. Check if larger than maximum\n3. Return final value\n\nWe can implement this using distinct functions and our new `pipe` method:\n\n```javascript\nfunction pipe(fns) {\n    let val = undefined;\n    for (let fn of fns) {\n        val = fn(val)\n    }\n    return val;\n}\n\nconst min = (val, min) => val < min ? min : val;\nconst max = (val, max) => val > max ? max : val;\n\nfunction clamp(props) {\n    return pipe([\n        // Step 1: Check if smaller than minimum\n        () => min(props.val, props.min),\n        // Step 2: Check if larger than maximum\n        val => max(val, props.max)\n    ])\n}\n\nclamp({min: 0, max: 10, val: 5}); // 5\nclamp({min: 0, max: 10, val: 15}); // 10\nclamp({min: 0, max: 10, val: -10}); // 0\n```\n\nWhile this might seem a bit confusing at first, the benefits are that we now are able to use the `min` and `max` method independently of `clamp`.\n\n```javascript\nmin(10, 0); // 10\nmin(0, 10); // 10\nmax(10, 0); // 0\nmax(0, 10); // 0\n```\n\n# What are built-in functional paradigms in JavaScript?\n\nWhile we\'ve touched on how to build many of our own functional ideals using JavaScript, many of the core concepts are built into JavaScript itself through usage of Array methods.\n\nFor example, want to run a function over each item of an array? [`Array.forEach` to the rescue!](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/forEach)\n\n```javascript\n[1, 2, 3].forEach(val => console.log(val));\n\n// Will output\n1\n2\n3\n```\n\n`Array.forEach` doesn\'t just pass a single value to the inner mapping function, it also passes the index of the item and the original array:\n\n```javascript\n[1,2,3].forEach((val, i, arr) => console.log({val, i, length: arr.length}));\n\n// Will output\n{val: 1, i: 0, length: 3}\n{val: 2, i: 1, length: 3}\n{val: 3, i: 2, length: 3}\n```\n\n## Mapping items in an array to a new value\n\nDon\'t have a use for "`forEach`"? No matter! There\'s also [`Array.map`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map) that enables you to have a list and want to change each item in the list in some way.\n\n```javascript\nconst listAddedByOne = [1, 2, 3].map(val => val + 1);\n```\n\n`Array.map` accepts a function that, when you return a new value, will update that item of the list.\n\nJust like `Array.forEach`, `Array.map` passes the index of the item and the original array to the inner function as well:\n\n```javascript\nconst newList = ["Eat", "Sleep", "Play Elden Ring"].map((val, i, arr) => {\n    return `${i + 1} / ${arr.length} - ${val}`;\n});\n\n// This will return:\n"1 / 3 - Eat"\n"2 / 3 - Sleep"\n"3 / 3 - Play Elden Ring"\n```\n\n## Filter a list down based on a function\'s return value\n\nSay that you have a list of numbers:\n\n```javascript\nconst numbers = [10, 20, 30, 40, 50, 60, 70, 80, 90];\n```\n\nAnd want to filter down this list to only include "small" numbers - aka when a number is smaller than 50. This is where we can use[`Array.fiter`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/filter):\n\n```javascript\nconst smallNumbers = numbers.filter(val => val < 50);\n```\n\nOnce again, you\'re also given the option to get the index and original array in the filter method.\n\n## Reduce an array down to a single value\n\nWhile there are other array methods, the last one we\'ll be taking a look at today enables you to reduce a list down to a single value. Let\'s take a list of numbers and sum them together to a final output.\n\n```javascript\nconst numbers = [1, 2, 3];\n// This will return "6"\nconst sum = numbers.reduce((acc, curr) => acc + prev, 0);\n```\n\nReduce is passed two items:\n\n1. The function that provides a reduced value when returned\n2. The initial value to set to `acc`\n\n# How can we re-write built-in JavaScript functional programming methods?\n\nWhile `forEach`, `map`, `filter`, and `reduce` are all built into JavaScript, the foundations of functional programming means that we can implement them ourselves. This doesn\'t have any practical usecases, but allows us to understand how JavaScript works under the hood a bit better.\n\nFor example, a `forEach` can be implemented using a basic `for` loop:\n\n```javascript\nconst forEach = (arr, callback) {\n    for (let i = 0; i < arr.length; i++) {\n        callback(arr[i], i, arr);\n    }\n};\n\nconst cars = ["Ford", "Volvo", "BMW"];\nforEach(cars, car => console.log(car));\n```\n\nSimilarly, you can write your own implementation of `map` with an intermediary array alongside a `for` loop.\n\n```javascript\nconst map = (arr, callback) {\n    const returnedVal = [];\n    for (let i = 0; i < arr.length; i++) {\n        const newVal = callback(arr[i], i, arr);\n        returnedVal.push(newVal);\n    }\n\n    return returnedVal;\n};\n\nconst cars = ["Ford", "Volvo", "BMW"];\nconst carNameLengths = map(cars, car => car.length);\nconsole.log(carNameLengths); // [4, 5, 3]\n```\n\nTo implement `filter` is as easy as adding a single `if` statement to our `map` implementation.\n\n```javascript\nconst filter = (arr, callback) {\n    const returnedVal = [];\n    for (let i = 0; i < arr.length; i++) {\n        const exist = callback(arr[i], i, arr);\n        if (exist) {\n            returnedVal.push(arr[i]);\n        }\n    }\n\n    return returnedVal;\n};\nconst cars = ["Ford", "Volvo", "BMW"];\nconst onlyBMW = filter(cars, car => car === "BMW");\nconsole.log(onlyBMW); // ["BMW"]\n```\n\nFinally, implementing `reduce` is similar to our `map` implementation, but instead of `pushing` new values to an array, we simply replace the old value between loop iterations.\n\n```javascript\nconst reduce = (arr, callback, init) => {\n    let returnedVal = init;\n    for (let i = 0; i < arr.length; i++) {\n            returnedVal = callback(returnedVal, arr[i], i, arr);\n    }\n\n    return returnedVal;\n};\n\nconst numbers = [1,2,3];\nconst sum = reduce(numbers, (acc, curr) => acc + curr, 0);\nconsole.log(sum); // 6\n```\n\n# Functional programming methods can be applied everywhere\n\nNow that you\'ve mastered the fundamentals of JavaScript functions, you can build more kinds of APIs for your applications. These APIs can help you make debugging easier, consolidate your application logic, and more.\n\n\nThe functional programming paradigms we\'ve touched on today are immensely popular in ecosystems like React applications and library development. In particular, [React uses these concepts alongside its `useEffect` API.](https://coderpad.io/blog/development/rules-of-reacts-useeffect/)\n\nThese concepts aren\'t unique to JavaScript, either! Python utilizes similar ideas in its ["list comprehension" functionality.](https://coderpad.io/blog/development/python-list-comprehension-guide/)\n\nIf you find any of these techniques useful (or even confusing, we know that functional programming can be a world of its own) [let us know on Twitter](http://twitter.com/coderPad/)!\n',
		},
		{
			title: "Joining Freenode IRC: A Guide",
			description:
				"Basic (but detailed) instructions for setting up a Freenode IRC account through various clients",
			published: "2019-08-22T05:12:03.284Z",
			authors: ["fennifith"],
			tags: ["tools"],
			attached: [],
			license: {
				id: "publicdomain-zero-1",
				footerImg: "https://licensebuttons.net/p/zero/1.0/88x31.png",
				licenceType: "Public Domain",
				explainLink: "https://creativecommons.org/publicdomain/zero/1.0/",
				name: "CC0 1.0 Universal (CC0 1.0) Public Domain Dedication",
				displayName: "Public Domain",
			},
			slug: "joining-freenode-irc",
			locale: "en",
			authorsMeta: [
				{
					id: "fennifith",
					name: "James Fenn",
					firstName: "James",
					lastName: "Fenn",
					description:
						"Enjoys writing software on loud keyboards. Starts too many projects. Consumes food.",
					socials: { twitter: "fennifith", github: "fennifith" },
					pronouns: "he",
					profileImg: "./fennifith.jpg",
					color: "#0091EA",
					roles: ["developer", "author", "community"],
					profileImgMeta: {
						height: 400,
						width: 400,
						relativePath: "./fennifith.jpg",
						relativeServerPath: "/content/data/fennifith.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\fennifith.jpg",
					},
					rolesMeta: [
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Joining Freenode IRC: A Guide",
				description:
					"Basic (but detailed) instructions for setting up a Freenode IRC account through various clients",
				published: "2019-08-22T05:12:03.284Z",
				authors: ["fennifith"],
				tags: ["tools"],
				attached: [],
				license: "publicdomain-zero-1",
			},
			contentMeta:
				"\nInternet Relay Chat is a difficult thing to get used to, especially for people who were born into this world of full graphical interfaces and messaging web apps that handle user interaction seamlessly. IRC is a little bit different, though it still has a lot of the functionality that conventional messengers do: group chats / channels, admin (operator) permissions, user ban lists, private messages, and _quite a bit more_. However, a lot of this functionality may seem obscured to new users, as most IRC clients don't have the fancy menus, dropdowns, or simple toggles and check box elements that are often taken for granted - they use more of a command line-like interface, having users remember the commands to execute a specific action instead, like `/motd` or `/whois fennifith`.\n\n# Choosing a Client\n\nThe first thing that you'll want to do before logging into freenode is choose an IRC client to connect with. I've compiled a list of the ones that I have tried below.\n\n- **Android**\n  - [Revolution IRC Client](https://play.google.com/store/apps/details?id=io.mrarm.irc)\n  - [Riot IM](https://about.riot.im/)\n  - [AndroIRC](https://play.google.com/store/apps/details?id=com.androirc)\n  - [IRCCloud](https://play.google.com/store/apps/details?id=com.irccloud.android)\n- **Linux**\n  - **CLI**\n    - [WeeChat](https://weechat.org/)\n    - [Irssi](https://irssi.org/)\n  - **GUI**\n    - [HexChat](https://hexchat.github.io/)\n    - [XChat](http://xchat.org/)\n- **Windows**\n  - [HexChat Windows](https://www.microsoft.com/en-us/p/hexchat/9nrrbgttm4j2)\n- **Web**\n  - [Riot IM](https://riot.im/app/)\n  - [Freenode Webchat](https://webchat.freenode.net/)\n  - [Kiwi IRC](https://kiwiirc.com/)\n  - [The Lounge](https://demo.thelounge.chat/)\n\n# Connecting to Freenode\n\nConnect to the freenode servers by specifying `chat.freenode.net` as the server, and either port `6697` if your client supports SSL/TLS connections, or `6667` if it does not. Many clients have a preset option for connections to freenode, for example in `irssi` you can simply type `/CONNECT Freenode` to connect to a freenode server without needing to configure anything else.\n\nFor a more detailed explanation of connecting to freenode, [Freenode's documentation](https://freenode.net/kb/answer/chat) might be useful.\n\n# Registering a Nickname\n\nFirst, you'll want to choose a nick. This will be something that all users will see and address you by, so it should be easy to remember. If you have a twitter or github handle, it is best to make it as similar as possible to that in order to stay consistent. In the following steps, replace the information surrounded by `<>` with the relevant data.\n\n1. Send the command `/nick <username>`, followed by a message to `NickServ` by running `/msg NickServ REGISTER <password> <email@example.com>`. \n2. You should receive an email with another command to run, along the lines of `/msg NickServ VERIFY REGISTER <username> <code>`. This will confirm your identity to freenode and reserve the nickname for your use.\n3. If you plan to use your account from multiple devices simultaneously, you will need to have one username for each. You can join them to your current account by:\n  - Setting your nick to a new username: `/nick <username2>`\n  - Identifying with your existing credentials: `/msg NickServ IDENTIFY <username> <password>`\n  - Grouping the nick with your account: `/msg NickServ GROUP`\n\nEach time you reconnect to freenode, you will need to log in. [Freenode's registration docs](https://freenode.net/kb/answer/registration) have more information on this, but it is possible to simply run `/msg NickServ IDENTIFY <username> <password>` each time you connect.\n\n# Joining a Channel\n\nOn most IRC servers, you can run `/list` to display a list of all of the channels on the server that you can join. However, as freenode has just shy of 50000 channels, this command will generate quite a large output that may not be to your liking. Two options here: you can either use a web index, such as [irc.netsplit.de](http://irc.netsplit.de/channels/?net=freenode), to view a list of channels in a more usable format, or you can use freenode's [alis tool](https://freenode.net/kb/answer/findingchannels) to search through the list with a query such as `/msg alis LIST programming`. Alis has quite a few other options to trim down the search results, and I reccomend taking a look at `/msg alis HELP LIST` before you start scrolling through 1000+ search results to look for a particular topic.\n\n# General Use\n\nBy now, you've probably gotten a decent feel for how IRC chat works - most commands handle faulty input fairly gracefully and let you know what they're doing and how to use them properly. Most commands and usernames are case insensitive, and help can usually be found by simply adding `help` after the root command, ex: `/msg NickServ HELP VERIFY`. If you haven't come across them already, here is a list of various useful commands and what they do:\n\n- `/info`: display information about the server\n- `/names`: show the usernames of members in the current channel\n- `/whois <username>`: looks up information about a particular user's connection\n- `/msg <username> <message>`: sends a private message to a user\n- `/join <channel>`: joins a particular channel\n- `/me <action>`: invoke a virtual action, such as `/me takes a humongous bite of their pie` to create a notice such as \"fennifith takes a humongous bite of their pie\"\n- `/describe <username> <description>`: similar to `/me`, using the username of someone else on the network, ex: `/describe steve012 crashes through the wall`\n- `/notify <username>`: tells the server to send you a notification when another user logs on\n- `/ping <username|channel>`: displays information about the distance between your computer and other users on the network\n- `/quit <message>`: quits the server, sending a final comment to any chats you may be involved with\n\nMore commands, along with basic descriptions of how they work and examples of their use, can be found [here](https://www.livinginternet.com/r/r.htm).\n\n# Policies\n\nLast, but certainly not least, I recommend that you scroll through [freenode's policies](https://freenode.net/policies) to get an idea of the purpose of the project and what is deemed acceptable use of their servers. Most channels have their own code of conduct to go along with these policies, which you should review to make sure that you aren't unknowingly violating any rules when contributing to a discussion. The [channel guidelines](https://freenode.net/changuide) also list more definitions of what is considered to be acceptable behavior on IRC (and really any social network).\n\nAnd, most importantly, have fun!\n",
		},
		{
			title: "Keeping API Keys Secret in React Apps",
			description:
				"Save yourself money by hiding your API keys from prying eyes and nasty bots.",
			published: "2020-04-20T22:07:09.945Z",
			authors: ["MDutro"],
			tags: ["react", "node"],
			attached: [],
			license: {
				id: "cc-by-nc-nd-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "https://creativecommons.org/licenses/by-nc-nd/4.0/",
				name: "Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) License",
			},
			slug: "keeping-api-keys-secret-in-react-apps",
			locale: "en",
			authorsMeta: [
				{
					id: "MDutro",
					name: "Micah Dutro",
					firstName: "Micah",
					lastName: "Dutro",
					description: "A non-profit lawyer turned budding web developer.",
					socials: { github: "MDutro" },
					pronouns: "he",
					profileImg: "./mdutro.jpg",
					color: "#7C4DFF",
					roles: ["developer", "author", "community"],
					profileImgMeta: {
						height: 700,
						width: 700,
						relativePath: "./mdutro.jpg",
						relativeServerPath: "/content/data/mdutro.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\mdutro.jpg",
					},
					rolesMeta: [
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Keeping API Keys Secret in React Apps",
				description:
					"Save yourself money by hiding your API keys from prying eyes and nasty bots.",
				published: "2020-04-20T22:07:09.945Z",
				authors: ["MDutro"],
				tags: ["react", "node"],
				attached: [],
				license: "cc-by-nc-nd-4",
			},
			contentMeta:
				"\nReact is a powerful JavaScript library that can make front end magic happen on screen. If you are on the path to understanding components, props, and state there are a lot of great free resources out there to help you along the way.\n\nIt doesn't take long before you begin learning how to make calls to external APIs. Getting data and manipulating it to populate great UI design is a big part of any front end developer's job, whether that data comes from an external source or from an internal API that links to your company's private customer database.\n\nBut there are a few pitfalls out there for the unwary new React developer. One of the big traps that can catch you off guard early on has to do with safely storing keys for external API calls. Personally, I had a hard time finding resources on how to accomplish this goal. In the end, I got the answers from a mentor, but I wanted to provide clear, written instructions on how to keep your API keys away from the prying eyes of nefarious bots and users.\n\nWhat does that mean?\n\n# Browsing in Public {#public}\n\nWell, as it turns out, anything that happens in the browser basically happens out in the open. Anyone who knows how to open a developer console can see the output of the JavaScript console, the results of network requests/responses, and anything hidden in the HTML or CSS of the current page. While you are able to mitigate this type of reverse-engineering by randomizing variable names in a build step (often called \"Obfuscating\" your code), even a fairly quick Google session can often undo all of the efforts you took to muddy the waters. The browser is a terrible place to try to store or use secret information like unencrypted passwords or API keys - and React runs in the browser!\n\nIn other words, React keeps no secrets from the user which means that it's a terrible place to keep *your* secrets.\n\nSo, what is the answer? How do you keep your API keys from falling into the hands of vicious web scraping bots in React? It's simple, really. You don't keep your secrets in React at all.\n\nWe can't keep things like API keys a secret in React because it runs in the browser on the user's computer. The solution is to make sure your React application never sees the API key or uses it all - that way, it is never sent to the user's local machine. Instead, we have to get a proxy server to make our API calls and send the data back to the React app.\n\n# What is a Proxy Server? {#proxy}\n\nIf you are unfamiliar with the term \"proxy server\", that's alright! If you think about how a React app would typically interface with an API, you'd have a `GET` call to the API server in order to get the data you want from the API. However, for APIs that require an API key of \"client_secret\", we have to include an API key along with the `GET` request in order to get the data we want. This is a perfectly understandable method for securing and limiting an API, but it introduces the problem pointed out above: We can't simply bundle the API key in our client-side code. As such, we need a way to keep the API key out of reach of our users but still make data accessible. To do so, we can utilize another server (that we make and host ourselves) that knows the API key and uses it to make the API call _for_ us. Here's what an API call would look like without a proxy server:\n\n![API request](./api_request.svg)\n\nMeanwhile, this is what an API call looks like with a proxy server:\n\n![Proxy server API request](./proxy_request.svg)\n\nAs you can see, the proxy server takes calls that you would like to make, adds the API key, and returns the data from the API server. It's a straightforward concept that we can implement ourselves.\n\n# How to use a Proxy Server {#how-to-use}\n\nIt might make more sense to talk about things the other way around and start with the front end. Instead of using React to make a direct request to an API for information, we tell React to send an HTTP request to our proxy server. Since we are writing our front end application in JavaScript, it makes life a little easier to write our server in Node, though you could use Ruby or Python or any other back end friendly language if you want.\n\nLet's take a look at a couple of code samples and get down to the details. The code snippets below are from an app I am developing that shows you the weather on Mars from the past week. The data is collected from NASA's InSight lander and is available from the [space agency's open APIs](https://api.nasa.gov/).\n\n```javascript\n// Get weather data from NASA API\ncomponentDidMount() {\n    fetch(\"http://localhost:3001\")\n        .then(res => res.json())\n        .then(data => {\n        const weather = data.sol_keys.map(key => {\n            data[key].AT.dayNumber = key*1;\n            // Add a key: value pair to toggle between Celsius and Farenheit\n            data[key].AT.isFarenheit = 'C';\n            return data[key];\n        });\n        this.setState({ weather });\n    })\n        .catch(console.log);  \n} \n```\n\nThis is an example of a basic HTTP request in React using the `fetch` API. This `fetch` request is wrapped in a `componentDidMount()` so the request is made when the component initially loads. The thing to note here is that the `fetch` request is to your development environment for the proxy server running on your own machine instead of directly to NASA's external API. React won't keep our secrets so we make sure the browser is communicating with the proxy server.\n\n> Remember that you can't run two things on the same port! So make sure that your development server and React app are running on different ports - 3000 and 3001 will work just fine.\n\nSince `fetch` returns a promise, we tack on a few `.then`s to do something with the data once we get it. In this case, since I'm using the `fetch` API, we need to parse the response into JSON with `res => res.json()`. NASA's JSON object's structure is a little awkward since I want to use the \"day number\" as a prop and NASA uses it as a key, so I add a couple of lines of code to manipulate the data and make it easier to use later. Finally, I use `this.setState()` so I can use it, pass it to child components, and otherwise bend it to my will.\n\nAll of this works without React ever making a direct connection to the NASA API.\n\nSo let's take a look at where we make that connection on the server side.\n\n```javascript\napp.get('/', (req, res) => {\n  const marsUrl = `https://api.nasa.gov/insight_weather/?api_key=${API_KEY}&feedtype=json&ver=1.0`;\n  axios.get(marsUrl)\n  .then(response => response.data)\n  .then(response => res.send(response))\n  .catch(err => console.log(err))\n});\n```\n\nThis snippet shows part of the server for my Mars Weather app written in Node.js and Express.js. Let's walk through it.\n\nFirst, the server is listening for a call to the root route. Since the app itself only has one page, and I want to get the latest Martian weather data when the page loads, this works great. That said, you might want to change the route name in Node and React depending on your deployment strategy.\n\nNext, I construct a URL using an ES6+ template literal. That's because I'm using a variable for my API key, the `mars` in the middle of the constructed URL. How does that variable work? Where does it come from? Don't worry, we'll get there!\n\nThe next block of code is an HTTP request using the `axios` library. In case, you're not familiar, `axios` is a library that makes HTTP requests easier and provides some simple ways to provide parameters and manipulate the resulting data. I used it here to show a different way to make an API call, but could have just as easily used the `fetch` API in Node too. Here, `axios` makes a get request to our constructed URL named `marsURL`.\n\nJust like `fetch`, `axios` returns a promise. So we get the data portion of the response object and send it back to the React app running in the browser which is waiting patiently for it thanks to the power of asynchronous JavaScript.\n\nThere are a couple of things I should mention before I show you where I hid my super-secret API key. First, you will need to make sure your server is using `cors`. A full explanation of [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) is beyond the scope of this article, but the short version is that the cross-origin HTTP requests are a security no-no by default. In other words, it will stop you from accessing requests from different origins. Fortunately, Express.js provides a simple, built-in way to solve this problem. Just toss `const cors = require('cors')` at the top of your server and make sure to include `app.use(cors())` before your `axios`/`fetch` requests and you should be now able to make cross-origin requests on your server.\n\nThe other thing is a little more ES6+ in `axios`. Because it returns a promise, `axios` supports the use of the `async` and `await` keywords. To use them with `axios`, you could refactor our Node `axios` request above to something like this:\n\n```javascript\napp.get('/', async (req, res) => {\n\tconst marsUrl = 'https://api.nasa.gov/insight_weather/?api_key=' + mars + \t'&feedtype=json&ver=1.0';\n\ttry {\n\t\tconst response = await axios.get(marsURL);\n\t\tres.send(response.data)\n\t} catch (error) {\n\t\tconsole.error(error);\n\t}\n}\n```\n\nWith that out of the way, let's get to the good part - keeping your API keys out of your source code!\n\n# Environmental Variables and You {#environment}\n\nMost of the time, we want to keep things like API keys and other credentials out of the source code of an app. There are some very good security reasons for this practice. For one thing, if your project is open source and hosted on a place like GitHub, it will be exposed to anyone browsing the website, not to mention the fact that there are some less-than-savory people out there who have written web scraping scripts to look for publicly exposed API keys and exploit them. Furthermore, even for private projects API keys integrated into the source code is a potential security vulnerability. A hacker could find a way into your system and compromise the usage of the API key. Being able to hide them away in a more configurable manner might keep things safer.\n\nThe trick to hiding your API keys and other credentials is to use environmental variables. If those sound intimidating, don't worry, they are actually pretty simple to understand and easy to use. In basic terms, environmental variables are variables that are set outside of the program itself, the Node server in our case.\n\nOnce we set some environmental variables, we import them into the server code so we can access and use them. This keeps our secrets out of the code itself since they are only referenced by the variable name we have assigned them.\n\nLet's break all of this down and take it step by step using the Mars Weather app as an example.\n\nFor a production environment, we would typically set environmental variables in a secure file that's [then injected into our bash environment](https://www.serverlab.ca/tutorials/linux/administration-linux/how-to-set-environment-variables-in-linux/). Alternatively, your server host might have a solution to safely store environmental variables. Be sure to research a bit about how to do so in a production environment for your use-case. For development mode, however, we store our variables in a file called `.env`\n\nFirst, create a file named `.env` and place it in the root directory of your project. In my `.env` I have exports that look something like this: `MARS_KEY=[API key goes here]`. Make sure your variable name is in all caps and that there are no spaces around the `=`. As usual, the syntax is important!\n\n```\nMARS_KEY=asdfasdfasdf\n```\n\nNext, we head back to our server code and add `const mars = process.env.MARS_KEY` at the top of your file with all of your `require()` statements. Now you're ready to use your secret API key (or whatever it is).\n\nAs usual, there are a couple of caveats. For one, you actually have to tell the server to use the environmental variables. Fortunately, that's easy - just type `source .env` into your command line before you start your server. It's no problem to do that in development but once in production, you might run into problems if your host server ever restarts for some reason. One solution is to use the `dotenv` npm package in your Node server, which will make sure the environmental variables are loaded automatically. All you have to do is put `require('dotenv').config()` as early as possible in your server code. I include it on line 1 just to be safe.\n\nThe other potential \"gotcha\" is to make sure to include the `.env` file in your project's `.gitignore`. Otherwise, you will find the API key you have worked so hard to keep secret posted on GitHub for the world to see. Not sure how to do that? Just open up your `.gitignore` file. It should be located in your project's root directory - if not, just make one. Then type `.env` on the next available line of the file and save it. That's all there is to it! Now you won't accidentally upload your secret credentials to GitHub, which would totally defeat the purpose of hiding them in the first place. If you do accidentally post your `.env` file to GitHub, the best thing to do is to add the file to your `.gitignore` and request a new API key from the external API service you are using.\n\nNow, It's true that you can use environmental variables in React. But they [will not keep your secrets](https://create-react-app.dev/docs/adding-custom-environment-variables/) the way they do in Node! Those variables will be embedded into your React build, which means that anyone will be able to see them.\n\n# Conclusion {#conclusion}\n\nNow you know how to whip up a simple Node server and use environmental variables to keep your secrets when making API calls with front end libraries/frameworks like React. It's actually pretty easy and can serve as an introduction to the basics of Node and Express if you haven't had a reason to use them before.\n\nIf your app is meant for your own educational purposes and you don't intend to deploy it, you might not have to worry about hiding your valuable API keys too much, though you should still make sure not to upload them to GitHub.\n\nEither way, following these steps will make your API calls more secure and keep your API keys a secret, tucked safely away on your deployment server and let you focus on presenting the API response data in interesting and user-friendly ways.\n",
		},
		{
			title: "Living off the iPad as an Engineer",
			description:
				"Tips on how to get yourself a proper development environment on the iPad to fully exploit its potential.",
			published: "2021-02-11T00:00:00.000Z",
			edited: "2021-02-12T00:00:00.000Z",
			authors: ["pierremtb"],
			tags: ["tools", "opinion"],
			attached: [],
			license: {
				id: "cc-by-nc-nd-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "https://creativecommons.org/licenses/by-nc-nd/4.0/",
				name: "Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) License",
			},
			slug: "living-off-the-ipad-as-an-engineer",
			locale: "en",
			authorsMeta: [
				{
					id: "pierremtb",
					name: "Pierre Jacquier",
					firstName: "Pierre",
					lastName: "Jacquier",
					description:
						"Junior Hardware Engineer at Algolux. Computationally curious.",
					socials: {
						twitter: "PierreJacquier",
						github: "pierremtb",
						website: "https://pierrejacquier.com",
						linkedIn: "pierrejacquier",
					},
					pronouns: "he",
					profileImg: "./pierremtb.jpg",
					color: "#FFEB3B",
					roles: ["author"],
					profileImgMeta: {
						height: 1164,
						width: 1164,
						relativePath: "./pierremtb.jpg",
						relativeServerPath: "/content/data/pierremtb.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\pierremtb.jpg",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Living off the iPad as an Engineer",
				description:
					"Tips on how to get yourself a proper development environment on the iPad to fully exploit its potential.",
				published: "2021-02-11T00:00:00.000Z",
				edited: "2021-02-12T00:00:00.000Z",
				authors: ["pierremtb"],
				tags: ["tools", "opinion"],
				attached: [],
				license: "cc-by-nc-nd-4",
			},
			contentMeta:
				"\nSince I transitioned from working all day on my personal MacBook Pro to receiving a work computer for a new engineering position, I decided to go for the only financially wise thing: selling my beloved 16\" MacBook Pro to live off the 2018 iPad Pro I had around for iOS app development as my **main computer** for my personal life.\n\nWhile I loved the feeling of knowing that I could open and run anything on the MacBook Pro — aka a conventional laptop — the idea of moving solely to the efficient machine that is the iPad Pro was appealing for various reasons. Yet the question remained: how would I continue the work on side-projects, whether they be software or hardware? There is a lot of talk these days about how [LumaFusion](https://freecadweb.org/) is real competition to Adobe Premiere, or that [Affinity Photo](https://affinity.serif.com/en-gb/photo/ipad/) has nothing to fear from desktop Photoshop. While I do spend some time with such creative apps, how am I supposed to maintain [my personal webpage](https://pierrejacquier.com), write code for my Raspberry Pi, or create CAD models for 3D printing?\n\nThe answer is mostly through remote access. Fear not, dear reader, we’ll try to rely on tools that are native or at least *feel* native on the iPad Pro, not just cheap Teamviewer-ing. What started as just a 9 to 5 setup challenge, not the other way around, is now much more than that.\n\n*Note 1: This is merely a shoutout to great products I’m using daily and isn’t sponsored. The links are not affiliated either. I’ll try to provide different options as well as keep some focus on open-source software.*\n\n*Note 2: The new iPad Air now features most of the laptop-like abilities of its Pro brother; therefore, I’ll only use the term “iPad” in the following. But bear in mind: the cheapest 2020 8th-gen iPad still has the old form-factor and a Lightning port, making it incompatible with some of the following.*\n\n![Photo by [Ernest Ojeh](https://unsplash.com/@namzo) on [Unsplash](https://unsplash.com/s/photos/magic-keyboard?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)](cover.jpeg)\n\n# External Monitor\n\n I was lucky enough to have an [LG Ultrafine 4K](https://www.apple.com/shop/product/HMUA2VC/A/lg-ultrafine-4k-display) display in my possession for use with the MacBook Pro. These fancy displays are designed hand-in-hand with Apple are compatible with both Thunderbolt devices like the MacBook and with standard USB-C devices like the iPad. However, you can’t use the same cable, so if you are planning to buy this one, make sure you’re using the one with an iPad label on it before returning it out of frustration!\n\nI believe it’s common knowledge that you can’t just work out of a laptop form-factor all day without destroying your neck. Here, the cheapest option would be to go with one of the pretty cool arm mounts specifically designed to put the iPad right in front of your eyes or just a pile of books. This allows the expensive pixels to get the amount of attention they deserve while also enabling instant video calling.\n\nWhile an external monitor is really comfortable, one thing to note is the lack of *full* external monitor support with iPadOS at the time of writing (version 14.4). Connecting a USB-C display like the Ultrafine essentially triggers an AirPlay mirroring of the iPad’s screen and is therefore really not as satisfying as a standard laptop+display setup with an extended desktop for greater multitasking. Depending on its size and resolution, you’ll most likely end up with black bars around the mirrored video flux. It's annoying even though you do get used to it. But there are ways around it.\n\nThe workaround is indeed in the ability of iOS apps to specify how an external monitor should be used. For instance, [Netflix](http://netflix.com) uses the iPad’s display for media controls while broadcasting the content onto the monitor. Luma Fusion has a mode for the video editor to stay on the iPad’s screen while live previewing on the monitor in full-screen.\n\nAnd in a clever workaround, a popular app called [Shiftscreen](http://shiftscreen.app) leverages these APIs to enable side-by-side web multitasking on the full external monitor, which is pretty convenient since nowadays a lot of work is actually happening within web apps like Google Docs or JIRA. On top of that, the app is still able to project the side-by-side browser on the external monitor even when it's in Split Mode, therefore enabling another iOS app to be interacted with, such as a todo-list or direct messaging.\n\n![shiftscreen.app, the app’s webpage](shiftscreen.jpeg)\n\nI have to say, it’s an excellent option for specific tasks, but after a while I just learned to love the mirrored interface. Now I’m rarely spending my time in apps that provide full monitor support. App Switching via Cmd+Tab or the gestures is hugely satisfying, plus I don’t think it has brought my productivity down at all. In fact, it might have improved my focus on the task at hand.\n\n# External Keyboard and Mouse/Trackpad \n\nSpeaking of hitting keys and performing gestures. While the iPad itself has an incredibly mobile form-factor, we owe ourselves a decent desk setup. After all, we are turning it into our personal workstation.\n\nOn the high-end of the spectrum lies the incredible [Magic Keyboard for iPad](https://www.apple.com/shop/product/MXQT2LL/A/magic-keyboard-for-ipad-air-4th-generation-and-ipad-pro-11-inch-2nd-generation-us-english). It’s heavy. It’s stupidly expensive. But it’s my best purchase of the year. It effectively turns the iPad into a laptop with its form-factor, Trackpad, and additional charging port. On top of that, the keys have nothing to envy from a real Magic Keyboard. It's so good it made it to my main desk. Thankfully though, Logitech came up with a much more affordable option, the [Folio Touch](https://www.logitech.com/en-ca/products/ipad-keyboards/folio-touch.html) for 11\" iPads.\n\nNow even cheaper options are possible, such as just getting a good regular Bluetooth keyboard to complete a stand mount like the mechanical [Keychron K2](https://www.keychron.com/products/keychron-k2-wireless-mechanical-keyboard), as well as a mouse — I can’t *not *recommend the [MX Master series](https://www.logitech.com/en-ca/products/mice/mx-master-3.910-005620.html), but the Pebble, for something on the pocketable side, is excellent and very affordable in the [K380 combo](https://www.logitech.com/en-ca/products/combos/k380-m350-keyboard-mouse-combo.html). The external [Magic Trackpad](https://www.apple.com/shop/product/MRMF2LL/A/magic-trackpad-2-space-gray) 2 is incredible to use and works well with iPadOS but is, granted, on the expensive end of the spectrum of pointing devices.\n\n![A quite simple desk setup. Doing some LumaFusion edits!](setup.jpeg)\n\n*Update: After quite some time with the Magic Keyboard for iPad on my desk, I revised the setup, with the tablet laying flat under the monitor to quickly take handwritten notes or drawings, with the Keychron K2 + Magic Trackpad 2 as input devices. We’ll see if it sticks!*\n\n# Software Dev: Remote Server and Native Apps\n\nLet’s get into some real engineering tools. As I'm sure you already know, there’s no walled garden like iOS/iPadOS. Apps are fully contained, *Files* is some kind of file explorer yet remains very limited, and firing up a local command line is pure fantasy.\n\n*How the heck do we write and run our beloved code, Pierre? 💁*\n\nAs is so common these days, the trick is in the cloud. While it comes with its drawbacks such as spotty connections, offloading the work to a remote, safe, always-accessible machine has some nice things going for it. A hosted instance can be fired up in a matter of minutes these days. To stay somewhat minimalist, I chose to keep an old laptop plugged in inside a closet, but there are many options out there.\n\nThere’s essentially two solutions that work for me at the moment: [Visual Studio Code](https://code.visualstudio.com/) in the browser, which can be achieved in various ways; or a native SSH client app such as [Termius](https://apps.apple.com/us/app/termius-ssh-client/id549039908) or [Blink Shell](https://blink.sh/). The former is a cross-platform cloud SSH/Mosh service that has really good iPad support. Its main downside is the lack of a full external monitor integration, as mentioned earlier. Blink Shell features it, and it works quite well. Picture that clean tmux/vim session on a 4K monitor, at the cost of losing mouse support, though.\n\n![A mobile web dev session in the native app Termius, with the side-kick browser](termius.png)\n\nFor a proper IDE, there are ways to run the undisputed leader of the last years — VS Code  — in Safari. I personally only fire it up for refactoring and large Git diffs. I’m happy with terminal-only work otherwise. [Code-server](http://code-server.dev/) is a project that does exactly that, and at the time of writing comes with a Beta parameter --link [that does all the hard work of securing the connection](https://github.com/cdr/code-server#cloud-program-%EF%B8%8F). A one line command is all it takes to install on various hosts, and another one-liner for port-forwarding to start the remote access. For more details on the setup with more technical bits, you can check out [my Notion project page](https://www.notion.so/iPad-Challenge-ba216d5956194453a0dd4d56f62d888c).\n\nThe big downside here is the [lack of scrolling support](https://github.com/microsoft/vscode/issues/106232). Lucky for me, I’m navigating keyboard-only with the help of the [Vim extension](https://marketplace.visualstudio.com/items?itemName=vscodevim.vim) ([Colemak version](https://marketplace.visualstudio.com/items?itemName=ollyhayes.colmak-vim)), but it’s a real barrier to entry. It’s related to a bug in the web engine. Nonetheless, there are a few hosted solutions with the same problem, such as [Stackblitz](https://stackblitz.com/) and [GitHub Codespaces](https://github.com/features/codespaces) — which both get honourable mentions yet aren’t open source — so I’m confident that issue might get solved soon.\n\n*Update: the scrolling issue is fixed as of iPadOS 14.5 Beta 1, which requires enrolling [here](https://beta.apple.com/sp/betaprogram/). This means more people will be able to enjoy a proper coding experience on the iPad, and is really good news.*\n\nThe example below shows VS Code running in Safari for iPad. It would be a great use case for Shiftscreen, which could have both VS Code and whatever docs on the side for a true multitasking experience on an external display.\n\n![A code-server session, that feels native since it’s the same VS Code as on a regular computer](code-server.png)\n\nSide note: there is no such thing as a system clipboard manager on iPadOS, which is quite inconvenient when coming from other desktop platforms. While there are various paid solutions that offer cloud clipboard syncing and beyond, the non-iPad-optimized [Clipboard++](https://apps.apple.com/ca/app/clipboard/id854707788) brought me exactly what I needed: a way to automatically save my Cmd+Cs so I don’t have to worry about overwriting the system buffer. Neat!\n\n# Software Dev (Bonus): Local Raspberry Pi\n\nThe folks for whom a cloud connection isn’t an option shouldn't lose hope: the most recent iteration of the sweet [Raspberry Pi](https://www.raspberrypi.org/products/raspberry-pi-4-model-b/) comes with a USB-C power and data port. Hence it’s possible to both run it and give it ethernet access from the iPad with one cable.\n\nThis enables a lot of possibilities, including local SSH, code-server-ing and access to the Desktop Environment. I have yet to test this, but there are plenty of guides out there, notably [one from the very official MagPi](https://magpi.raspberrypi.org/articles/connect-raspberry-pi-4-to-ipad-pro-with-a-usb-c-cable).\n\nA great way to make sure some coding work gets done when we get to travel again ✈️\n\n# Hardware Dev: Remote Server and Remote Desktop\n\nHere comes the harder part: hardware (*easy)*.\n\nTo put it bluntly, there’s no SSHing into Computer Aided Design software. There’s no way of vim-editing a SolidWorks file. [OpenSCAD](https://www.openscad.org/) might be an exception to these statements, yet it’s most definitely niche.\n\nTwo options I have explored:\n\n* use some kind of Remote Desktop software to access our closet computer/server and run the software remotely;\n\n* choose a web-based CAD software.\n\nThe first option could apply to a broad range of software beyond just CAD. The real bottleneck here is the quality of the iPad app. I’ve gone through many of the free options *à la* TeamViewer or Chrome Remote Desktop. But none provided mandatory things for my use case like full mouse buttons support (including click-and-drag with the wheel, for instance). Jumping into more premium territory, Splashtop remains free for personal and same-network use and has a great iPad app, but has a monthly fee for real remote access. The one that ended up meeting all my needs was the $19.99 [Jump Destkop](https://jumpdesktop.com/). With its outdated app icon and steep price tag, this was clearly not my first choice. But their Fluid Remote Desktop protocol for Windows and macOS has just been a very smooth experience. It works wonders with external mice and Trackpads, and it has full external monitor support on the iPad with automatic resolution matching. On top of that, it supports VNC (even over SSH tunnels) to connect to Linux hosts such as a (local) Raspberry Pi or other instances I use for work on a daily basis.\n\nAnd it has stood the test of time: the whole design for my [GeeXY 3D printer project](https://www.notion.so/Geeetech-CoreXY-Conversion-GeeXY-b46d9f7b4b0643faa60bd2f20399c0b6) was created through Jump Desktop on the iPad. No regrets so far!\n\n![My GeeXY printer model, fully created through Jump on the iPad](freecad.png)\n\nThe second option lies in the cloud web-based CAD system: [Onshape](http://onshape.com). I’ve been bullish on their system through college since they’ve nailed quite a lot of CAD aspects that are out of this article’s scope. While I do use it from time to time on Safari on the iPad, I’ve been loyal to the great open-source [FreeCAD](https://freecadweb.org/) lately because I’m also using it at work (it even runs on Linux!).\n\n![Despite a few small bugs on Safari, Onshape is an excellent CAD system, fully usable on the iPad](onshape.png)\n\nA life of workarounds? Most definitely.\n\nComing from macOS, the holy grail for many curious people who care about a furnished software library, first-class terminal experience and compatibility, the fully mobile iPad path is definitely not the easiest path to meet our specific needs as developers or engineers.\n\nBut the joy, I mean it, the joy, that this iPad experience brings is what got me up for the challenge and kept me on the hook for side-projects as well as working from home. At the moment, there’s no going back and it’s become clear that Intel chips are not missed at all, by me or many people with the new M1 Macs.\n\nOne curious thing I noticed in the iPadOS environment is a widespread old-school pay-once/use-forever business model, which offers quite a shelter from our subscription-based world. Shiftscreen was $3.99, Jump $19.99, and LumaFusion $29.99. It’s now paid for. Let’s enjoy the ride.\n",
		},
		{
			title: "Making a Slack Bot using NodeJS and MongoDB",
			description:
				"Join us as we teach you how to create a Slack bot from scratch using their Node SDK and MongoDB for persistence",
			published: "2020-02-18T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["mongodb", "node", "slack"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "making-a-slack-bot-with-node-and-mongo",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Making a Slack Bot using NodeJS and MongoDB",
				description:
					"Join us as we teach you how to create a Slack bot from scratch using their Node SDK and MongoDB for persistence",
				published: "2020-02-18T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["mongodb", "node", "slack"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nModern-day remote live communication has never been as efficient or fast as it is today. Services like Slack make it easy to join huge multi-channel communication workspaces for pleasure or business. These channels are often able to be super-powered by in-chat bots and applications that can inform you of new information from external services or even add new functionality to the chat. Luckily for us, Slack has put a lot of effort into making these extensions to Slack easy to write.\n\nOne way they've made extension development easier is by providing an SDK for Node developers to use and create extensions with. This post will outline how we can create a Slack bot to add functionality to chats.\n\n# Initial Signup {#signup-for-dev-account}\n\nTo start, we'll need to [sign up for a developer account and create an app to host our application logic using this link](https://api.slack.com/apps). This will allow us to create new Slack apps and bots to add into our workspace.\n\n![The create app dialog that shows up once \"create app\" is pressed](./create_app_dialog.png)\n\nEnter in an app name, and assign the workspace where you want the app to live during development. Once done, you should be greeted by a dashboard for your Slack app. You'll want to keep this screen open during development, as we'll be referring to it throughout this post.\n\n![The initial screen that'll be shown when a new app is created](./initial_screen.png)\n\nThis screen (and the tabs off to the side) provides the configuration for all of the interactions with Slack that we'll build upon with our code. We're even able to customize the look of our application in our Slack settings at the bottom of this homepage.\n\n![Towards the bottom of the initial page will show how to customize the description and such.](./display_info.png)\n\nAs mentioned previously, Slack provides an SDK for Node applications. [You can find the homepage for the npm package at the following URL.](https://github.com/slackapi/node-slack-sdk)\n\nIn order to quickly set up the SDK, we'll create a new directory for our code to live. Once we have a clear directory, we can run:\n\n```\nnpm init -y\n```\n\nTo setup an initial `package.json`. Once we have a `package.json`, we can add the packages we require to use the Slack SDK:\n\n```\nnpm install @slack/web-api @slack/events-api\n```\n\nAfter this, we'll then be able to use their example API from the README of their project as a starter for our app:\n\n```javascript\n// index.js\n// Initialize using signing secret from environment variables\nconst { createEventAdapter } = require('@slack/events-api');\n// Slack requires a secret key to run your bot code. We'll find and figure out this signing secret thing in the next steps\nconst slackEvents = createEventAdapter(process.env.SLACK_SIGNING_SECRET);\nconst port = process.env.PORT || 3000;\n\n// Attach listeners to events by Slack Event \"type\". See: https://api.slack.com/events/message.im\nslackEvents.on('message', (event) => {\n  console.log(`Received a message event: user ${event.user} in channel ${event.channel} says ${event.text}`);\n});\n\n// Handle errors (see `errorCodes` export)\nslackEvents.on('error', console.error);\n\n// Start a basic HTTP server\nslackEvents.start(port).then(() => {\n  // Listening on path '/slack/events' by default\n  console.log(`server listening on port ${port}`);\n});\n```\n\nThis code is what we'll need to run a `console.log` every time a user sends a message. However, _we'll need to set things up more to get this code actually working due to Slack's permissions systems_ and such. For now, we'll save this code to `index.js` in the same folder we saved our `package.json` file.\n\nAnother thing that was mentioned in the code sample was the `process.env.SLACK_SIGNING_SECRET`. This is the key that Slack will use to connect your code to your workspace. We'll want to keep in mind how to store the signing secret (as the name implies, _we want to keep this key a secret as otherwise anyone can hijack your Slack app_). As the above code hints at, it's suggested to use an environment variable file or configuration.\n\nWhile environment variables are typically assigned by system configurations, we'll make development easier by setting up a `.env` file with the expected credentials. Then, to inject the `.env` file contents into our process, we'll run our code using [the `env-cmd` package](https://www.npmjs.com/package/env-cmd). We'll start by installing the package:\n\n```\nnpm i env-cmd\n```\n\nThis package will look for a `.env` file and inject it into your command that follows `env-cmd`. So, for example, you can **make a new file called `.env` and place the following contents in it**:\n\n```\nSLACK_SIGNING_SECRET=<SIGNING_SECRET_FROM_HOMESCREEN>\n```\n\nThen, in your `package.json`, you can **edit your `start` script** to reflect the following:\n\n```json\n{\n  \"scripts\": {\n    \"start\": \"env-cmd node ./index.js\"\n  }\n}\n```\n\nNow, whenever your code uses `process.env.SLACK_SIGNING_SECRET`, it'll represent the value present in your `.env` file.\n\n# Development Hosting {#development-environment-setup}\n\nIn order to have these events called, we'll need to get a public URL to route to our local development server. In order to do this, we can [use `ngrok`](https://github.com/inconshreveable/ngrok) to host a public URL in our local environment:\n\n```\nnpm i -D ngrok\nnpx ngrok http 3000\n```\n\n> Keep in mind that this should NOT be used to host your Slack application when you're ready to publish.\n> This should only be used during development process. In order to see how to deploy, you'll want to check out [the section on doing so using Heroku](#deployment).\n\nAfter doing so, you should be given an `ngrok.io` subdomain to map to your local IP address with a message like this:\n\n```\nForwarding https://9fca9f3e.ngrok.io -> http://localhost:3000\n```\n\n![Showing ngrok running in the terminal](./ngrok_running.png)\n\nWe're now able to use this URL as a bridge between the external internet and the local environment we're in. This is how we'll tell Slack to run our `index.js` file when we receive a new event.\n\nHowever, there's yet another step to enable the functionality. Slack, in order to ensure security, wants to confirm that you own this domain. As such, they have _a utility you'll need to run to ensure that you own the domain_. So, for example, in order to add in the events subscription to our current code, we'll run the following command:\n\n```\n./node_modules/.bin/slack-verify --secret <signing_secret>\n```\n\nWhere the `<signing_secret>` is the same signing secret from the `.env` file.\n\n![Showing the command running](./slack_verify.png)\n\nWith this command still running, you can **press on the \"Add features and functionality\" tab** in the homescreen you saw when you first created your Slack app in the browser. Once the \"features and functionality\" is open, **press \"Event Subscriptions\"**.\n\nThis will bring you to a page with an \"On/Off\" toggle. **Toggle it to \"On\"** and **add the `ngrok` domain** in the request URL.\n\n![Adding the ngrok domain into the \"event subscription\" area](./event_subscription_enable.png)\n\nThis should show \"Verified\" to explain that your domain is verified to have belonged to you, but the domain isn't saved yet; We first need to **add workspace events to subscribe to**. This is to ensure that any app doesn't simply have root permissions to everything for privacy and security's sake and instead has to ask for granular permissions.\n\n![Searching for OAuth permissions to add to the event handler.](./searching_events.png)\n\nLet's say we want to handle all of the public messages to a channel, we can add `message.channels` to get the permissions to do so.\n\n![After adding the permission and the app is saved, it should look like this](./added_channels_read.png)\n\nIf you look through the code that we now have in the `index.js` file, you'll see that we're listening for `messages`:\n\n```javascript\nslackEvents.on('message', (event) => {\n  console.log(`Received a message event: user ${event.user} in channel ${event.channel} says ${event.text}`);\n});\n```\n\nI can hear you asking \"But here we're requesting `message.channels`, how do we know that those two match each other?\"\n\nYou can actually check the event `type` from [the API reference documentation](https://api.slack.com/events/message.channels) to see that the `type`s match up.\n\n# Development App Installation {#development-installation}\n\nYou'll notice, as I first did, that if you start your server with `npm start` and then send a message to a public channel that you'll notice something in your terminal. Or, well, rather, a lack of something in your terminal. The `console.log` that you would expect to run isn't doing so - why is that?\n\nThat's because the app isn't actually enabled in your workspace yet (A real 🤦‍♂️ for me when I discovered this one).\n\nTo do so, check the sidebar to the right of your Slack API homepage for the `install` section:\n\n![The preview of the \"install\" page](./install_app.png)\n\nSimply click `Install App to Workspace`, then `Allow` to give permissions to add the app to your workspace.\n\n> Keep in mind, folks can use Slack for personal communication. You may want to give folks in your workspace a heads-up or simply create a new Slack workspace for testing.\n\nOnce this is done, you can send a test message to a public channel and see it printed out in your console!\n\n![A showcase of the message \"Hello, World\" being sent to the app](./hello_world.png)\n\n# App Interactivity {#interactive-message-package}\n\nWhile listening to events alone can be very useful in some circumstances, oftentimes having a way to interact with your application can be very helpful. As a result, the Slack SDK also includes the `@slack/interactive-messages` package to help you provide interactions with the user more directly. Using this package, you can respond to the user's input. For example, let's say we wanted to replicate the [PlusPlus](https://go.pluspl.us/) Slack bot as a way to track a user's score. \n\nWe want to have the following functionality for an MVP:\n\n- `@UserOrThing++`: A way to add a point to a user or thing\n- `@UserOrThing--`: A way to remove a point from a user or thing\n- `@PointsRUs leaderboard`: A flat list of the items/people with points\n\nEach of these messages will prompt the bot to respond with a message in the same channel. Ideally we'd use a database to store score for long-term projects, but for now, let's use in-memory storage for an MVP of the interactivity we're hoping for.\n\n## Setup {#interactive-bot-setup}\n\nFirst and foremost, something you'll need to do is add a new OAuth permission to enable the functionality for the bot to write to the channel. Go into the dashboard and go to the \"OAuth & Permissions\" tab. The second section of the screen should be called \"Scopes\", where you can add the `chat:write:bot` permission.\n![The permissions searching for \"chat\" which shows that \"chat:write:bot\" permission we need to add](./chat_write_bot_oauth.png) \n\nAfter enabling the new OAuth permission, you'll need to reinstall your app. This is because you're changing the permissions of your apps and you need to accept the new permissions when you reinstall the app. If you scroll to the top of the same OAuth page, you should see a `Reinstall App` button that will help you do this easily.\n\n![The top of the \"OAuth & Permissions\" screen that shows that access token and the \"Reinstall app\" button](./oauth_tokens.png)\n\nOnce this is done, you can access the OAuth token for the fresh installation of your workspace. This token will enable us to send messages to the workspace itself. It acts as a user-login of sorts for your Slack bot.\n\n> This token is unique per-workspace, so if you're intending for a broader release of your bot (to be easily added to multiple workspaces with a single button click), you'll likely need to [walk through their OAuth token request system](https://api.slack.com/authentication/oauth-v2#asking). Since this is meant as an introductory look at their APIs, we'll simply keep things locally and copy-paste.\n\nCopying the token from the top of the screen, store it into our `.ENV` file so that we can utilize it in our application. I named the environment variable `OAUTH_TOKEN`, so when you see that in code examples, know that this is in reference to this value.\n\n## The Code {#leaderboard-local-code}\n\nTo start adding in response functionality, we need to install the package that'll allow us to use the web API:\n\n```\nnpm i @slack/web-api\n```\n\nThe web API should enable us to use the [`postMessage`](https://api.slack.com/methods/chat.postMessage) method to send messages to a channel when they send a message.\n\nOnce this is installed, we're able to instantiate the web API with the OAuth token we grabbed earlier\n\n```javascript\nconst { WebClient } = require('@slack/web-api');\nconst token = process.env.OAUTH_TOKEN;\nconst web = new WebClient(token);\n```\n\nAfter this is setup, we could run code like:\n\n```javascript\nweb.chat.postMessage({\n  text: 'A post message',\n  channel: channelId,\n});\n```\n\nTo send a message. Let's try to use this API to add some trivial logic into our existing `events` listening functionality.\n\n```javascript\nconst { createEventAdapter } = require('@slack/events-api');\nconst { WebClient } = require('@slack/web-api');\n\nconst token = process.env.OAUTH_TOKEN;\nconst slackSigningSecret = process.env.SLACK_SIGNING_SECRET;\n\nconst slackEvents = createEventAdapter(slackSigningSecret);\nconst web = new WebClient(token);\nconst port = process.env.PORT || 3000;\n\nslackEvents.on('message', async event => {\n\tconsole.log(`Received a message event: user ${event.user} in channel ${event.channel} says ${event.text}`);\n\n  // Check if the text includes the text we'd want to use to check the leaderboard\n\tif (/@pointsrus leaderboard/i.exec(event.text)) {\n\t\tconst result = await web.chat.postMessage({\n      // We'll add more functionality in the future. We just want to test it works, first\n\t\t\ttext: 'This should output a leaderboard',\n\t\t\tchannel: event.channel,\n\t\t});\n\n\t\tconsole.log(`Successfully send message ${result.ts} in conversation ${event.channel}`);\n\t}\n});\n\nslackEvents.on('error', console.error);\n\nslackEvents.start(port).then(() => {\n\tconsole.log(`server listening on port ${port}`);\n});\n```\n\nAs it did before, the code will listen for every message we send. Then, we listen for any time the user typed the message `@pointsrus leaderboard` and respond with a placeholder value when they do so. We're making sure to use the same channel ID by using the `event.channel` property.\n\n> Remember, the channel ID is not the same thing as the human-readable channel name. It's a unique ID generated by Slack and as such you'd have to use the API to get the channel ID if you only knew the human-readable name\n\n## Adding State {#interactive-local-state}\n\nLuckily for our MVP, we've already outlined that we won't be using a database for the initial version of the bot. As such, we're able to keep a simple stateful object and simply mutate it to keep track of what's being scored.\n\nFor example, given a mutable `state` variable, we can do actions to read and write as such:\n\n```javascript\nconst state = {};\nstate.word1 = 1;\nstate.word1 = state.word1 + 1;\nstate.word2 = -1;\nconsole.log(state); // {word1: 2, word2: -1}\n```\n\nFollowing this pattern, let's go through and add a few lines of code to the last example to fulfill the expected behavior:\n\n```javascript\nconst { tablize } = require('batteries-not-included/utils');\n\n/**\n * @type <Record<string, number>> A record of the word and score. Should start at 0.\n * This should be replaced by a database for persistence. This is just a demo and as\n * such simply mutates this object to be stateful.\n */\nconst state = {};\n\n/**\n * A function that accepts a string, then returns the action and the word to score.\n */\nconst getIsPlusOrMinus = str => {\n\t// Accept em-dash for cases like MacOS turning -- into an emdash\n\tconst plusOrMinusRegex = /\\@(\\w+?)(\\-{2}|\\+{2}|\\—{1})/;\n  // The first item in the array is the full string, then the word to score, then the opperator\n\tconst [_, itemToScore, scoreStr] = plusOrMinusRegex.exec(str) || [];\n\tswitch (scoreStr) {\n\t\tcase '--':\n\t\tcase '—':\n\t\t\treturn { action: 'minus', word: itemToScore };\n\t\tcase '++':\n\t\t\treturn { action: 'add', word: itemToScore };\n\t\tdefault:\n\t\t\treturn { action: '', word: undefined };\n\t}\n};\n\nslackEvents.on('message', async event => {\n\tconsole.log(`Received a message event: user ${event.user} in channel ${event.channel} says ${event.text}`);\n\n\tconst { action, word } = getIsPlusOrMinus(event.text);\n  // If the `event.text` did not include a score (of plus or minus), it will return `{}`\n  // And therefore `action` will be `undefined`\n\tif (action) {\n\t\tconst currentState = state[word] || 0;\n    // Mutate the state to update the score of the word.\n\t\tstate[word] = action == 'add' ? currentState + 1 : currentState - 1;\n\t\tconst actionString = action == 'add' ? 'had a point added' : 'had a point removed';\n\t\tconst result = await web.chat.postMessage({\n\t\t\ttext: `${word} ${actionString}. Score is now at: ${state[word]}`,\n\t\t\tchannel: event.channel,\n\t\t});\n\n\t\tconsole.log(`Successfully send message ${result.ts} in conversation ${event.channel}`);\n\t}\n\n\tif (/@pointsrus leaderboard/i.exec(event.text)) {\n\t\t// Tablize just takes a 2D array, treats the first item as a header row, then makes an ASCII table\n\t\tconst tableString = tablize([['Item', 'Count'], ...Object.entries(state)]);\n\n\t\t// Send the table in a code block to use a monospace font and render properly.\n\t\tconst result = await web.chat.postMessage({\n\t\t\ttext: '```\\n' + tableString + '```',\n\t\t\tchannel: event.channel,\n\t\t});\n\n\t\tconsole.log(`Successfully send message ${result.ts} in conversation ${event.channel}`);\n\t}\n});\n```\n\nAs you can see, we're able to add in the functionality for the score-keeping relatively easily with little additional code. Slightly cheating, but to pretty-print the score table, we're using a `tablize` package that's part of [the \"batteries not included\" library we've built](https://github.com/unicorn-utterances/batteries-not-included) in order to provide an ASCII table for our output.\n\n# Adding a Database {#mongodb}\n\nEven though the bot works well so far, it's not ideal to keep a score in memory. If your server crashes or if there's any other form of interruption in the process running, you'll lose all of your data. As such, we'll be replacing our local store with a database. As our data needs are simple and I want to keep this article relatively short, let's use a NoSQL database to avoid having to structure tables. We'll use MongoDB in order to keep our data stored.\n\n> This section will cover the setup of MongoDB Atlas, if you'd like to [skip ahead to the code section where we switch our in-memory store with a MongoDB database, you can click here](#mongodb-code)\n\nTo remain consistent in keeping our app setup as trivial as possible, we'll be using MongoDB Atlas. Atlas enables us to have a serverless MongoDB service at our disposal. In order to use Atlas, you'll need to [sign up for an account](https://cloud.mongodb.com/user#/atlas/register/accountProfile). \n\nOnce done, you'll need to \"Build a new cluster\" in order to create a database cluster for your Slack app.\n\n![An image of the \"Build a new cluster\" button](build_a_new_cluster.png)\n\nFrom here, you'll select the cloud provider that you'll use to host your database. There's AWS, Google Cloud Platform, and Azure. All three of these options have a Free tier that you can use to host smaller applications and have **plenty** of storage and run time for smaller projects.\n\n![The \"create new cluster\" screen with a price of $0.54 an hour](./create_new_cluster.png)\n\n> While all three have free tiers, you're limited to one free cluster per account. I have already created one, which is why it shows the price in the screenshot above. Yours should be free if you select one of the \"Free tier available\" hosting locations and read the instructions.\n\nOnce the cluster is created, it may take some time to propagate the changes to the hosting solution itself. Once it is done, however, we're able to create a new user for database access. This will allow you to create a user for your MongoDB code to connect to a make interactions. Go to the \"Database Access\" tab of Atlas and press \"Add New User\",\n\n![The \"Database Access\" screen with a \"Add new user\" button](./database_access.png)\n\nOnce there, you'll add a username and password. You'll also want to enable the permission to read and write to a database, seeing as we'll be editing the scores collection in the database.\n\n![A new user creation screen with \"dbuser\" and \"dbpass\" as the username and password. Selected to have \"full read and write\" permissions.](./new_db_user.png)\n\n> Be sure to remember that password! You'll want to store it in your .ENV file as plain text (so be sure you're on a secured computer! You do not want to store your passwords in such insecure ways for production).\n\nWe'll store the MongoDB username and password into our `.ENV` file. The username under `MONGOUSER` and the password under `MONGOPASS`.\n\nOnce this is done, we'll want to go back to the homepage of the Atlas cluster. You should then see a button labeled \"Connect\". Press that to start the instructions for how to connect our Node code to MongoDB.\n\n![The image of the cluster0 with the \"connect\" button highlighted](./mongodb_atlas_connect.png)\n\nThis will bring up the dialog for the cluster. You'll see different connection options for Mongo Shell, Compass, or various drivers. Since we'll be using the NodeJS driver to connect our code, we'll select \"Connect Your Application\".\n\n![Showing the first dialog of \"create cluster\"](./db_connect_1.png)\n\nThis will bring up a dialog where you can select the _Node.JS_ driver. This will give you the connection string with `<username>` and `<password>` that you'll need to replace with the credentials we created earlier.\n\n![The dialog that shows connection string to add to NodeJS code](./db_connect_2.png)\n\nThis string is called the _connection string_ which is [a URI](https://en.wikipedia.org/wiki/Uniform_Resource_Identifier). This URI will be used to connect your code to the database you just created. Let's store that string [in a template literal, which will allow us to interpolate variables into the string](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals) for the password:\n\n```javascript\nconst uri = `mongodb+srv://${mongoUser}:${mongoPass}@cluster0-xxxxx.mongodb.net/test?retryWrites=true&w=majority`; \n```\n\nNow that we understand the URI we need to pass to the Node driver to connect to the database, we'll dive into the code we need to change to enable MongoDB.\n\n## The Code {#mongodb-code}\n\n```javascript\nconst { createEventAdapter } = require('@slack/events-api');\nconst { WebClient } = require('@slack/web-api');\nconst { MongoClient } = require('mongodb');\nconst { tablize } = require('batteries-not-included/dist/utils/index.js');\n\nconst token = process.env.OAUTH_TOKEN;\nconst slackSigningSecret = process.env.SLACK_SIGNING_SECRET;\n// Grab the MongoDB password and username we stored in our env file\nconst mongoPass = process.env.MONGOPASS;\nconst mongoUser = process.env.MONGOUSER;\nconst port = process.env.PORT || 3000;\nconst uri = `mongodb+srv://${mongoUser}:${mongoPass}@cluster0-xxxxx.mongodb.net/test?retryWrites=true&w=majority`;\n\nconst slackEvents = createEventAdapter(slackSigningSecret);\nconst web = new WebClient(token);\nconst dbClient = new MongoClient(uri, { useNewUrlParser: true });\n\n// Connect to Mongo server instance\ndbClient.connect(err => {\n\t// Show any errors that showup in the \n\tif (err) console.error(err);\n  // Connect to the test database in a cluster. Connect to the scores collection in that database\n\tconst collection = dbClient.db('test').collection('scores');\n\n\tconst getIsPlusOrMinus = str => {\n\t\tconst plusOrMinusRegex = /\\@(\\w+?)(\\-{2}|\\+{2}|\\—{1})/;\n\t\tconst [_, itemToScore, scoreStr] = plusOrMinusRegex.exec(str) || [];\n\t\tswitch (scoreStr) {\n\t\t\tcase '--':\n\t\t\tcase '—':\n\t\t\t\treturn { action: 'minus', word: itemToScore };\n\t\t\tcase '++':\n\t\t\t\treturn { action: 'add', word: itemToScore };\n\t\t\tdefault:\n\t\t\t\treturn { action: '', word: undefined };\n\t\t}\n\t};\n\n\tslackEvents.on('message', async event => {\n\t\ttry {\n\t\t\tconsole.log(`Received a message event: user ${event.user} in channel ${event.channel} says ${event.text}`);\n\n\t\t\tconst { action, word } = getIsPlusOrMinus(event.text);\n\t\t\tif (action) {\n\t\t\t\tconst value = action == 'add' ? 1 : -1;\n\n\t\t\t\t// Update the document and also return the document's value for us to use\n\t\t\t\tconst doc = await collection.findOneAndUpdate(\n\t\t\t\t\t{ word },\n\t\t\t\t\t// Add `value` to \"count\" property. If `-1`, then remove one from \"count\"\n\t\t\t\t\t{ $inc: { count: value } },\n\t\t\t\t\t// `returnOriginal: false` says to return the updated document\n\t\t\t\t\t// `upsert` means that if the document doesn't already exist, create a new one\n\t\t\t\t\t{ returnOriginal: false, upsert: true }\n\t\t\t\t);\n\n\t\t\t\tconst actionString = action == 'add' ? 'had a point added' : 'had a point removed';\n\n\t\t\t\tconst result = await web.chat.postMessage({\n\t\t\t\t\ttext: `${doc.value.word} ${actionString}. Score is now at: ${doc.value.count}`,\n\t\t\t\t\tchannel: event.channel,\n\t\t\t\t});\n\n\t\t\t\tconsole.log(`Successfully send message ${result.ts} in conversation ${event.channel}`);\n\t\t\t}\n\n\t\t\tif (/@pointsrus leaderboard/i.exec(event.text)) {\n\t\t\t\tconst topTenCollection = await collection\n\t\t\t\t\t// Find ANY document \n\t\t\t\t\t.find({})\n\t\t\t\t\t// Sort it from highest to lowest\n\t\t\t\t\t.sort({ count: 1 })\n\t\t\t\t\t// Limit it to 10 in case there are hundreds of values\n\t\t\t\t\t.limit(10)\n\t\t\t\t\t// Then, return it as a promise that has an array in it\n\t\t\t\t\t.toArray();\n\t\t\t\t// Mapping the array to display with `tablize`\n\t\t\t\tconst state = topTenCollection.map(doc => {\n\t\t\t\t\treturn [doc.word, doc.count];\n\t\t\t\t});\n\t\t\t\tconst tableString = tablize([['Item', 'Count'], ...state]);\n\n\t\t\t\tconst result = await web.chat.postMessage({\n\t\t\t\t\ttext: '```\\n' + tableString + '```',\n\t\t\t\t\tchannel: event.channel,\n\t\t\t\t});\n\n\t\t\t\tconsole.log(`Successfully send message ${result.ts} in conversation ${event.channel}`);\n\t\t\t}\n\t\t} catch (e) {\n\t\t\tconsole.error(e);\n\t\t}\n\t});\n\n\tslackEvents.on('error', console.error);\n\n\tslackEvents.start(port).then(() => {\n\t\tconsole.log(`server listening on port ${port}`);\n\t});\n});\n```\n\nIf you do a diff against the previous code, you'll see that we were able to add the database using only 4 or 5 new operations. These operations are to:\n\n- Connect to the Mongo driver\n- Create a new connection to the database\n- An update and get query\n- A find query to list the leaderboard\n\nBecause we now have a database running the data show, we can be sure that our data will persist - even if or when our server goes down (either for maintenance or a crash). Now that we have the code updates, let's get to deploying the code we had set up.\n\n# Deployment {#deployment}\n\nIdeally, since our Slack app is a small side project, we'd like to host things in a straightforward manner for cheap/free. One of my favorite hosting solutions for such projects is [Heroku](heroku.com/). Heroku is no stranger to Slack apps, either. They have [an official blog post outlining making their own Slack bot using the web notification feature within Slack](https://blog.heroku.com/how-to-deploy-your-slack-bots-to-heroku). That said, our route is going to be a bit different from theirs because we chose to use the events subscriptions instead.\n\nLet's start our step-by-step guide immediately after [you've created an account with Heroku](https://signup.heroku.com/).\n\nOnce you're logged in, you should see a dashboard like the following:\n\n![The dashboard of Heroku with the \"New\" dropdown showing an option to \"Create a new app\"](./heroku_create_dropdown.png)\n\nOnce you see this page, select \"New\", then \"Create new app\".\n\n![The \"Create a new app\" page with the \"points-r-us\" name shown as available](./heroku_create_naming.png)\n\nThis should let you provide a name for your project. This name should be memorable, since it will be used to generate the subdomain on Heroku's servers. For example, my `points-r-us` app is available at [points-r-us.herokuapp.com/](https://points-r-us.herokuapp.com/). While ultimately it doesn't matter much for a simple Slack bot, if you wanted to use this subdomain for other things later on that you might add on, it helps to have a memorable name.\n\nOnce this is done, open the Heroku app you just created by selecting it. You should see a dashboard screen like this:\n\n![The dashboard screen like this with instructions of how to deploy to Heroku](./initial_heroku_instructions.png)\n\nThe instructions that will show up While we'll be following these instructions shortly, we'll first want to setup our environment variables, just as we did with our `.env` file locally. You should see a \"Settings\" tab at the top of your dashboard.\n\n![The settings page with a button labeled \"Reveal Config Vars\"](./heroku_hidden_config_vars.png)\n\nUpon opening the tab, you should see a button labeled \"Reveal Config Vars\". Press the button and copy your environment variables from your `.env` file into the fields available.\n\n![All of the .env file variables with the same name saved into Heroku](./heroku_config_vars.png)\n\nNow that we have that, we can go back to our instructions that were on the main dashboard. Let's open up the same folder we have our `package.json` and `index.js` in, and install the Heroku CLI:\n\n```\nnpm i -g heroku\n```\n\n> It's worth noting that Heroku officially suggests using [an alternative installation method for the CLI](https://devcenter.heroku.com/articles/heroku-cli) due to Node.JS incompatibilities, but I've faced no such issues with my (admittedly limited) usage.\n\nOnce this is done, we can:\n\n- Sign into our account using `heroku login`\n\n- Initialize a git repo into this folder `git init`\n\n- Add Heroku as a remote place to deploy to. We should be able to see our Git URL from the settings page, so for example I would run:\n\n  ```\n  git remote add heroku https://git.heroku.com/points-r-us.git\n  ```\n\nNow that we have Heroku set up, we're able to `git push heroku master` to have Heroku deploy our `npm start` script. This means that anything we put in our `package.json`'s `start` `script` property, then commit and push, will then be run on our server. As such, the first thing we need to do is verify that we own that subdomain for Slack to send events to.\n\nWhile our `package.json` might have looked like this before:\n\n```json\n\"scripts\": {\n  \"start:dev\": \"env-cmd node ./index.js\",\n  \"start\": \"node ./index.js\",\n},\n```\n\nWe'll want to update it so that the `start` command uses the signing secret from our server environment variables to verify:\n\n```json\n\"verify\": \"slack-verify --secret $SLACK_SIGNING_SECRET --port=$PORT\",\n\"start\": \"npm run verify\",\n```\n\nWe need to allow Heroku to dictate the port to host our verification command as well, to get past their firewall they automatically route to the app's subdomain; hence the `--port` attribute. \n\nAfter making this change, we'll run:\n\n- `git commit -m \"Enforced verification\"`\n- `git push heroku master`\n\nAnd watch as our app gets deployed:\n\n![The app being deployed during the `git push`](./heroku_initial_deploy.png)\n\nAfter this, we can go back to the Slack app dashboard and change the Event Subscription URL.\n\n![The event subscription being updated to \"points-r-us.herokuapp.com\"](./slack_verify_heroku.png)\n\n> Don't forget to hit \"Save\" once you change the URL 😉\n\nFinally after this change is made, you can modify your `package.json` to run the server with `node` once again:\n\n```json\n\"scripts\": {\n  \"start\": \"node ./index.js\",\n},\n```\n\n> Be sure to use `node` and not `env-cmd`, as we want to actually use the values from the environment variable, not from a `.env` file.\n\nRun that last `git commit` and `git push heroku master` and congrats! You should have everything deployed and ready to use!\n\n![A demo of the app by adding a point to \"botsRCool\" and removing one from \"failedDemos\"](./showcase.png)\n\n# Conclusion {#conclusion}\n\nSlack provides a feature-rich, very useful chat application. Being able to add in your own functionality to said application only makes things more powerful for either your group or your end users. I know many businesses will use Slack bots as another experience for their business users. Now you've been able to see the power of their Node SDK and how easy it is to setup and deploy your very own Slack app using MongoDB and Heroku!\n\nAny questions or comments we didn't touch on here? Let us know down below or [in our Discord](https://discord.gg/FMcvc6T) where you can ask questions in real time with folks from our community!\n",
		},
		{
			title: "Building an Angular Blog With Scully",
			description:
				"NuxtJS and Gatsby allow you to make SSG-enabled blogs, but Angular doesn't have an equivalent... Until now. Let's build a blog with Scully!",
			published: "2020-03-17T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["angular", "ssg", "scully"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "making-an-angular-blog-with-scully",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Building an Angular Blog With Scully",
				description:
					"NuxtJS and Gatsby allow you to make SSG-enabled blogs, but Angular doesn't have an equivalent... Until now. Let's build a blog with Scully!",
				published: "2020-03-17T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["angular", "ssg", "scully"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nIf you've ever used something like [Gatsby](https://www.gatsbyjs.org/) or [NuxtJS](https://nuxtjs.org/), you may already be familiar with Static Site Generation (SSG). If not, here's a quick rundown: You're able to export a React application to simple HTML and CSS during a build-step. This export means that (in some cases), you can disable JavaScript and still navigate your website as if you'd had it enabled. It also often means much faster time-to-interactive times, as you no longer have to run your JavaScript to render your HTML and CSS.\n\nFor a long time, React and Vue have had all of the SSG fun... Until now. \n\nRecently, a group of extremely knowledgeable developers has created [Scully, a static site generator for Angular projects](https://github.com/scullyio/scully). If you prefer Angular for your stack, you too can join in the fun! You can even trivially migrate existing Angular projects to use Scully!\n\nIn this article, we'll outline how to set up a new blog post site using Scully. If you have an existing blog site that you'd like to migrate to use Scully, the blog post should help you understand some of the steps you'll need to take as well.\n\nWithout further ado, let's jump in, shall we?\n\n# Initial Setup {#initial-setup}\n\nFirst, we have some requirements:\n\n- Node 12\n- Angular CLI installed globally\n\nYou're able to do this using `npm i -g @angular/cli`. You'll want to make sure you're using the latest version if you already have it pre-installed.\n\nNow that we have that covered let's generate our project!\n\n```\nng new my-scully-blog\n```\n\nWe'll want to choose `y` when it asks us to add routing. The second question that will be raised is regarding what flavor of CSS you'd like. I like `SCSS`, so I chose that, but you're free to select any of the options that you deem fit for your blog.\n\nIf we pause here and run `ng serve`, we'll find ourselves greeted with the default generated app screen from the Angular core team upon visiting the `localhost:4200` URI in our browser.\n\nThe file that this code lives under is the `app.component.html` file. We'll be modifying that code later on, as we don't want that UI to display on our blog site.\n\n## Adding Scully {#adding-scully}\n\nAfter that, open the `my-scully-blog` directory and run the following command to install and add Scully to the project:\n\n```\nng add @scullyio/init\n```\n\nThis will yield us some changed files. You'll see a new `scully.my-scully-blog.config.js` file that will help us configure Scully. You'll also notice that your `package.json` file has been updated to include two new commands:\n\n```\n\"scully\": \"scully\",\n\"scully:serve\": \"scully serve\"\n```\n\nHere's where the \"SSG\" portion of Scully comes into play. You see, once you run `ng build` to build your application, you should be running `npm run scully` to run the static generation. That way, it will generate the HTML and CSS that your Angular code will generate on the client ahead-of-time. This means that you have one more build step, but it can be incredibly beneficial for your site's speed and usability.\n\nWe'll need to run the `npm run scully` command later on, but for now, let's focus on adding Markdown support to our blog:\n\n# Adding Markdown Support\n\nWhile Scully [_does_ have a generator to add in blog support](https://github.com/scullyio/scully/blob/master/docs/blog.md), we're going to add it in manually. Not only will this force us to understand our actions a bit more to familiarize ourselves with how Scully works, but it means this article is not reliant on the whims of a changing generator. \n\n> This isn't a stab at Scully by any means, if anything I mean it as a compliment. The team consistently improves Scully and I had some suggestions for the blog generator at the time of writing. While I'm unsure of these suggestions making it into future versions, it'd sure stink to throw away an article if they were implemented.\n\n## Angular Routes {#angular-blog-routes}\n\nBefore we get into adding in the Scully configs, let's first set up the page that we'll want our blog to show up within. We want a `/blog` sub route, allowing us to have a `/blog` for the list of all posts and a `/blog/:postId` for the individual posts.\n\nWe'll start by generating the `blog` module that will hold our routes and components.\n\n```\nng g module blog --route=blog --routing=true --module=App\n```\n\nThis will create a route called `blog` and generate or modify the following files:\n\n```\nCREATE src/app/blog/blog-routing.module.ts (341 bytes)\nCREATE src/app/blog/blog.module.ts (344 bytes)\nCREATE src/app/blog/blog.component.scss (0 bytes)\nCREATE src/app/blog/blog.component.html (21 bytes)\nCREATE src/app/blog/blog.component.spec.ts (622 bytes)\nCREATE src/app/blog/blog.component.ts (275 bytes)\nUPDATE src/app/app-routing.module.ts (433 bytes)\n```\n\nIf you look under your `app-routing.module.ts` file, you'll see that we have a new route defined:\n\n```typescript\nconst routes: Routes = [\n  {\n    path: \"blog\",\n    loadChildren: () =>\n      import(\"./blog/blog.module\").then(m => m.BlogModule)\n  }\n]\n```\n\nThis imports the `blog.module` file to use the further children routes defined there. If we now start serving the site and go to `localhost:4200/blog`, we should see the message \"blog works!\" at the bottom of the page. \n\n### Routing Fixes {#router-outlet}\n\nThat said, you'll still be seeing the rest of the page. That's far from ideal, so let's remove the additional code in `app.component.html` to be only the following:\n\n```html\n<router-outlet></router-outlet>\n```\n\nNow, on the `/blog` route, we should _only_ see the \"blog works\" message!\n\nHowever, if you go to `localhost:4200/`, you'll see nothing there. Let's add a new component to fix that.\n\n```\nng g component homepage -m App\n```\n\nThis will create a new `homepage` component under `src/app/homepage`. It's only got a basic HTML file with `homepage works!` present, but it'll suffice for now. Now we just need to update the `app-routing.module.ts` file to tell it that we want this to be our new home route:\n```typescript\nimport { HomepageComponent } from \"./homepage/homepage.component\";\n\nconst routes: Routes = [\n  {\n    path: \"blog\",\n    loadChildren: () =>\n      import(\"./blog/blog.module\").then(m => m.BlogModule)\n  },\n  {\n    path: \"\",\n    component: HomepageComponent\n  }\n];\n```\n\nNow, we have both `/blog` and `/` working as-expected!\n\n### Adding Blog Post Route {#blog-post-route}\n\nJust as we added a new route to the existing `/` route, we're going to do the same thing now, but with `/blog` paths. Let's add a `blog-post` route to match an ID passed to `blog`. While we won't hookup any logic to grab the blog post by ID yet, it'll help to have that route configured.\n\n```\nng g component blog/blog-post -m blog\n```\n\nThen, we'll need to add that path to the blog list:\n\n```typescript\nconst routes: Routes = [\n  { path: \":postId\", component: BlogPostComponent },\n  { path: \"\", component: BlogComponent }\n];\n```\n\nThat's it! Now, if you go to `localhost:4200/blog`, you should see the `blog works!` message and on the `/blog/asdf` route, you should see `blog-post works!`. With this, we should be able to move onto the next steps!\n\n\n## The Markdown Files {#frontmatter}\n\nTo start, let's create a new folder at the root of your project called `blog`. It's in this root folder that we'll add our markdown files that our blog posts will live in. Let's create a new markdown file under `/blog/test-post.md`. \n\n```markdown\n---\ntitle: Test post\ndescription: This is a post description\npublish: true\n---\n\n# Hello, World\n\nHow are you doing?\n```\n\n> Keep in mind that the file name will be the URL for the blog post later on. In this case, the URL for this post will be `/blog/test-post`.\n\nThe top of the file `---` block is called the \"frontmatter\"_. You're able to put metadata in this block with a key/value pair. We're then able to use that metadata in the Angular code to generate specific UI based on this information in the markdown file. Knowing that we can store arbitrary metadata in this frontmatter allows us to expand the current frontmatter with some useful information:\n\n```markdown\n---\ntitle: Test post\ndescription: This is a post description\npublish: true\nauthorName: Corbin Crutchley\nauthorTwitter: crutchcorn\n---\n```\n\nIt's worth mentioning that the `publish` property has some built-in functionality with Scully that we'll see later on. We'll likely want to leave that field in and keep it `true` for now.\n\n## Scully Routes {#scully-blog-route-config}\n\nNow we'll tell Scully to generate one route for each markdown file inside of our `blog` folder. As such, we'll update our `scully.my-scully-blog.config.js` file to generate a new `/blog/:postId` route for each of the markdown files:\n\n```javascript\nexports.config = {\n  // This was generated by the `ng add @scullyio/init`\n  projectRoot: \"./src\",\n  projectName: \"my-scully-blog\",\n  outDir: './dist/static',\n\t// This is new\n  routes: {\n    '/blog/:postId': {\n      type: 'contentFolder',\n      postId: {\n        folder: \"./blog\"\n      }\n    },\n  }\n};\n```\n\nBefore we start the build process and run Scully, let's add one more change to our `blog-post.component.html` file:\n\n```html\n<h1>My Blog Post</h1>\n<hr>\n<!-- This is where Scully will inject the static HTML -->\n<scully-content></scully-content>\n<hr>\n<h2>End of content</h2>\n```\n\nAdding in the `scully-content` tags will allow Scully to inject the HTML that's generated from the related Markdown post into that tag location. To register this component in Angular, we also need to update our `blog.module.ts` file to add an import:\n\n```typescript\nimport {ScullyLibModule} from '@scullyio/ng-lib';\n\n@NgModule({\n  declarations: [BlogComponent, BlogPostComponent],\n  imports: [CommonModule, BlogRoutingModule, ScullyLibModule]\n})\nexport class BlogModule {}\n```\n\nYou'll notice that if you run `ng serve` at this stage and try to access `localhost:4200/blog/test-post`, you'll see... Not the blog post. You'll see something like:\n\n```html\n<h1>Sorry, could not parse static page content</h1>\n<p>This might happen if you are not using the static generated pages.</p>\n```\n\nThis message is showing because we're not able to get the HTML of the markdown; we haven't statically generated the site to do so. Scully injects the markdown's HTML at build time, so we're unable to get the contents of the markdown file during the development mode. We _can_ get the route metadata from the frontmatter on the blog post, however. If you want to learn more about that, you'll have to read the next section. 😉\n\n# Running the Build\n\n> Even if you're familiar with Angular's build process, you should read this section! Scully does some non-standard behavior that will prevent some of the steps in the next sections if not understood properly.\n\nNow that we have our code configured to generate routes based on our Markdown files let's run `ng build`. The build should go off without a hitch if the code was updated alongside the post.\n\n> If you hit an error at this step, make sure to read through the steps again and pay attention to the error messages. Angular does a decent job of indicating what you need to change to get the build working again.\n\nNow, let's run `npm run scully`; Doing so should give us some message like this:\n\n```\nRoute \"\" rendered into file: \"/Users/ccrutchley/git/my-scully-blog/dist/static/index.html\"\nRoute \"/blog\" rendered into file: \"/Users/ccrutchley/git/my-scully-blog/dist/static/blog/index.html\"\nRoute \"/blog/2020-03-12-blog\" rendered into file: \"/Users/ccrutchley/git/my-scully-blog/dist/static/blog/2020-03-12-blog/index.html\"\nsend reload\n```\n\n> \"ScullyIO not generating markdown blog post route\" is something I've attempted to Google multiple times.\n>\n> If you happen to see an error like `Pull in data to create additional routes.\n> missing config for parameters (postId) in route: /blog/:postId. Skipping\n> Route list created in files` you've misconfigured your `scully.config.js` file.\n>\n> For example, at one point I had the following code in my config file when I was getting that error:\n>\n> ```javascript\n> '/blog/:postId': {\n>   type: 'contentFolder',\n>   slug: {\n>     folder: \"./blog\"\n>   }\n> },\n> ```\n>\n> The problem is that the route and the config are mismatched. You need to configure it to look like this:\n>\n> ```javascript\n> '/blog/:postId': {\n>   type: 'contentFolder',\n>   postId: {\n>     folder: \"./blog\"\n>   }\n> },\n> ```\n>\n> Making sure that your params match like this should generate the pages as-expected.\n\nNow, we can access the server at the bottom of the build output:\n\n```\nThe server is available on \"http://localhost:1668/\"\n```\n\nFinally, if we go to [http://localhost:1668/blog/test-post](http://localhost:1668/blog/test-post), we can see the post contents alongside our header and footer.\n\n![A preview of the post as seen on-screen](./hello_world_blog_post.png)\n\n## Scully Build Additions {#scully-build-folder}\n\nYou'll notice that if you open your `dist` folder, you'll find two folders:\n\n- `my-scully-blog`\n- `static`\n\n![An image showing the folder layout of dist](./dist-folders.png)\n\nThe reason for the two separate folders is because Scully has it's own build folder. When you ran `ng build`, you generated the `my-scully-blog` folder, then when you later ran `npm run scully`, it generated the `static` folder. As such, if you want to host your app, you should use the `static` folder.\n\n## Asset Routes {#scully-build-routes}\n\nIf you open the `/src/assets` folder, you'll notice another file you didn't have before `npm run scully`. This file is generated any time you run Scully and provides you the routing metadata during an `ng serve` session. [Remember how I mentioned that there was a way to access the Markdown frontmatter data?](#scully-blog-route-config) Well, this is how! After running a Scully build, you'll be provided metadata at your disposal. In the next section, we'll walk through how to access that metadata!\n\n# Listing Posts {#scully-route-acess}\n\nTo get a list of posts, we're going to utilize Scully's route information service. To start, let's add that service to the `blog.component.ts` file:\n\n```typescript\nimport { Component, OnInit } from '@angular/core';\nimport { ScullyRoutesService } from '@scullyio/ng-lib';\n\n@Component({\n  selector: 'app-blog',\n  templateUrl: './blog.component.html',\n  styleUrls: ['./blog.component.scss']\n})\nexport class BlogComponent implements OnInit {\n  constructor(private scully: ScullyRoutesService) {}\n\n  ngOnInit(): void {      \n  }\n}\n```\n\nNow that we have access to said service, we can add some calls inside of our `ngOnInit` lifecycle method to list out the routes:\n\n```typescript\nngOnInit(): void {\n  this.scully.available$.subscribe(routes => console.log(routes));\n}\n```\n\nIf you now start your server (`ng serve`) and load up your `/blog` route, you should see the following printed out to your log:\n\n```javascript\n0: {route: \"/\"}\n1: {route: \"/blog/test-post\", title: \"Test post\", description: \"This is a post description\", publish: true, authorName: \"Corbin Crutchley\", …}\n2: {route: \"/blog\"}\n```\n\nSee? We're able to see all of the routes that Scully generated during the last `npm run scully` post-build step. Additionally, any of the routes that were generated from a markdown file contains it's frontmatter!\n\n> [Remember how I said earlier that the frontmatter fields impacted Scully?](#frontmatter) Well, that `publish` field will toggle if a route shows up in this list or not. If you change that field to `false`, then rebuild and re-run the `scully` command, it will hide it from this list.\n>\n> Want to list **all** of the routes, including the ones with `publish: false`? Well, change `this.scully.available$` to `this.scully.allRoutes$`, and you'll even have those in the fray!\n\nWe now have the list of routes, but surely we don't want to list the `/blog` or the `/` routes, do we? Simple enough, let's add a filter:\n\n```typescript\nroutes.filter(route =>\n\troute.route.startsWith('/blog/') && route.sourceFile.endsWith('.md')\n);\n```\n\nAnd that'll give us what we're looking for:\n\n```javascript\n0: {route: \"/blog/test-post\", title: \"Test post\", description: \"This is a post description\", publish: true, authorName: \"Corbin Crutchley\", …}\n```\n\n## Final Blog List {#scully-avail-routes}\n\nWe can cleanup the code a bit by using [the Angular `async` pipe](https://angular.io/api/common/AsyncPipe):\n\n```typescript\n// blog.component.ts\nimport { Component } from '@angular/core';\nimport { ScullyRoutesService } from '@scullyio/ng-lib';\nimport { map } from 'rxjs/operators';\n\n@Component({\n  selector: 'app-blog',\n  templateUrl: './blog.component.html',\n  styleUrls: ['./blog.component.scss']\n})\nexport class BlogComponent {\n  constructor(private scully: ScullyRoutesService) {}\n\n  $blogPosts = this.scully.available$.pipe(\n    map(routes =>\n      routes.filter(\n        route =>\n          route.route.startsWith('/blog/') && route.sourceFile.endsWith('.md')\n      )\n    )\n  );\n}\n```\n\n```html\n<!-- blog.component.html -->\n<ul aria-label=\"Blog posts\">\n  <li *ngFor=\"let blog of $blogPosts | async\">\n    <a [routerLink]=\"blog.route\">\n      {{blog.title}} by {{blog.authorName}}\n    </a>\n  </li>\n</ul>\n```\n\nThis code should give us a straight list of blog posts and turn them into links for us to access our posts with! \n\n![A preview of the post list as seen on-screen](./post_list_preview.png)\n\nWhile this isn't a pretty blog, it is a functional one! Now you're able to list routes; we can even get the metadata for a post\n\n## Final Blog Post Page {#scully-avail-routes-filtered}\n\nBut what happens if you want to display metadata about a post on the post page itself? Surely being able to list the author metadata in the post would be useful as well, right?\n\nRight you are! Using [RxJS' `combineLatest` function](https://rxjs.dev/api/index/function/combineLatest) and [the `ActivatedRoute`'s `params` property](https://angular.io/api/router/ActivatedRoute#params) (alongside [the RxJS `pluck` opperator](https://rxjs.dev/api/operators/pluck) to make things a bit easier for ourselves), we're able to quickly grab a post's metadata from the post page itself.\n\n```typescript\n// blog-post.component.ts\nimport { Component } from '@angular/core';\nimport { ActivatedRoute } from '@angular/router';\nimport { ScullyRoutesService } from '@scullyio/ng-lib';\nimport { combineLatest } from 'rxjs';\nimport { map, pluck } from 'rxjs/operators';\n\n@Component({\n  selector: 'app-blog-post',\n  templateUrl: './blog-post.component.html',\n  styleUrls: ['./blog-post.component.scss']\n})\nexport class BlogPostComponent {\n  constructor(\n    private activatedRoute: ActivatedRoute,\n    private scully: ScullyRoutesService\n  ) {}\n\n  $blogPostMetadata = combineLatest([\n    this.activatedRoute.params.pipe(pluck('postId')),\n    this.scully.available$\n  ]).pipe(\n    map(([postId, routes]) =>\n      routes.find(route => route.route === `/blog/${postId}`)\n    )\n  );\n}\n```\n\n```html\n<!-- blog-post.component.html -->\n<h1 *ngIf=\"$blogPostMetadata | async as blogPost\">Blog Post by {{blogPost.authorName}}</h1>\n<hr>\n<!-- This is where Scully will inject the static HTML -->\n<scully-content></scully-content>\n<hr>\n<h2>End of content</h2>\n```\n\n![A preview of the post list as seen on-screen](./post_page_preview.png)\n\n\n\n\n\n# Conclusion\n\nWhile this blog site is far from ready from release, it's functional. It's missing some core SEO functionality as well as general aesthetics, but that could be easily remedied. Using a package like [`ngx-meta`](https://www.npmjs.com/package/@ngx-meta/core) should allow you to make short work of the SEO meta tags that you're missing where areas adding some CSS should go a long way with the visuals of the site.\n\nAll in all, Scully proves to be a powerful tool in any Angular developer's toolkit, and knowing how to make a blog with it is just one use case for such a tool.\n\nAs always, I'd love to hear from you down below in our comments or even [in our community Discord](https://discord.gg/FMcvc6T). Also, don't forget to subscribe to our newsletter so you don't miss more content like this in the future!\n",
		},
		{
			title: "Master React Unidirectional Data Flow",
			description:
				"Making sure your app's code is structured well is critical. Mastering React Unidirectionality is a huge part of that. Learn how to here.",
			published: "2021-04-27T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["react", "javascript"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/master-react-unidirectional-data-flow/",
			slug: "master-react-unidirectional-data-flow",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Master React Unidirectional Data Flow",
				description:
					"Making sure your app's code is structured well is critical. Mastering React Unidirectionality is a huge part of that. Learn how to here.",
				published: "2021-04-27T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["react", "javascript"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/master-react-unidirectional-data-flow/",
			},
			contentMeta:
				'\nAs with any form of programming, there are dozens of ways to manage data inside a React application. That said, not all methods are equally capable of scaling. There are some "suggested patterns" for your React applications to follow that will ensure you\'re not forced to pause in order to reorganize or re-evaluate your existing code when you’re building the application.\n\nToday, we\'ll be covering one of the most important structural best practices to follow when building your React applications: Unidirectional data flow.\n\n# What is Unidirectional Data Flow?\n\nUnidirectional data flow is the idea that components should only raise data in one direction. Child components should only call functions from parent components, while parent components should only set/pass data to their children.\n\n![A chart showing two directions being bad, one direction being good](./good_bad_direction.svg)\n\nIn order to explain how both of these look in real code, let\'s start with how a properly unidirectional parent and child component would be written.\n\n# Unidirectional Demo\n\nA great example of a set of components we\'ll use to demonstrate unidirectionality is a parent "App" component and a child "Form" component.\n\nLet\'s take a look at a code sample that follows this unidirectionality first:\n\n<iframe src="https://app.coderpad.io/sandbox?question_id=176771" loading="lazy"></iframe>\n\nAs you can see we\'re passing the `onChange` and value props to `SimpleForm`. This keeps our state consolidated inside of the `App` component rather than split between `App` and `SimpleForm`. Once you "submit" the form, `SimpleForm` calls `onDone` which changes the state stored inside of `App`. This in turn causes a re-render of `SimpleForm`.\n\nWhile `SimpleForm` is displaying the data to the user, the logic itself stays within `App`. `SimpleForm` contains no state or application logic; we call components like these "dumb" components. "Dumb" components are utilized for styling and composability, but not for app logic or state.\n\nThis is what a set of proper React components *should* look like. This pattern of raising state out of the component itself and leaving "dumb" component comes from the guidance of the React team itself. This pattern is called[ "lifting state up"](https://reactjs.org/docs/lifting-state-up.html).\n\nNow that we have a better understanding of the patterns to follow let\'s take a look at the wrong way to do things.\n\n# Breaking from Suggested Patterns\n\nNow that we\'ve "lifted" the state, let\'s drop back down into `SimpleForm`. We\'ll start by changing `SimpleForm` to a class component and adding state.\n\n```jsx\nclass SimpleForm extends React.Component {\n// State is now a part of the SimpleForm component\n  state = {\n    input: ""\n  }\n\n  onChange(e) {\n    this.setState({\n      input: e.target.value\n    })\n  }\n\n  render() {\n    return (\n      <div>\n        <label>\n          <div>Username</div>\n          <input onChange={this.onChange.bind(this)} value={this.state.input}/>\n        </label>\n        <button onClick={this.props.onDone}>Submit</button>\n      </div>\n    )\n  }\n}\n```\n\nNow, we can use ref in `App` to access the class methods and state.\n\n```jsx\nexport default function App() {\n  const simpleRef = React.useRef()\n  const [displayTxt, setDisplayTxt] = React.useState("")\n\n  const onDone = () => {\n    // Reach into the Ref to access the state of the component instance\n    setDisplayTxt(simpleRef.current.state.input)\n  }\n\n  return (\n    <div>\n      <SimpleForm\n        onDone={onDone}\n        ref={simpleRef}\n      />\n      <p>{displayTxt}</p>\n    </div>\n  )\n}\n```\n\n<iframe src="https://app.coderpad.io/sandbox?question_id=176773" loading="lazy"></iframe>\n\nThis code works, but has some inherent complexity issues. When you start expanding this component, this idea of separating your state and having to inspect the child reference from the parent makes development more difficult. Let\'s take a look visually how following the application logic is now more difficult with this pattern.\n\n# Visualizing the Problem\n\nFirst, let\'s start by taking a look at the `simpleRef` component, where the state is "lowered down" to the `SimpleForm` component:\n\n![A simple chart explained below](./one_way_flow.svg)\n\nIn this example, the flow of the application state is as follows:\n\n- `App` (and its children, `SimpleForm`) render\n- The user makes changes to the data stored in `SimpleForm`\n- The user triggers the `onDone` action, which triggers a function in `App`\n- The `App` `onDone` method inspects the data from `SimpleForm`\n- Once the data is returned to `App`, it changes its own data, thus triggering a re-render of `App` and `SimpleForm` both\n\nAs you can see from the chart above and the outline of the data flow, one action goes back and forth between the parent and child as `App` attempts to access the data stored in `SimpleForm`. This is a prime example of a bi-directional component action. This code sample gets even more complex when onDone is expected to change the state in SimpleForm.\n\nNow, let\'s contrast that to the mental model needed to work with unidirectionality enforced.\n\n![A simple chart explained below](./two_way_flow.svg)\n\n- App (and its children, `SimpleForm`) render\n- The user makes changes in `SimpleForm`, the state is raised up to `App` through callbacks\n- The user triggers the `onDone` action, which triggers a function in App\n- The `App` `onDone` method already contains all of the data it needs in it\'s own component, so it simply re-renders `App` and `SimpleForm` without any additional logic overhead\n\nAs you can see, while the number of steps is similar between these methods (but may not be in a less trivial example), the unidirectional flow is much more streamlined and easier to follow.\n\nThis is why the React core team (and the community at large) strongly suggests you use unidirectionality as often as possible.\n\n# Conclusion & Challenge\n\nUnderstanding unidirectionality is integral to scaffolding scalable React applications. Unidirectionality doesn\'t just apply to React, either - Angular and Vue applications often require similar patterns for large scale codebases to be easier to follow and more performant.\n\nNow that we have a deeper understanding of unidirectionality, here\'s a challenge for you: Refactor the following components to better reflect unidirectionality in this coding pad.\n\n<iframe src="https://app.coderpad.io/sandbox?question_id=176774" loading="lazy"></iframe>\n\nThe functionality of the app should be consistent with the previous version. Stuck?\n\nStart with:\n\n- Move the `getNewActivity` into a `React.useEffect` in App\n- Move the `state.activity` into a `React.useState` in App\n- Pass all props to `DisplayActivities`, making it a "dumb" component\n\nStill stuck? Maybe you\'re excited to share your solution?[ Send us a Tweet @CoderPad](https://twitter.com/CoderPad) or[ ask us in our community Slack](https://bit.ly/coderpad-slack). We\'d be excited to hear from you!\n',
		},
		{
			title: "Minecraft Data Pack Programming: Command Syntax",
			description:
				"Learn the beginnings of data pack development in Minecraft - using positions, entity selectors, and conditional logic in commands!",
			published: "2022-06-15T21:12:03.284Z",
			authors: ["fennifith"],
			tags: [],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			series: "Minecraft Data Pack Programming",
			order: 2,
			slug: "minecraft-data-packs-cmd-syntax",
			locale: "en",
			authorsMeta: [
				{
					id: "fennifith",
					name: "James Fenn",
					firstName: "James",
					lastName: "Fenn",
					description:
						"Enjoys writing software on loud keyboards. Starts too many projects. Consumes food.",
					socials: { twitter: "fennifith", github: "fennifith" },
					pronouns: "he",
					profileImg: "./fennifith.jpg",
					color: "#0091EA",
					roles: ["developer", "author", "community"],
					profileImgMeta: {
						height: 400,
						width: 400,
						relativePath: "./fennifith.jpg",
						relativeServerPath: "/content/data/fennifith.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\fennifith.jpg",
					},
					rolesMeta: [
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Minecraft Data Pack Programming: Command Syntax",
				description:
					"Learn the beginnings of data pack development in Minecraft - using positions, entity selectors, and conditional logic in commands!",
				published: "2022-06-15T21:12:03.284Z",
				authors: ["fennifith"],
				tags: [],
				attached: [],
				license: "cc-by-nc-sa-4",
				series: "Minecraft Data Pack Programming",
				order: 2,
			},
			contentMeta:
				"\n> Please note: this guide specifically covers the **Java Edition** version of Minecraft. Bedrock Edition does not use data packs, but provides customization through [add-ons](https://minecraft.fandom.com/wiki/Add-on).\n\nThe data packs built in this series can be found in the [unicorn-utterances/mc-datapacks-tutorial](https://github.com/unicorn-utterances/mc-datapacks-tutorial/tree/main/2-command-syntax) repository. Feel free to use it for reference as you read through these articles!\n\n# A note on tooling\n\nAt this point, we're starting to write more complex behavior in our data packs, and it might be useful to have some tools to check that our commands are valid while we're writing them.\n\nI use the [Visual Studio Code](https://code.visualstudio.com) editor with the [language-mcfunction](https://marketplace.visualstudio.com/items?itemName=arcensoth.language-mcfunction) extension by Arcensoth, which provides syntax highlighting and autocompletion for my commands directly in the text editor. However, there are many similar extensions with different features, and other text editors likely have their own plugins for providing this behavior as well.\n\n# Conditional logic with the \"/execute\" command\n\nIn the previous post, we ended on an interesting question &mdash; how do we write a command that only executes if the player is standing on a particular block?\n\nWell, Minecraft actually has a specific command for checking preconditions and other attributes of a command before running it - the [`/execute`](https://minecraft.fandom.com/wiki/Commands/execute) command!\n\nThis command can be used with an indefinite number of arguments, which might make it confusing to understand by reading its documentation &mdash; but this effectively means that you can add any number of preconditions to this command.\n\nFor example:\n\n```shell\nexecute if block ~ ~ ~ air run say \"You're standing in air!\"\n```\n\nThis uses two subcommands of the `execute` command: `if block ~ ~ ~ air` checks if the block identifier at the player's location is `minecraft:air`, and `run say \"You're standing in air!\"` will invoke the `say` command if the previous conditions have passed.\n\nTry running this command in Minecraft! As long as you're standing in an air block, you should see its message appear in the chat. If you stand underwater or in any block that isn't air (such as bushes/foliage), it should stop executing.\n\n| Standing in air | Standing in water |\n|-----------------|-------------------|\n| ![A Minecraft player standing on land, in a highlighted block of air](./if_block_air.png) | ![A Minecraft player standing in a pond, in a highlighted block of water](./if_block_water.png) |\n\nIf we want to negate this condition, we can replace the `if` subcommand with `unless` &mdash; this will print its message as long as the player *isn't* standing in air.\n\n```shell\nexecute unless block ~ ~ ~ air run say \"You aren't standing in air!\"\n```\n\nYou could also change the block identifier to look for a different type of block. For example, `if block ~ ~ ~ water` would make sure that the player is standing in water.\n\n# Position syntax\n\nSo what do the tildes (`~ ~ ~`) mean in the previous command? This is referring to *the current position* (in the X, Y, and Z axes) of the player that is executing the command. There are a few different ways to write positions like these in Minecraft, which I'll explain here:\n\n- ###### Absolute coordinates\n  Coordinates can be written as a fixed position in the world - say, `32 60 -94` (these coordinates can be obtained by opening the [F3 debug screen](https://minecraft.fandom.com/wiki/Debug_screen) and finding the \"Targeted block\" position.\n- ###### Current coordinates (tilde notation)\n  Using the tilde symbols (`~ ~ ~`) will reference *the current position* that the command is executed at. This can also be mixed with static values, such as `32 ~ -94`, which will reference the block at (x: 32, z: -94) using the player's current y-axis.\n- ###### Relative coordinates\n  These positions can also be *offset* by a certain number of blocks in any direction by adding a number after the tilde. For example, `~2 ~-4 ~3` will move 2 blocks horizontally from the player's x-axis, 4 blocks down in the y-axis, and 3 blocks horizontally in the z-axis.\n- ###### Directional coordinates (caret notation)\n  Similar to relative coordinates, directional coordinates (`^ ^ ^`) will start from wherever the command is executed from. However, any offsets will be applied relative to *wherever the current player or entity is looking.* For example, `^2 ^-4 ^3` will move 2 blocks to the left of the player, 4 blocks downward, and 3 blocks in front of the direction the player faces.\n\nTo experiment with the position syntax and see where certain positions end up in the world, we can add coordinates to the `/summon` command to spawn entities at a specific location. `/summon pig ~ ~ ~` would use the current position of the player (its default behavior), while `/summon pig ~ ~-4 ~` would probably spawn the pig underground. If you spawn too many pigs, you can use `/kill @e[type=pig]` to remove them.\n\nAn important note when using these positions: for players (and most other entities), any positions will actually start *at the player's feet.* If we want to start at the player's head, we can use the `anchored eyes` subcommand to correct this &mdash; using directional coordinates, `/execute anchored eyes run summon pig ^ ^ ^4` should summon a pig 4 blocks forward in the exact center of wherever the player is looking.\n\n## Positions in an \"/execute\" subcommand\n\n> In the following sections, it might help to keep in mind that every command has a specific *context* that it executes in. This context consists of a **position in the world** and a **selected entity** that runs the command. When you type a command in Minecraft's text chat, the **position** is your current location in the world, and the **selected entity** is your player.\n>\n> This context affects what blocks, locations, and entities certain commands and syntax will be referring to. The `/execute` command can change this context for any commands that it runs, which is what you'll see in the following example...\n\nThe `/execute` command also has a subcommand that can change its location in the world: `positioned ~ ~ ~`. Using this, we can rewrite our previous command:\n\n```shell\nexecute anchored eyes run summon pig ^ ^ ^4\nexecute anchored eyes positioned ^ ^ ^4 run summon pig ~ ~ ~\n```\n\nThese two commands do the same thing! When we use `positioned ^ ^ ^4`, we're moving the location of our command to those coordinates. Our `summon pig` command then uses its current position at `~ ~ ~`, which is in the location we've moved it to.\n\n### Using \"/execute\" with functions\n\nIf you recall the function we created in the previous chapter, we ended up making a single command (`/function fennifith:animals/spawn`) that spawns a bunch of animals at once.\n\nIf we use `/execute` to set the position of this function before it runs, this will also affect the location of *every command in that function.*\n\n```shell\nexecute anchored eyes positioned ^ ^ ^4 run function fennifith:animals/spawn\n```\n\nSince our `spawn` function summons all of the animals at its **current coordinates**, we can use the `/execute` command to change that position! This command should now spawn all the animals in front of the player, rather than directly on top of them.\n\n## Coordinate grid alignment\n\nIn order to align a position with the edge of a block, we can use another subcommand: `/execute align xyz`. This will align the command's position on the X, Y, and Z axes. You can also omit any axes that don't need alignment, so `align x` or `align xz` would also work as expected.\n\nWe can use this to ensure that a summoned entity is always spawned in alignment with the block grid, and not partway in-between block coordinates:\n\n```shell\nexecute align xz run summon pig ~ ~ ~\n```\n\nHowever, an important thing to note about Minecraft's coordinate system is that **whole numbers do not refer to the center of a block.** Instead, they are aligned with the bottom corner in the negative direction of each axis.\n\nThis means that, if you summon an entity at `0 ~ 0`, it will actually end up on the corner of the block at (0, 0). To fix this, you'll need to correct for the offset by moving it `0.5` on each axis; i.e. `0.5 ~ 0.5`.\n\n![A block grid showing the coordinate at 0,0 and the coordinate at 0.5,0.5](./coordinate-grid-0-5.svg)\n\nThus, to summon an entity in the center of a block, we can use this command:\n\n```shell\nexecute align xz run summon pig ~0.5 ~ ~0.5\n```\n\n# Entity selectors\n\nSo we've figured out how to use the position of the player, but how can we refer to other entities in the world? If you've paid attention to the `/kill @e[type=pig]` command from earlier, this is actually using an *entity selector* to reference all of the pigs in the world. We're using the `@e` variable (all entities in the world), and filtering it by `type=pig` to only select the entities that are pigs.\n\nHere's a list of some other selector variables we can use:\n- `@p` targets only the **nearest player** to the command's execution\n- `@a` targets **every player** in the world (useful for multiplayer servers / realms)\n- `@e` targets **every player, animal, and entity** in the world\n- `@s` targets only **the entity that executed the command**\n\nAnd here are some of the ways that we can apply the filter attributes:\n- `[type=player]` selects the entity type (`pig`, `cow`, `item_frame`, etc.)\n- `[gamemode=survival]` can select players in a specific game mode (`creative`, `spectator`, etc.)\n- `[limit=1]` will restrict the total number of entities that can be picked by the selector\n- `[sort=nearest]` will affect the order of entities selected (`furthest`, `random`, `arbitrary`)\n\nUsing these selectors, we can use `@e[type=pig,sort=nearest,limit=3]` to reference the three nearest pigs to player that executes the command.\n\nWhat if we use `/kill @a[type=pig]`? This won't select anything &mdash; because `@a` only selects *player* entities. Similarly, `@s[type=pig]` won't select anything either, because `@s` refers to the entity that runs the command &mdash; which is you, an entity of `type=player`.\n\n## Entities in an \"/execute\" subcommand\n\nJust like how `/execute positioned <x> <y> <z>` can be used to set the position of the command it runs, the `/execute as <entity>` subcommand can be used to set the entity that runs the command. This will effectively *change the entity that `@s` refers to* in anything it executes. Let's use this with our `/kill @e[type=pig]` command!\n\n```shell\nkill @e[type=pig]\nexecute as @e[type=pig] run kill @s\n```\n\nAn important note about how this feature works is that, after the `as @a[type=pig]` subcommand, it will actually run any following subcommands *once for every entity it selects.* This means that it is individually running `kill @s` once for every entity of `type=pig`.\n\n## Entity positions in an \"/execute\" subcommand\n\nSo, we *could* use this with our `if block ~ ~ ~ air` command from earlier to select only the pig entities that are standing in a block of air... but that might not work quite as we expect.\n\n```shell\nexecute as @e[type=pig] if block ~ ~ ~ air run kill @s\n```\n\nYou'll notice that this is actually affecting *all* pigs in the world... unless you stand underwater or in a block of foliage, in which case it won't do anything. This is because, while the `as <entity>` command changes the executing entity, it doesn't affect the position of the command's execution &mdash; it's still running at your location.\n\nWhile we can use relative positions with the `positioned ~ ~ ~` subcommand, you'll notice that there isn't any way to refer to a selected entity in this syntax... that's why we'll need to use the `at <entity>` subcommand instead!\n\n```shell\nexecute as @e[type=pig] at @s if block ~ ~ ~ air run kill @s\n```\n\nThis command first selects all `@e[type=pig]` entities, then - for each pig - changes the position of the command to the position of `@s` (the selected entity). As a result, the position at `~ ~ ~` now refers to the position of `@s`.\n\nThis can also be used with functions, same as before! However, I'm going to add a `limit=5` onto our entity selector here &mdash; otherwise it might spawn an increasing number of entities each time it runs, which could cause lag in your game if executed repeatedly.\n\n```shell\nexecute as @e[type=pig,limit=5] at @s run function fennifith:animals/spawn\n```\n\n# Filtering entities by position\n\nIn addition to the filter attributes we discussed earlier, the `[distance=<range>]` and `[x=<number>,dx=<number>]` attributes can be used to select entities based on their location in the world.\n\nHere are a few examples of this in use:\n\n## Radius selection\n\nWith the `[distance=<range>]` attribute, entities will be selected if they are within a specific radius of a position. However, for this to work as expected, the value needs to be a **range**, not a number. For example, `[distance=6]` will only select entities at a distance of exactly 6 blocks away.\n\nRanges can be specified by placing two dots (`..`) as the range between two numbers. If either side is left out, the range is interpreted as *open*, and will accept any number in that direction. By itself, `..` is a range that includes all numbers, `5..` will accept any number above 5, `..5` accepts any number below 5, and `1..5` accepts any number between 1 and 5.\n\n| `@e[distance=..5]` | `@e[distance=5..]` | `@e[distance=2..5]` |\n|--------------------|--------------------|---------------------|\n| ![A circle showing the selected area within a radius of 5 blocks](./select-radius-lt-5.svg) | ![A circle showing the selected area beyond a radius of 5 blocks](./select-radius-gt-5.svg) | ![A circle showing the selected area between a radius of 2 and 5 blocks](./select-radius-2-5.svg) |\n\n## Area selection\n\nThe `[x=]`, `[y=]`, and `[z=]` attributes will filter entities by their exact position. However, since entities can move to positions in-between blocks, their coordinates usually aren't in whole numbers &mdash; so it is unlikely that these filters by themselves will select any entities.\n\nHowever, these attributes can be paired with `[dx=]`, `[dy=]`, and `[dz=]` to select a range of values on the X, Y, and Z axes. For example, `[y=10,dy=20]` will filter any entity with a position between `Y=10` and `Y=30`.\n\nUsing all of these attributes togther can create a box area to search for entities within. For example, `@e[x=1,y=2,z=3,dx=10,dy=20,dz=30]` is effectively creating a box that is 10 blocks wide, 20 blocks high, 30 blocks deep, starting at the position (1, 2, 3).\n\n| `@e[x=5,z=1]` | `@e[x=5,dx=10]` | `@e[x=5,z=1,dx=10,dz=5]` |\n|---------------|-----------------|--------------------------|\n| ![A point showing the selected position at 5, 1](./select-area-5-1.svg) | ![An area showing the selected range on the X axis from 5 to 15](./select-area-x-5-15.svg) | ![A box showing the selected area from 5, 1 to 15, 6](./select-area-5-1-to-15-6.svg) |\n\n# Challenge: Using \"/execute\" in our tick.mcfunction\n\nIn the previous post, we got our data pack to print a message on every game tick. Let's try to change that &mdash; see if you can write a command that will check *the block below the player* to see if it is `air`. If the block underneath the player is air, they are probably falling, so let's print \"aaaaaaaaaaaaaaaaaaaa\" in the text chat.\n\n<details>\n  <summary>Need a hint?</summary>\n\n  There is some potential for confusion here, as the `tick` event doesn't actually run with any particular entity or position in the Minecraft world &mdash; by default, the location of `~ ~ ~` will be at (0, 0, 0), and `@s` will not refer to any entity.\n\n  You'll need to use a different selector to find the player and get their position before using the `if block` condition.\n</details>\n\n\n<details>\n  <summary>Solution</summary>\n\n  This command should select the player, get their position, and execute `say aaaaaaaaaaaaa` for every tick when the player is falling down or jumping in the air.\n\n  ```shell\n#       at each player position...\n#       |     if the block below is air...\n#       |     |                        print \"aaaaa\" in the chat!\nexecute at @a if block ~ ~-1 ~ air run say \"aaaaaaaaaaaaaaaaaaaa!\"\n  ```\n\n  There are a few other approaches that could be used here &mdash; if you used `as @a at @s`, you'll notice that `say` actually prints your username before its message. This is because you've changed the selected entity to you, the player; so you're sending the message as yourself.\n\n  If you try to flip the order of those two subcommands, `at @a as @s` won't actually select the right entity. You'll need to use `at @a as @p` to get the nearest player to the position of the selected player &mdash; which is a bit redundant when `as @a` could simply select the player entities to begin with.\n</details>\n\n**Note:** If you use the `as` and `at` subcommands together, be aware that both will run any consecutive subcommands *for every entity they select.* So `as @a at @a`, on a multiplayer server, will first select every player entity, then (for every player entity) will run at the position of every player entity. If `n = the number of players`, this will result in the command running `n*n` times in total.\n\nYou can try this with `@e[type=pig]` to see how many times it prints:\n\n```shell\n# This command will print far more messages than the number of pigs in your world.\nexecute as @e[type=pig] at @e[type=pig] run say hi\n```\n\n# Conclusion\n\nSo far, we've started using conditional logic and covered most of the syntax you'll see in Minecraft commands.\n\nBetween articles, feel free to experiment with [other commands](https://minecraft.fandom.com/wiki/Commands), such as `/setblock` or `/playsound`. Most of these won't be directly mentioned in the rest of this series, so it'll be useful to read through this list to figure out what each command can do.\n\nIn the next post, we'll cover an entirely different feature of Minecraft: *player scoreboards!* These will allow us to keep count of different variables, detect certain in-game actions, and store a player-specific or global state in our data packs.\n",
		},
		{
			title: "Minecraft Data Pack Programming: Introduction",
			description:
				"Learn the beginnings of data pack development in Minecraft - using commands and functions to add custom behavior from scratch!",
			published: "2022-06-14T21:12:03.284Z",
			authors: ["fennifith"],
			tags: [],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			series: "Minecraft Data Pack Programming",
			order: 1,
			slug: "minecraft-data-packs-introduction",
			locale: "en",
			authorsMeta: [
				{
					id: "fennifith",
					name: "James Fenn",
					firstName: "James",
					lastName: "Fenn",
					description:
						"Enjoys writing software on loud keyboards. Starts too many projects. Consumes food.",
					socials: { twitter: "fennifith", github: "fennifith" },
					pronouns: "he",
					profileImg: "./fennifith.jpg",
					color: "#0091EA",
					roles: ["developer", "author", "community"],
					profileImgMeta: {
						height: 400,
						width: 400,
						relativePath: "./fennifith.jpg",
						relativeServerPath: "/content/data/fennifith.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\fennifith.jpg",
					},
					rolesMeta: [
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Minecraft Data Pack Programming: Introduction",
				description:
					"Learn the beginnings of data pack development in Minecraft - using commands and functions to add custom behavior from scratch!",
				published: "2022-06-14T21:12:03.284Z",
				authors: ["fennifith"],
				tags: [],
				attached: [],
				license: "cc-by-nc-sa-4",
				series: "Minecraft Data Pack Programming",
				order: 1,
			},
			contentMeta:
				'\n> Please note: this guide specifically covers the **Java Edition** version of Minecraft. Bedrock Edition does not use data packs, but provides customization through [add-ons](https://minecraft.fandom.com/wiki/Add-on).\n\nThe data packs built in this series can be found in the [unicorn-utterances/mc-datapacks-tutorial](https://github.com/unicorn-utterances/mc-datapacks-tutorial/tree/main/1-introduction) repository. Feel free to use it for reference as you read through these articles!\n\n# What is a data pack?\n\nMinecraft\'s data pack system allows players to fundamentally modify existing behavior of the game by "replacing" or adding to its data files. Data packs typically use `.mcfunction` files to specify their functionality as a list of commands for the game to run, and `.json` files for writing advancements or loot tables.\n\nOne thing to note: While data packs are simple to use and enable a huge amount of functionality, they do have a couple drawbacks. One is that, while data packs allow most game features to be *changed*, they do not allow players to *add new features* into the game (although some can convincingly create that illusion with a few tricks).\n\nIf you want to add new controls to the game, integrate with external services, or provide a complex user interface, a Minecraft modding framework such as [Fabric](https://fabricmc.net) or [Spigot](https://www.spigotmc.org/wiki/spigot/) might be better for you.\n\n## Advantages of Minecraft mods\n\n- ###### Can communicate with external services\n  Mods can perform HTTP requests, talk to other applications, or use any library that is compatible with Minecraft\'s Java runtime.\n- ###### Able to modify the user interface and settings menus\n  Some data packs have used innovative (and highly complex) workarounds to this [using modified item textures](https://www.youtube.com/watch?v=z4tvTrqhBZE), but in general, Minecraft\'s controls and user interface cannot be fundamentally changed without the use of a mod.\n- ###### Can add entirely new functionality to the game\n  While data packs *can* add things like custom mobs or items through a couple workarounds, there are always some limitations. Mods can add *any* code to the game with no restrictions on their behavior.\n- ###### More performant than data packs when running large operations\n  This obviously depends on how well their functionality is written, but mods can provide much better performance with multithreading, asynchronous code, and generally faster access to the data they need. In comparison, data packs are limited by the performance of the commands available to them.\n\n## Advantages of data packs\n\n- ###### Easy to install on any Minecraft (Java Edition) version\n  Data packs are widely supported in almost any Minecraft launcher, mod loader, and hosting provider. In comparison, mods will require players to set up a specific Minecraft installation (such as Fabric or Forge) before they can be used.\n- ###### Generally simpler to test and write\n  While some modding tools can provide fairly seamless testing & debugging, they all require programming knowledge in Java and/or Kotlin, and it can be tedious to set up a development environment for that if you don\'t have one already. Most data pack behavior can be written in any text editor and tested right in the text chat of your game!\n- ###### Safer to make mistakes with\n  Since data packs are restricted to interacting with the commands Minecraft provides, it typically isn\'t possible to do anything that will entirely break your game. Mods can run any arbitrary code on your system, however &mdash; which means there\'s a higher chance that things can go wrong.\n- ###### Typically better update compatibility\n  While some commands do change in new Minecraft updates, I have (anecdotally) found the changes to be less impactful than the work required to bring mods up to date with new versions. Since mods often use [mixins](https://github.com/SpongePowered/Mixin/wiki) and directly interact with Minecraft\'s internal code, they can be affected by under-the-hood changes that wouldn\'t make any difference to a data pack.\n\n## Summary\n\nI usually prefer to write data packs for most things I work on, as I find them to be more useful to a wider audience because of their easier installation process. Some players simply don\'t want the trouble of setting up another installation folder or using a different Minecraft loader to play with a specific mod, and data packs can work with almost any combination of other mods and server technology.\n\nWith that said, data packs can certainly be tedious to write at times &mdash; while they are easier to build for simple functionality that can be directly invoked through commands, more complex behavior might be better off as a mod if those advantages are more appealing. Nothing is without its drawbacks, and any choice here is a valid one.\n\n# Writing our first Minecraft function\n\nData packs make frequent use of `.mcfunction` files, which are text files that contain a list of commands for Minecraft to run. But how do we know which commands to write? We can actually test them in Minecraft first!\n\nLet\'s try making a new Minecraft world; I\'ll name mine "testing" so I can find it easily. Make sure that the "Allow Cheats" option is set to "ON", then press "Create World".\n\n![Minecraft\'s "Create World" menu, with the "Allow Cheats" option set to "ON"](./create-world-w-cheats.png)\n\nIf you press "t" to bring up the text chat, then type "/s", a list of commands should appear! This list can be navigated with the "up" and "down" arrow keys, and includes every command in the game. If you start typing one out, it should prompt you for any additional syntax it requires. If the command turns red, that means the syntax is invalid.\n\n![A "summon cat" command being typed into the game\'s chat window](./chat-command-summon.png)\n\nLet\'s try making a list of commands that can spawn some animals. The below commands should all work when typed into the text chat, and will summon the entity at the same location as the player.\n\n```shell\n/summon cow\n/summon sheep\n/summon pig\n/summon goat\n/summon llama\n```\n\nNow let\'s see if we can put these into a function!\n\n## Building a data pack folder structure\n\nWe\'ll need to make a new folder to build our data pack in &mdash; I\'ll name mine "1-introduction" to reflect the name of this article. We then need to place a "pack.mcmeta" file inside this folder to describe our pack.\n\n```json\n{\n    "pack": {\n        "pack_format": 10,\n        "description": "Spawns a bunch of animals around the player"\n    }\n}\n```\n\nThe `"pack_format": 10` in this file corresponds to Minecraft 1.19; typically, the format changes with each major update, so for newer versions you might need to increase this number...\n\n| Minecraft Version | `"pack_format"` value |\n|-------------------|-----------------------|\n| 1.19              | `"pack_format": 10`   |\n| 1.18.2            | `"pack_format": 9`    |\n| 1.18-1.18.1       | `"pack_format": 8`    |\n| 1.17-1.17.1       | `"pack_format": 7`    |\n\nWe then need to create a series of folders next to this file, which should be nested inside each other as follows:\n\n```\ndata/fennifith/functions/animals/\n```\n\nIn this path, the `fennifith/` folder can be called a *namespace* &mdash; this should be unique to avoid potential clashes if someone tries to use multiple data packs at once; if two data packs use exactly the same function name, at least one of them won\'t work as expected.\n\nThe namespace and the `animals/` folder can be renamed as you like, but the `data/` and `functions/` folders must stay the same for the data pack to work. Additionally, it is important that the "functions" folder is exactly *one level* below the "data" folder. For example, `data/functions/` or `data/a/b/functions/` would **not** be valid structures.\n\nFinally, we should make our `.mcfunction` file in this folder. I\'m going to name mine `spawn.mcfunction`:\n\n```shell\nsummon cow\nsummon sheep\nsummon pig\nsummon goat\nsummon llama\n```\n\nNote that, while a preceding `/` is needed to type these commands into the text chat, it should **not** be included in the `.mcfunction` file.\n\nWe should now have our data pack organized as follows:\n\n```shell\n1-introduction/\n  pack.mcmeta\n  data/\n    fennifith/\n      functions/\n        animals/\n          spawn.mcfunction\n```\n\n## Installing & testing the data pack\n\nTo turn this folder into a data pack, we simply need to convert the "1-introduction" folder into a zip file.\n\n<!-- tabs:start -->\n\n# Windows\n\nThis can be done by holding down the Shift key and selecting both the `pack.mcmeta` and `data/` files in the file explorer. Then, right click and choose "Send to > Compressed (zipped) folder".\n\nThis should create a zip file in the same location &mdash; you might want to rename this to the name of your data pack. Right click & copy it so we can move it to the Minecraft world!\n\nTo find the location of your world save, open Minecraft and find the "testing" world that we created earlier. Click on it, then choose the "Edit" option, and "Open World Folder".\n\nIn the Explorer window that opens, enter the "datapacks" folder. Right click and paste the zip file here.\n\n# MacOS\n\nThis can be done by opening your data pack in Finder and selecting both the `pack.mcmeta` and `data/` files. Control-click or tap the selected files using two fingers, then choose "Compress" from the options menu.\n\nYou should now have a file named "Archive.zip" &mdash; you might want to rename this to the name of your data pack. Then, copy this file so we can move it to the Minecraft world!\n\nTo find the location of your world save, open Minecraft and find the "testing" world that we created earlier. Click on it, then choose the "Edit" option, and "Open World Folder".\n\nIn the Finder window that opens, enter the "datapacks" folder, then paste the zip file inside it.\n\n# Linux\n\nThis can be done using the `zip` command in your terminal. After `cd`-ing into the data pack folder, run the command below to create a zip file.\n\n```shell\ncd 1-introduction/\nzip -r 1-introduction.zip ./*\n```\n\nThen, assuming you named your world "testing", the command `ls ~/.minecraft/saves/testing` should list that world\'s save files. Run `mv ./1-introduction.zip ~/.minecraft/saves/testing/datapacks/` to move the zip file into the world\'s datapacks folder.\n\n<!-- tabs:end -->\n\nNow that we\'ve installed the data pack, you should be able to enter the world save again (or use the `/reload` command if you still have it open). But nothing happens!\n\nThat\'s because, while our function exists, it isn\'t connected to any game events &mdash; we still need to type a command to actually run it. Here\'s what the command should look like for my function:\n\n```shell\n/function fennifith:animals/spawn\n```\n\nIf you didn\'t use the same folder names, autocomplete should help you figure out what your function is named. After running this command, if you see all your animals spawn, you have a working data pack!\n\n# Specifying a function tag\n\nIn order to run a function automatically, Minecraft provides two built-in [function tags](https://minecraft.fandom.com/wiki/Tag#Function_tags) that run during specific events: `load` (when the world is opened) and `tick` (every game tick).\n\n## Using the "load" event\n\nWe\'ll start with `load` &mdash; for which we\'ll need to create two new files in our folder structure! Below, I\'m creating a new `load.mcfunction` next to our previous function, and a `minecraft/tags/functions/load.json` file for the `load` tag.\n\n```shell\n1-introduction/\n  pack.mcmeta\n  data/\n    minecraft/\n      tags/\n        functions/\n          load.json\n    fennifith/\n      functions/\n        animals/\n          load.mcfunction\n          spawn.mcfunction\n```\n\nNote that, while I\'m using the `fennifith/` namespace for my functions, the tag file lives under the `minecraft/` namespace. This helps to keep some data isolated from the rest of the game &mdash; any files in the `minecraft/` folder are *modifying Minecraft\'s functionality,* while anything in a different namespace is creating something that belongs to my data pack.\n\nInside `load.json`, we can add a JSON array that contains the name of our load function as follows:\n\n```json\n{\n\t"values": ["fennifith:animals/load"]\n}\n```\n\nIn `load.mcfunction`, I\'ll just write one command for testing:\n\n```shell\nsay Hello, world!\n```\n\n## Testing the "load" event\n\nIf you repeat the steps to [install the data pack](#Installing--testing-the-data-pack) now, you should see a "Hello, world" message appear in the chat window! You could modify this message to display information about your data pack or explain how to use it.\n\nTo invoke the "load" tag manually, you can either use the `/reload` command, or type `/function #minecraft:load` (note the `#` symbol used to specify the tag).\n\n## And the "tick" event...\n\n> **Be aware** that when using the tick event, it is very easy to do things that cause humongous amounts of lag in your game. For example, connecting this to our `spawn.mcfunction` from earlier might have some adverse consequences when summoning approximately 100 animals per second.\n\nNow, what if we try adding a file for the `tick` event with the same contents? We could add a `tick.json` file pointing to a `fennifith:animals/tick` function &mdash; and write a `tick.mcfunction` file for it to run.\n\nThe chat window fills up with "Hello, world" messages! Every time the `tick` function tag is invoked (the game typically runs 20 ticks per second) it adds a new message! This is probably not something we want to do.\n\nCould there be a way to check some kind of condition before running our commands? For example, if we wanted to run our `say` command when the player stands on a specific block...\n\nTry experimenting! See if you can find a command that does this &mdash; and check out the next post in this series for the solution!\n\n# Conclusion\n\nIf your data pack hasn\'t worked first try &mdash; don\'t worry! There are a lot of steps here, and the slightest typo or misplacement will cause Minecraft to completely ignore your code altogether. If you\'re ever stuck and can\'t find the issue, the [Unicorn Utterances discord](https://discord.gg/FMcvc6T) is a great place to ask for help!\n\nSo far, we\'ve covered the basics of data packs and how to write them &mdash; but there\'s a lot more to get into. Next, we\'ll start writing conditional behavior using block positions and entity selectors!\n',
		},
		{
			title: "Minecraft Data Pack Programming: Scoreboard Usage",
			description:
				"Learn data pack development in Minecraft - using player scoreboards, variables, and operations!",
			published: "2022-08-20T19:10:03.284Z",
			authors: ["fennifith"],
			tags: [],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			series: "Minecraft Data Pack Programming",
			order: 3,
			slug: "minecraft-data-packs-scoreboards",
			locale: "en",
			authorsMeta: [
				{
					id: "fennifith",
					name: "James Fenn",
					firstName: "James",
					lastName: "Fenn",
					description:
						"Enjoys writing software on loud keyboards. Starts too many projects. Consumes food.",
					socials: { twitter: "fennifith", github: "fennifith" },
					pronouns: "he",
					profileImg: "./fennifith.jpg",
					color: "#0091EA",
					roles: ["developer", "author", "community"],
					profileImgMeta: {
						height: 400,
						width: 400,
						relativePath: "./fennifith.jpg",
						relativeServerPath: "/content/data/fennifith.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\fennifith.jpg",
					},
					rolesMeta: [
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Minecraft Data Pack Programming: Scoreboard Usage",
				description:
					"Learn data pack development in Minecraft - using player scoreboards, variables, and operations!",
				published: "2022-08-20T19:10:03.284Z",
				authors: ["fennifith"],
				tags: [],
				attached: [],
				license: "cc-by-nc-sa-4",
				series: "Minecraft Data Pack Programming",
				order: 3,
			},
			contentMeta:
				'\n> Please note: this guide specifically covers the **Java Edition** version of Minecraft. Bedrock Edition does not use data packs, but provides customization through [add-ons](https://minecraft.fandom.com/wiki/Add-on).\n\nThe data packs built in this series can be found in the [unicorn-utterances/mc-datapacks-tutorial](https://github.com/unicorn-utterances/mc-datapacks-tutorial/tree/main/3-scoreboards) repository. Feel free to use it for reference as you read through these articles!\n\nPreviously, this series has covered the structure of a data pack, conditional statements, and other command syntax. This article will build on top of that to cover scoreboards, which allows us to keep track of player information and store variables in our programs.\n\n# Storing scores\n\nIn many data packs, you might find a need to store information that can\'t be directly accessed through an entity or another command. A common way to do this is through the use of *scoreboards,* which can store a table of numbers for each entity or player. These can be used to reference player statistics, such as the number of blocks mined, or keep track of arbitrary values in your code.\n\n## Creating a scoreboard\n\nWe can use the subcommands of `/scoreboard objectives` to create and modify scoreboards in a world. Let\'s try making a scoreboard to track the number of animals that each player has spawned through our data pack.\n\n```shell\nscoreboard objectives add fennifith.animals_spawned dummy\n```\n\nThis creates an objective named `fennifith.animals_spawned` that is connected to the `dummy` game statistic. We\'ll talk about other statistics later on, but the `dummy` statistic effectively means the scoreboard will only be modified if you set its values yourself.\n\n### What is an objective?\n\nThe naming of "objective" and "scoreboard" can be a point of confusion. In this article, for simplicity\'s sake, they can be considered as two names for the same thing — even though they might have slightly different meanings.\n\nGenerally speaking, an "objective" is a relation between a set of scores and a statistic. Here, the objective name is `fennifith.animals_spawned` and the statistic is `dummy`. The objective contains its scores for each player in the form of a scoreboard.\n\n## Scoreboard conventions\n\n### Namespaced objective names\n\nPlayers often want to have multiple data packs installed in their world at once. Since all scoreboards operate globally in the world, we need to make sure that our scoreboard names will not conflict with any scoreboards used by other data packs.\n\nFor example, what might happen if two data packs want to track different blocks that the player has mined? The first might create a scoreboard for `blocksMined` that tracks stone, while the second might use `blocksMined` to track dirt. However, both data packs will be referencing the same `blocksMined` scoreboard in the world, which could end up tracking both stone and dirt, mixing up the behavior of both. We need a way to separate the scores of these data packs and prevent them from conflicting with each other.\n\nTo accomplish this, it is common to "namespace" the scoreboard names within your data pack by adding a certain prefix. Here, I\'ve started my scoreboard names with `fennifith.animals` to indicate that they belong to my data pack.\n\n### Creating & removing scoreboards\n\nTypically, you\'ll want to create any scoreboards you need in a `load.mcfunction` function, connected to the `#minecraft:load` function tag.\n\nSome data packs additionally create an `uninstall.mcfunction` file, not connected to any function tag, that can be executed to remove all of the data pack\'s scoreboard objectives. This is useful for when a player wants to remove your data pack from their world without leaving any of its behavior behind.\n\n## Setting values\n\nWe can set values of a scoreboard using the `/scoreboard players` subcommands. Most of these subcommands accept two arguments for the `<selector>` and `<objective>` of the score to change. For example, the following command will set our entry in the `fennifith.animals_spawned` table to `1`.\n\n```shell\n#                  set our scoreboard entry\n#                  |   use the entry of the current player ("fennifith")\n#                  |   |  modify the scoreboard named "fennifith.animals_spawned"\n#                  |   |  |                         set "1" as the value of this entry\n#                  |   |  |                         |\nscoreboard players set @s fennifith.animals_spawned 1\n```\n\n<div style="margin-top: -2em;">\n\n| Entry     | fennifith.animals_spawned |\n| --------- | ------------------------- |\n| fennifith | 1                         |\n\n</div>\n\nIf we want to add to this value, we can use the `scoreboard players add` subcommand instead. Likewise, `scoreboard players remove` will subtract a value from our scoreboard.\n\n```shell\n#                  add a number to the current scoreboard value\n#                  |   use the entry of the current player\n#                  |   |                    use "2" as the number to add\n#                  |   |                    |\nscoreboard players add @s fennifith.animals_spawned 2\n```\n<div style="margin-top: -2em;">\n\n| Entry     | fennifith.animals_spawned |\n| --------- | ------------------------- |\n| fennifith | 3                         |\n\n</div>\n\n> **Note:** Be wary of the difference between `/scoreboard objectives add` and `/scoreboard players add`, as they are easy to confuse — I even mixed them up a few times while writing this article! The `objectives` subcommands are used exclusively for creating or removing entire scoreboards, while the `players` subcommands can modify specific entries in existing scoreboards to change their values.\n>\n> `objectives add` is saying to "add a new scoreboard", while `players add` is increasing the value of a scoreboard entry by a given number.\n\n### Using global entries\n\nIn certain cases, we want to store values that aren\'t player specific, but instead affect our entire data pack. For example, we might want to track the total number of animals spawned in our world in addition to the number of animals for each player.\n\nWe can do this by referencing a *nonexistent player*. The scoreboard will include an entry for any entity or name, regardless of whether it actually exists in our world — so by using a name that will never exist, we can reference it globally from anywhere in our code.\n\n```shell\nscoreboard players set $global fennifith.animals_spawned 4\n```\n\n<div style="margin-top: -2em;">\n\n| Entry     | fennifith.animals_spawned |\n| --------- | ------------------------- |\n| fennifith | 3                         |\n| $global   | 4                         |\n\n</div>\n\nThis trick works because `$` is not a character that Minecraft players can register in their username. As such, we can ensure that the `$global` entry will never be used by any actual player or entity in the world.\n\nIf we didn\'t include the `$` before our variable name in this snippet, our code would still work! However, what would happen if a player registered the username `global` and tried to use our data pack? Their score would use the same entry as our global variable, and both would attempt to store their values in the same place — causing any logic we write to appear broken.\n\nSince the `$` is an invalid username character, we can safely use it for global values without that possibility.\n\n### Using the "/execute store" subcommand\n\nEach Minecraft command provides a "success" and a "result" value which specify if the command was successful — and if so, what value it returned.\n\nThe `execute store` subcommand can be used to designate a place to store these values, such as a scoreboard entry.\n\nFor example, this command will copy the value of our `$global` variable into `$global_2`...\n\n```shell\n#       store the result of the command\n#       |                  place it in "$global_2"\n#       |                  |                                       run a command that returns the value of "$global"\n#       |                  |                                       |\nexecute store result score $global_2 fennifith.animals_spawned run scoreboard players get $global fennifith.animals_spawned\n```\n\n<div style="margin-top: -2em;">\n\n| Entry     | fennifith.animals_spawned |\n| --------- | ------------------------- |\n| fennifith | 3                         |\n| $global   | 4                         |\n| $global_2 | 4                         |\n\n</div>\n\n> While this example will successfully copy our `$global` variable to `$global_2`, there is somewhat shorter way to achieve that using [scoreboard operations](#Scoreboard-operations)...\n\nIt might not always be obvious what value a command returns as its "result", as this is sometimes different from what it prints in the game chat. However, all commands can be looked up on the [Minecraft wiki](https://minecraft.fandom.com/wiki/Commands) to see what values and behavior they should provide.\n\n## Scoreboard operations\n\nIf we want to set a scoreboard value based on another entry, we can use the `scoreboard players operation` subcommand to specify a conceptual state of existence between the two values.\n\nFor example, to make our `$global` entry in the previous examples equal to the `fennifith` entry, we can use the following command:\n\n\n```shell\n#                            write the result *to* the $global entry\n#                            |                                 set the scoreboards equal to each other\n#                            |                                 | get the value *from* @s\n#                            |                                 | |\nscoreboard players operation $global fennifith.animals_spawned = @s fennifith.animals_spawned\n```\n<div style="margin-top: -2em;">\n\n| Entry     | fennifith.animals_spawned |\n| --------- | ------------------------- |\n| fennifith | 3                         |\n| $global   | 3                         |\n| $global_2 | 4                         |\n\n</div>\n\n### Math operations\n\nWe can also replace the `=` operation with other math operations that can be performed on the scoreboard entry.\n\nFor example, to add the `@s` entry to `$global`:\n\n```shell\n#                            write the result *to* the $global entry\n#                            |                                 add to the existing value\n#                            |                                 |  get the value *from* @s\n#                            |                                 |  |\nscoreboard players operation $global fennifith.animals_spawned += @s fennifith.animals_spawned\n```\n<div style="margin-top: -2em;">\n\n| Entry     | fennifith.animals_spawned |\n| --------- | ------------------------- |\n| fennifith | 3                         |\n| $global   | 6                         |\n| $global_2 | 4                         |\n\n</div>\n\nThe `operation` subcommand only runs on scoreboard entries, so we cannot pass constant values to it. `scoreboard players operation $global fennifith.animals_spawned /= 2` is, unfortunately, not a command that the game will run.\n\nIf we want to divide our `$global` entry by two, we need to write the divisor value to another temporary scoreboard first.\n\n```shell\n# set the "$divisor" variable to "2"\nscoreboard players set $divisor fennifith.animals_spawned 2\n# divide the "$global" entry by "$divisor" (2)\nscoreboard players operation $global fennifith.animals_spawned /= $divisor fennifith.animals_spawned\n```\n\n<div style="margin-top: -2em;">\n\n| Entry     | fennifith.animals_spawned |\n| --------- | ------------------------- |\n| fennifith | 3                         |\n| $divisor  | 2                         |\n| $global   | 3                         |\n| $global_2 | 4                         |\n\n</div>\n\nThis results in `$global`, which was previously `6`, being divided by `2` — as such, its value is now `3`.\n\nHere is a list of all the other operations that can be performed with this command.\n`lhs` denotes the *left hand side* of the operation (the scoreboard entry being written to), while `rhs` denotes the *right hand side*.\n\n- `=` sets `lhs` to the value of `rhs`\n- `+=` adds `rhs` to `lhs`\n- `-=` subtracts `rhs` from `lhs`\n- `*=` multiplies `lhs` by `rhs`\n- `/=` divides `lhs` by `rhs`\n- `%=` sets `lhs` to the remainder of `lhs / rhs`\n- `<` sets `lhs` to `rhs` only if `rhs` is *smaller*\n- `>` sets `lhs` to `rhs` only if `rhs` is *larger*\n- `><` swaps the values of `lhs` and `rhs`\n\n> While both sides of these operations accept entity selectors, only `lhs` can refer to multiple entities. For example, `@e[type=pig]` could be used to set the scoreboards of every pig entity in the game.\n>\n> In `rhs`, you may need to add a `limit=1` attribute to limit the number of entities that it can select.\n\n# Displaying scores\n\nIn order to see what scores are applied to any entity, there are a few methods of displaying the scoreboard values to players.\n\n## In-game display\n\nThe `/scoreboard objectives setdisplay` subcommand can be used to set a particular scoreboard to display in part of the UI. For example, `/scoreboard objectives setdisplay sidebar fennifith.animals_spawned` will show every player and the number of animals they have spawned in a sidebar on the right of the screen.\n\nMore areas other than `sidebar` include:\n- `list`, which shows the scores next to player names in the tab menu (in Multiplayer only)\n- `belowName`, which displays a player\'s score underneath their name tag\n\n| Sidebar | List | Below Name |\n| ------- | ---- | ---------- |\n| ![A sidebar with two player entries on the right of the screen](./scoreboard.png) | ![The online player list, with scores next to the player names](./list.png) | ![A player\'s nametag with a score displayed below it](./belowName.png) |\n\n## `/tellraw` command\n\nThe `/tellraw` command can be used to send a formatted message in the game chat. It has a wide variety of uses and formatting options, one of which can embed a scoreboard value into the printed message.\n\n`/tellraw` accepts an array of arguments which it concatenates together to form its message. To reference a score in this array, we can write an element with the structure `{"score":{"name":"<selector>","objective":"<objective>"}}`. For example, here is a command that prints the number of animals that the player (`@s`) has spawned:\n\n```shell\ntellraw @s ["You have summoned ",{"score":{"name":"@s","objective":"fennifith.animals_spawned"}}," animals!"]\n```\n\n# Conditions with scoreboard values\n\nWhat if we have a command that we only want to run if the player has a certain score?\n\nIn the previous article, you may have noticed that `/execute` has an additional `if score` subcommand. We can use this to check our scoreboard values as a condition!\n\n## Comparing values between scoreboards\n\nWith the `<`, `<=`, `=`, `>=`, or `>` symbols, we can use this command to compare values between different scoreboard entries. For example, the following command compares a player\'s score between the `fennifith.animals_spawned` and `fennifith.berries_eaten` scoreboards...\n\n```shell\n#       check a score condition...\n#       |        if the player\'s "fennifith.animals_spawned" score...\n#       |        |                            is greater than...\n#       |        |                            | the player\'s "fennifith.berries_eaten" score...\n#       |        |                            | |                              send the player a message!\n#       |        |                            | |                              |\nexecute if score @s fennifith.animals_spawned > @s fennifith.berries_eaten run tellraw @s "You\'ve spawned more animals than berries!"\n```\n\nIn this example, if the player\'s score for `fennifith.animals_spawned` is greater than `fennifith.berries_eaten`, the condition will be valid — and it will run the `tellraw` command that follows it.\n\n## Comparing number ranges with "matches"\n\nUsing the `matches` option, it is also possible to directly compare a scoreboard with a number range.\n\n```shell\n#       if this score condition is valid...\n#       |        for the current player\'s entry in "fennifith.animals_spawned"...\n#       |        |                            if its value matches "0"...\n#       |        |                            |             send the player a message!\n#       |        |                            |             |\nexecute if score @s fennifith.animals_spawned matches 0 run tellraw @s "You haven\'t summoned any animals yet!"\n```\n\nThis command checks if the player\'s score in "fennifith.animals_spawned" is exactly equal to 0. However, we could also use `..0` for "less than or equal", `0..` for "greater than or equal", and so on.\n\nNumber ranges can also be bound on both sides — such as `10..50` for "between 10 and 50" — and are *inclusively bound*, meaning that a range of `10..50` will also include both `10` and `50` in addition to any numbers in-between.\n\n## Checking nonexistent scores\n\nWhat happens if we access a scoreboard entry that doesn\'t exist? Normally, the game treats nonexistent scoreboard entries as "0" — the `/scoreboard players add` command, for example, will increase any nonexistent score to "1".\n\nHowever, this works a bit differently for `if score` conditions. If we check the condition `$nonexistent fennifith.animals_spawned matches 0..`, it won\'t run the command — because `$nonexistent` doesn\'t have a value. Both the range `0..` and `..0` will fail — if the score has a value, we would expect at least one of those conditions to be true.\n\nNormally, this behavior is not a concern — if you are checking a scoreboard in a condition, it is generally expected that the condition will not work for any unset scores. However, if you want to directly check if a score exists, the following command is one way to do that...\n\n```shell\n#       check that $nonexistent <= 0\n#       |                                                               check that $nonexistent >= 0\n#       |                                                               |                                                                   if neither are true, the score cannot exist\n#       |                                                               |                                                                   |\nexecute unless score $nonexistent fennifith.animals_spawned matches ..0 unless score $nonexistent fennifith.animals_spawned matches 0.. run tellraw @s "The score for $nonexistent in fennifith.animals_spawned doesn\'t exist!"\n```\n\nThere\'s another slightly simpler way to check this, which takes advantage of the maximum value that the game can store in a scoreboard. Minecraft\'s scoreboards are limited by Java\'s minimum/maximum integer size of 32 bits, or a range from `-2147483648` to `2147483647`. We can write this in a single condition to check if the score is anywhere within that range.\n\n```shell\n#       check if the score is anywhere within Java\'s integer bounds\n#       |                                                                                       if not, the score cannot exist\n#       |                                                                                       |\nexecute unless score $nonexistent fennifith.animals_spawned matches -2147483648..2147483647 run tellraw @s "The score for $nonexistent in fennifith.animals_spawned doesn\'t exist!"\n```\n\n# Tracking statistics\n\nScoreboards can also be created to track *game statistics*, such as the number of blocks mined or number of times an item has been used. These can be found in the game by opening the pause menu in any world or server and clicking the "Statistics" button — and the names used to reference them can be found [on the Minecraft wiki](https://minecraft.fandom.com/wiki/Scoreboard#Criteria).\n\nWe can use any statistic as the second argument of `/scoreboard objectives add` when we create a new objective — for example:\n\n```shell\nscoreboard objectives add fennifith.animals_carrot_stick minecraft.used:minecraft.carrot_on_a_stick\n```\n\n> **Note:** These statistics are only tracked for players! While we can still manipulate scoreboard values for other entities using commands, non-player entities do not have statistics, and their objectives will not be updated when an action is performed.\n\nWhile this scoreboard will be updated when its statistic changes, its entries can also be individually changed by the data pack, so it might not necessarily reflect the same value as the statistic at all times.\n\nFor example, we can create the scoreboard above to track the number of times a "Carrot on a Stick" has been used. If we then set our entry to `0` in that scoreboard, its value will stay at `0`, regardless of the player\'s statistic for that item. If the player then uses the "Carrot on a Stick" again, the statistic and the scoreboard will both increase by 1.\n\n## Detecting events with statistics\n\nWe can use this behavior in our `tick.mcfunction` (which runs on every game tick) to detect when a player has used the carrot on a stick. We\'ll first set the value for all players to 0, then check the scoreboard on every tick to see if it has increased. If it has, we know that the item has been used, and can reset it to 0 to detect it again.\n\nTo check each player\'s value in our scoreboard, we can use the `/execute if score` subcommand along with a number range to conditionally execute our function if the scoreboard has a value >= 1.\n\nIf it does, we\'ll run the `fennifith:animals/spawn` function — which was created in the previous article — to spawn a group of animals.\n\n1. We first need to create our scoreboard when our data pack is loaded by the game — so we\'ll place the following line in our `load.mcfunction`:\n\t```shell\n\t# data/fennifith/functions/animals/load.mcfunction\n\n\t# create a new scoreboard tracking the "carrot_on_a_stick" statistic\n\tscoreboard objectives add fennifith.animals_carrot_stick minecraft.used:minecraft.carrot_on_a_stick\n\t```\n2. Then, we can place a command in `tick.mcfunction` to run our `fennifith:animals/spawn` function if the scoreboard has a value >= 1.\n\t```shell\n\t# data/fennifith/functions/animals/tick.mcfunction\n\n\t#       for every player in the game...\n\t#       |     if their score for "carrot_stick" is >= 1\n\t#       |     |                                                      spawn some animals\n\t#       |     |                                                      |\n\texecute as @a if score @s fennifith.animals_carrot_stick matches 1.. run function fennifith:animals/spawn\n\t```\n3. Finally, after we run our function, we need to reset the scoreboard value so that it won\'t run until the item is used again:\n\t```shell\n\t# set the "carrot_stick" score for all players to 0\n\tscoreboard players set @a fennifith.animals_carrot_stick 0\n\t```\n\n# Examples of scoreboard functionality\n\n## Applying unique values to each entity in a selector\n\nIf we have an entity selector, such as `@e[type=pig]`, we might want to assign a different scoreboard value to each entity. This can be done somewhat concisely using the `execute store result` subcommand...\n\n```shell\n# create a dummy objective to store unique pig entity ids\nscoreboard objectives add fennifith.animals_id dummy\n\n# set a $counter variable to 0\nscoreboard players set $counter fennifith.animals_id 0\n\n#       for every entity in @e[type=pig]...\n#       |               store the result as the entity\'s "fennifith.animals_id" score\n#       |               |                                              add "1" to the $counter variable\n#       |               |                                              |\nexecute as @e[type=pig] store result score @s fennifith.animals_id run scoreboard players add $counter fennifith.animals_id 1\n```\n\nFor each pig entity, the `scoreboard add` command increments our `$counter` variable by 1. Conveniently, the `add` command also returns the total value of its scoreboard as its result, so we can use that to store the incremented value as the pig entity\'s score.\n\n## Challenge: Maximum value of a scoreboard\n\nNow that the `fennifith.animals_id` scoreboard has a few entries in it, how can we find the highest score it contains? (without using the `$counter` variable...)\n\nTo accomplish this, we can use the `@e[type=pig]` selector to target every pig entity in the game, and store the result in `$max fennifith.animals_id`.\n\n<details>\n<summary>Hint</summary>\n\nConsider using the scoreboard operations that we have available, such as `>`. Remember that any command can also be used with `execute` to run it multiple times.\n\nYou might want to set an initial value of `0` to `$max fennifith.animals_id`, then apply some operations to increase it to the highest value in the scoreboard.\n\n</details>\n\n<details>\n<summary>Solution</summary>\n\nFirst, we set our `$max` variable to an initial value of 0. Then, we use an `execute` command to run through each entity in `@e[type=pig]`. For each player, the `$max > @s` operation sets the value of `$max` only if the player\'s score is greater than its current value.\n\n```shell\n# initially, set the max value to 0\nscoreboard players set $max fennifith.animals_id 0\n\n#       for every pig entity in the game...\n#       |               run a scoreboard operation...\n#       |               |                                set $max in fennifith.animals_id...\n#       |               |                                |                         if the following value is larger...\n#       |               |                                |                         | to @s in fennifith.animals_id.\n#       |               |                                |                         | |\nexecute as @e[type=pig] run scoreboard players operation $max fennifith.animals_id > @s fennifith.animals_id\n```\n\nThis results in `$max` holding the highest value in the scoreboard — you can use the command `scoreboard players get $max fennifith.animals_id` to confirm this!\n\n</details>\n\n# Conclusion\n\nThis article has covered most of the scoreboard commands we can use, but there is a lot more that can be done with them. These can be used throughout functions to write almost any numerical logic; try experimenting to see what you can accomplish!\n\nIn the next post, we\'ll cover *advancements*, which provide some alternative ways to detect specific player actions and other conditions.\n',
		},
		{
			title: "Networking 101: UDP & TCP",
			description:
				"If networking is analogous to physical mail, then let's take a look at the letters being sent themselves. Let's dive into UDP and TCP",
			published: "2020-03-31T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["networking"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			series: "Networking 101",
			order: 2,
			slug: "networking-101-udp-and-tcp",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Networking 101: UDP & TCP",
				description:
					"If networking is analogous to physical mail, then let's take a look at the letters being sent themselves. Let's dive into UDP and TCP",
				published: "2020-03-31T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["networking"],
				attached: [],
				license: "cc-by-nc-sa-4",
				series: "Networking 101",
				order: 2,
			},
			contentMeta:
				"\nIn the last article in the series, we outlined what a packet architected network was, what the OSI layers represent, and demonstrated how we could use physical mail as an analogy for how packet-based networks function. Since we've gone to a hundred-mile view in the last series, I figured we'd take a look at what we deliver in an HTTP network. You see, the internet, as you know it, is merely a large scale HTTP network; it's built upon the packet architecture. There are two common types of packets that are delivered in the HTTP network: UDP and TCP.\n\n# Commonalities {#udp-and-tcp-both}\n\nLet's start by talking about what similarities UDP and TCP have. While they do have their distinct differences, they share a lot in common. \n\nSince they're both packet-based, they both require an \"address\" of sorts to infer where they've come from and where they're going.\n\n## IP Addresses {#ip-address}\n\nThe \"address\" used to identify the \"to\" and \"from\" metadata about a packet is an \"IP Address.\" When you send a packet of data out, you label it with an IP address to go to; then, through a process of various other utilities processing that data, it's sent! An IP address might look something like this: `127.0.0.0`, or something like this: `0:0:0:0:0:0:0:1`\n\nThis IP address is then stored in a packet's header ([if you recall, that's where the metadata about the packet lives](/posts/basic-overview-of-packets-and-osi/#packet-metadata)), and that's then used to direct the packet to its correct recipient.\n\n![A packet being directed to the correct client matching the IP in the header](./showing-an-ip-address.svg)\n\n### Different Types of IP Addresses {#ipv4-vs-ipv6}\n\nWhile IP addresses may seem somewhat arbitrary at first glance, there are important rules to abide by to have what's considered a \"valid\" IP address. What's considered \"valid\" is defined by the TCP/IP specification, which is lead by the [Internet Engineering Task Force](https://en.wikipedia.org/wiki/Internet_Engineering_Task_Force), a group created specifically to manage and handle network protocol standardization. As time has gone on, there have been various revisions to the IP validation methods. What was once valid is now considered outdated and migrated to a newer standard of IP address. The two most commonly used standards for defining IP addresses today are:\n\n- IPv4 (Internet Protocol version 4)\n- IPv6 (Internet Protocol version 6)\n\nDue to the explosion of internet enabled-devices, we have had to make changes to the way we assign network addresses. The previous version of the IP protocol (v4) allowed for 4,294,967,296 (2^32) unique IP addresses. While this number may seem excessive, it's important to realize that we ran out of unique IP addresses in 2017. The only reason why we even lasted that long is due to a myriad of techniques that networking companies (like your ISP) utilized to extend the life of the IPv4 protocol. With IPv6, we're able to have 340,282,366,920,938,463,463,374,607,431,768,211,456 (2^128) (yes, that's correct) unique addresses - no fear of immediate exhaustion of addresses.\n\n![A showcase of an example IPv4 address and an IPv6 address. IPv4 example is \"131.198.246.34\" while IPv6 is \"4131:e0fd:ef8e:ed27:f5b:ac98:640c:bfa5\"](./ip-comparison.svg)\n\n#### What Happened to version 5? {#ipv5}\n\nAs mentioned previously, the Internet Engineering Task Force manages various specifications regarding the standardization of internet communication. Back in 1995, they gathered to attempt to create a new version of the protocol to handle the growing use of live-streamed communication. To make a long story short, IPv5 was abandoned for various reasons, and they moved on to tackle the issue of unique identifiers rapidly diminishing. To avoid confusion with the attempted streaming protocol improvements, when a new version of the protocol was being worked on afterward, it was called IPv6.\n\n> If you'd like to read more about this version for fun, you can read through [the Wikipedia page](https://en.wikipedia.org/wiki/Internet_Stream_Protocol). Unfortunately, there's limited information, and things get very quickly highly technical due to the \"in progress\" nature that things were left at.\n\n## Ports  {#udp-ports}\n\nContinuing with the mail analogy, just like an apartment complex can have a single mailbox for multiple apartments living within the same building, so too can a single machine have multiple landing sites for network packets.\n\nThese separated landing sites are called \"ports\"; called as such because they operate very similarly to the seaside \"ports\" that are used to dock ships. You're able to \"open\" a port to start engaging in network activity through that port, or \"close\" it to stop communication from flowing through that port. A single machine may choose to open a myriad of ports ranging anywhere from `0` to `65,535`. Any one of these ports can receive a different stream of information in-bound and out-bound alike.\n\nThis method of port address selection even has it's own shorthand. For example, if you wanted to send data to IP address `192.168.1.50` on port `3000`, you'd send that data to: `192.168.1.50:3000`, being sure to use a colon to delineate between the IP address and the port number.\n\n### Pre-Assigned Ports {#standard-ports}\n\nLike an apartment complex may pre-assign individuals to specific rooms, so too does the specification for Internet Protocol pre-assign specific applications to specific ports. For example, port 21 is officially designated to the [File Transfer Protocol (FTP)](https://en.wikipedia.org/wiki/File_Transfer_Protocol), which can be used to transfer files if a server is set up on a machine to handle this protocol. As a result, it's strongly discouraged to use these ports that are reserved for your application stack if you want to use a specific port for networking in your app or project.\n\n### A Note On IP Addresses {#localhost}\n\nYou might remember from [the start of this section](#ip-addresses) that I listed `127.0.0.1` and `0:0:0:0:0:0:0:1` as examples of IPv4 and IPv6 addresses. This isn't without reason! These addresses are known as \"loopback\" addresses, and forward all traffic addressed to those IP addresses back to your machine! Why might this be useful? Let's take the following real-world example:\n\nLet's say you're developing a web application using React and want to see it hosted on your local development environment without deploying it to the public internet to see. In this example, you could spin up a server to host the React code on `127.0.0.1:3000`, and you could then access it via `localhost:3000` in your browser. For programs like React, this functionality is built-in to [it's CLI utility](https://reactjs.org/docs/create-a-new-react-app.html), but this isn't limited to React; It's universal for any form of network communication you need to test locally.\n\n# UDP {#udp}\n\nNow that we've explained what IP addresses are and what ports are let's walk through how UDP is unique. _UDP stands for \"User datagram protocol.\"_ You may be familiar with \"User\" and \"Protocol,\" but the term **\"datagram\"** may be new. \n\nIf you're familiar with how a telegram (like the old-school messaging method, not the new-age messaging platform) used to work, you may already be familiar with how a datagram works.\n\n*A datagram is a unidirectional, non-verifiably-sent piece of communication that contains data.*\n\nWhoa. What's that even mean?\n\nWhen you send a letter through the mail (barring any additional \"protections\" you might add to a valuable package. We'll get to that later), you have no way of knowing if it made it to the intended recipient. \n\nBecause the packet of information could be lost somewhere or sustain damage, which makes the data unreadable (say, via data corruption), you are unable to reliably ensure that it was received.\n\nLikewise, if you've sent multiple packets at once, you have no way of knowing if your data is received in the same order they came in. While this isn't much of a problem for small-scale communication, this can become a problem for larger-scale bi-directional data transfer.\n\n\n\n## When is UDP Useful? {#udp-uses}\n\nUDP is useful for various low-level communication used to set up networks in ways that we'll touch later in the series. That said, there are also application-level usages for UDP's core strength: Speed. See, because UDP does not engage in any form of delivery confirmation, it tends to be significantly faster than it's TCP counterpart. As such, if you require high-speed data throughput and can afford to lose some data, UDP is the way to go. This speed is why it's often utilized in video calling software. You can scale up/down the video quality based on which packets are able to make it through but keep latency low due to pressing forward when packets don't arrive in time.\n\n# TCP {#tcp}\n\nIf you've ever sent an expensive package through a mail courier service, you may have opted to have the recipient \"sign\" for the package, as a method of certifying that they did, in fact, get the package.\n\nThat's what TCP is for HTTP packets. TCP stands for \"Transmission Control Protocol\" and solves one of the biggest problems in UDP: delivery verification. It does this by using a three-way \"handshake\" to verify an open connection between the clients, and a number associated with each packet to tell which order the data should arrive in.\n\nThe three-step handshake is broken down to these steps:\n\n1) The client sends a request to the host, asking if it's acceptable to connect. It includes a \"Synchronize Sequence Number\" (SYN), which tells which packet number the communication is going to start with. This step is formally known as SYN\n\n2) The host then acknowledges (ACK) the request, and sends it's own SYN. This step is formally known as SYN/ACK\n\n3) The client acknowledges the SYN from the host, and data starts transmitting. This step is formally known as ACK.\n\nWhen you disconnect from the host, a similar disconnect handshake is done. Once the setup handshake is completed, and data starts flowing, every request to host will be returned by an acknowledgment of delivery. This ACK makes sure that you know your packets are delivered. If your packet acknowledgment is not resolved within a certain time, TCP includes the idea of timers running on the client that will re-send the packet.\n\nBecause of this more robust delivery pattern, TCP is often used for most high-level network connections.\n\n# Conclusion\n\nThis has been a brief overview of UDP and TCP! In this series, we're hoping to introduce the fundamentals of networking. While UDP/TCP is not often seen in higher-level coding directly, it's usage is integral to understand many other aspects of networking. In the next article in the series, we'll explain how IP addresses are assigned by using UDP thanks to DHCP.  Even further into the series, we'll walk through how the domain name URLs you type into your web browser are resolved into IP addresses through the domain name system (DNS).\n\nTo make sure you don't miss any of these articles, you may want to subscribe to our newsletter. We promise not to spam you with unrelated stuff and keep emails to a minimum. Otherwise, [we also have a Discord](https://discord.gg/FMcvc6T) you can join to see announcements for new articles, ask questions of the posts' authors, and engage in general community chatter\n",
		},
		{
			title: "Mutable vs Immutable Data Types",
			description:
				"Using mutable data types can be dangerous in multi-threaded applications. To help that we can make sure of thread safer immutable data types",
			published: "2022-07-20T16:56:03.000Z",
			authors: ["alexchadwick"],
			tags: ["typescript", "data structures", "computer science"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "new-post-mutable-vs-immutable",
			locale: "en",
			authorsMeta: [
				{
					id: "alexchadwick",
					name: "Alex Chadwick",
					firstName: "Alex",
					lastName: "Chadwick",
					description:
						"I'm a full-stack web developer in the UK (but born in sunny Spain!) \n I spend too much time reading articles on clean code and not enough refactoring 🤣",
					socials: {
						twitch: "alexchadwicc",
						twitter: "TheAlexChadwick",
						github: "AlexChadwickP",
						linkedin: "alexchadwickp",
						website: "https://alexchadwick.com",
					},
					pronouns: "he",
					profileImg: "./alexchadwick.jpg",
					color: "",
					roles: ["author", "translator"],
					profileImgMeta: {
						height: 2316,
						width: 2315,
						relativePath: "./alexchadwick.jpg",
						relativeServerPath: "/content/data/alexchadwick.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\alexchadwick.jpg",
					},
					rolesMeta: [
						{ id: "author", prettyname: "Author" },
						{ id: "translator", prettyname: "Translator" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Mutable vs Immutable Data Types",
				description:
					"Using mutable data types can be dangerous in multi-threaded applications. To help that we can make sure of thread safer immutable data types",
				published: "2022-07-20T16:56:03.000Z",
				authors: ["alexchadwick"],
				tags: ["typescript", "data structures", "computer science"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				'\n\n# Defining Mutable and Immutable\n\nMutable means "can change". Immutable means "cannot change". And these meanings  remain the same in the technology world. For example, a mutable string can be changed, and an immutable string cannot be changed.\n\nIt\'s important to note that this does not relate to a variable, but to a value. Constants are not always immutable, and non-constant variables are not always mutable.\n\nFor example, objects in JavaScript are by default mutable, even if they\'re assigned to a constant variable. The following is valid TypeScript:\n\n```typescript\nconst myObj = {\n    one: 1,\n    two: 2\n};\n// Here myObj is { one: 1, two: 2 }\n\nmyObj.three = 3;\n// Here myObj is { one: 1, two: 2, three: 3 }\n```\n\nThe only thing you cannot do with a constant is reassign it, e.g:\n\n```typescript\nconst myObj = {\n    one: 1,\n    two: 2\n};\n// Here myObj is { one: 1, two: 2 }\n\nmyObj = {\n    one: "one",\n    two: "two"\n}\n// Uncaught TypeError: Assignment to constant variable\n```\n\nAnd the same is the case with arrays.\n\n# What is the problem with mutable variables?\n\nThe biggest problem with mutable variables is that they are not thread-safe. Thread safe code is defined as: "Thread-safe code only manipulates shared data structures in a way that ensures that all threads behave properly and fulfill their design specifications without unintended interaction." (src: [Thread safety - Wikipedia](https://en.wikipedia.org/wiki/Thread_safety))\n\nWhat this means is that threads can access a data structure without producing unexpected results.\n\nTake this example from [Statics &amp; Thread Safety: Part I](https://odetocode.com/Articles/313.aspx) for instance: Say I\'ve got a shopping cart with 10 items at my local shop. I go to checkout and the clerk grabs each item and puts it through the register and then computes my cost. Without human error, we would expect the correct total to be shown.\n\nNow imagine if we had 5 checkout lanes, each one with one clerk, but only 1 shared register. If multiple clerks are putting in items through the register at the same time, no one would get their correct total.\n\nThe solution is to ensure that only 1 clerk will have access at any one time to the register (a lock), and no other clerks can use the register until my 10 items are scanned.\n\n# How does immutability solve this issue?\n\nImmutability solves this issue by ensuring that a data structure cannot be modified, only read. Create once, read many times. So what if you need to perform an operation on an immutable data structure? You\'d return the result in a *new* immutable instance of the data structure.\n\nSo how does this look in typescript?\n\n```typescript\nclass ImmutableUser {\n    readonly name: string;\n    readonly age: number;\n    \n    constructor(name: string, age: number) {\n        this.name = name;\n        this.age = age;\n    }\n\n    increaseAgeByOne(): ImmutableUser {\n        return new ImmutableUser(this.name, this.age + 1);\n    }\n}\n```\n\nNow whenever we want to perform an operation (in this case increase the age in the event of a birthday for example), we create a whole new instance of `ImmutableUser` instead of modifying the current instance. We\'ve also marked `name` and `age` as `readonly` to make sure that the end user also isn\'t able to modify these variables.\n\nHere is what it would look like to use an `ImmutableUser`\n\n```typescript\nlet testUser = new ImmutableUser("John Doe", 19); // instance A\n\n// Increase age\ntestUser = testUser.increaseAgeByOne(); // instance B\n```\n\nNow in the scenario that Thread 1 is reading `instance A` and Thread 2 wants to increase the age, it will have to do so by creating an `instance B` instead of directly modifying `instance A`, so it is assured that Thread 1 will produce expected behaviour.\n\nThanks for taking the time to read this article, and make sure to check other Unicorn Utterance\'s blog posts!\n\n',
		},
		{
			title:
				"How Binary and Hexadecimal Work: An introduction to non-decimal number systems",
			description:
				"Learn how to convert decimal to binary and hexadecimal, how CSS colors are calculated, and how your computer interprets letters into binary.",
			published: "2019-11-07T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["computer science"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "non-decimal-numbers-in-tech",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title:
					"How Binary and Hexadecimal Work: An introduction to non-decimal number systems",
				description:
					"Learn how to convert decimal to binary and hexadecimal, how CSS colors are calculated, and how your computer interprets letters into binary.",
				published: "2019-11-07T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["computer science"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				'\nComputers, on a very low level, are built upon binary (ones and zeros). Think about that — all of the text you\'re reading on your screen started life as either a one or a zero in some form. That\'s incredible! How can it turn something so simple into a sprawling sheet of characters that you can read on your device? Let\'s find out together!\n\n# Decimal {#decimal}\n\nWhen you or I count, we typically use 10 numbers in some variation of combination to do so: `0`, `1`, `2`, `3`, `4`, `5`, `6`, `7`, `8`, and `9`.\n\nWhen you count to `10`, you\'re really using a combination of `1` and `0` in order to construct a larger number that we cognizantly recognize. The number `10` persists in our minds even when we have it written out; **ten**.\n\n![An image showcasing the symbols for decimal with one and zero highlighted to make up the number "10"](./introduction_to_symbols.svg)\n\nKnowing that we can separate the number from our thoughts allows us to further categorize the number, mentally breaking it down into smaller groupings. For example, the number `34` can be broken down into three groups: the _ones_, the _tens_, and the _hundreds_.\n\n![A "0" in the hundreds column, a "3" in the tens column, a "4" in the ones column which drop down to show "30 + 4" which equals 34](./base_10_34.svg)\n\nFor the number `34`, we break it down into: `0` _hundreds_, `3` _tens_, and `4` _ones_. We can then multiply the higher number with the lower number (the column they\'re in) to get the numbers **`30`** (`3` _tens_) and **`4`** (`4` _ones_). Finally, we add them all together to make the number we all know and love: **`34`**.\n\nThis breakdown showcases a limitation with having 10 symbols to represent numbers; with only a single column, the highest number we can represent is _`9`_.\nRemember that the number **`10`** is a combination of **`1`** and **`0`**? That\'s due to this limitation. Likewise - with two columns - the highest number we can represent is _`99`_.\n\n![A "9" in the tens column, and a "9" in the ones column which drop down to show "90 + 9" which equals 99](./base_10_99.svg)\n\n# Binary {#binary}\n\nNow this may seem rather simplistic, but it\'s an important distinction to be made to understand binary. Our typical decimal numeral system is known as the _base 10_ system. **It\'s called as such because there are 10 symbols used to construct all other numbers** (once again, that\'s: `0`, `1`, `2`, `3`, `4`, `5`, `6`, `7`, `8`, and `9`).\nBinary, on the other hand, is _base two_. **This means that there are only two symbols that exist in this numeral system.**\n\n> For the Latin enthusiasts, binary comes from "binarius" meaning "two together". _Deca_, meaning 10, is where "decimal" comes from.\n> Additionally, the term "radix" is sometimes used instead of "base" when describing numeral systems, especially in programming.\n\nInstead of using numbers, which can get very confusing very quickly while learning for the first time, let\'s use **`X`**s and **`O`**s as our two symbols for our first few examples. _An **`X`** represents if a number is present and that we should add it to the final sum; an **`O`** means that the number is not present and that we should not add it_.\nTake the following example:\n\n![A "X" on the two column and a "X" on the ones column which add together to make 3](./base_2_3_symbols.svg)\n\nIn this example, both `1` and `2` are present, so we add them together to make **`3`**. You\'ll see that since we can only have a value present or not present — because we only have two symbols in binary — this conversion has fewer steps than using decimal. For example, if you only wanted the number two, you could simply mark the `1` as "not present" using the **`O`**:\n\n![A "X" on the two column and an "O" on the ones column which add together to make 2](./base_2_2_symbols.svg)\n\nYou can even replace the two symbols with `1` and `0` to get the actual binary number of `10` in order to represent `2`:\n\n![A "1" on the two column and an "0" on the ones column which add together to make 2](./base_2_2.svg)\n\nSo, how does this play out when trying to represent the number **`50`** in binary?\n\n![The binary number "110010" which shows 32, 64, and 2 to combine together to make 50. See the below explanation for more](./base_2_50.svg)\n\nAs you can see, we create columns that are powers of `2` for similar reasons as using powers of `10` in decimal; you can\'t represent `4`, `8`, `16`, or `32` without creating a new column otherwise.\n\n> Remember, in this system, a number can only be present or not; there is no _`2`_. This means that only the symbols `1` and `0` are present. Keeping this in mind, it then means that we can only have `11` as the highest represented number without another column. **`11`** in binary is **`3`** in decimal. _This shows that with only 2 binary digits, only the decimal numbers that can be represented are: `0`, `1`, `2`, and `3`_. As a result, we need to add a _`4`_ column in order to represent that number in binary.\n>\n> Continuing on with this pattern: without an **`8`** column, you can only have a `4`, `2`, and `1` which would yield a maximum value of **`7`**. It\'s important to note that these values are always one less than a power of 2.\n\nOnce each of these powers is laid out, we can start adding `1`s where we have the minimum amount of each value. For example:\n\n- Is `64` less than or equal to `50`? No. That\'s a **`0`**.\n- Is `32 <= 50`? Yes, therefore that\'s a **`1`**.\n    - `50 - 32 = 18`\n- Moving down the list, is `16 <= 18`? Yes, that\'s a **`1`**.\n    -`18 - 16 = 2`\n- Is `8 <= 2`? No, that\'s a **`0`**.\n- `4 <= 2`? No, that\'s a **`0`** as well.\n- `2 <= 2`? Yes, that\'s a **`1`**.\n    - `2 - 2 = 0`\n- Now that we\'re left with `0`, we know that the rest of the digits will be `0`.\n\nAdd up all those numbers:\n\n| Column | Value   |  \n| ------ | ------- |  \n| `64`   | **`0`** |  \n| `32`   | **`1`** |  \n| `16`   | **`1`** |  \n| `8`    | **`0`** |  \n| `4`    | **`0`** |  \n| `2`    | **`1`** |  \n| `1`    | **`0`** |  \n\nAnd voilà, you have the binary representation of `50`: **`0110010`**.\n\n> Author\'s note:\n>\n> While there are plenty of ways to find the binary representation of a decimal number, this example uses a "greedy" algorithm. I find this algorithm to flow the best with learning the binary number system, but it\'s not the only way (or even the best way, oftentimes).\n\n# Hexadecimal {#hexadecimal}\n\nBinary isn\'t the only non-decimal system. You\'re able to use any number as your base as long as you have enough symbols to represent the digits. Let\'s look at another example of a non-decimal system: _hexadecimal_.\n\nHexadecimal is the base 16 number system.\n\n> _Hexa_ means "six" in Latin, and _deca_ means "ten", so these are combined to form "sixteen".\n\nNow you may wonder how you can count to 16 in a single column when we only use 10 symbols to represent numbers. The answer, to many developers, is to fill the remaining last 6 with other symbols: alphabetical letters.\n\n`0`, `1`, `2`, `3`, `4`, `5`, `6`, `7`, `8`, `9`, `A`, `B`, `C`, `D`, `E`, `F`\n\nThese are the symbols that make up the hexadecimal numeral system for many developers. _`A`_, in this case, represents the number **`10`**; _`F`_ represents the number **`15`**. In this numeral system, there are the _sixteens_, the _two-hundred fifty sixes_ (gathered by multiplying 16 by itself — 16<sup>2</sup>), and other powers of 16.\n\nGiven this information, how would we represent the number **`50`**?\n\n![The hexadecimal number "032" which shows 0 "two-hundred fifty sixes", 3 "sixteens", and 2 "ones" to combine together to make 50. See the below explanation for more](./base_16_50.svg)\n\nAssuming we have a _ones_ column, a _sixteens_ column, and a _two-hundred fifty sixes_ column, we can calculate the number in a similar way to the binary example earlier:\n\n- Is `256` less than or equal to `50`? No. That\'s a **`0`**\n- Is `16 <= 50`? Yes. So we know it\'s _at least `1`_.\n    - Now, how many times can you put `16` in `50`?\n        - `16 * 2 = 32` and `32 <= 50`, so it\'s _at least_ _`2`_.\n        - `16 * 3 = 48` and `48 <= 50` so it\'s _at least_ _`3`_.\n        - `16 * 4 = 64`. However, `64 > 50`, therefor the _sixteenth_ place cannot be _`4`_, therefore it must be **`3`**.\n    - Now that we know the most we can have in the _sixteenth_ place, we can subtract the sum (`48`) from our result (`50`).\n        - `50 - 48 = 2`\n- Now onto the _ones_ place: how many _ones_ can fit into _`2`_?\n    - `1 * 1 = 1` and `1 <= 2`, so it\'s _at least_ _`1`_.\n    - `1 * 2 = 2` and `2 <= 2` and because these numbers are equal, we know that there must be **`2`** _twos_.\n\nNow if we add up these numbers:\n\n| Column | Value   |\n| ------ | ------- |\n| `256`  | **`0`** |\n| `16`   | **`3`** |\n| `1`    | **`2`** |\n\n## Why `256`?\n\nWhile reading through this, you may wonder, "Where did the `256` come from?". Let\'s take a step back to analyze this question.\n\nIf you recall, we use these 15 symbols to represent digits in hexadecimal:\n\n`0`, `1`, `2`, `3`, `4`, `5`, `6`, `7`, `8`, `9`, `A`, `B`, `C`, `D`, `E`, `F`\n\nUsing just a single digit (or, phrased in another way: A single number column), the biggest number we can represent is `F`, or `15` in decimal.\n\nThis is similar to how the biggest number we can represent with a single digit in decimal is `9`.\n\nIn order to add a number larger than `15` in the hexadecimal system, we need to add another digit/column. This column would represent the _sixteens_ place. Having `F` in both this column and the _ones_ column, the highest number we can represent would be `FF`, or `255` in decimal. As a result, we need to add a _two-hundred-fifty-six_ column to represent any numbers higher.\n\n> For those that have experience in algebra, you\'ll notice that these are all powers of 16.\n>\n> Just as _`100`_ is 10<sup>2</sup> for the decimal system, `256` is 16<sup>2</sup>. We can follow this pattern to the next number in the hexadecimal column: `4096`, which is 16<sup>3</sup>. You can even apply it to `1` which is 16<sup>0</sup>.\n>\n> Binary works in the same manner. The first 5 columns/digits of binary are: `1`, `2`, `4`, `8`, `16`. These numbers align respectively to their binary exponents: 2<sup>0</sup>, 2<sup>1</sup>, 2<sup>2</sup>, 2<sup>3</sup>, 2<sup>4</sup>.\n>\n> It\'s also worth noting that decimal numbers can be written out the same way. \n>\n> _`732`_ for example, in base 10, can be written as (7 × 10<sup>2</sup>) + (3 × 10<sup>1</sup>) + (2 × 10<sup>0</sup>).\n\n## To Binary {#hexadecimal-to-binary}\n\nRemember that at the end of the day, hexadecimal is just another way to represent a value using a specific set of symbols. Just as we\'re able to convert from binary to decimal, we can convert from hexadecimal to binary and vice versa. \nIn binary, the set of symbols is much smaller than in hexadecimal, and as a result, the symbolic representation is longer.\n\n![The hexadecimal number "032" and the binary number "110010" which both represent the decimal value 50](./binary_vs_hexadecimal.svg)\n\nAfter all, they\'re just reflections of the numbers that we represent using a specific set of symbols. In binary, those symbols are more restrictive than in hexadecimal, and therefore the symbolic representation is longer.\n\n# Applications\n\n## CSS Colors {#hex-css}\n\nFunnily enough, if you\'ve used a "hex" value in HTML and CSS, you may already be loosely familiar with a similar scenario to what we walked through with the hexadecimal section.\n\nFor example, take the color `#F33BC6` (a pinkish color). This color is a combination of `3` two-column hexadecimal numbers back-to-back. These numbers are:\n\n`F3`, `3B`, `C6`\n\n_They reflect the amount of red, green, and blue (respectively) in that color._ Because these numbers are two-digit hexadecimal numbers, _the highest a number can be to reflect one of these colors is `255`_ (which is **FF** in hexadecimal).\n\n> If you\'re unfamiliar with how red, green, and blue can combine to make the colors we\'re familiar with (such as yellow, orange, purple, and much more), it might be worth taking a look at some of the color theory behind it. [You can find resources on the topic on Wikipedia](https://en.wikipedia.org/wiki/RGB_color_model) and elsewhere.\n\nThese numbers, in decimal, are as follows:\n\n| Hex  | Decimal |\n| ---- | ------- |\n| `F3` | `243`   |\n| `3B` | `59`    |\n| `C6` | `196`   |\n\nAnd construct the amount of `Red`, `Green`, and `Blue` used to construct that color\n\n| Represents | Hex  | Decimal |\n| ---------- | ---- | ------- |\n| Red        | `F3` | `243`   |\n| Green      | `3B` | `59`    |\n| Blue       | `C6` | `196`   |\n\nEven without seeing a visual representation, you can tell that this color likely has a purple hue - since it has a high percentage of red and blue.\n\n![A visual representation of the color above, including a color slider to show where it falls in the ROYGBIV spectrum](./F33BC6.png)\n\n## Text Encoding {#ascii}\n\nAlthough hexadecimal has a much more immediately noticeable application with colors, we started this post off with a question: "How does your computer know what letters to display on the screen from only binary?"\n\nThe answer to that question is quite complex, but let\'s answer it in a very simple manner (despite missing a lot of puzzle pieces in a very ["draw the owl"](https://knowyourmeme.com/memes/how-to-draw-an-owl) kind of way).\n\nLet\'s take a real way that computers used to (and still do, to some extent) represent letters internally: [ASCII](https://en.wikipedia.org/wiki/ASCII). ASCII is an older standard for representing each textual character as a different number inside your computer. Take the following (simplified) chart:\n\n![An ASCII chart that maps the numbers 64 which is capital A through to 90 which is capital Z and 97 which is lowercase a to 122 which is capital z](./ascii_chart.svg)\n\nWhen the user types _"This"_, what the computer interprets (using ASCII) is `84`, `104`, `105`, and `115` for `T`, `h`, `i`, and `s`, respectively.\n\n> You might be wondering, "Why are there a bunch of missing numbers"?\n>\n> I\'ve removed them to keep the examples simple, but many of them are for symbols (EG: `#`, `/`, and more), and some of them are for internal key commands that were used for terminal computing long ago that your computer now does without you noticing.\n>\n> It\'s also worth mentioning that ASCII (which does have more characters than what\'s presented here) was eventually replaced in various applications by [Unicode](https://en.wikipedia.org/wiki/Unicode) and other text encoding formats as it lacks various functionality we expect of our machines today, such as emoji and non-latin symbols (like Kanji). ASCII still sticks around to some extent though, as the first 255 characters in Unicode are the same as they originally were in ASCII.\n\nWhile I\'ve used the above chart to reflect _A_ as `65`, it\'d be more accurate to say that your computer interprets the symbol as `01000001` internally. This is again due to the fact that your computer must interpret every number and letter as binary.\n\n# Conclusion\n\nWhile this has been only a high-level overview of how your computer interprets these non-decimal numbers (and some of their applications), it can provide some basic insights to what your computer is doing every time you make a keystroke or see a color on screen. Under the hood, everything is binary, and now you understand the introduction to how to convert binary to numbers you and I may understand better: to decimal!\n',
		},
		{
			title: "Pointers and References in C/C++",
			description:
				"An overview of how pointers and references function in C/C++",
			published: "2020-06-02T09:40:00.000Z",
			authors: ["seanmiller"],
			tags: ["computer science", "cpp"],
			attached: [],
			license: {
				id: "cc-by-nc-nd-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "https://creativecommons.org/licenses/by-nc-nd/4.0/",
				name: "Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) License",
			},
			slug: "pointers-and-references-cpp",
			locale: "en",
			authorsMeta: [
				{
					id: "seanmiller",
					name: "Sean Miller",
					firstName: "Sean",
					lastName: "Miller",
					description:
						"Howdy! Computer Science major at Texas A&M University, with a minor in cybersecurity. Super passionate about all things software!",
					socials: {
						twitter: "beastosean",
						github: "tamuseanmiller",
						website: "https://sean.millerfamily.tech",
						linkedIn: "tamuseanmiller",
					},
					pronouns: "he",
					profileImg: "./seanmiller.jpg",
					color: "#551a8b",
					roles: ["author"],
					profileImgMeta: {
						height: 3451,
						width: 3452,
						relativePath: "./seanmiller.jpg",
						relativeServerPath: "/content/data/seanmiller.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\seanmiller.jpg",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Pointers and References in C/C++",
				description:
					"An overview of how pointers and references function in C/C++",
				published: "2020-06-02T09:40:00.000Z",
				authors: ["seanmiller"],
				tags: ["computer science", "cpp"],
				attached: [],
				license: "cc-by-nc-nd-4",
			},
			contentMeta:
				'\nEvery new C/C++ programmer will eventually reach the point at which they are forced to work with pointers and will undoubtedly realize that they extremely dislike using them because they are a little complex. Today, we\'ll be looking at what pointers are, deconstructing their usage, and hopefully, making the usage of pointers easier to grok.\n\n# What is a Pointer? {#what-is-a-pointer}\n\nA pointer is simply a variable or object that instead of holding a value, holds a memory address to another spot in memory. You will commonly see a pointer being most recognizable by their declaration including the **\\*** operator, also known as the **dereference operator**. This operator is called the dereference operator because when you try to access the value that the pointer is referencing, you have to use the **\\*** operator to "de-reference" the value. Which is just a fancy way of saying, "go to that reference".\n\nHere\'s an example:\n\n```cpp\n\t// Defines int variable num\n\tint num = 12;\n\n\t// Declares pointer p\n\t// Ignore the \'&\' symbol here, we\'ll discuss that next\n\tint *p = &num;\n\n\t// Prints out the memory address that p is pointing to\n\tcout << p << endl;\n\n\t// Prints out the memory address of num\n\t// Again ignore the \'&\' symbol here, we\'ll discuss that next\n\tcout << &num << endl;\n\n\t// Dereferences the pointer p\n\tcout << *p << endl;\n\n\t// Prints out the value num\n\tcout << num << endl;\n```\n  \nThis should print out something like...\n\n```\n\t0xffffcc14\n\t0xffffcc14\n\t12\n\t12\n```\n\nAs you can see, the pointer p holds the memory address of num, and when you use the dereference operator, the value at num is printed out.\n\nPointers can also get a lot more complex and must be used in certain situations. For example, if you put an object on the heap (Check out my article on Virtual Memory to learn more about heap memory) then you will have to use a pointer because you can\'t access the heap directly. So, instead of having a pointer to an address on the stack, it will point to an address on the heap. You might even find yourself using double or triple pointers as you get more used to them.\n\n# What is a Reference? {#what-is-a-reference}\n\nIn simple terms, a reference is simply the address of whatever you\'re passing. The difference between a pointer and a reference lies in the fact that a reference is simply the **address** to where a value is being stored and a pointer is simply a variable that has it\'s own address as well as the address it’s pointing to. I like to consider the **&** operator the "reference operator" even though I\'m pretty sure that\'s not actually what it is called. I used this operator in the last example, and it\'s pretty straightforward.\n\n```cpp  \n\tint num = 12;\n\tint *val = &num;\n\tint **doublePointer = &val;\n\n\tcout << "Address of num: " << &num << endl;\n\tcout << "Value of val" << val << endl;\n\t\n\t// Pointers have memory addresses too!\n\tcout << "Address of val" << &val << endl;\n\t\n\t// Prints out every phase of the double pointer\n\tcout << &doublePointer << " : " << doublePointer << " : ";\n\n\tcout << *doublePointer << " : " << **doublePointer << endl;\n```\n\nThe output will look something like this...\n\n```\n\tAddress of num: 0xffffcc1c\n\tValue of val: 0xffffcc1c\n\tAddress of val: 0xffffcc10\n\t0xffffcc08 : 0xffffcc10 : 0xffffcc1c : 12\n```\n  \nAs you can see, all the **&** operator does is gives you the memory address at its specific spot in memory. I also included a small example of a double-pointer which just contains one more layer of abstraction then a single pointer. You can see how the memory addresses line up in the output.\n\nHere’s what this looks like in memory with more easily understandable addresses in a “0x…” format.\n\n**![Memory Example](./memory.png)**\n\n# Pass by Reference vs. Pass by Value {#passing}\n\nThis is another more complex topic that we as programmers need to be aware of in almost all languages - even languages without pointers. The idea of the two all stems from functions, sometimes called methods, and their parameters. Whenever you pass something into a function, does the original variable/object that is passed in get updated inside as well as outside the function, or is it hyperlocal and it just creates a copy of the original parameter? "Pass by reference" refers to when the parameter is changed both within the function and outside of it. "Pass by value" refers to when the parameters are merely a copy and have their own memory address, only being updated inside of the function.\n\nThe primary difference between the two is what happens when you change values. If you pass by reference and update the property, it will update the original variable that was passed as well. However, if you pass by value and update it in the function, it will not impact the original variable.\n\nThe neat part of C++ is that you can control whether something is passed by reference or passed by value, but rather than try and explain it further let\'s look at an example.\n\n```cpp\n\t// Pass by reference\n\tvoid passByReference(int &num) {\n\t\tnum += 2;\n\t}\n\t  \n\t// Pass by value\n\tvoid passByValue(int num) {\n\t\tnum += 2;\n\t}\t  \n\n\tint main() {\n\t\n\t\tint num1 = 0;\n\t\tint num2 = 0;\n\t\tcout << "Original value: " << num1 << endl;\n\n\t\t// call passByReference()\n\t\tpassByReference(num1);\n\n\t\tcout << "After passing by reference: " << num1 << endl;\n\t\t\n\t\t// call passByValue()\n\t\tpassByValue(num2);\n\n\t\tcout << "After passing by value: " << num2 << endl;\n\t\t\n\t}\n```\n\nThe output of this looks like...\n\n```\n\tOriginal value: 0\n\tAfter passing by reference: 2\n\tAfter passing by value: 0\n```\n\nAs you can see, when passed by reference, the local value is changed, but when it is passed by value, it is not; even though they both perform the same operation. Some other languages, such as Java, do not give you this control. Java always passes by value, though it does pass addresses by value.\n\nThis gets confusing after a while if you\'re not paying attention to your outputs. In fact, Python gets even more confusing, but that\'s a topic for another day; be sure to sign up for our newsletter to see when that lands 😉\n\n# Review/Conclusion {#conclusion}\n\nPointers and References are extremely important in your day to day work in languages like C/C++. C++ gives you a lot of manual control with the most common being memory. Knowing how each one of your pointers or variables are stored will help you write code faster and more efficiently. Knowing also how parameters are passed to your functions as well as how they are updated, will make your life **so** much easier.\n',
		},
		{
			title: "Project Management for Individuals",
			description:
				"Having the ability to structure your projects (and these don't exclusively have to be programming related) gives you a massive advantage when it comes to being organised, and keeping your life organised.",
			published: "2022-07-26T15:45:03.000Z",
			authors: ["alexchadwick"],
			tags: ["opinion"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "project-management-for-individuals",
			locale: "en",
			authorsMeta: [
				{
					id: "alexchadwick",
					name: "Alex Chadwick",
					firstName: "Alex",
					lastName: "Chadwick",
					description:
						"I'm a full-stack web developer in the UK (but born in sunny Spain!) \n I spend too much time reading articles on clean code and not enough refactoring 🤣",
					socials: {
						twitch: "alexchadwicc",
						twitter: "TheAlexChadwick",
						github: "AlexChadwickP",
						linkedin: "alexchadwickp",
						website: "https://alexchadwick.com",
					},
					pronouns: "he",
					profileImg: "./alexchadwick.jpg",
					color: "",
					roles: ["author", "translator"],
					profileImgMeta: {
						height: 2316,
						width: 2315,
						relativePath: "./alexchadwick.jpg",
						relativeServerPath: "/content/data/alexchadwick.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\alexchadwick.jpg",
					},
					rolesMeta: [
						{ id: "author", prettyname: "Author" },
						{ id: "translator", prettyname: "Translator" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Project Management for Individuals",
				description:
					"Having the ability to structure your projects (and these don't exclusively have to be programming related) gives you a massive advantage when it comes to being organised, and keeping your life organised.",
				published: "2022-07-26T15:45:03.000Z",
				authors: ["alexchadwick"],
				tags: ["opinion"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\n# Project Management for Individuals\n\n> Before I begin this post, I am **not** a project manager, but at my job, I perform a lot of project management as I work largely by myself on multiple projects, so any tips covered here I consider them to work for individuals, and maybe small teams, but will definitely not work for larger teams.\n\n## Introduction\n\nProject management is an underrated skill to have for anyone that isn't a project manager.\n\nHaving the ability to structure your projects (and these don't exclusively have to be programming related) gives you a massive advantage when it comes to being organised, and keeping your life organised.\n\nAnd I felt I was lacking organisation when I started the job I'm currently at. I work on a variety of projects (ranging from internal tooling to commercial software), by myself. Since I had total control over the projects I worked on, when I worked on them and when I delivered them, it felt like I had no sort of pressure or deadline to work towards, nor did I have a structured way of working.\n\nAnd jumping from one project to another because I got bored of one proved to be the wrong way to do things.\n\nSo I spent a weekend just researching basic project management, productivity tips for developers, different methodologies (agile, scrum, xp) and tried to find something that would suit my line of work, but this was difficult. Agile and Scrum were complete overkill, and XP was hard to grasp for someone that was new to managing projects.\n\nSo what I went and did, was develop a methodology of my own, that was tailored to my own needs, and in this post I'd like to share with you how you can do the same (or use mine!).\n\n## My Methodology\n\nI was looking for a methodology that would fit nicely in Azure DevOps Boards, so I could use it there, and that was clear enough that if more people were to join my team they would understand immediately how it worked, however the tips that I'll describe later on in this blog post will be aplicable to other software, as well as physical boards!\n\nSo I developed the most simple thing that would work.\n\n### The task types\n\nThere are 2 task types:\n\n* Tasks: You can nest tasks within tasks. They can be anything: feature implementation, refactoring, writing tests, chores, etc. Anything except issues or bugs\n\n* Bugs: They can be nested under tasks, but not under other bugs. They must be atomic, meaning they can't be broken down into smaller pieces\n\n### Tags\n\nThere are a few tags that I like to use when defining bugs and tasks:\n\n* Feature: For tasks the implement a feature\n\n* Refactor: For tasks that relate to a refactor of some sorts\n\n* Chore: For tasks that may be boring / don't affect the end result too much like internal documentation and configuration\n\n* Test: For tasks or bugs about testing\n\n* Blocker: For bugs that are very urgent\n\nBy using these tags it becomes easier to manage tasks and bugs as you can filter through them. Some people might prefer making each tag it's own task type, but personally I prefer to have the one type of task with one or more tags instead.\n\n### Branching\n\nFor branching I use the following method:\n\n1. Create a task that the branch relates to\n\n2. Create a branch with a brief description of what it's for and the task / bug number, e.g: 372-fix-document-view\n\n3. Make your changes\n\n4. Push your changes\n\n5. Create a pull request\n\n6. Merge with the main or trunk branch\n\n7. Execute CI/CD operations to test and build the project\n\n8. If all is successful, merge main and production branches\n\n### Development Cycle\n\nThe development cycle, for those that don't know, is the process followed by an individual or team to develop software.\n\nThis is what my usual development cycle looks like:\n\n1. Requirements: Firstly I gather the requirements of the product or feature\n\n2. Design: I usually jot down on a notebook a rough design of the feature. Design here doesn't refer exclusively to UI, but also code design. How will I break this down? If I'm in the backend, do I need a new controller? Do I need to add a service?\n\n3. Writing tests: I prefer test driven development, so firstly I write unit and integration tests where I can. And I make sure they all fail!\n\n4. Implementation: Now that I've got the tests, I will program my implementation. For every test that succeeds I will create a commit.\n\n5. Refactoring / Documenting: Now that it's implemented and working, I do some refactoring and documenting where needed to make it easier to understand.\n\n6. CI: Now I will push all of my commits, and wait for the Continuous Integration pipeline to verify that all the testing, linting and building is successful\n\n7. (Optional) CD: This step is optional because I don't always deploy the changes I make immediately. I'll only run a Continuous Delivery pipeline if I'm fixing an important bug, in which case, this step will take place immediately after CI. If not then I'll wait to accumulate a few features to deliver my updated application\n\n8. Start again\n\n## How do you come up with your own methodology?\n\nThis is an incredibly complex question, because you can make this as simple or as complicated as you like, and it might change depending on the tools you're using or the technologies you work with.\n\nBut I still wanted to put out a general sort of guide to coming up with your own methodology that can be applicable to your software projects, so here are my tips:\n\n### 1. How do you want to break down your to-dos?\n\nIn my case, I wanted to break them down into Tasks and Bugs, each with optional tags. And it works great for me because it integrates well with Azure DevOps. But if you're using a different system then maybe you want to rethink this. Maybe you want Test Writing to be it's own type of task because you find it feels better in your system. It's *your* methodology so remember to tailor it to yourself.\n\n### 2. Which branching strategy do you want?\n\nThere are many options. I like to go for a simple branching strategy as it's just me working on this, so I don't need anything overly complex, but maybe if you want more structure you can be more complicated. I like to have a branch per issue, then it all gets added to the same \"nightly\" branch which happens to be my default / main branch, and a production branch that triggers my CD.\n\n### 3. What will your development cycle look like?\n\nWhether it's well defined or not defined at all, you inevitably have some sort of routine that you follow when programming. Write this down, and also maybe consider if there are any improvements you could easily add to your routine. If you have trouble remembering when to commit for example (like me!) then try to set some sort time when you commit, like for example, when you've written 5 functions or when you've finished a step in your development cycle.\n\n### 4. Miscellaneous bits\n\nThere are many other things that you can add to your methodology, but I chose to skip in mine. For example, a priority system, the fields you want your task types to have, do you want an effort system? Do you want to write a word document for a major feature? Do you want to include notes in the task?\n\nYou can also work out how your pipelines are going to work. Do you want Continuous Integration (CI) to be separate from your Continuous Delivery (CD)? Do you want the CI/CD pipeline run automatically or manually?\n\n## Conclusion\n\nHaving your own methodology is incredibly handy for your personal projects, and even more so when you've got multiple going on at the same time.\n\nThere is no use in a methodology that doesn't work for you if you're working on a personal project, you'll be most productive when you follow a system that you feel comfortable using.\n\nHowever, never close the doors to any suggestions anyone may have, and don't be afraid to try something new to see if it works for you as well. And with that said, please do offer me your suggestions to improve my own system! I'm always keen on new productivity tips and I'm very interested in finding out what other people do!\n",
		},
		{
			title: "Python List Comprehension - The Comprehensive Guide",
			description:
				"Python is a language with broad and powerful APIs. One such API is 'List Comprehensions'. Let's learn to use them to improve your code!",
			published: "2021-05-07T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["python"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink: "https://coderpad.io/blog/python-list-comprehension-guide/",
			slug: "python-list-comprehension-guide",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Python List Comprehension - The Comprehensive Guide",
				description:
					"Python is a language with broad and powerful APIs. One such API is 'List Comprehensions'. Let's learn to use them to improve your code!",
				published: "2021-05-07T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["python"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/python-list-comprehension-guide/",
			},
			contentMeta:
				'\nPython list comprehensions allow for powerful and readable list mutations. In this article, we\'ll learn many different ways in how they can be used and where they\'re most useful. \n\nPython is an incredibly powerful language that’s widely adopted across a wide range of applications. As with any language of sufficient complexity, Python enables multiple ways of doing things. However, the community at large has agreed that code should follow a specific pattern: be “Pythonic”. While “Pythonic” is a community term, the official language defines what they call [“The Zen of Python” in PEP 20](https://www.python.org/dev/peps/pep-0020/). To quote just a small bit of it:\n\n> Explicit is better than implicit.\n>\n> Simple is better than complex.\n>\n> Complex is better than complicated.\n>\n> Flat is better than nested.\n\n\nIntroduced in Python 2.0 with [PEP 202](https://www.python.org/dev/peps/pep-0202/), list comprehensions help align some of these goals for common operations in Python. Let’s explore how we can use list comprehensions and where they serve the Zen of Python better than alternatives.\n\n## What is List Comprehension?\n\n\nLet’s say that we want to make an array of numbers, counting up from 0 to 2. We could assign an empty array, use `range` to create a generator, then `append` to that array using a `for` loop\n\n```python\nnumbers = []\nfor x in range(3):\n    numbers.append(x)\n```\n\nAlternatively, we could use list comprehension to shorten that to one line of code.\n\n```python\nnumbers = [x for x in range(3)]\n```\n\nConfused on the syntax? Let’s outline what’s happening token-by-token.\n\n![Breakdown of a list comprehension explained more below](./list_comp_breakdown.png)\n\nThe first and last brackets simply indicate that this is a list comprehension. This is also how I remember that a list comprehension outputs an array - it looks like we’re constructing an array with logic inside.\n\nSecond, we have the “x” before the “for”. This is the return value. This means that if we change the comprehension to:\n\n```python\nnumbers = [x*2 for x in range(3)]\n```\n\nInstead of “0, 1, 2”, we’d get “0, 2, 4”.\n\nNext up, we have a declaration of a `for` loop. This comprises of three separate parts:\n\n1. “for” - the start of the loop\n2. “x” - declaring the name of the variable to assign in each iteration\n3. “in” - denoting the start of listening for the iterator\n\nFinally, we have the `range`. This acts as the iterator for the `for` loop to iterate through. This can be replaced with anything a `for` loop can go through: a list, a tuple, or anything else that implements the iterator interface.\n\n## Are List Comprehension Pythonic?\n\nWhile it might seem counterintuitive to learn a new syntax for manipulating lists, let’s look at what the alternative looks like. Using `map`, we can pass an anonymous function (lambda) to multiply a number by 2, pass the `range` to iterate through. However, once this is done, we’re left with a `map` object. In order to convert this back to a list, we have to wrap that method in `list`.\n\n```python\nnumbers = list(map(lambda x: x*2, range(3)))\n```\n\nCompare this to the list comprehension version:\n\n```python\nnumbers = [x*2 for x in range(3)]\n```\n\nLooking at the comprehension, it’s significantly more readable at a glance. Thinking back to The Zen of Python, “Simple is better than complex,” list comprehensions seem to be more Pythonic than using `map`.\n\nWhile others might argue that a “for” loop might be easier to read, the Zen of Python also mentions “Flat is better than nested”. Because of this, list comprehensions for simple usage like this are more Pythonic.\n\nNow that we’re more familiar with basic usage of list comprehension, let’s dive into some of it’s more powerful capabilities.\n\n## Filtering\n\nWhile it might seem like list comprehension is only capable of doing a 1:1 match like `map`, you’re actually able to implement logic more similar to `filter` to change how many items are in the output compared to what was input.\n\nIf we add an `if` to the end of the statement, we can limit the output to only even numbers:\n\n```python\neven_numbers = [x for x in range(10) if x%2==0] #[0, 2, 4, 6, 8]\n```\n\nThis can of course be combined with the changed mutation value:\n\n```python\ndouble_even_numbers = [x*2 for x in range(10) if x%2==0] #[0, 4, 8, 12, 16]\n```\n\n## Conditionals\n\nWhile filtering might seem like the only usage of `if` in a list comprehension, you’re able to use them to act as conditionals to return different values from the original.\n\n```python\nnumber_even_odd = ["Even" if x % 2 == 0 else "Odd" for x in range(4)]\n# ["Even", "Odd", "Even", "Odd"]\n```\n\nKeep in mind, you could even combine this ternary method with the previous filtering `if`:\n\n```python\nthirds_even_odd = ["Even" if x % 2 == 0 else "Odd" for x in range(10) if x%3==0]\n# [0, 3, 6, 9] after filtering numbers\n# ["Even", "Odd", "Even", "Odd"] after ternary to string\n```\n\nIf we wanted to expand this code to use full-bodied functions, it would look something like this:\n\n```python\nthirds_even_odd = []\nfor x in range(10):\n    if x%3==0:\n        if x%2==0:\n            thirds_even_odd.append("Even")\n        else:\n            thirds_even_odd.append("Odd")\n```\n\n## Nested Loops\n\nWhile we explained that you’re able to have less items in the output than the input in our “filtering” section, you’re able to do the opposite as well. Here, we’re able to nest two “for” loops on top of each other in order to have a longer output than our initial input.\n\n```python\nrepeated_list = [y for x in ["", ""] for y in [1, 2, 3]]\n# [1, 2, 3, 1, 2, 3]\n```\n\nThis logic allows you to iterate through two different arrays and output the final value in the nested loop. If we have to rewrite this, we’d write it out as:\n\n```python\nrepeated_list = []\nfor x in ["", ""]:\n    for y in [1, 2, 3]:\n        repeated_list.append(y)\n```\n\nThis allows us to nest the loops and keep the logic flat. However, you’ll notice in this example, we’re not utilizing the “x” variable. Let’s change that and do a calculations based on the “x” variable as well:\n\n```python\nnumbers_doubled = [y for x in [1, 2] for y in [x, x*2]]\n# 1, 2, 2, 4\n```\n\nNow that we’ve explored using hard-coded arrays to nest loops, let’s go one level deeper and see how we can utilize list comprehensions in a nested manner.\n\n## Nested Comprehensions\n\nThere are two facts that we can combine to provide list comprehension with a super power:\n\n1. You can use lists inside of a list comprehension\n2. List comprehensions returns lists\n\nCombining these leads to the natural conclusion that you can nest list comprehensions inside of other list comprehensions.\n\nFor example, let’s take the following logic that, given a two-dimensional list, returns all of the first index items in one list and the second indexed items in a second list.\n\n```python\nrow_list = [[1, 2], [3,4], [5,6]]\nindexed_list = []\nfor i in range(2):\n    indexed_row = []\n    for row in row_list:\n        indexed_row.append(row[i])\n    indexed_list.append(indexed_row)\n\nprint(indexed_list)\n# [[1, 3, 5], [2, 4, 6]]\n```\n\nYou’ll notice that the first indexed items (`1`, `3`, `5`) are in the first array, and the second indexed items (`2`, `4`, `6`) are in the second array.\n\nLet’s take that and convert it to a list comprehension:\n\n```python\nrow_list = [[1, 2], [3,4], [5,6]]\nindexed_list = [[row[i] for row in row_list] for i in range(2)]\nprint(indexed_list)\n# [[1, 3, 5], [2, 4, 6]]\n```\n\n## Readable Actions and Other Operators\n\nSomething you may have noticed while working with list comprehension is how close some of these operators are to a typical sentence. While basic comprehensions serve this well on their own, they’re advanced by the likes of Python’s other grammatical-style operators. For example, operators may include:\n\n- `and` - Logical “and”\n- `or` - Logical “or”\n- `not` - Logical “not”\n- `is` - Equality check\n- `in` - Membership check/second half of `for` loop\n\nThese can be used for great effect. Let’s look at some options we could utilize:\n\n```python\nvowels = \'aeiou\'\nword = "Hello!"\n\nword_vowels = [letter for letter in word if letter.lower() in vowels]\n\nprint(word_vowels)\n\n# [\'e\', \'o\']\n```\n\nAlternatively we could check for consonants instead, simply by adding one “not”:\n\n```python\nword_consonants = [letter for letter in word if letter.lower() not in vowels]\n# [\'H\', \'l\', \'l\']\n```\n\nFinally, to showcase boolean logic, we’ll do a slight contrived check for numbers that mod 2 and 3 perfectly but are not 4:\n\n```python\nrestricted_number = 4\n\nsafe_numbers = [x for x in range(6) if (x%2==0 or x%3==0) and x is not restricted_number]\n\n# [0, 2, 3]\n```\n\n## Conclusion & Challenge\n\n\nWe’ve covered a lot about list comprehension in Python today! We’re able to build complex logic into our applications while maintaining readability in most situations. However, like any tool, list comprehension can be abused. When you start including too many logical operations to comfortably read, you should likely migrate away from list comprehension to use full-bodied `for` loops.\n\nFor example, given this sandbox code pad of a long and messy list comprehension, how can you refactor to remove all usage of list comprehensions? Avoid using `map`, `filter` or other list helpers, either. Simply use nested `for` loops and `if` conditionals to match the behavior as it was before.\n\n<iframe src="https://app.coderpad.io/sandbox?question_id=177671" loading="lazy"></iframe>\n\nThis is an open-ended question meant to challenge your skills you’ve learned throughout the article!\n\nStuck? Wanting to share your solution? [Join our community Slack](https://bit.ly/coderpad-slack), where you can talk about list comprehensions and the challenge in-depth with the CoderPad team!\n',
		},
		{
			title: "Python None",
			description:
				"Interpreted languages have various footguns. Let's explore one such footgun I ran into recently with Python and how I fixed it.",
			published: "2022-07-27T20:00:00.945Z",
			authors: ["williamcook"],
			tags: ["python", "go"],
			attached: [],
			license: {
				id: "cc-by-nc-nd-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "https://creativecommons.org/licenses/by-nc-nd/4.0/",
				name: "Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) License",
			},
			originalLink: "https://williamgeorgecook.com/posts/python_none/",
			slug: "python-none",
			locale: "en",
			authorsMeta: [
				{
					id: "williamcook",
					name: "William George Cook",
					firstName: "William",
					lastName: "Cook",
					description:
						"Full stack developer who loves to help! Find me in the garden, up a tree, or at Disney World ✨",
					socials: {
						twitter: "wgeorgecook",
						github: "wgeorgecook",
						linkedin: "wgeorgecook",
						website: "https://williamgeorgecook.com",
					},
					pronouns: "he",
					profileImg: "./williamcook.jpg",
					color: "#AF7AC5",
					roles: ["author"],
					profileImgMeta: {
						height: 256,
						width: 256,
						relativePath: "./williamcook.jpg",
						relativeServerPath: "/content/data/williamcook.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\williamcook.jpg",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Python None",
				description:
					"Interpreted languages have various footguns. Let's explore one such footgun I ran into recently with Python and how I fixed it.",
				published: "2022-07-27T20:00:00.945Z",
				authors: ["williamcook"],
				tags: ["python", "go"],
				attached: [],
				license: "cc-by-nc-nd-4",
				originalLink: "https://williamgeorgecook.com/posts/python_none/",
			},
			contentMeta:
				"\nToday at work we had a silly bug that exposes how reliant I am on Go's type system and compiler. I personally am too comfortable building a Docker image and assuming that the most egregious bugs were caught simply because the build was successful.\n\n## The Bug\nPython doesn't require you to specify a return value. In fact, you can have a function that may not explicitly return at all. Since Python is a scripting language, it will automatically return when it hits the bottom of the function being called. When this happens without returning a specific value, any variable assigned to the function call will be `None`. A silly but illustrating example:\n\n```python\ndef change_string(do_it: bool) -> str: \n    if do_it:\n        return \"changed!\"\n```\nThis function accepts a boolean that determines whether to do anything at all. According to the type hints and the function name, a string is the expected return type. You can assign the output of this function to a variable like normal:\n\n```python\nmy_string = change_string(False)\n```\n\nHowever, since the argument to `change_string` is `False`, the assignment will suffer from this bug. There is no return statement for a fasly `do_it` condition, so when Python reaches the end of the function it will have no choice but to return `None`. You can confirm the assignment by printing the value and type of `my_string`:\n\n```python\nprint(my_string)\nprint(type(my_string))\n\n> None\n> <class 'NoneType'>\n```\n\n## Lesson Learned\nWe switched to Go for the concurrency benefits but also the type system and compiler helps save us from these runtime errors. The same function in Go would result in a compile time error:\n\n```go\nfunc changeString(doIt bool) string {\n        if doIt {\n                return \"Changed!\"\n        }\n}\n\n\nfunc main() {\n        s := changeString(false)\n        fmt.Println(s)\n\n}\n\n> go run main.go\n> ./main.go:10:1: missing return\n```\n\nThis Python service isn't a candidate for rewriting in Go any time soon. Remembering to be more thorough in my code review and testing would have saved me from an embarrassing run time error that had some client impact today. \n",
		},
		{
			title: "React Refs: The Complete Story",
			description:
				"React Refs are an immensely powerful, yet often misunderstood API. Let's learn what they're capable of, and how they're usually misused.",
			published: "2020-12-01T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["react", "javascript"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "react-refs-complete-story",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "React Refs: The Complete Story",
				description:
					"React Refs are an immensely powerful, yet often misunderstood API. Let's learn what they're capable of, and how they're usually misused.",
				published: "2020-12-01T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["react", "javascript"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				'\nProgramming terminology can be rather confusing. The first time I\'d heard about "React Refs", it was in the context of [getting a reference to a DOM node](#dom-ref). However, with the introduction of hooks, the `useRef` hook has expanded the definition of "refs".\n\nToday, we\'ll be walking through two definitions of refs:\n\n- A [mutable data property](#use-ref-mutate) to persist data across renders\n\n- A [reference to DOM elements](#dom-ref)\n\nWe\'ll also be exploring additional functionality to each of those two definitions, such as [component refs](#forward-ref), [adding more properties to a ref](#use-imperative-handle), and even exploring [common code gotchas associated with using `useRef`](#refs-in-use-effect). \n\n> As most of this content relies on the `useRef` hook, we\'ll be using functional components for all of our examples. However, there are APIs such as [`React.createRef`](https://reactjs.org/docs/refs-and-the-dom.html#creating-refs) and [class instance variables](https://www.seanmcp.com/articles/storing-data-in-state-vs-class-variable/) that can be used to recreate `React.useRef` functionality with classes.\n\n# Mutable Data Storage {#use-ref-mutate}\n\nWhile `useState` is the most commonly known hook for data storage, it\'s not the only one on the block. React\'s `useRef`  hook functions differently from `useState`, but they\'re both used for persisting data across renders.\n\n```jsx\nconst ref = React.useRef();\n\nref.current = "Hello!";\n```\n\nIn this example, `ref.current` will contain `"Hello!"` after the initial render. The returned value from `useRef` is an object that contains a single key: `current`.\n\nIf you were to run the following code:\n\n```jsx\nconst ref = React.useRef();\n\nconsole.log(ref)\n```\n\nYou\'d find a `{current: undefined}` printed to the console. This is the shape of all React Refs. If you look at the TypeScript definition for the hooks, you\'ll see something like this:\n\n```typescript\n// React.d.ts\n\ninterface MutableRefObject {\n\tcurrent: any;\n}\n\nfunction useRef(): MutableRefObject;\n```\n\nWhy does `useRef` rely on storing data inside of a `current` property? It\'s so that you can utilize JavaScript\'s "pass-by-reference" functionality in order to avoid renders.\n\nNow, you might think that the `useRef` hook is implemented something like the following:\n\n```jsx\n// This is NOT how it\'s implemented\nfunction useRef(initial) {\n  const [value, setValue] = useState(initial);\n  const [ref, setRef] = useState({ current: initial });\n\n  useEffect(() => {\n    setRef({\n      get current() {\n        return value;\n      },\n\n      set current(next) {\n        setValue(next);\n      }\n    });\n  }, [value]);\n  \n  return ref;\n}\n```\n\nHowever, that\'s not the case. [To quote Dan Abramov](https://github.com/facebook/react/issues/14387#issuecomment-493676850):\n\n> ... `useRef` works more like this:\n>\n> ```jsx\n> function useRef(initialValue) {\n>   const [ref, ignored] = useState({ current: initialValue })\n>   return ref\n> }\n> ```\n\n\n\nBecause of this implementation, when you mutate the `current` value, it will not cause a re-render.\n\nThanks to the lack of rendering on data storage, it\'s particularly useful for storing data that you need to keep a reference to but don\'t need to render on-screen. One such example of this would be a timer:\n\n```jsx\n  const dataRef = React.useRef();\n\n  const clearTimer = () => {\n    clearInterval(dataRef.current);\n  };\n\n  React.useEffect(() => {\n    dataRef.current = setInterval(() => {\n      console.log("I am here still");\n    }, 500);\n\n    return () => clearTimer();\n  }, [dataRef]);\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-mutable-data?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\n# Visual Timer with Refs {#visual-timers}\n\nWhile there are usages for timers without rendered values, what would happen if we made the timer render a value in state?\n\nLet\'s take the example from before, but inside of the `setInterval`, we update a `useState` that contains a number to add one to its state.\n\n```jsx\n const dataRef = React.useRef();\n\n  const [timerVal, setTimerVal] = React.useState(0);\n\n  const clearTimer = () => {\n    clearInterval(dataRef.current);\n  }\n\n  React.useEffect(() => {\n    dataRef.current = setInterval(() => {\n      setTimerVal(timerVal + 1);\n    }, 500)\n\n    return () => clearInterval(dataRef.current);\n  }, [dataRef])\n\n  return (\n      <p>{timerVal}</p>\n  );\n```\n\nNow, we\'d expect to see the timer update from `1` to `2` (and beyond) as the timer continues to render. However, if we look at the app while it runs, we\'ll see some behavior we might not expect:\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-mutable-buggy-code?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\nThis is because [the closure](https://whatthefuck.is/closure) that\'s passed to the `setInterval` has grown stale. This is a common problem when using React Hooks. While there\'s a simple solution hidden in `useState`\'s API, let\'s solve this problem using mutations and `useRef`.\n\nBecause `useRef` relies on passing by reference and mutating that reference, if we simply introduce a second `useRef` and mutate it on every render to match the `useState` value, we can work around the limitations with the stale closure.\n\n```jsx\n  const dataRef = React.useRef();\n\n  const [timerVal, setTimerVal] = React.useState(0);\n  const timerBackup = React.useRef();\n  timerBackup.current = timerVal;\n\n  const clearTimer = () => {\n    clearInterval(dataRef.current);\n  };\n\n  React.useEffect(() => {\n    dataRef.current = setInterval(() => {\n      setTimerVal(timerBackup.current + 1);\n    }, 500);\n\n    return () => clearInterval(dataRef.current);\n  }, [dataRef]);\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-mutable-fixed-code?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\n> * I would not solve it this way in production. `useState` accepts a callback which you can use as an alternative (much more recommended) route:\n>\n> ```jsx\n>   const dataRef = React.useRef();\n> \n>   const [timerVal, setTimerVal] = React.useState(0);\n> \n>   const clearTimer = () => {\n>     clearInterval(dataRef.current);\n>   };\n> \n>   React.useEffect(() => {\n>     dataRef.current = setInterval(() => {\n>       setTimerVal(tVal => tVal + 1);\n>     }, 500);\n> \n>     return () => clearInterval(dataRef.current);\n>   }, [dataRef]);\n> ```\n> We\'re simply using a `useRef` to outline one of the important properties about refs: mutation.\n\n# DOM Element References {#dom-ref}\n\nAt the start of this article, I mentioned that `ref`s are not just a mutable data storage method but a way to reference DOM nodes from inside of React. The easiest of the methods to track a DOM node is by storing it in a `useRef` hook using any element\'s `ref` property:\n\n```jsx\n  const elRef = React.useRef();\n\n  React.useEffect(() => {\n    console.log(elRef);\n  }, [elRef]);\n\n  return (\n    <div ref={elRef}/>\n  )\n```\n\n> Keep in mind, the `ref` attribute is added and handled by React on any HTML Element. This example uses a `div`, but this applies to `span`s and `header`s and beyond, "oh my".\n\nIn this example, if we took a look at the `console.log` in the `useEffect`, we\'d find [an `HTMLDivElement` instance](https://developer.mozilla.org/en-US/docs/Web/API/HTMLDivElement) in the `current` property. Open the following StackBlitz and look at the console value to confirm:\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-effect?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\nBecause `elRef.current` is now a `HTMLDivElement`, it means we now have access to [the entire `Element.prototype` JavaScript API](https://developer.mozilla.org/en-US/docs/Web/API/Element#Properties). As such, this `elRef` can be used to style the underlying HTML node:\n\n```jsx\n  const elRef = React.useRef();\n\n  React.useEffect(() => {\n    elRef.current.style.background = \'lightblue\';\n  }, [elRef]);\n\n  return (\n    <div ref={elRef}/>\n  )\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-effect-style?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\n## Alternative Syntax {#ref-function}\n\nIt\'s worth noting that the `ref` attribute also accepts a function. While [we\'ll touch on the implications of this more in the future](#callback-refs), just note that this code example does exactly the same thing as `ref={elRef}`:\n\n```jsx\n  const elRef = React.useRef();\n\n  React.useEffect(() => {\n    elRef.current.style.background = \'lightblue\';\n  }, [elRef]);\n\n  return (\n    <div ref={ref => elRef.current = ref}/>\n  )\n```\n\n#  Component References {#forward-ref}\n\nHTML elements are a great use-case for `ref`s. However, there are many instances where you need a ref for an element that\'s part of a child\'s render process. How are we able to pass a ref from a parent component to a child component?\n\nBy passing a property from the parent to the child, you can pass a ref to a child component. Take an example like this:\n\n```jsx\nconst Container = ({children, divRef}) => {\n  return <div ref={divRef}/>\n}\n\nconst App = () => {\n  const elRef = React.useRef();\n\n  React.useEffect(() => {\n    if (!elRef.current) return;\n   elRef.current.style.background = \'lightblue\';\n  }, [elRef])\n\n  return (\n    <Container divRef={elRef}/>\n  );\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-effect-style-forward-ref-wrong-kinda?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\nYou might be wondering why I didn\'t call that property `ref` instead of `divRef`. This is because of a limitation with React. If we try to switch the property\'s name to `ref`, we find ourselves with some unintended consequences.\n\n```jsx\n// This code does not function as intended\nconst Container = ({children, ref}) => {\n  return <div ref={ref}/>\n}\n\nconst App = () => {\n  const elRef = React.useRef();\n\n  React.useEffect(() => {\n    if (!elRef.current) return;\n    // If the early return was not present, this line would throw an error:\n    // "Cannot read property \'style\' of undefined"\n   elRef.current.style.background = \'lightblue\';\n  }, [elRef])\n\n  return (\n    <Container ref={elRef}/>\n  );\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-effect-style-forward-ref-wrong?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\nYou\'ll notice that the `Container` `div` is not styled to have a `lightblue` background. This is because `elRef.current` is never set to contain the `HTMLElement` ref. As such, for simple ref forwarding, you cannot use the `ref` property name.\n\nHow do you get the `ref` property name to work as expected with functional components?\n\nYou can use the `ref` property name to forward refs by using the `forwardRef` API. When defining a functional component, instead of simply being an arrow function like you would otherwise, you assign the component to a `forwardRef` with the arrow function as it\'s first property. From there, you can access `ref` from the second property of the inner arrow function.\n\n```jsx\nconst Container = React.forwardRef((props, ref) => {\n  return <div ref={ref}>{props.children}</div>\n})\n\nconst App = () => {\n  const elRef = React.useRef();\n\n  React.useEffect(() => {\n    console.log(elRef);\n   elRef.current.style.background = \'lightblue\';\n  }, [elRef])\n\n  return (\n    <Container ref={elRef}/>\n  );\n```\n\nNow that we are using `forwardRef`, we can use the `ref` property name on the parent component to get access to the `elRef` once again.\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-effect-style-forward-ref?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\n# Class Component References {#class-ref}\n\nWhile I mentioned that we\'ll be using functional components and hooks for a majority of this article, I think it\'s important that I cover how class components handle the `ref` property. Take the following class component:\n\n```jsx\nclass Container extends React.Component {\n  render() {\n    return <div>{this.props.children}</div>;\n  }\n}\n```\n\nWhat do you think will happen if we try to pass a `ref` attribute?\n\n```jsx\nconst App = () => {\n  const compRef = React.useRef();\n\n  React.useEffect(() => {\n    console.log(compRef.current);\n  });\n\n  return (\n    <Container ref={container}>\n      <h1>Hello StackBlitz!</h1>\n      <p>Start editing to see some magic happen :)</p>\n    </Container>\n  );\n}\n```\n\n> If you\'d rather, you can also write `App` as a class component:\n>\n> ```jsx\n> class App extends React.Component {\n>   compRef = React.createRef();\n> \n>   componentDidMount() {\n>     console.log(this.compRef.current);\n>   }\n> \n>   render() {\n>     return (\n>       <Container ref={this.compRef}>\n>         <h1>Hello StackBlitz!</h1>\n>         <p>Start editing to see some magic happen :)</p>\n>       </Container>\n>     );\n>   }\n> }\n> ```\n\n<iframe src="https://stackblitz.com/edit/react-class-ref-instance?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\nIf you look at the `console.log` statement, you\'ll notice that it prints something like this:\n\n```\nContainer {props: {…}, context: {…}, refs: {…}, updater: {…}…}\ncontext: Object\nprops: Object\nrefs: Object\nstate: null\nupdater: Object\n_reactInternalInstance: Object\n_reactInternals: FiberNode\n__proto__: Container\n```\n\nYou\'ll notice that it prints out the value of a `Container` instance. In fact, if we run the following code, we can confirm that the `ref.current` value is an instance of the `Container` class:\n\n```jsx\nconsole.log(container.current instanceof Container); // true\n```\n\nHowever, what _is_ this class? Where are those props coming from? Well, if you\'re familiar with [class inheritance](https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Objects/Inheritance), it\'s the properties coming from `React.Component` that\'s being extended. If we take a look at the [TypeScript definition for the `React.Component` class](https://github.com/DefinitelyTyped/DefinitelyTyped/blob/master/types/react/index.d.ts#L436), we can see some pretty familiar properties in that class:\n\n```jsx\n// This is an incomplete and inaccurate type definition shown for educational purposes - DO NOT USE IN PROD\nclass Component {\n  render(): ReactNode;\n  context: any;\n  readonly props: Object;\n  refs: any;\n  state: Readonly<any>;\n}\n```\n\nNot only do the `refs`, `state`, `props`, and `context` line up with what we\'re seeing in our `console.log`, but methods that are part of the class (like `render`) are present as well:\n\n```jsx\nconsole.log(this.container.current.render);\n```\n\n```\nƒ render()\n```\n\n## Custom Properties and Methods {#class-ref-methods-props}\n\nNot only are React Component built-ins (like `render` and `props`) accessible from a class ref, but you can access data that you attach to that class as well. Because the `container.current` is an instance of the `Container` class, when you add custom properties and methods, they\'re visible from the ref!\n\nSo, if you change the class definition to look like this:\n\n```jsx\nclass Container extends React.Component {\n  welcomeMsg = "Hello"\n\n  sayHello() {\n    console.log("I am saying: ", this.welcomeMsg)\n  }\n\n  render() {\n    return <div>{this.props.children}</div>;\n  }\n}\n```\n\nYou can then reference the `welcomeMsg` property and `sayHello` method:\n\n```jsx\nfunction App() {\n  const container = React.useRef();\n\n  React.useEffect(() => {\n    console.log(container.current.welcomeMsg); // Hello\n    container.current.sayHello(); // I am saying: Hello\n  });\n\n  return (\n    <Container ref={container}>\n      <h1>Hello StackBlitz!</h1>\n      <p>Start editing to see some magic happen :)</p>\n    </Container>\n  );\n}\n```\n\n<iframe src="https://stackblitz.com/edit/react-class-ref-instance-custom-props?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\n# Unidirectional Flow {#unidirectional-flow}\n\nWhile the concept of "universal directional flow" is a broader subject than what I originally wanted to cover with this article, I think it\'s important to understand why you shouldn\'t utilize the pattern outlined above. One of the reasons refs are so useful is one of the reasons they\'re so dangerous as a concept: They break unidirectional data flow.\n\nTypically, in a React app, you want your data to go one way at a time.\n\n![A circle going from state, to view, to action, then back to state](./unidirectional_flow.svg)\n\nLet\'s take a look at a code sample that follows this unidirectionality:\n\n```jsx\nimport React from "react";\n\nclass SimpleForm extends React.Component {\n  render() {\n    return (\n      <div>\n        <label>\n          <div>Username</div>\n          <input\n            onChange={e => this.props.onChange(e.target.value)}\n            value={this.props.value}\n          />\n        </label>\n        <button onClick={this.props.onDone}>Submit</button>\n      </div>\n    );\n  }\n}\n\nexport default function App() {\n  const [inputTxt, setInputTxt] = React.useState("");\n  const [displayTxt, setDisplayTxt] = React.useState("");\n\n  const onDone = () => {\n    setDisplayTxt(inputTxt);\n  };\n\n  return (\n    <div>\n      <SimpleForm\n        onDone={onDone}\n        onChange={v => setInputTxt(v)}\n        value={inputTxt}\n      />\n      <p>{displayTxt}</p>\n    </div>\n  );\n}\n```\n\nIn this example, because both the `onChange` property and `value` property are being passed into the `SimpleForm` component, you\'re able to keep all of the relevant data in one place. You\'ll notice that none of the actual logic happens inside of the `SimpleForm` component itself. As such, this component is called a "dumb" component. It\'s utilized for styling and composability, but not for the logic itself.\n\nThis is what a proper React component _should_ look like. This pattern of raising state out of the component itself and leaving "dumb" component comes from the guidance of the React team itself. This pattern is called ["lifting state up"](https://reactjs.org/docs/lifting-state-up.html).\n\nNow that we have a better understanding of the patterns to follow let\'s take a look at the wrong way to do things.\n\n## Breaking from Suggested Patterns {#bidirectionality-example}\n\nDoing the inverse of "lifting state," let\'s lower that state back into the `SimpleForm` component. Then, to access that data from `App`, we can use the `ref` property to access that data from the parent.\n\n```jsx\nimport React from "react";\n\nclass SimpleForm extends React.Component {\n  // State is now a part of the SimpleForm component\n  state = {\n    input: ""\n  };\n\n  onChange(e) {\n    this.setState({\n      input: e.target.value\n    });\n  }\n\n  render() {\n    return (\n      <div>\n        <label>\n          <div>Username</div>\n          <input onChange={this.onChange.bind(this)} value={this.state.input} />\n        </label>\n        <button onClick={this.props.onDone}>Submit</button>\n      </div>\n    );\n  }\n}\n\nexport default function App() {\n  const simpleRef = React.useRef();\n  const [displayTxt, setDisplayTxt] = React.useState("");\n\n  const onDone = () => {\n    // Reach into the Ref to access the state of the component instance\n    setDisplayTxt(simpleRef.current.state.input);\n  };\n\n  return (\n    <div>\n      <SimpleForm \n        onDone={onDone} \n        ref={simpleRef} \n      />\n      <p>{displayTxt}</p>\n    </div>\n  );\n}\n```\n\nHowever, the problem is that when you look to start expanding, you\'ll find managing this dual-state behavior more difficult. Even following the application logic is more difficult. Let\'s start taking a look at what these two components\' lifecycle look like visually.\n\nFirst, let\'s start by taking a look at the `simpleRef` component, where the state is "lowered down" in the `SimpleForm` component:\n\n![Arrows pointing back and forth from App and SimpleForm to demonstrate the data going both directions](./two_way_flow.svg)\n\nIn this example, the flow of the application state is as follows:\n\n- `App` (and it\'s children, `SimpleForm`) render\n- The user makes changes to the data as stored in `SimpleForm`\n- The user triggers the `onDone` action, which triggers a function in `App`\n- The `App` `onDone` method inspects the data from `SimpleForm`\n- Once the data is returned to `App`, it changes it\'s own data, thus triggering a re-render of `App` and `SimpleForm` both\n\nAs you can see from the chart above and the outline of the data flow, you\'re keeping your data separated across two different locations. As such, the mental model to modify this code can get confusing and disjointed. This code sample gets even more complex when `onDone` is expected to change the state in `SimpleForm`.\n\nNow, let\'s contrast that to the mental model needed to work with unidirectionality enforced.\n\n![Arrows pointing in a single circular direction from App to SimpleForm to demonstrate data going one-way](./one_way_flow.svg)\n\n- `App` (and it\'s children, `SimpleForm`) render\n- The user makes changes in `SimpleForm`, the state is raised up to `App` through callbacks\n- The user triggers the `onDone` action, which triggers a function in `App`\n- The `App` `onDone` method already contains all of the data it needs in it\'s own component, so it simply re-renders `App` and `SimpleForm` without any additional logic overhead\n\nAs you can see, while the number of steps is similar between these methods (and may not be in a less trivial example), the unidirectional flow is much more streamlined and easier to follow.\n\nThis is why the React core team (and the community at large) highly suggests you use unidirectionality and rightfully shuns breaking away from that pattern when it\'s not required.\n\n# Add Data to Ref {#use-imperative-handle}\n\nIf you\'ve never heard of the `useImperativeHandle` hook before, this is why. It enables you to add methods and properties to a `ref` forwarded/passed into a component. By doing this, you\'re able to access data from the child directly within the parent, rather than forcing you to raise state up, which can break unidirectionality.\n\nLet\'s look at a component that we could extend using `useImperativeHandle`:\n\n```jsx\nimport React from "react";\nimport "./style.css";\n\nconst Container = React.forwardRef(({children}, ref) => {\n  return <div ref={ref} tabIndex="1">\n    {children}\n  </div>\n})\n\nexport default function App() {\n  const elRef = React.useRef();\n\n  React.useEffect(() => {\n    elRef.current.focus();\n  }, [elRef])\n\n  return (\n    <Container ref={elRef}>\n      <h1>Hello StackBlitz!</h1>\n      <p>Start editing to see some magic happen :)</p>\n    </Container>\n  );\n}\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-imperative-handle-demo-pre?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\nAs you can witness from the embedded demo it will focus you on the `Container` `div` when the application renders. This example does not use the `useImperativeHandle` hook but instead relies on the timing of `useEffect` to have the `ref`\'s `current` already defined.\n\nLet\'s say that we wanted to keep track of every time the `Container` `div` was focused programmatically. How would you go about doing that? There are many options to enable that functionality, but one way that wouldn\'t require any modification of `App` (or other `Container` consumers) would be to utilize `useImperativeHandle`.\n\nNot only does `useImperativeHandle` allow properties to be added to ref, but you can provide an alternative implementation of native APIs by returning a function of the same name.\n\n```jsx\nimport React from "react";\nimport "./style.css";\n\nconst Container = React.forwardRef(({children}, ref) => {\n  const divRef = React.useRef();\n\n  React.useImperativeHandle(ref, () => ({\n    focus: () => {\n      divRef.current.focus();\n      console.log("I have now focused");\n    }\n  }))\n\n  return <div ref={divRef} tabIndex="1">\n    {children}\n  </div>\n})\n\nexport default function App() {\n  const elRef = React.useRef();\n\n  React.useEffect(() => {\n    elRef.current.focus();\n  }, [elRef])\n\n  return (\n    <Container ref={elRef}>\n      <h1>Hello StackBlitz!</h1>\n      <p>Start editing to see some magic happen :)</p>\n    </Container>\n  );\n}\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-imperative-handle-demo-post?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\n> If you look in the console, you\'ll find the `console.log` has run when `focus()` ran!\n\nAs you can, `useImperativeHandle` can be used in combination with `forwardRef` to maximize the natural look-and-feel of the component\'s API.\n\nHowever, be warned that if you look to supplement the native APIs with your own, only properties and methods returned in the second param are set to ref. That means that if you now run:\n\n```jsx\n  React.useEffect(() => {\n    elRef.current.style.background = \'lightblue\';\n  }, [elRef])\n```\n\nIn `App`, you will face an error, as `style` is not defined on `elRef.current` anymore.\n\nThat said, you\'re not limited to simply the names of native APIs. What do you think this code sample in a different `App` component might do?\n\n```jsx\n  React.useEffect(() => {\n    elRef.current.konami();\n  }, [elRef])\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-imperative-handle-demo-useful?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\n> When your focus is set to the `Container` element, try typing in the ["Konami code"](https://en.wikipedia.org/wiki/Konami_Code) using your arrow keys. What does it do when that\'s done?\n\n# React Refs in `useEffect ` {#refs-in-use-effect}\n\nI have to make a confession: I\'ve been lying to you. Not maliciously, but I\'ve repeatedly used code in the previous samples that should not ever be used in production. This is because without hand-waving a bit, teaching these things can be tricky.\n\nWhat\'s the offending code?\n\n```jsx\nReact.useEffect(() => {\n  elRef.current.anything.here.is.bad();\n}, [elRef])\n```\n\n> What?\n\nThat\'s right! You shouldn\'t be placing `elRef.current` inside of any `useEffect` (unless you _really_ **really** _**really**_ know what you\'re doing).\n\n> Why\'s that?\n\nBefore we answer that fully, let\'s take a look at how `useEffect` works.\n\nAssume we have a simple component that looks like this:\n\n```jsx\nconst App = () => {\n  const [num, setNum] = React.useState(0);\n\n  React.useEffect(() => {\n    console.log("Num has ran");\n  }, [num])\n\n  return (\n    // ...\n  )\n}\n```\n\nYou might expect that when `num` updates, the dependency array "listens" for changes to `num`, and when the data updates, it will trigger the side-effect. This line of thinking is such that "useEffect actively listens for data updates and runs side effects when data is changed". This mental model is inaccurate and can be dangerous when combined with `ref` usage. Even I didn\'t realize this was wrong until I had already started writing this article!\n\nUnder non-ref (`useState`/props) dependency array tracking, this line of reasoning typically does not introduce bugs into the codebase, but when `ref`s are added, it opens a can of worms due to the misunderstanding.\n\nThe way `useEffect` _actually_ works is much more passive. During a render, `useEffect` will do a check against the values in the dependency array. If any of the values\' memory addresses have changed (_this means that object mutations are ignored_), it will run the side effect. This might seem similar to the previously outlined understanding, but it\'s a difference of "push" vs. "pull". `useEffect` does not listen to anything and does not trigger a render in itself, but instead, the render triggers `useEffect`\'s listening and comparison of values. **This means that if there is not a render, `useEffect` cannot run a side effect, even if the memory addresses in the array have changed.**\n\nWhy does this come into play when `ref`s are used? Well, there are two things to keep in mind:\n\n- Refs rely on object mutation rather than reassignment\n- When a `ref` is mutated, it does not trigger a re-render\n\n- `useEffect` only does the array check on re-render\n- Ref\'s current property set doesn\'t trigger a re-render ([remember how `useRef` is _actually_ implemented](#use-ref-mutate))\n\nKnowing this, let\'s take a look at an offending example once more:\n\n```jsx\nexport default function App() {\n  const elRef = React.useRef();\n\n  React.useEffect(() => {\n    elRef.current.style.background = "lightblue";\n  }, [elRef]);\n\n  return (\n    <div ref={elRef}>\n      <h1>Hello StackBlitz!</h1>\n      <p>Start editing to see some magic happen :)</p>\n    </div>\n  );\n}\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-effect-style?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\nThis code behaves as we might initially expect, not because we\'ve done things properly, but instead, thanks to the nature of React\'s `useEffect` hook\'s timing.\n\nBecause `useEffect` happens _after_ the first render, `elRef` is already assigned by the time `elRef.current.style` has its new value assigned to it. However, if we somehow broke that timing expectancy, we\'d see different behavior.\n\n\nWhat do you think will happen if you make the `div` render happen _after_ the initial render?\n\n```jsx\nexport default function App() {\n  const elRef = React.useRef();\n  const [shouldRender, setRender] = React.useState(false);\n\n  React.useEffect(() => {\n    if (!elRef.current) return;\n    elRef.current.style.background = \'lightblue\';\n  }, [elRef.current])\n\n  React.useEffect(() => {\n    setTimeout(() => {\n      setRender(true);\n    }, 100);\n  }, []);\n\n  return !shouldRender ? null : ( \n    <div ref={elRef}>\n      <h1>Hello StackBlitz!</h1>\n      <p>Start editing to see some magic happen :)</p>\n    </div>\n  );\n}\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-effect-bug-effect?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\nOh no! The background is no longer `\'lightblue\'`! Because we delay the rendering of the `div`, `elRef` is _not_ assigned for the initial render. Then, once it _is_ rendered, it mutates the `.current` property of `elRef` to assign the ref. Because mutations do not trigger a re-render (and `useEffect` only runs during renders), `useEffect` does not have a chance to "compare" the differences in value and, therefore, run the side-effect.\n\nConfused? That\'s okay! So was I at first. I made a playground of sorts to help us kinesthetic learners!\n\n```jsx\n  const [minus, setMinus] = React.useState(0);\n  const ref = React.useRef(0);\n\n  const addState = () => {\n    setMinus(minus + 1);\n  };\n\n  const addRef = () => {\n    ref.current = ref.current + 1;\n  };\n\n  React.useEffect(() => {\n    console.log(`ref.current:`, ref.current);\n  }, [ref.current]);\n\n  React.useEffect(() => {\n    console.log(`minus:`, minus);\n  }, [minus]);\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-not-updating?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\n> Open your console and take notes of what `console.log` runs when you change the respective values!\n\nHow do you use this example? Great question!\n\nFirst, start by clicking the button under the `useState` header. You\'ll notice that each time you click the button, it promptly triggers a re-render, and your value displayed in the UI is immediately updated. Thus, it enables the `useEffect` (with `num` as a dep) to compare the previous value to the current one - they don\'t match up - and run the `console.log` side effect.\n\nNow, once you\'ve triggered the `useState` "add" button, do the same with the `useRef` button. Click it as many times as you\'d like, but it (alone) will never trigger a re-render. Because `useRef` mutations do not re-render the DOM, neither `useEffect` is able to make a comparison of values, and therefore neither `useEffect` will run. However, the values in `.current` _are_ updating - they\'re just not showing up in the UI (because the component is not re-rendering). Once you trigger a re-render (by pressing the `useState` "add" button again), it will update the UI to match the internal memory value of `.current`.\n\n[TL;DR](https://www.dictionary.com/browse/tldr) - Try pressing `useState` "add" twice. The value on-screen will be 2. Then, try pressing the `useRef` "add" button thrice. The value on-screen will be 0. Press `useState`\'s button once again and et voilà - both values are 3 again!\n\n## Comments from Core Team {#core-team-comments}\n\nBecause of the unintended effects of tracking a `ref` in a `useEffect`, the core team has explicitly suggested avoiding doing so.\n\n[Dan Abramov Said on GitHub:](https://github.com/facebook/react/issues/14387#issuecomment-503616820)\n\n> As I mentioned earlier, if you put [ref.current] in dependencies, you\'re likely making a mistake. Refs are for values whose changes don\'t need to trigger a re-render.\n>\n> If you want to re-run effect when a ref changes, you probably want a callback ref instead.\n\n[... twice:](https://github.com/facebook/react/issues/14387#issuecomment-493677168)\n\n> When you try to put `ref.current` in dependencies, you usually want a callback ref instead\n\n[An even again on Twitter:](https://twitter.com/dan_abramov/status/1093497348913803265)\n\n> I think you want callback ref for that. You can’t have component magically react to ref changes because ref can go deep down and have independent lifecycle of the owner component.\n\nThese are great points... But what does Dan mean by a "callback ref"?\n\n# Callback Refs {#callback-refs}\n\nTowards the start of this article, we mentioned an alternative way to assign refs. Instead of:\n\n```jsx\n<div ref={elRef}>\n```\n\nThere\'s the valid (and slightly more verbose):\n\n```jsx\n<div ref={node => elRef.current = node}>\n```\n\nThis is because `ref` can accept callback functions. These functions are called with the element\'s node itself. This means that if you wanted to, you could inline the `.style` assignment we\'ve been using multiple times throughout this article:\n\n```jsx\n<div ref={node => node.style.background = "lightblue"}>\n```\n\nBut, you\'re probably thinking that if it accepts a function, we could pass a callback declared earlier in the component. That\'s correct!\n\n```jsx\n  const elRefCB = React.useCallback(node => {\n    if (node !== null) {\n      node.style.background = "lightblue";\n    }\n  }, []);\n\n  return !shouldRender ? null : (\n    <div ref={elRefCB}>\n      <h1>Hello StackBlitz!</h1>\n      <p>Start editing to see some magic happen :)</p>\n    </div>\n  );\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-callback-styling?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\n> But hey! Wait a minute! Even though the `shouldRender` timing mismatch is still there, the background is being applied all the same! Why is the `useEffect` timing mismatch not causing the bug we were experiencing before?\n\nWell, that\'s because we eliminated the usage of `useEffect` entirely in this example! Because the callback function is running only once `ref` is available, we can know for certain that `.current` _will_ be present, and because of that, we can assign property values and more inside said callback!\n\n> But I also need to pass that `ref` to other parts of the codebase! I can\'t pass the function itself; that\'s just a function - not a ref!\n\nThat\'s true. However, you _can_ combine the two behaviors to make a callback that _also_ stores its data inside a `useRef` (so you can use that reference later).\n\n```jsx\n  const elRef = React.useRef();\n\n  console.log("I am rendering");\n\n  const elRefCB = React.useCallback(node => {\n    if (node !== null) {\n      node.style.background = "lightblue";\n      elRef.current = node;\n    }\n  }, []);\n\n  React.useEffect(() => {\n    console.log(elRef.current);\n  }, [elRef, shouldRender]);\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-callback-and-effect?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\n# `useState` Refs {#usestate-refs}\n\nSometimes the combination of `useRef` and callback refs is not enough. There are the rare instances where you need to re-render whenever you get a new value in `.current.`. The problem is that the inherent nature of `.current` prevents re-rendering. How do we get around that? Eliminate `.current` entirely by switching your `useRef` out for a `useState`.\n\nYou can do this relatively trivially using callback refs to assign to a `useState` hook.\n\n```jsx\n  const [elRef, setElRef] = React.useState();\n\n  console.log(\'I am rendering\');\n\n  const elRefCB = React.useCallback(node => {\n    if (node !== null) {\n      setElRef(node);\n    }\n  }, []);\n\n  React.useEffect(() => {\n    console.log(elRef);\n  }, [elRef])\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-callback-and-use-state?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\nNow that the `ref` update causes a re-render, you can now _**safely**_ use the `ref` in `useEffect`\'s dependency array.\n\n```jsx\n const [elNode, setElNode] = React.useState();\n\n  const elRefCB = React.useCallback(node => {\n    if (node !== null) {\n      setElNode(node);\n    }\n  }, []);\n\n  React.useEffect(() => {\n    if (!elNode) return;\n    elNode.style.background = \'lightblue\';\n  }, [elNode])\n```\n\n<iframe src="https://stackblitz.com/edit/react-use-ref-callback-and-state-effect?ctl=1&embed=1" sandbox="allow-modals allow-forms allow-popups allow-scripts allow-same-origin"></iframe>\n\nHowever, this comes at an offset cost of performance. Because you\'re causing a re-render, it will inherently be slower than if you were not triggering a re-render. There are valid uses for this, however. You just have to be mindful of your decisions and your code\'s usage of them.\n\n# Conclusion\n\nAs with most engineering work, knowing an API\'s limitations, strengths, and workarounds can increase performance, cause fewer bugs in production, and make the organization of code more readily available. Now that you know the whole story surrounding refs, what will you do with that knowledge? We\'d love to hear from you! Drop a comment down below or [join us in our community Discord](https://discord.gg/FMcvc6T)!\n',
		},
		{
			title: "Rules of React's useEffect",
			description:
				"useEffect is prolific in React apps. Here are four rules associated with the hook and in-depth explanations of why they're important.",
			published: "2022-02-22T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["react", "javascript"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/development/rules-of-reacts-useeffect/",
			slug: "rules-of-reacts-useeffect",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Rules of React's useEffect",
				description:
					"useEffect is prolific in React apps. Here are four rules associated with the hook and in-depth explanations of why they're important.",
				published: "2022-02-22T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["react", "javascript"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/development/rules-of-reacts-useeffect/",
			},
			contentMeta:
				'\r\nReact’s `useEffect` is a powerful API with lots of capabilities, and therefore flexibility. Unfortunately, this flexibility often leads to abuse and misuse, which can greatly damage an app’s stability. \r\n\r\nThe good news is that if you follow a set of rules designated to protect you during coding, your application can be secure and performant.\r\n\r\nNo, we’re not talking about React’s “[Rules of Hooks](https://reactjs.org/docs/hooks-rules.html)”, which includes rules such as:\r\n\r\n- No conditionally calling hooks\r\n- Only calling hooks inside of hooks or component\r\n- Always having items inside of the dependency array\r\n\r\nThese rules are good, but can be detected automatically with linting rules. It\'s good that they\'re there (and maintained by Meta), but overall, we can pretend like everyone has them fixed because their IDE should throw a warning.\r\n\r\nSpecifically, I want to talk about the rules that can only be caught during manual code review processes:\r\n\r\n- Keep all side effects inside `useEffect`\r\n- Properly clean up side effects\r\n- Don\'t use `ref` in `useEffect`\r\n- Don\'t use `[]` as a guarantee that something only happens once\r\n\r\nWhile these rules may seem obvious at first, we\'ll be taking a deep dive into the "why" of each. As a result, you may learn something about how React works under the hood - even if you\'re a React pro.\r\n\r\n## Keep all side effects inside `useEffect`\r\n\r\nFor anyone familiar with React’s docs, you’ll know that this rule has been repeated over and over again. But why? Why is this a rule?\r\n\r\nAfter all, what would prevent you from storing logic inside of a `useMemo` and simply having an empty dependency array to prevent it from running more than once?\r\n\r\nLet’s try that out by running a network request inside of a `useMemo`:\r\n\r\n```jsx\r\nconst EffectComp = () => {\r\n  const [activity, setActivity] = React.useState(null);\r\n\r\n  const effectFn = React.useMemo(() => {\r\n    // Make a network request here\r\n    fetch("https://www.boredapi.com/api/activity")\r\n      .then(res => res.json())\r\n      .then(res => setActivity(res.activity));\r\n  }, [])\r\n\r\n  return <p>{activity}</p>\r\n}\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=205251" loading="lazy"></iframe>\r\n\r\nHuh. It works first try without any immediately noticeable downsides. This works because `fetch` is asynchronous, meaning that it doesn’t block the [event loop](https://www.youtube.com/watch?v=8aGhZQkoFbQ&vl=en). Instead, let’s change that code to be a synchronous `XHR` request and see if that works too.\r\n\r\n```\r\nfunction getActivity() {\r\n  var request = new XMLHttpRequest();\r\n  request.open(\'GET\', \'https://www.boredapi.com/api/activity\', false);  // `false` makes the request synchronous\r\n  request.send(null);\r\n\r\n  return JSON.parse(request.responseText);\r\n}\r\n\r\nconst EffectComp = () => {\r\n  const [data, setData] = React.useState(null);\r\n\r\n  const effectFn = React.useMemo(() => {\r\n    setData(getActivity().activity);\r\n  }, []);\r\n\r\n  return <p>Hello, world! {data}</p>;\r\n}\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=205252" loading="lazy"></iframe>\r\n\r\nHere, we can see behavior that we might not expect to see. When using useMemo alongside a blocking method, the entire screen will halt before drawing anything. The initial paint is then made after the fetch is finally finished.\r\n\r\n<video src="./useMemoRendering.mp4"></video>\r\n\r\nHowever, if we use useEffect instead, this does not occur.\r\n\r\n<video src="./useEffectRendering.mp4"></video>\r\n\r\nHere, we can see the initial paint occur, drawing the “Hello” message before the blocking network call is made.\r\n\r\nWhy does this happen?\r\n\r\n### Understanding hook lifecycles\r\n\r\nThe reason `useEffect` is still able to paint but useMemo cannot is because of the timings of each of these hooks. You can think of `useMemo` as occurring right in line with the rest of your render code.\r\n\r\nIn terms of timings, the two pieces of code are very similar:\r\n\r\n```jsx\r\nconst EffectComp = () => {\r\n  const [data, setData] = React.useState(null);\r\n\r\n  const effectFn = React.useMemo(() => {\r\n    setData(getActivity().activity);\r\n  }, []);\r\n\r\n  return <p>Hello, world! {data}</p>;\r\n}\r\nconst EffectComp = () => {\r\n  const [data, setData] = React.useState(null);\r\n\r\n  setData(getActivity().activity);\r\n\r\n  return <p>Hello, world! {data}</p>;\r\n}\r\n```\r\n\r\nThis inlining behavior occurs because `useMemo` runs during the “render” phase of a component. `useEffect`, on the other hand, runs **after** a component renders out, which allows an initial render before the blocking behavior halts things for us.\r\n\r\nThose among you that know of “useLayoutEffect” may think you have found a gotcha in what I just said.\r\n\r\n“Ahh, but wouldn’t useLayoutEffect also prevent the browser from drawing until the network call is completed?”\r\n\r\nNot quite! You see, while useMemo runs during the render phase, useLayoutEffect runs during the “*commit”* phase and therefore renders the initial contents to screen first.\r\n\r\n> [useLayoutEffect’s signature is identical to useEffect, but it fires synchronously after all DOM mutations.](https://reactjs.org/docs/hooks-reference.html#uselayouteffect)\r\n\r\nSee, the commit phase is the part of a component’s lifecycle *after* React is done asking all the components what they want the UI to look like, has done all the diffing, and is ready to update the DOM.\r\n\r\n![img](./hooks_lifecycle.png)\r\n\r\n> If you’d like to learn more about how React does its UI diffing and what this process all looks like under the hood, take a look at [Dan Abramov’s wonderful “React as a UI Runtime” post](https://overreacted.io/react-as-a-ui-runtime/).\r\n>\r\n> There’s also [this awesome chart demonstrating how all of the hooks tie in together](https://github.com/Wavez/react-hooks-lifecycle) that our chart is a simplified version of.\r\n\r\nNow, this isn’t to say that you should optimize your code to work effectively with blocking network calls. After all, while `useEffect` allows you to render your code, a blocking network request still puts you in the uncomfortable position of your user being unable to interact with your page.\r\n\r\nBecause JavaScript is single-threaded, a blocking function will prevent user interaction from being processed in the event loop.\r\n\r\n> If you read the last sentence and are scratching your head, you’re not alone. The idea of JavaScript being single-threaded, what an “event loop” is, and what “blocking” means are all quite confusing at first.\r\n>\r\n> We suggest taking a look at [this great explainer talk from Philip Robers](https://www.youtube.com/watch?v=8aGhZQkoFbQ) to understand more.\r\n\r\nThat said, this isn’t the only scenario where the differences between `useMemo` and `useEffect` cause misbehavior with side effects. Effectively, they’re two different tools with different usages and attempting to merge them often breaks things.\r\n\r\nAttempting to use `useMemo` in place of `useEffect` leads to scenarios that can introduce bugs, and it may not be obvious what’s going wrong at first. After long enough, with enough of these floating about in your application, it’s sort of “death by a thousand paper-cuts”.\r\n\r\nThese papercuts aren\'t the only problem, however. After all, the APIs for useEffect and useMemo are not the same. This incongruity between APIs is especially pronounced for network requests because a key feature is missing from the `useMemo` API: effect cleanup.\r\n\r\n## Always clean up your side effects\r\n\r\nOccasionally, when using `useEffect`, you may be left with something that requires cleanup. A classic example of this might be a network call.\r\n\r\nSay you have an application to give bored users an activity to do at home. Let’s use a network request that retrieves an activity from an API:\r\n\r\n```jsx\r\nconst EffectComp = () => {\r\n  const [activity, setActivity] = React.useState(null);\r\n\r\n  React.useEffect(() => {\r\n    fetch("https://www.boredapi.com/api/activity")\r\n      .then(res => res.json())\r\n      .then(res => setActivity(res.activity));\r\n  }, [])\r\n\r\n  return <p>{activity}</p>\r\n}\r\n```\r\n\r\nWhile this works for a single activity, what happens when the user completes the activity? \r\n\r\nLet’s give them a button to rotate between new activities and include a count of how many times the user has requested an activity.\r\n\r\n```jsx\r\nconst EffectComp = () => {\r\n  const [activity, setActivity] = React.useState(null);\r\n  const [num, setNum] = React.useState(1);\r\n\r\n  React.useEffect(() => {\r\n    // Make a network request here\r\n    fetch("https://www.boredapi.com/api/activity")\r\n      .then(res => res.json())\r\n      .then(res => setActivity(res.activity));\r\n    // Re-run this effect when `num` is updated during render\r\n  }, [num])\r\n\r\n  return (\r\n  <div>\r\n    <p>You should: {activity}</p>\r\n    <p>You have done {num} activities</p>\r\n    <button onClick={() => setNum(num + 1)}>Request new activity</button> \r\n  </div>\r\n  )\r\n}\r\n```\r\n\r\nJust as we intended, we get a new network activity if we press the button. We can even press the button multiple times to get a new activity per press.\r\n\r\nBut wait, what happens if we slow down our network speed and press the “request” button rapidly?\r\n\r\n<video src="./before_signal.mp4"></video>\r\n\r\nOh no! Even tho we’ve stopped clicking the button, our network requests are still coming in. This gives us a sluggish feeling experience, especially when latency times between network calls are high.\r\n\r\nWell, this is where our cleanup would come into effect. Let’s add an [AbortSignal](https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal) to cancel a request when we request a new one.\r\n\r\n```jsx\r\nconst EffectComp = () => {\r\n  const [activity, setActivity] = React.useState(null);\r\n  const [num, setNum] = React.useState(1);\r\n\r\n  React.useEffect(() => {\r\n    const controller = new AbortController();\r\n    const signal = controller.signal;\r\n\r\n    // Make a network request here\r\n    fetch("https://www.boredapi.com/api/activity", {signal})\r\n      .then(res => res.json())\r\n      .then(res => setActivity(res.activity));\r\n   \r\n    return () => {\r\n      controller.abort();\r\n    }\r\n    // Re-run this effect when `num` is updated during render\r\n  }, [num])\r\n\r\n  return (\r\n  <div>\r\n    <p>You should: {activity}</p>\r\n    <p>You have done {num} activities</p>\r\n    <button onClick={() => setNum(num + 1)}>Request new activity</button> \r\n  </div>\r\n  )\r\n}\r\n```\r\n\r\nIf we open our network request tab, you’ll notice how our network calls are now being canceled when we initialize a new one. \r\n\r\n![img](./cancelled_request.png)\r\n\r\nThis is a good thing! It means that instead of a jarring experience of jumpiness, you’ll now only see a single activity after the end of a chain of clicking.\r\n\r\n<video src="./after_signal.mp4"></video>\r\n\r\nWhile this may seem like a one-off that we created ourselves using artificial network slowdowns, this is the real-world experience users on slow networks may experience!\r\n\r\nWhat’s more, when you consider API timing differences, this problem may be even more widespread.\r\n\r\nLet’s say that you’re using a [new React concurrent feature](https://coderpad.io/blog/why-react-18-broke-your-app/), which may cause an interrupted render, forcing a new network call before the other has finished.\r\n\r\nThe first call hangs on the server for slightly longer for whatever reason and takes 500ms, but the second call goes through immediately in 20ms. But oh no, during that 480ms there was a change in the data!\r\n\r\n![img](./manual_waterfall.png)\r\n\r\nThis means that our `.then` which runs `setActivity` will execute on the first network call – complete with stale data (showing “10,000”) – **after** the second network call.\r\n\r\nThis is important to catch early, because these shifts in behavior can be immediately noticeable to a user when it happens. These issues are also often particularly difficult to find and work through after the fact.\r\n\r\n## Don’t use refs in useEffect\r\n\r\nIf you’ve ever used a useEffect to apply an `addEventListener`, you may have written something like the following:\r\n\r\n```jsx\r\nconst RefEffectComp = () => {\r\n  const buttonRef = React.useRef();\r\n\r\n  const [count, setCount] = React.useState(0);\r\n\r\n  React.useEffect(() => {\r\n    function buttonAdder() {\r\n        setCount(v => v + 1);\r\n    }\r\n   \r\n    buttonRef.current.addEventListener(\'click\', buttonAdder);\r\n   \r\n    return () => {\r\n        buttonRef.current.removeEventListener(\'click\', buttonAdder);    \r\n    }\r\n  }, [buttonRef.current])\r\n\r\n  return <div>\r\n    <p>{count}</p>\r\n    <button ref={buttonRef}>Click me</button>\r\n  </div>\r\n}\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=205242" loading="lazy"></iframe>\r\n\r\n<video src="./button_incrementing.mp4"></video>\r\n\r\nWhile this might make intuitive sense due to utilizing `useEffect`’s cleanup, this code is actually not correct. You should not utilize a `ref` or `ref.current` inside of a dependency array for a hook.\r\n\r\nThis is because **changing refs does not force a re-render and therefore useEffect never runs when the value changes.**\r\n\r\nWhile most assume that `useEffect` “listens” for changes in this array and runs the effect when it changes, this is an inaccurate mental model.\r\n\r\nA more apt mental model might be: “useEffect only runs at most once per render. However, as an optimization, I can pass an array to prevent the side effect from running if the variable references inside of the array have not changed.”\r\n\r\nThis shift in understanding is important because the first version can easily lead to bugs in your app. For example, instead of rendering out the button immediately, let’s say that we need to defer the rendering for some reason.\r\n\r\nSimple enough, we’ll add a `setTimeout` and a boolean to render the button.\r\n\r\n```jsx\r\nconst RefEffectComp = ()=>{\r\n  const buttonRef = React.useRef();\r\n\r\n  const [count, setCount] = React.useState(0);\r\n\r\n  React.useEffect(() => {\r\n    function buttonAdder() {\r\n      setCount(v => v + 1);\r\n    }\r\n          console.log(\'UseEffect has run\');\r\n          // This will throw an error during the first render otherwise\r\n    if (!buttonRef.current) return;\r\n   \r\n    buttonRef.current.addEventListener(\'click\', buttonAdder);\r\n   \r\n    return () => {\r\n      buttonRef.current.removeEventListener(\'click\', buttonAdder);    \r\n    }\r\n  }, [buttonRef.current])\r\n\r\n   \r\n  const [shouldRender, setShouldRender] = React.useState(false);\r\n\r\n  React.useEffect(() => {\r\n    const timer = setTimeout(() => {\r\n      setShouldRender(true);\r\n    }, 1000);\r\n   \r\n    return () => {\r\n      clearTimeout(timer);\r\n      setShouldRender(false);\r\n    }\r\n  }, []);\r\n\r\n\r\n  return <div>\r\n    <p>{count}</p>\r\n    {shouldRender && <button ref={buttonRef}>Click me</button>}\r\n  </div>\r\n}\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=205243" loading="lazy"></iframe>\r\n\r\nNow, if we wait a second for the button to render and click it, our counter doesn’t go up!\r\n\r\n<video src="./button_not_incrementing.mp4"></video>\r\n\r\nThis is because once our `ref` is set after the initial render, it doesn’t trigger a re-render and our `useEffect` never runs.\r\n\r\nA better way to write this would be to utilize a [“callback ref”](https://unicorn-utterances.com/posts/react-refs-complete-story#callback-refs), and then use a `useState` to force a re-render when it’s set.\r\n\r\n```jsx\r\nconst RefEffectComp = ()=>{\r\n  const [buttonEl, setButtonEl] = React.useState();\r\n\r\n  const [count, setCount] = React.useState(0);\r\n\r\n  React.useEffect(() => {\r\n    function buttonAdder() {\r\n      setCount(v => v + 1);\r\n    }\r\n   \r\n    if (!buttonEl) return;\r\n   \r\n    buttonEl.addEventListener(\'click\', buttonAdder);\r\n   \r\n    return () => {\r\n      buttonEl.removeEventListener(\'click\', buttonAdder);    \r\n    }\r\n  }, [buttonEl])\r\n\r\n   \r\n  const [shouldRender, setShouldRender] = React.useState(false);\r\n\r\n  React.useEffect(() => {\r\n    const timer = setTimeout(() => {\r\n      setShouldRender(true);\r\n    }, 1000);\r\n   \r\n    return () => {\r\n      clearTimeout(timer);\r\n      setShouldRender(false);\r\n    }\r\n  }, []);\r\n\r\n\r\n  return <div>\r\n    <p>{count}</p>\r\n    {shouldRender && <button ref={buttonElRef => setButtonEl(buttonElRef)}>Click me</button>}\r\n  </div>\r\n}\r\n```\r\n\r\nThis will force the re-render when `ref` is set after the initial render and, in turn, cause the `useEffect` to trigger as expected.\r\n\r\nTo be fair, this “rule” is more of a soft rule than anything. There are absolutely instances - such as setTimeout timers - where utilizing a ref inside of a useEffect make sense. Just make sure you have a proper mental model about refs and useEffect and you’ll be fine. \r\n\r\n> Want to refine your understanding of refs even further? [See my article outlining the important details of refs for more.](https://unicorn-utterances.com/posts/react-refs-complete-story)\r\n\r\n## Don’t expect an empty dependency array to only run once\r\n\r\nWhile previous versions of React allowed you to utilize an empty array to guarantee that a `useEffect` would only run once, [React 18 changed this behavior](https://coderpad.io/blog/why-react-18-broke-your-app/). As a result, now `useEffect` may run any number of times when an empty dependency array passes, in particular when a [concurrent feature is utilized](https://github.com/reactwg/react-18/discussions/46#discussioncomment-846786).\r\n\r\nConcurrent features are new to React 18 and allow React to pause, halt, and remount a component whenever React sees it appropriate.\r\n\r\nAs a result, this may break various aspects of your code.\r\n\r\nYou can [read more about how an empty dependency array can break in your app from our article about React 18’s changes to mounting.](https://coderpad.io/blog/why-react-18-broke-your-app/)\r\n\r\n## Conclusion\r\n\r\nReact’s useEffect is an instrumental part of modern React applications. Now that you know more about its internals and the rules around it, you can build stronger and more dynamic programs!\r\n\r\nIf you want to continue learning skills that will help make your React apps better, I suggest taking a look at [our guide to React Unidirectionality](https://coderpad.io/blog/master-react-unidirectional-data-flow/), which outlines a good way to keep your application flow more organized.',
		},
		{
			title: "Rust Enums, Matching, & Options API",
			description:
				"Rust allows you to build super-fast and flexible applications. Let's build one leveraging enums, pattern matching, and the Options API.",
			published: "2021-04-16T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["rust"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink: "https://coderpad.io/blog/rust-enums-matching-options-api/",
			slug: "rust-enums-matching-options-api",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Rust Enums, Matching, & Options API",
				description:
					"Rust allows you to build super-fast and flexible applications. Let's build one leveraging enums, pattern matching, and the Options API.",
				published: "2021-04-16T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["rust"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/rust-enums-matching-options-api/",
			},
			contentMeta:
				'\nIf you’ve been active in the programming community within the past few years, you’ve undoubtedly heard of [Rust](https://www.rust-lang.org/). Its technical foundation and vibrant community have proven themselves to be a good benchmark for quick language growth.\n\nBut what does Rust do that has garnered such a positive response from the community? Not only does Rust provide a great deal of memory safety (something that’s rare in low-level languages in the past), but also includes powerful features that make development much nicer.\n\nOne of the many features that highlights Rust’s capabilities is its handling of enums and matching.\n\n# Enums\n\nLike many languages with strict typings, Rust [has an enum feature](https://doc.rust-lang.org/book/ch06-01-defining-an-enum.html). To declare an enum is simple enough, start with `pub enum` and name the values.\n\n```rust\npub enum CodeLang {\n    Rust,\n    JavaScript,\n    Swift,\n    Kotlin,\n    // ...\n}\n```\n\nTo create a variable with the type of that enum, you can use the name of the enum with the value:\n\n```rust\nfn main() {\n   let lang = CodeLang::Rust;\n}\n```\n\nLikewise, you can use the `enum` as a type in places like function params. Let’s say that you want to detect which version of a programming language supported in CoderPad. We’ll start by hard-coding the version of Rust:\n\n```rust\nfn get_version(_lang: CodeLang) -> &\'static str {\n   return "1.46";\n}\n```\n\nWhile this code *works*, it’s not very functional. If you pass in “CodeLang::JavaScript”, the version number isn’t correct. Let’s take a look at how we can fix that in the next section.\n\n# Matching\n\nWhile you *could* use `if` statements to detect which enum is passed in, like so:\n\n```rust\nfn get_version(lang: CodeLang) -> &\'static str {\n    if let CodeLang::Rust = lang {\n        return "1.46";\n    }\n    \n    if let CodeLang::JavaScript = lang {\n        return "2021";\n    }\n    \n    return ""\n}\n\nfn main() {\n    let lang = CodeLang::Rust;\n\n    let ver = get_version(lang);\n\n    println!("Version {}", ver);\n}\n```\n\nThis easily becomes unwieldy when dealing with more than one or two values in the enum. This is where Rust’s `match` operator comes into play. Let’s match the variable with all of the existing values in the enum:\n\n```rust\nfn get_version(lang: CodeLang) -> &\'static str {\n   match lang {\n       CodeLang::Rust => "1.46",\n       CodeLang::JavaScript => "2021",\n       CodeLang::Swift => "5.3",\n       CodeLang::Python => "3.8"\n   }\n}\n```\n\nIf you’re familiar with a programming language that has a feature similar to “[switch/case](https://www.tutorialspoint.com/cprogramming/switch_statement_in_c.htm)”, this example is a close approximation of that functionality. However, as you’ll soon see, `match` in Rust is significantly more powerful than most implementations of switch/case.\n\n# Pattern Matching\n\nWhile most implementations of `switch/case` only allow simple primitives matching, such as strings or numbers, Rust’s `match` allows you to have more granular control over what is matched and how. For example, you can match anything that isn’t matched otherwise using the `_` identifier:\n\n```rust\nfn get_version(lang: CodeLang) -> &\'static str {\n   match lang {\n       CodeLang::Rust => "1.46",\n       _ => "Unknown version"\n   }\n}\n```\n\nYou are also able to match more than a single value at a time. In this example, we’re doing a check on versions for more than one programming language at a time.\n\n```rust\nfn get_version<\'a>(lang: CodeLang, other_lang: CodeLang) -> (&\'a str, &\'a str) {\n   match (lang, other_lang) {\n       (CodeLang::Rust, CodeLang::Python) => ("1.46", "3.8"),\n       _ => ("Unknown", "Unknown")\n   }\n}\n```\n\nThis shows some of the power of `match` . However, there’s more that you’re able to do with enums.\n\n# Value Storage\n\nNot only are enums values within themselves, but you can also store values within enums to be accessed later.\n\nFor example, CoderPad supports two different versions of Python. However, instead of creating a `CodeLang::Python` and `CoderLang::Python2` enum values, we can use one value and store the major version within.\n\n```rust\npub enum CodeLang {\n   Rust,\n   JavaScript,\n   Swift,\n   Python(u8),\n   // ...\n}\n\nfn main() {\n   let python2 = CodeLang::Python(2);\n\n   let pythonVer = get_version(python2);\n}\n```\n\n\nWe’re able to expand our `if let` expression from before to access the value within:\n\n```rust\nif let CodeLang::Python(ver) = python2 {\n    println!("Python version is {}", ver);\n}\n```\n\nHowever, just as before, we’re able to leverage `match` to unpack the value within the enum:\n\n```rust\nfn get_version(lang: CodeLang) -> &\'static str {\n   match lang {\n       CodeLang::Rust => "1.46",\n       CodeLang::JavaScript => "2021",\n       CodeLang::Python(ver) => {\n           if ver == 3 { "3.8" } else { "2.7" }\n       },\n        _ => "Unknown"\n   }\n}\n```\n\nNot all enums need to be manually set, however! Rust has some enums built-in to the language, ready for use.\n\n# Option Enum\n\nWhile we’re currently returning the string `”Unknown”` as a version, that’s not ideal. Namely, we’d have to do a string comparison to check if we’re returning a known version or not, rather than having a value dedicated to a lack of value.\n\nThis is where Rust’s `Option` enum comes into play. `Option<T>` describes a data type that either has `Some(data)` or `None` to speak of.\n\nFor example, we can rewrite the above function to:\n\n```rust\nfn get_version<\'a>(lang: CodeLang) -> Option<&\'a str> {\n   match lang {\n       CodeLang::Rust => Some("1.46"),\n       CodeLang::JavaScript => Some("2021"),\n       CodeLang::Python(ver) => {\n           if ver == 3 { Some("3.8") } else { Some("2.7") }\n       },\n        _ => None\n   }\n}\n```\n\nBy doing this, we can make our logic more representative and check if a value is `None` \n\n```rust\nfn main() {\n    let swift_version = get_version(CodeLang::Swift);\n\n    if let None = swift_version {\n        println!("We could not find a valid version of your tool");\n        return;\n    }\n}\n```\n\nFinally, we can of course use `match` to migrate from an `if` to check when values are set:\n\n```rust\nfn main() {\n    let code_version = get_version(CodeLang::Rust);\n\n    match code_version {\n        Some(val) => {\n            println!("Your version is {}", val);\n        },\n        None => {\n            println!("We could not find a valid version of your tool");\n            return;\n        }\n    }\n}\n```\n\n# Operators\n\nWhile the above code functions as intended, if we add more conditional logic, we may find ourselves wanting to make abstractions. Let’s look at some of these abstractions Rust provides for us\n\n## Map Operator\n\nWhat if we wanted to convert `rust_version` to a string, but wanted to handle edge-cases where `None` was present.\n\nYou might write something like this:\n\n```rust\nfn main() {\n    let rust_version = get_version(CodeLang::Rust);\n\n    let version_str = match rust_version {\n        Some(val) => {\n            Some(format!("Your version is {}", val))\n        },\n        None => None\n    };\n    \n    if let Some(val) = version_str {\n        println!("{}", val);\n        return;\n    }\n}\n```\n\nThis `match` of taking `Some` and mapping it to a new value and leaving `None` s to resolve as `None` still is baked into the Option enum as a method called `.map` :\n\n```rust\nfn main() {\n    let rust_version = get_version(CodeLang::Rust);\n\n    let version_str = rust_version.map(|val| {\n      format!("Your version is {}", val)\n    });\n    \n    if let Some(val) = version_str {\n        println!("{}", val);\n        return;\n    }\n}\n```\n\nHow close is the implementation of `.map` to what we were doing before? Let’s take a look at [Rust’s source code implementation of `.map` ](https://github.com/rust-lang/rust/blob/8dc0ae24bcafeb52259ae20fcad29185acf31fcc/library/core/src/option.rs#L485-L490):\n\n```rust\npub fn map<U, F: FnOnce(T) -> U>(self, f: F) -> Option<U> {\n   match self {\n       Some(x) => Some(f(x)),\n       None => None,\n   }\n}\n```\n\nAs you can see, we matched our implementation very similarly, matching `Some` to another `Some` and `None` to another `None` \n\n## And Then Operator\n\nWhile the automatic wrapping of the `.map` function return value into a `Some` can be useful in most instances, there may be times where you want to conditionally make something inside the `map`\n\nLet’s say that we only want version numbers that contain a dot (indicating there’s a minor version). We could do something like this:\n\n```rust\nfn main() {\n    let rust_version = get_version(CodeLang::JavaScript);\n\n    let version_str = match rust_version {\n        Some(val) => {\n            if val.contains(".") {\n                Some(format!("Your version is {}", val))\n            } else {\n                None\n            }\n        },\n        None => None\n    };\n    \n    if let Some(val) = version_str {\n        println!("{}", val);\n        return;\n    }\n}\n```\n\nWhich we can rewrite using Rust’s `and_then` operator:\n\n```rust\nfn main() {\n    let rust_version = get_version(CodeLang::JavaScript);\n\n    let version_str = rust_version.and_then(|val| {\n        if val.contains(".") {\n            Some(format!("Your version is {}", val))\n        } else {\n            None\n        }\n    });\n    \n    if let Some(val) = version_str {\n        println!("{}", val);\n        return;\n    }\n}\n```\n\nIf we look at [Rust’s source code for the operator](https://github.com/rust-lang/rust/blob/8dc0ae24bcafeb52259ae20fcad29185acf31fcc/library/core/src/option.rs#L722-L727), we can see the similarity to the `.map` implementation, simply without wrapping `fn` in `Some` :\n\n```rust\npub fn and_then<U, F: FnOnce(T) -> Option<U>>(self, f: F) -> Option<U> {\n        match self {\n            Some(x) => f(x),\n            None => None,\n        }\n    }\n```\n\n# Putting it Together\n\nNow that we’re familiar with the Option enum, operators, and pattern matching let’s put it all together!\n\nLet’s start with the same `get_version` function baseline we’ve been using for a few examples:\n\n```rust\nuse regex::Regex;\n\npub enum CodeLang {\n   Rust,\n   JavaScript,\n   Swift,\n   Python(u8),\n   // ...\n}\n\nfn get_version<\'a>(lang: CodeLang) -> Option<&\'a str> {\n   match lang {\n       CodeLang::Rust => Some("1.46"),\n       CodeLang::JavaScript => Some("2021"),\n       CodeLang::Python(ver) => {\n           if ver == 3 { Some("3.8") } else { Some("2.7") }\n       },\n        _ => None\n   }\n}\n\nfn main() {\n    let lang = CodeLang::JavaScript;\n\n    let lang_version = get_version(lang);\n}\n```\n\nGiven this baseline, let’s build a semver checker. Given a coding language, tell us what the major and minor versions of that language are.\n\nFor example, Rust (1.46) would return “**Major: 1. Minor: 46**”, while JavaScript (2021) would return **“Major: 2021. Minor: 0**”\n\nWe’ll do this check using a Regex that parses any dots in the version string.\n\n```\n(\\d+)(?:\\.(\\d+))?\n```\n\nThis regex will match the first capture group as anything before the first period, then optionally provide a second capture if there is a period, matching anything after that period. Let’s add that Regex and the captures in our `main` function:\n\n```rust\nlet version_regex = Regex::new(r"(\\d+)(?:\\.(\\d+))?").unwrap();\n\nlet version_matches = lang_version.and_then(|version_str| {\n    return version_regex.captures(version_str);\n});\n```\n\nIn the code sample above, we’re using `and_then` in order to flatten `captures` into a single-layer `Option` enum - seeing as `lang_version` is an Option itself and `captures` returns an Option as well.\n\nWhile `.captures` sounds like it should return an array of the capture strings, in reality it returns [a structure with various methods and properties](https://docs.rs/regex/1.1.9/regex/struct.Captures.html). To get the strings for each of these values, we’ll use `version_matches.map` to get both of these capture group strings:\n\n```rust\nlet major_minor_captures = version_matches\n        .map(|caps| {\n            (\n                caps.get(1).map(|m| m.as_str()),\n                caps.get(2).map(|m| m.as_str()),\n            )\n        });\n```\n\nWhile we’d expect capture group 1 to always provide a value (given our input), we’d see “None” returned in capture group 2 if there’s no period (like with JavaScript’s version number of “2021”). Because of this, there are instances where `caps.get(2)` may be `None` . As such, we want to make sure to get a `0` in the place of `None` and convert the `Some<&str>, Option<&str>` into `Some<&str, &str>` . To do this, we’ll use `and_then` and a `match` :\n\n```rust\nlet major_minor = major_minor_captures\n    .and_then(|(first_opt, second_opt)| {\n        match (first_opt, second_opt) {\n            (Some(major), Some(minor)) => Some((major, minor)),\n            (Some(major), None) => Some((major, "0")),\n            _ => None,\n        }\n    });\n```\n\nFinally, we can use an `if let` to deconstruct the values and print the major and minor versions:\n\n```rust\nif let Some((first, second)) = major_minor {\n    println!("Major: {}. Minor: {}", first, second);\n}\n```\n\nThe final version of the project should look something like this:\n\n```rust\nuse regex::Regex;\n\npub enum CodeLang {\n   Rust,\n   JavaScript,\n   Swift,\n   Python(u8),\n   // ...\n}\n\nfn get_version<\'a>(lang: CodeLang) -> Option<&\'a str> {\n   match lang {\n       CodeLang::Rust => Some("1.46"),\n       CodeLang::JavaScript => Some("2021"),\n       CodeLang::Python(ver) => {\n           if ver == 3 { Some("3.8") } else { Some("2.7") }\n       },\n        _ => None\n   }\n}\n\nfn main() {\n    let lang = CodeLang::JavaScript;\n\n    let lang_version = get_version(lang);\n\n    let version_regex = Regex::new(r"(\\d+)(?:\\.(\\d+))?").unwrap();\n\n    let version_matches = lang_version.and_then(|version_str| {\n        return version_regex.captures(version_str);\n    });\n    \n    let major_minor_captures = version_matches\n        .map(|caps| {\n            (\n                caps.get(1).map(|m| m.as_str()),\n                caps.get(2).map(|m| m.as_str()),\n            )\n        });\n\n\n    let major_minor = major_minor_captures\n        .and_then(|(first_opt, second_opt)| {\n            match (first_opt, second_opt) {\n                (Some(major), Some(minor)) => Some((major, minor)),\n                (Some(major), None) => Some((major, "0")),\n                _ => None,\n            }\n        });\n\n\n    if let Some((first, second)) = major_minor {\n        println!("Major: {}. Minor: {}", first, second);\n    }\n}\n```\n\n# Conclusion & Challenge\n\nAll of these features are used regularly in Rust applications: enums, matching, option operators. We hope that you can take these features and utilize them in your applications along your journey to learn Rust.\n\nLet’s close with a challenge. If you get stuck anywhere along the way or have comments/questions about this article, you can join our[ public chat community where we talk about general coding topics as well as interviewing](http://bit.ly/coderpad-slack).\n\n\nLet’s say that we have the “patch” version of a software tracked. We want to expand the logic of our code to support checking “5.1.2” and return “2” as the “patch” version. Given the modified regex to support three optional capture groups:\n\n```\n(\\d+)(?:\\.(\\d+))?(?:\\.(\\d+))?\n```\n\nHow can you modify the code below to support the match version being listed out properly?\n\n<iframe src="https://app.coderpad.io/sandbox?question_id=175664" loading="lazy"></iframe>\n\nYou’ll know the code is working when you’re able to output the following:\n\n```\nMajor: 2021. Minor: 0, Patch: 0\nMajor: 1. Minor: 46, Patch: 0\nMajor: 5. Minor: 1, Patch: 2\n```\n',
		},
		{
			title:
				"Autogenerate Changelogs and Manage Releases using Conventional Commit",
			description:
				"Whether creating changelogs or just keeping track of git tags, releases matter. Learn how to automate your release process with conventional-commits!",
			published: "2020-06-23T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["npm", "javascript"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "setup-standard-version",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title:
					"Autogenerate Changelogs and Manage Releases using Conventional Commit",
				description:
					"Whether creating changelogs or just keeping track of git tags, releases matter. Learn how to automate your release process with conventional-commits!",
				published: "2020-06-23T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["npm", "javascript"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nWriting changelogs for a project can be tedious. Usually, this lengthy process would start with your project manager, organizing your tickets in the sprint (depending on how your project is organized), and taking time out of the day to write the changelog itself. This process becomes even more complicated when working on developer-centric projects. Remembering what is and isn't a breaking change (to keep a sensible [SEMVER](https://www.geeksforgeeks.org/introduction-semantic-versioning/)), what technical changes were made, and what you should do to migrate to newer versions might be a challenge in itself, on top of the typical release patterns.\n\nThis versioning complexity birthed _a set of tools that allows you to generate changelogs automatically_. Now, this may sound too good to be true: \"How can it generate something without any metadata?\" Well, dear reader, that's the trick of it: You **do** provide the metadata in the form of commit messages.\n\nIf you _enforce a standardized set of commit messages_ (both header and body), then _a tool can automatically run through each commit_ since your last release _and generate the changelog_. Furthermore, because the commit message standards you'll follow outline when a new feature, bug fix, or breaking change is introduced, _this tooling can assume what portion of SEMVER (major, minor, or patch) to bump_. It can change the version numbers in your files as well!\n\n# Step 0: Commit Rules {#conventional-commit}\n\nBefore we start setting up tooling (to generate the changelogs, commit message verification, and more), we need first to understand what the rules are that we're signing up for. As mentioned before, we'll need to standardize the way we write our commit messages for our tooling to work effectively. The standardized commit message template we'll be following in this article is called [Conventional Commits](https://www.conventionalcommits.org/). Conventional Commits generally follow an outline as such:\n\n- First, start with the _type_ of change you're making\n- Then, have an (optional) scope, indicating what section of your app you're changing\n- A description of your changes\n- Then, an optional body that outlines further information that you might want to preserve in your changelog\n\n```\ntype(scope): description\n\nbody\n```\n\n\"Now, by 'type', what exactly do you mean?\"\n\nI'm glad you've asked! In Conventional Commits setups, there is an allowed array of terms that can be used for your _type_. For example, when following the Angular Style of commit messages, you'll have these options at your disposal:\n\n```javascript\n[\n  'build',\n  'ci',\n  'docs',\n  'feat',\n  'fix',\n  'perf',\n  'refactor',\n  'revert',\n  'style',\n  'test'\n]\n```\n\nThis means that your commit message might be something along the lines of:\n\n```\ntest(pagination): added pagination edgecase to test suite\n\nWe had an error thrown as a result of a miscalculation when changing pages on an odd number of items in the collection. This test should ensure this bug doesn't regress\n```\n\nIn this case, your _type_ is `test`, whereas your scope is `pagination`. This way, when you're generating your public changelog, it will likely not include this commit message, as your users don't often care about the implementation or tests within. While this isn't a great example, let's take the next two examples:\n\n```\nfix(pagination): fixed pagination throwing errors when an odd number of items in collection\n```\n\n```\nfeat(pagination): added new \"first\" and \"last\" events when pagination is moved to first or the last page \n```\n\nYour tooling knows only to bump the patch release because your first example is listed as a *type* of `fix`. However, in the second example, you have a _type_ of `feat` that tells your tooling to bump your release version by a minor number.\n\nLikewise, to tell your tooling that a commit introduces a breaking change, you'll do something along the lines of this:\n\n```\nrefactor(pagination): consolidates \"first\" and \"last\" events into a \"pageTo\" event that includes the number in the event payload\n\nBREAKING CHANGE: If you're using the `first` or `last` events in the paginator, you'll need to migrate your logic to use `pageTo` event and getting the page from the event payload (using `$event`). By doing so, you can add back conditional logic based on the number of page jumps \n```\n\nThe `BREAKING CHANGE:` at the start of your commit body tells your tooling that this should indicate a package bump of a MAJOR version, and will highlight this change at the top of your changelog as such.\n\n## Commit Scope {#lerna-usage}\n\nAn immediate question that might be asked is, \"why would I put the scope of changes? How could this realistically help me?\" One use-case where adding a commit scope is hugely advantageous is when using a monorepo for multiple packages in a single repo. When using [Lerna](https://github.com/lerna/lerna) to help manage a monorepo, there are even addons that enable [restricting your _scope_ to match one of the project's packages names](https://github.com/conventional-changelog/commitlint/tree/master/@commitlint/config-lerna-scopes). By doing so, you're able to generate individual `CHANGELOG.md` files for each package, enabling your tooling to scope with your project's scale.\n\n# Step 1: Commit Message Enforcement {#commit-lint}\n\nAny suitable set of tooling should have guide-rails that help you follow the rules you set for yourself (and your team). Like a linter helps keeps your codebase syntactically consistent, _Conventional Commit setups often have a linter setup of their own_. This linter isn't concerned about your code syntax, but rather your commit message syntax. \n\nJust as you have many options regarding what linting ruleset you'd like to enforce on your codebase, you have a few options provided to you for your commit messages. You can utilize [the default linting rules out-of-the-box](https://github.com/conventional-changelog/commitlint/tree/master/@commitlint/config-conventional), follow [the Angular Team's guidelines](https://github.com/conventional-changelog/commitlint/tree/master/@commitlint/config-angular), or even [utilize the format that Jira has set out](https://github.com/Gherciu/commitlint-jira).\n\nAnother similarity to their code syntax contemporaries is that your commit linter has [a myriad of configuration options available](https://commitlint.js.org/#/reference-rules?id=rules). These options allow you to overwrite the existing configuration you're utilizing or even create your configuration from scratch.\n\n## Setup {#install-commit-lint}\n\nWhile you can go as in-depth as creating your own configuration, let's assume that we want to stick with the out-of-box settings. Let's assume that you already have a `package.json` configured. First thing's first, let's install the dependencies we need:\n\n```\nnpm install --save-dev @commitlint/cli @commitlint/config-conventional\n```\n\nThe [`commitlint` CLI](https://commitlint.js.org/) is what will actually do the linting on the commit message while the `@commitlint/config-conventional` is the ruleset that the linter will follow. Now, we'll create the configuration file that will tell the CLI what rules to use. Create a file called `commitlint.config.js` at the root of your project and place the following code inside:\n\n```javascript\nmodule.exports = {extends: ['@commitlint/config-conventional']};\n```\n\nNow, you can test that your setup works properly by linting the last commit in your branch:\n\n```\nnpx commitlint --from=HEAD~1\n```\n\nIt should either validate or fail, depending on whether the last commit message followed the ruleset.\n\n### Husky Setup {#husky}\n\nWhile you _could_ set up a CI system with something like the `commitlint` command from above, it wouldn't be very effective at making sure you and your team remain vigilant with your commit schema. You're _able to enforce your commit messages directly from your development machine_ at the time of commit. To do so, we'll hookup git hooks to validate our commit messages before they finalize (and prevent a commit when they don't pass the linting rules). While there _are_ ways to do this manually, the easiest (and most sharable) method to do so using `package.json` is by installing a dependency called `husky`.\n\n```\nnpm install --save-dev husky\n```\n\nBy installing `husky`, we can now add the following to our `package.json` to tell git to run our `commitlint`:\n\n```json\n{\n  \"husky\": {\n    \"hooks\": {\n      \"commit-msg\": \"commitlint -E HUSKY_GIT_PARAMS\"\n    }\n  }\n}\n```\n\n## Test The Hook {#testing-husky}\n\nNow that we have `husky` configured properly, we're able to ensure that the linting is working as expected. Now, if you run `git commit` it will give the following behavior pattern:\n\n```\ngit commit -m \"foo: this will fail\"\nhusky > commit-msg (node v10.1.0)\nNo staged files match any of provided globs.\n⧗   input: foo: this will fail\n✖   type must be one of [build, chore, ci, docs, feat, fix, perf, refactor, revert, style, test] [type-enum]\n\n✖   found 1 problems, 0 warnings\nⓘ   Get help: https://github.com/conventional-changelog/commitlint/#what-is-commitlint\n\nhusky > commit-msg hook failed (add --no-verify to bypass)\n```\n\n# Step 2: Manage Your Releases {#standard-version}\n\nWhile contiguous commit consistency is cool (what a mouthful), our end goal is to have easier management of our releases. To this end, we have the [`standard-version` ](https://github.com/conventional-changelog/standard-version). This tool allows you to generate git tags, changelogs, and bump your `package.json` files. To start, we'll install the package as a developer dependency:\n\n```\nnpm i --save-dev standard-version\n```\n\nAfterward, we can add a `release` script in our `package.json`:\n\n```json\n{\n  \"scripts\": {\n    \"release\": \"standard-version\"\n  }\n}\n```\n\nFinally, `standard-version` needs to have a starting point to append the CHANGELOG and other versions to. Simply run:\n\n```\nnpm run release -- --first-release\n```\n\nTo generate your initial `CHANGELOG.md` file. This will also create a tag of the current state so that every subsequent release can change your version numbers. \n\n## Usage {#use-standard-version}\n\nHaving an initial starting point for releases is cool but ultimately useless without understanding how to cut a new release. Once you've made a series of commits, you'll want to re-run `npm run release`. This will do all of the standard release actions. [As mentioned before, the `type` of commits will dictate what number (patch, minor, major) is bumped](#conventional-commits). As all of your changes will make it into your `CHANGELOG.md`, you may want to consider squashing PRs before merging them, so that your changelog is clean and reflective of your public changes (not just the implementation detail).\n\nOne thing to note is that you'll want to run `npm run release` _**before**_ running your build or release. This is because it bumps your package version, and as-such won't change the package version in your deployed updates.\n\n## Changelog Customization {#customize-changelog}\n\nFrom here, your `CHANGELOG.md` file should look like the following:\n\n```markdown\n# Changelog\n\nAll notable changes to this project will be documented in this file. See [standard-version](https://github.com/conventional-changelog/standard-version) for commit guidelines.\n\n### 0.0.1-alpha.1 (2020-01-01)\n\nInitial release\n```\n\n\nLet's say we introduce a new version that has a set of features and bug fixes:\n\n```markdown\n### [0.0.2](https://github.com/unicorn-utterances/batteries-not-included/compare/v0.0.1...v0.0.2) (2020-02-25)\n\n### Features\n\n* added overflow property to keyboard handler ([3f85fdc](https://github.com/unicorn-utterances/batteries-not-included/commit/3f85fdcc9ff2bf2e765585c500b0d2f3421c92dc))\n* added wrap number util ([762f1cd](https://github.com/unicorn-utterances/batteries-not-included/commit/762f1cd5ff60274b221eccf6da829b72fac97d7b))\n\n### Bug Fixes\n\n* parameter in name in doc in wrap-number.ts ([249b63b](https://github.com/unicorn-utterances/batteries-not-included/commit/249b63bebe1816655dd64cc1acf7f57875b0613e))\n* updated overflow to work on keyboard handler ([eb50de0](https://github.com/unicorn-utterances/batteries-not-included/commit/eb50de0c401d98f84a5c9628c6d34c6cef311eb1))\n```\n\nYou might think \"Well, this file is auto-generated. I shouldn't modify it, least it stop working!\" Luckily for us, this is not the case! So long as we leave the headers as-is, we're able to customize the `CHANGELOG.md` file with further details. _We can even include images_ using the standard markdown `![]()` syntax! Using this knowledge, we can create extremely robust and explanative changelogs for our consumers.\n\n## Bump Version Files {#bump-package-json}\n\nWhile working in a monorepo, I often find myself needing to change the version number in more than a single file at a time. I've also found myself in need of multi-file version bumping when using a different `package.json` for release than the one I use for development.\n\nRegardless of the reason behind needing to change multiple files' package number, `standard-version`'s got you covered!\n\nYou'll want to create a `.versionrc` file and put the following in it:\n\n```json\n{\n  \"bumpFiles\": [\n    {\n      \"filename\": \"MY_VERSION_TRACKER.txt\",\n      // The `plain-text` updater assumes the file contents represents the version.\n      \"type\": \"plain-text\"\n    },\n    {\n      \"filename\": \"a/deep/package/dot/json/file/package.json\",\n      // The `json` updater assumes the version is available under a `version` key in the provided JSON document.\n      \"type\": \"json\"\n    },\n    {\n      \"filename\": \"package.json\",\n      \"type\": \"json\"\n    },\n  ]\n}\n```\n\nMultiple different kinds of files that can be updated, and you can even [write your own `updater` method to update any file you'd so like](https://github.com/conventional-changelog/standard-version#custom-updaters).\n\n# Conclusion {#conclusion}\n\nKeep in mind, simply because you have a new tool to manage releases doesn't mean that you have a free pass on ignoring your branching strategy. If you're developing a developer tool that has breaking  changes every week, you're certainly going to alienate anyone that's not a staunch consumer. You'll want to keep following best practices for your use-cases to ensure that this tool isn't squandered by other project issues.\n\nWhile the outline we've provided should suffice for most usage, each of these tools includes many options that you're able to utilize customize the process to your liking.\n\nFind options you think we should cover in this article? Have questions about how to get `conventional-commit` and `standard-version` working? Let us know! We've got a comments section down below as well as [a Discord Community](https://discord.gg/FMcvc6T) that we use to chat.\n\n",
		},
		{
			title: "The Complete Guide to Regular Expressions (Regex)",
			description:
				"A Regular Expression – or regex for short – is a syntax that allows you to match strings with specific patterns. Think of it as a suped-up text search",
			published: "2022-04-17T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["regex", "computer science"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/development/the-complete-guide-to-regular-expressions-regex/",
			slug: "the-complete-guide-to-regular-expressions-regex",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "The Complete Guide to Regular Expressions (Regex)",
				description:
					"A Regular Expression – or regex for short – is a syntax that allows you to match strings with specific patterns. Think of it as a suped-up text search",
				published: "2022-04-17T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["regex", "computer science"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/development/the-complete-guide-to-regular-expressions-regex/",
			},
			contentMeta:
				'\r\nA Regular Expression – or regex for short– is a syntax that allows you to match strings with specific patterns. Think of it as a suped-up text search shortcut, but a regular expression adds the ability to use quantifiers, pattern collections, special characters, and capture groups to create extremely advanced search patterns.\r\nRegex can be used any time you need to query string-based data, such as:\r\n\r\n- Analyzing command line output\r\n- Parsing user input\r\n- Examining server or program logs\r\n- Handling text files with a consistent syntax, like a CSV\r\n- Reading configuration files\r\n- Searching and refactoring code\r\n\r\nWhile doing all of these is *theoretically* possible without regex, when regexes hit the scene they act as a superpower for doing all of these tasks.\r\n\r\nIn this guide we\'ll cover:\r\n\r\n- [What does a regex look like?](#what-does-a-regex-look-like)\r\n- [How to read and write a regex](#how-to-read-write-regex)\r\n  - [What\'s a "quantifier"?](#quantifiers)\r\n  - [What\'s a "pattern collection"?](#pattern-collections)\r\n  - [What\'s a "regex token"?](#general-tokens)\r\n- [How to use a regex](#how-to-use-a-regex)\r\n- [What\'s a "regex flag"?](#flags)\r\n- [What\'s a "regex group"?](#groups)\r\n\r\n> [Download our Regex Cheat Sheet](https://coderpad.io/regular-expression-cheat-sheet/)\r\n\r\n# What does a regex look like? {#what-does-a-regex-look-like}\r\n\r\nIn its simplest form, a regex in usage might look something like this:\r\n\r\n![We\'re using a regular expression /Test/ to look for the word "Test"](./regex_intro_test_testing.png)\r\n\r\n> This screenshot is of the [regex101 website](https://regex101.com/). All future screenshots will utilize this website for visual reference.\r\n\r\nIn the "Test" example the letters test formed the search pattern, same as a simple search.\r\nThese regexes are not always so simple, however. Here\'s a regex that matches 3 numbers, followed by a "-", followed by 3 numbers, followed by another "-", finally ended by 4 numbers.\r\n\r\nYou know, like a phone number:\r\n\r\n```\r\n^(?:\\d{3}-){2}\\d{4}$\r\n```\r\n\r\n![The phone number "555-555-5555" will match with the regex above, but "555-abc-5555" will not](./intro_phone_number.png)\r\n\r\nThis regex may look complicated, but two things to keep in mind:\r\n\r\n1. We\'ll teach you how to read and write these in this article\r\n2. This is a fairly complex way of writing this regex.\r\n\r\nIn fact, most regexes can be written in multiple ways, just like other forms of programming. For example, the above can be rewritten into a longer but slightly more readable version:\r\n\r\n```\r\n^[0-9]{3}-[0-9]{3}-[0-9]{4}$\r\n```\r\n\r\n> Most languages provide a built-in method for searching and replacing strings using regex. However, each language may have a different set of syntaxes based on what the language dictates.\r\n>\r\n> In this article, we\'ll focus on the ECMAScript variant of Regex, which is used in JavaScript and shares a lot of commonalities with other languages\' implementations of regex as well.\r\n\r\n# How to read (and write) regexes {#how-to-read-write-regex}\r\n\r\n## Quantifiers {#quantifiers}\r\n\r\nRegex quantifiers check to see how many times you should search for a character.\r\n\r\nHere is a list of all quantifiers:\r\n\r\n- `a|b` - Match either "a" or "b\r\n- `?` - Zero or one\r\n- `+` - one or more\r\n- `*` - zero or more\r\n- `{N}` - Exactly N number of times (where N is a number)\r\n-  `{N,}` - N or more number of times (where N is a number)\r\n- `{N,M}` - Between N and M number of times (where N and M are numbers and N < M)\r\n- `*?` - Zero or more, but stop after first match\r\n\r\nFor example, the following regex:\r\n\r\n```\r\nHello|Goodbye\r\n```\r\n\r\nMatches both the string "Hello" and "Goodbye".\r\n\r\nMeanwhile:\r\n\r\n```\r\nHey?\r\n```\r\n\r\nWill track "y" zero to one time, so will match up with "He" and "Hey".\r\n\r\nAlternatively:\r\n\r\n```\r\nHello{1,3}\r\n```\r\n\r\nWill match "Hello", "Helloo", "Hellooo", but not "Helloooo", as it is looking for the letter "o" between 1 and 3 times.\r\n\r\nThese can even be combined with one another:\r\n\r\n```\r\nHe?llo{2}\r\n```\r\n\r\nHere we\'re looking for strings with zero-to-one instances of "e" and the letter "o" times 2, so this will match "Helloo" and "Hlloo".\r\n\r\n### Greedy matching\r\n\r\nOne of the regex quantifiers we touched on in the previous list was the `+` symbol. This symbol matches one or more characters. This means that:\r\n\r\n```\r\nHi+\r\n```\r\n\r\nWill match everything from "Hi" to "Hiiiiiiiiiiiiiiii". This is because all quantifiers are considered "greedy" by default.\r\n\r\nHowever, if you change it to be "lazy" using a question mark symbol (`?`) to the following, the behavior changes.\r\n\r\n```\r\nHi+?\r\n```\r\n\r\nNow, the `i` matcher will try to match as few times as possible. Since the `+` icon means "one or more", it will only match one "i". This means that if we input the string "Hiiiiiiiiiii", only "Hi" will be matched.\r\n\r\nWhile this isn\'t particularly useful on its own, when combined with broader matches like the the `.` symbol, it becomes extremely important as we\'ll cover in the next section. The `.` symbol is used in regex to find "any character".\r\n\r\nNow if you use:\r\n\r\n```\r\nH.*llo\r\n```\r\n\r\nYou can match everything from "Hillo" to "Hello" to "Hellollollo".\r\n\r\n![We\'re using a regex /H.*llo/ to look for the words "Hillo", "Hello", and "Helloollo"](./h_star_llo.png)\r\n\r\nHowever, what if you want to only match "Hello" from the final example?\r\n\r\nWell, simply make the search lazy with a `?` and it\'ll work as we want:\r\n\r\n```\r\nH.*?llo\r\n```\r\n\r\n![We\'re using a regex /H.*?llo/ to look for the words "Hillo", "Hello", and partially match the "Hello" in "Helloollo"](./h_star_question_llo.png)\r\n\r\n## Pattern collections {#pattern-collections}\r\n\r\nPattern collections allow you to search for a collection of characters to match against. For example, using the following regex:\r\n\r\n```\r\nMy favorite vowel is [aeiou]\r\n```\r\n\r\nYou could match the following strings:\r\n\r\n```\r\nMy favorite vowel is a\r\nMy favorite vowel is e\r\nMy favorite vowel is i\r\nMy favorite vowel is o\r\nMy favorite vowel is u\r\n```\r\n\r\nBut nothing else.\r\n\r\nHere\'s a list of the most common pattern collections:\r\n\r\n- `[A-Z]` - Match any uppercase character from "A" to "Z"\r\n- `[a-z]` - Match any lowercase character from "a" to "z"\r\n- `[0-9]` - Match any number\r\n- `[asdf]` - Match any character that\'s either "a", "s", "d", or "f"\r\n- `[^asdf]` - Match any character that\'s not any of the following: "a", "s", "d", or "f"\r\n\r\nYou can even combine these together:\r\n\r\n- `[0-9A-Z]` - Match any character that\'s either a number or a capital letter from "A" to "Z"\r\n- `[^a-z]` - Match any non-lowercase letter\r\n\r\n## General tokens {#general-tokens}\r\n\r\nNot every character is so easily identifiable. While keys like "a" to "z" make sense to match using regex, what about the newline character?\r\n\r\n> The "newline" character is the character that you input whenever you press "Enter" to add a new line.\r\n\r\n- `.` - Any character\r\n- `\\n` - Newline character\r\n- `\\t` - Tab character\r\n- `\\s` - Any whitespace character (including `\\t`, `\\n` and a few others)\r\n- `\\S` - Any non-whitespace character\r\n- `\\w` - Any word character (Uppercase and lowercase Latin alphabet, numbers 0-9, and `_`)\r\n- `\\W` - Any non-word character (the inverse of the `\\w` token)\r\n- `\\b` - Word boundary: The boundaries between `\\w` and `\\W`, but matches in-between characters\r\n- `\\B` - Non-word boundary: The inverse of `\\b`\r\n- `^` - The start of a line\r\n- `$` - The end of a line \r\n- `\\\\ `- The literal character "\\"\r\n\r\nSo if you wanted to remove every character that starts a new word you could use something like the following regex:\r\n\r\n```\r\n\\s.\r\n```\r\n\r\nAnd replace the results with an empty string. Doing this, the following:\r\n\r\n```\r\nHello world how are you\r\n```\r\n\r\nBecomes:\r\n\r\n```\r\nHelloorldowreou\r\n```\r\n\r\n![We\'re using a regex /\\s./ to look for the whitespaces alongside the following character in the string "Hello world how are you"](./whitespace_dot.png)\r\n\r\n## Combining with collections\r\n\r\nThese tokens aren\'t just useful on their own, though! Let\'s say that we want to remove any uppercase letter or whitespace character. Sure, we could write\r\n\r\n```\r\n[A-Z]|\\s\r\n```\r\n\r\nBut we can actually merge these together and place our `\\s` token into the collection:\r\n\r\n```\r\n[A-Z\\s]\r\n```\r\n\r\n![An explaination can be found in the next line. Apologies, Markdown formatting broke for this example](./a_through_z_whitespace.png)\r\n\r\n\r\n\r\nWe\'re using a regex `/[A-Z\\s]/` to look for uppercase letters and whitespaces in the string "Hello World how are you"\r\n\r\n## Word boundaries\r\n\r\nIn our list of tokens, we mentioned `\\b` to match word boundaries. I thought I\'d take a second to explain how it acts a bit differently from others.\r\n\r\nGiven a string like "This is a string", you might expect the whitespace characters to be matched – however, this isn\'t the case. Instead, it matches between the letters and the whitespace:\r\n\r\n![We\'re using a word boundary regex /\\b/ to look for the in-between spaces in characters](./word_boundary.png)\r\n\r\nThis can be tricky to get your head around, but it\'s unusual to simply match against a word boundary. Instead, you might have something like the following to match full words:\r\n\r\n```\r\n\\b\\w+\\b\r\n```\r\n\r\n![We\'re using a regex /\\b\\w+\\b/ to look for full words. In the string "This is a string" we match "this", "is", "a", and "string"](./boundary_whitespace_boundary.png)\r\n\r\nYou can interpret that regex statement like this:\r\n\r\n"A word boundary. Then, one or more \'word\' characters. Finally, another word boundary".\r\n\r\n## Start and end line\r\n\r\nTwo more tokens that we touched on are `^` and `$`. These mark off the start of a line and end of a line, respectively.\r\n\r\nSo, if you want to find the first word, you might do something like this:\r\n\r\n```\r\n^\\w+\r\n```\r\n\r\nTo match one or more "word" characters, but only immediately after the line starts. Remember, a "word" character is any character that\'s an uppercase or lowercase Latin alphabet letters, numbers 0-9, and `_`.\r\n\r\n![The regex /^\\w+/ matches the first word in the string. In "This is a string" we match "This"](./start_whitespace_plus.png)\r\n\r\nLikewise, if you want to find the last word your regex might look something like this:\r\n\r\n```\r\n\\w+$\r\n```\r\n\r\n![You can use /\\w+$/ to match the last word in the string. In "This is a string" we match "string"](./whitespace_end.png)\r\n\r\nHowever, just because these tokens **typically** end a line doesn\'t mean that they can\'t have characters after them.\r\n\r\nFor example, what if we wanted to find every whitespace character between newlines to act as a basic [JavaScript minifier](https://en.wikipedia.org/wiki/Minification_(programming))? \r\n\r\nWell, we can say "Find all whitespace characters after the end of a line" using the following regex:\r\n\r\n```\r\n$\\s+\r\n```\r\n\r\n![We can use /$\\s+/ to find all whitespace between the end of a string and the start of the next string.](./basic_minifier.png)\r\n\r\n## Character escaping\r\n\r\nWhile tokens are super helpful, they can introduce some complexity when trying to match strings that actually contain tokens. For example, say you have the following string in a blog post:\r\n\r\n```\r\n"The newline character is \'\\n\'"\r\n```\r\n\r\nOr want to find every instance of this blog post\'s usage of the "\\n" string. Well, you can escape characters using `\\`. This means that your regex might look something like this:\r\n\r\n```\r\n\\\\n\r\n```\r\n\r\n# How to use a regex {#how-to-use-a-regex}\r\n\r\nRegular expressions aren\'t simply useful for *finding* strings, however. You\'re also able to use them in other methods to help modify or otherwise work with strings.\r\n\r\nWhile many languages have similar methods, let\'s use JavaScript as an example.\r\n\r\n## Creating and searching using regex\r\n\r\nFirst, let\'s look at how regex strings are constructed. \r\n\r\nIn JavaScript (along with many other languages), we place our regex inside of `//` blocks. The regex searching for a lowercase letter looks like this:\r\n\r\n```javascript\r\n/[a-z]/\r\n```\r\n\r\nThis syntax then generates [a RegExp object](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp) which we can use with [built-in methods, like `exec`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/exec), to match against strings.\r\n\r\n```javascript\r\n/[a-z]/.exec("a"); // Returns ["a"]\r\n/[a-z]/.exec("0"); // Returns null\r\n```\r\n\r\nWe can then use this [truthiness](https://developer.mozilla.org/en-US/docs/Glossary/Truthy) to determine if a regex matched, like we\'re doing in line #3 of this example:\r\n\r\n<iframe loading="lazy" src="https://app.coderpad.io/sandbox?question_id=211635"></iframe>\r\n\r\nWe can also alternatively call a `RegExp` constructor with the string we want to convert into a regex:\r\n\r\n```javascript\r\nconst regex = new RegExp("[a-z]"); // Same as /[a-z]/\r\n```\r\n\r\n## Replacing strings with regex\r\n\r\nYou can also use a regex to search and replace a file\'s contents as well. Say you wanted to replace any greeting with a message of "goodbye". While you could do something like this:\r\n\r\n```javascript\r\nfunction youSayHelloISayGoodbye(str) {\r\n  str = str.replace("Hello", "Goodbye");\r\n  str = str.replace("Hi", "Goodbye");\r\n  str = str.replace("Hey", "Goodbye");  str = str.replace("hello", "Goodbye");\r\n  str = str.replace("hi", "Goodbye");\r\n  str = str.replace("hey", "Goodbye");\r\n  return str;\r\n}\r\n```\r\n\r\nThere\'s an easier alternative, using a regex:\r\n\r\n```javascript\r\nfunction youSayHelloISayGoodbye(str) {\r\n  str = str.replace(/[Hh]ello|[Hh]i|[Hh]ey/, "Goodbye");\r\n  return str;\r\n}\r\n```\r\n\r\n<iframe loading="lazy" src="https://app.coderpad.io/sandbox?question_id=211638"></iframe>\r\n\r\nHowever, something you might notice is that if you run `youSayHelloISayGoodbye` with "Hello, Hi there": it won\'t match more than a single input:\r\n\r\n![An explanation for this image is in the next sentence. Apologies - there are issues with the markdown processing on this one](./hello_hey_hi_insensative_1.png)\r\n\r\nIf the regex /[Hh]ello|[Hh]i|[Hh]ey/ is used on the string "Hello, Hi there", it will only match "Hello" by default.\r\n\r\nHere, we should expect to see both "Hello" and "Hi" matched, but we don\'t.\r\n\r\nThis is because we need to utilize a Regex "flag" to match more than once.\r\n\r\n# Flags {#flags}\r\n\r\nA regex flag is a modifier to an existing regex. These flags are always appended after the last forward slash in a regex definition. \r\n\r\nHere\'s a shortlist of some of the flags available to you.\r\n\r\n- `g` - Global, match more than once\r\n- `m` - Force $ and ^ to match each newline individually\r\n- `i` - Make the regex case insensitive\r\n\r\nThis means that we could rewrite the following regex:\r\n\r\n```javascript\r\n/[Hh]ello|[Hh]i|[Hh]ey/\r\n```\r\n\r\nTo use the case insensitive flag instead:\r\n\r\n```javascript\r\n/Hello|Hi|Hey/i\r\n```\r\n\r\nWith this flag, this regex will now match:\r\n\r\n```\r\nHello\r\nHEY\r\nHi\r\nHeLLo\r\n```\r\n\r\nOr any other case-modified variant.\r\n\r\n## Global regex flag with string replacing\r\n\r\nAs we mentioned before, if you do a regex replace without any flags it will only replace the first result:\r\n\r\n```javascript\r\nlet str = "Hello, hi there!";\r\nstr = str.replace(/[Hh]ello|[Hh]i|[Hh]ey/, "Goodbye");\r\nconsole.log(str); // Will output "Goodbye, hi there"\r\n```\r\n\r\nHowever, if you pass the `global` flag, you\'ll match every instance of the greetings matched by the regex:\r\n\r\n```javascript\r\nlet str = "Hello, hi there!";\r\nstr = str.replace(/[Hh]ello|[Hh]i|[Hh]ey/g, "Goodbye");\r\nconsole.log(str); // Will output "Goodbye, hi there"\r\n```\r\n\r\n## A note about JavaScript\'s global flag\r\n\r\nWhen using a global JavaScript regex, you might run into some strange behavior when running the `exec` command more than once.\r\n\r\nIn particular, if you run `exec` with a global regex, it will return `null` every other time:\r\n\r\n![If we assign a regex to a variable then run `exec` on said variable, it will find the results properly the first and third time, but return `null` the second time](./inconsistent_regex.png)This is because, as [MDN explains](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/exec):\r\n\r\n> JavaScript[ RegExp](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp) objects are **stateful** when they have the[ global](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/global) or[ sticky](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/sticky) flags set… They store a[ lastIndex](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/lastIndex) from the previous match. Using this internally, exec() can be used to iterate over multiple matches in a string of text…\r\n\r\nThe `exec` command attempts to start looking through the `lastIndex` moving forward. Because `lastIndex` is set to the length of the string, it will attempt to match `""` – an empty string – against your regex until it is reset by another `exec` command again. While this feature can be useful in specific niche circumstances, it\'s often confusing for new users.\r\n\r\nTo solve this problem, we can simply assign `lastIndex` to 0 before running each `exec` command:\r\n\r\n![If we run `regex.lastIndex = 0` in between each `regex.exec`, then every single `exec` runs as intended](./consistent_regex_fix.png)\r\n\r\n# Groups {#groups}\r\n\r\nWhen searching with a regex, it can be helpful to search for more than one matched item at a time. This is where "groups" come into play. Groups allow you to search for more than a single item at a time.\r\n\r\nHere, we can see matching against both `Testing 123` and `Tests 123` without duplicating the "123" matcher in the regex.\r\n\r\n```javascript\r\n/(Testing|tests) 123/ig\r\n```\r\n\r\n![With the regex /(Testing|tests) 123/ig we can match "Testing 123" and "Tests 123"](./test_ig.png)Groups are defined by parentheses; there are two different types of groups--capture groups and non-capturing groups:\r\n\r\n- `(...)` - Group matching any three characters\r\n- `(?:...)` - Non-capturing group matching any three characters\r\n\r\nThe difference between these two typically comes up in the conversation when "replace" is part of the equation. \r\n\r\nFor example, using the regex above, we can use the following JavaScript to replace the text with "Testing 234" and "tests 234":\r\n\r\n```javascript\r\nconst regex = /(Testing|tests) 123/ig;\r\n\r\nlet str = `\r\nTesting 123\r\nTests 123\r\n`;\r\n\r\nstr = str.replace(regex, \'$1 234\');\r\nconsole.log(str); // Testing 234\\nTests 234"\r\n```\r\n\r\nWe\'re using `$1` to refer to the first capture group, `(Testing|tests)`. We can also match more than a single group, like both `(Testing|tests)` and `(123)`:\r\n\r\n```javascript\r\nconst regex = /(Testing|tests) (123)/ig;\r\n\r\nlet str = `\r\nTesting 123\r\nTests 123\r\n`;\r\n\r\nstr = str.replace(regex, \'$1 #$2\');\r\nconsole.log(str); // Testing #123\\nTests #123"\r\n```\r\n\r\nHowever, this is only true for capture groups. If we change:\r\n\r\n```javascript\r\n/(Testing|tests) (123)/ig\r\n```\r\n\r\nTo become:\r\n\r\n```javascript\r\n/(?:Testing|tests) (123)/ig;\r\n```\r\n\r\nThen there is only one captured group – `(123)` – and instead, the same code from above will output something different:\r\n\r\n```javascript\r\nconst regex = /(?:Testing|tests) (123)/ig;\r\n\r\nlet str = `\r\nTesting 123\r\nTests 123\r\n`;\r\n\r\nstr = str.replace(regex, \'$1\');\r\nconsole.log(str); // "123\\n123"\r\n```\r\n\r\n<iframe loading="lazy" src="https://app.coderpad.io/sandbox?question_id=211705"></iframe>\r\n\r\n## Named capture groups\r\n\r\nWhile capture groups are awesome, it can easily get confusing when there are more than a few capture groups. The difference between `$3` and `$5` isn\'t always obvious at a glance.\r\n\r\nTo help solve for this problem, regexes have a concept called "named capture groups"\r\n\r\n- `(?<name>...)` - Named capture group called "name" matching any three characters\r\n\r\nYou can use them in a regex like so to create a group called "num" that matches three numbers:\r\n\r\n```javascript\r\n/Testing (?<num>\\d{3})/\r\n```\r\n\r\nThen, you can use it in a replacement like so:\r\n\r\n```javascript\r\nconst regex = /Testing (?<num>\\d{3})/\r\nlet str = "Testing 123";\r\nstr = str.replace(regex, "Hello $<num>")\r\nconsole.log(str); // "Hello 123"\r\n```\r\n\r\n## Named back reference\r\n\r\nSometimes it can be useful to reference a named capture group inside of a query itself. This is where "back references" can come into play.\r\n\r\n- `\\k<name>` Reference named capture group "name" in a search query\r\n\r\nSay you want to match:\r\n\r\n```\r\nHello there James. James, how are you doing?\r\n```\r\n\r\nBut not:\r\n\r\n```\r\nHello there James. Frank, how are you doing?\r\n```\r\n\r\nWhile you could write a regex that repeats the word "James" like the following:\r\n\r\n```javascript\r\n/.*James. James,.*/\r\n```\r\n\r\nA better alternative might look something like this:\r\n\r\n```javascript\r\n/.*(?<name>James). \\k<name>,.*/\r\n```\r\n\r\nNow, instead of having two names hardcoded, you only have one.\r\n\r\n<iframe loading="lazy" src="https://app.coderpad.io/sandbox?question_id=211711"></iframe>\r\n\r\n## Lookahead and lookbehind groups\r\n\r\nLookahead and behind groups are extremely powerful and often misunderstood.\r\n\r\nThere are four different types of lookahead and behinds:\r\n\r\n- `(?!)` - negative lookahead\r\n- `(?=)` - positive lookahead\r\n- `(?<=)` - positive lookbehind\r\n- `(?<!)` - negative lookbehind\r\n\r\nLookahead works like it sounds like: It either looks to see that something *is* after the lookahead group or *is not* after the lookahead group, depending on if it\'s positive or negative.\r\n\r\nAs such, using the negative lookahead like so:\r\n\r\n```javascript\r\n/B(?!A)/\r\n```\r\n\r\nWill allow you to match `BC` but not `BA`.\r\n\r\n![With the regex /B(?!A)/ we can match "B" in "BC" but not in "BA"](./b_not_a.png)\r\n\r\nYou can even combine these with `^` and `$` tokens to try to match full strings. For example, the following regex will match any string that **does not** start with "Test"\r\n\r\n```javascript\r\n/^(?!Test).*$/gm\r\n```\r\n\r\n![/^(?!Test).*$/gm lets us match "Hello" and "Other", but not "Testing 123" and "Tests 123"](./start_not_test_end.png)\r\n\r\nLikewise, we can switch this to a positive lookahead to enforce that our string **must** start with "Test"\r\n\r\n```javascript\r\n/^(?=Test).*$/gm\r\n```\r\n\r\n![Inversing our previous item - /^(?=Test).*$/gm lets us match "Testing 123" and "Tests 123", but not "Hello" and "Other"](./require_test_start.png)\r\n\r\n# Putting it all together\r\n\r\nRegexes are extremely powerful and can be used in a myriad of string manipulations. Knowing them can help you refactor codebases, script quick language changes, and more!\r\n\r\nLet\'s go back to our initial phone number regex and try to understand it again:\r\n\r\n```\r\n^(?:\\d{3}-){2}\\d{4}$\r\n```\r\n\r\nRemember that this regex is looking to match phone numbers such as:\r\n\r\n```\r\n555-555-5555\r\n```\r\n\r\nHere this regex is:\r\n\r\n- Using `^` and `$` to define the start and end of a regex line.\r\n- Using a non-capturing group to find three digits then a dash\r\n  - Repeating this group twice, to match `555-555-`\r\n- Finding the last 4 digits of the phone number\r\n\r\nHopefully, this article has been a helpful introduction to regexes for you. If you\'d like to see quick definitions of useful regexes, check out our cheat sheet.\r\n\r\n> [Download our Regex Cheat Sheet](https://coderpad.io/regular-expression-cheat-sheet/)',
		},
		{
			title: "Continuous Integration with Travis CI for Android",
			description:
				"An in-depth tutorial explaining how to set up Travis CI to deploy signed builds to Google Play. Among other things",
			published: "2019-08-22T05:12:03.284Z",
			authors: ["fennifith"],
			tags: ["android", "ci"],
			attached: [],
			license: {
				id: "publicdomain-zero-1",
				footerImg: "https://licensebuttons.net/p/zero/1.0/88x31.png",
				licenceType: "Public Domain",
				explainLink: "https://creativecommons.org/publicdomain/zero/1.0/",
				name: "CC0 1.0 Universal (CC0 1.0) Public Domain Dedication",
				displayName: "Public Domain",
			},
			slug: "travis-ci-for-android",
			locale: "en",
			authorsMeta: [
				{
					id: "fennifith",
					name: "James Fenn",
					firstName: "James",
					lastName: "Fenn",
					description:
						"Enjoys writing software on loud keyboards. Starts too many projects. Consumes food.",
					socials: { twitter: "fennifith", github: "fennifith" },
					pronouns: "he",
					profileImg: "./fennifith.jpg",
					color: "#0091EA",
					roles: ["developer", "author", "community"],
					profileImgMeta: {
						height: 400,
						width: 400,
						relativePath: "./fennifith.jpg",
						relativeServerPath: "/content/data/fennifith.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\fennifith.jpg",
					},
					rolesMeta: [
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Continuous Integration with Travis CI for Android",
				description:
					"An in-depth tutorial explaining how to set up Travis CI to deploy signed builds to Google Play. Among other things",
				published: "2019-08-22T05:12:03.284Z",
				authors: ["fennifith"],
				tags: ["android", "ci"],
				attached: [],
				license: "publicdomain-zero-1",
			},
			contentMeta:
				'\nLast week, I started setting up continuous integrations for some of my projects. The basic idea of a continuous integration is that you have a server to build your project on a regular basis, verify that it works correctly, and deploy it to wherever your project is published. In this case, my project will be deployed to the releases of its GitHub repository and an alpha channel on the Google Play Store. In order to do this, I decided to use [Travis CI](https://travis-ci.com/), as it seems to be the most used and documented solution (though there are others as well). Throughout this blog, I will add small snippets of the files I am editing, but (save for the initial `.travis.yml`) never an entire file. If you get lost or would like to see a working example of this, you can find a sample project [here](/redirects/?t=github&d=TravisAndroidExample).\n\nA small preface, make sure that you create your account on [travis-ci.com](https://travis-ci.com/), not [travis-ci.org](https://travis-ci.org/). Travis previously had their free plans on their .org site and only took paying customers on .com, but they have since begun [migrating all of their users](https://docs.travis-ci.com/user/open-source-on-travis-ci-com/) to travis-ci.com. However, for some reason they have decided _not to say anything about it_ when you create a new account, so it would be very easy to set up all of your projects on their .org site, then (X months later) realize that you have to move to .com. This isn\'t a huge issue, but it could be a little annoying if you have _almost 100 repositories_ like I do which you would have to change (though I have only just started using Travis, so it doesn\'t actually affect me). Just something to note.\n\n# Step 1: Start your first build\n\nThere are a few basic things to do in order to build your project. Assuming that you have already [set up your account](https://docs.travis-ci.com/user/tutorial/) and authenticated it with your GitHub, you will next want to create a file named `.travis.yml` in your project\'s root directory. One thing to keep in mind here is that the YAML format in this file is heavily dependent on whitespace; tab characters are invalid, indents must be made only in spaces, and a sub-section or parameter **must** be indented or it will not be treated as such. To start, let\'s write a basic file that should properly build most up-to-date Android projects.\n\n```yaml\nlanguage: android\nandroid:\n  components:\n    - tools\n    - platform-tools\n    - build-tools-28.0.3\n    - android-28\n    - extra-google-google_play_services\n    - extra-google-m2repository\n    - extra-android-m2repository\njdk:\n  - oraclejdk8\nbefore_install:\n  - chmod +x gradlew\n```\n\nYou will want to update the `android` and `build-tools` versions to match the respective values in your project\'s `build.gradle` file, and `extra-google-google_play_services` can be omitted (it will speed up build times) if you are not using it. The same goes for the `jdk`. Note the `before_install` section; statements placed there are executed before your project is built or installed (side-note: you will want to make sure `gradlew` and `gradle/wrapper` are in your version control; Travis uses them to build your project).\n\nNow, when you commit this file to your repository (the branch should not make a difference), Travis should build your project and notify you of the result.\n\n# Step 2. Signing APKs\n\nSo Travis _can_ successfully build your APK, but that itself is not very useful. It can do something with debug APKs, sure, but deploying them won\'t be very useful as they won\'t be under the same signature, and users won\'t be able to update from the existing application. So... we need a way to sign the application using an existing keystore that Travis has access to.\n\n> LET\'S UPLOAD OUR KEYSTORE TO GIT!\n\nNot a bad idea. This will easily give Travis the ability to sign our APK. Isn\'t there some reason that you shouldn\'t share your keystore online, though, maybe something about "malicious developers and companies can use it to update your application without your knowledge"? Weeeelll why don\'t we use Travis\'s built-in encryption service? This will give you an encrypted file (like `key.jks.enc`) that you can safely add to git, and add a command to the `before_install` section in your `.travis.yml` to decrypt it.\n\n> But... can\'t someone just look in your `.travis.yml`, get the command, and use it to decrypt your file?\n\nNo, they can\'t. This is because the values passed to the command are two [environment variables](https://docs.travis-ci.com/user/environment-variables/#defining-variables-in-repository-settings) which are stored only on Travis. As long as you _don\'t_ check the "show value in log" box when you create an environment variable, they will never be output anywhere in your build logs, and nobody will be able to see them or know what they are.\n\nIf you are worried about security (or if you aren\'t worried enough), I highly recommend that you read [Travis\'s documentation](https://docs.travis-ci.com/user/best-practices-security/#Steps-Travis-CI-takes-to-secure-your-data) on best practices regarding secure data. \n\n## Part A. Encrypting files\n\nYou can go about this two ways: a difficult way, or a difficult way. You can either install [Travis\'s CLI tool](https://docs.travis-ci.com/user/encrypting-files/) for the sole purpose of logging in, encrypting your file, and setting its environment variables, or you can just do it yourself. I will provide instructions for both. Do what you like.\n\nNote that if you want to automatically deploy your builds to Google Play, you may want to come back here and go through the exact same process later on, so you might want to skip this for now. If you don\'t, or want to do it twice anyway... carry on...\n\n### Using Travis\'s CLI\n\nFirst, install it. Assuming you have Ruby set up, you\'ll want to run `gem install travis`. Since not everyone has Ruby set up, [here are their installation instructions](https://www.ruby-lang.org/en/documentation/installation/). A bit of a pain for something that you can just write yourself in my opinion, but hey, anything to avoid writing more code.\n\nAfter that, you\'ll want to log in. Run `travis login` and it will walk you through it. Note: (related to the preface at the start) no matter what site you are using when you use the Travis CLI, you should append either `--org` or `--com` to **every command** to specify which site it should use.\n\nNow, find your keystore. Place it in your root directory. The CLI detects git repos to determine what project you want to modify, so this is necessary. Do not add it to git. That is bad and not good. Don\'t do that.\n\nAssuming you have named your keystore `key.jks`, you will want to run `travis encrypt-file key.jks --add`. This will encrypt the file, add the command to your `.travis.yml`, and upload the environment variables all at once. You can then add `key.jks.enc` to git, commit and push, and it will be available to your next build.\n\nSide-note: if your keystore is a `.keystore` file, it shouldn\'t make a difference - just replace `key.jks` with `key.keystore` (or whatever it is named) whenever it appears.\n\n### Doing It Yourself\n\nPick a key and a password. They shouldn\'t be excessively long, but not tiny either. Do not use special characters. In this example, I will use "php" as the key and "aaaaa" as the password.\n\nAdd them to Travis CI as environment variables. You can do this by going to your project page in Travis, clicking on "More Options > Settings", then scrolling down to "Environment Variables". I will name mine "enc_keystore_key" and "enc_keystore_pass", respectively.\n\nNow, time to encrypt the file. Run this command in the terminal:\n\n```bash\nopenssl aes-256-cbc -K "php" -iv "aaaaa" -in key.jks -out key.jks.enc\n```\n\nNow, you will want to add a line to decrypt the file in `before_install` of your `.travis.yml`. You should not pass your key/password here, as this file will be pushed to git, and that would be bad. Instead, we will reference the environment variables.\n\n```yaml\nbefore_install:\n  - ...\n  - openssl aes-256-cbc -K $enc_keystore_key -iv $enc_keystore_pass -in key.jks.enc -out key.jks -d\n```\n\nThat\'s it! Push your changes to `.travis.yml` as well as `key.jks.enc`, and Jekyll should build your project.\n\n## Part B. Dummy files\n\nThis isn\'t entirely necessary, but you can use some fake "dummy" files to add to version control alongside the "real" encrypted ones. When Travis decrypts your encrypted files, they will be overwritten, but otherwise they serve as quite a nice substitute to prevent anyone from getting their hands on the real files (and to prevent you from uploading the real ones by accident). You can find a few (`key.jks`, `service.json`, and `secrets.tar`) in the sample project [here](/redirects/?t=github&d=TravisAndroidExample).\n\n## Part C. Signing the APK\n\nNow we want to actually use the key to sign our APKs. This requires a few changes to our app\'s build.gradle. Specifically, we need to specify a `signingConfig` that ONLY exists on Travis - we don\'t want our local builds (or the builds of other contributors) to be affected by this. Luckily, not only can we read environment variables from our `build.gradle` file using `System.getenv`, Travis automatically creates a nice "CI" variable to tell us that the build is happening in a Continuous Integration, so why don\'t we use that.\n\nFull credit, this solution was taken from [this wonderful article](https://android.jlelse.eu/using-travisci-to-securely-build-and-deploy-a-signed-version-of-your-android-app-94afdf5cf5b4) that describes almost the same thing that I have been explaining since the start of this article.\n\nI\'ll create three environment variables that will be used here: the keystore password as "keystore_password", the keystore alias as "keystore_alias", and the alias\'s password as "keystore_alias_password". Note that special characters cannot be used in these either.\n\n```\nandroid {\n    ...\n    signingConfigs {\n        release\n    }\n    buildTypes {\n        release {\n            ...\n            signingConfig signingConfigs.release\n        }\n    }\n\n    def isRunningOnTravis = System.getenv("CI") == "true"\n    if (isRunningOnTravis) {\n        signingConfigs.release.storeFile = file("../key.jks")\n        signingConfigs.release.storePassword = System.getenv("keystore_password")\n        signingConfigs.release.keyAlias = System.getenv("keystore_alias")\n        signingConfigs.release.keyPassword = System.getenv("keystore_alias_password")\n    }\n}\n```\n\nOf course, Travis isn\'t currently building a release variant (I think it defaults to `./gradlew build`), so this `signingConfig` won\'t be applied. We need to change that. Add the following to your `.travis.yml`...\n\n```yaml\nscript:\n  - ./gradlew assembleRelease\n```\n\nNow it will create a proper release using these signing configs. Push everything to git and it should build a properly signed APK. Yay.\n\n# Step 3. Deploying to github releases\n\nThis part is fairly simple, as Travis provides its own deployment functionality for this purpose. According to [their documentation](https://docs.travis-ci.com/user/deployment/releases/), for the bare minimum functionality all that you will need is to add the following to your `.travis.yml`...\n\n```yaml\ndeploy:\n  - provider: releases\n    api_key: "GITHUB OAUTH TOKEN"\n    file: app/build/outputs/apk/release/*\n    file_glob: true\n    skip_cleanup: true\n    on:\n        tags: true\n```\n\nNow, you _could_ follow this exactly and place your GitHub token directly in your `.travis.yml`, but that\'s just asking for trouble. Luckily, you can use MORE ENVIRONMENT VARIABLES! Enter your API key with the name ex. "GITHUB_TOKEN", and write `api_key: "$GITHUB_TOKEN"` instead.\n\nThis should now create a release with a built (and signed) APK each time there is a new tag. Fair enough; all you have to do for it to deploy is create a new tag.\n\n## Part A. Creating tags\n\nWhat if you\'re lazy like me, though? What if you want to create a new release on each push to the master branch? (I have two branches in most of my projects, `develop` and `master`, for this purpose - only the commits currently in production are in the `master` branch)\n\nA simple modification to the `on` section of the previous snippet does the trick.\n\n```yaml\ndeploy:\n    ...\n    on:\n        branch: master\n```\n\nWell, it almost does the trick. The thing is, since we haven\'t created a tag, Travis doesn\'t know what version number we want to use. It just creates a new release using the commit hash as a title. That isn\'t very good. I wonder if we could somehow get the version number from our build.gradle file and use that instead...\n\n## Part B. Version numbers\n\nLet\'s write a gradle task to print our version number! Place the following in your app\'s `build.gradle`.\n\n```\ntask printVersionName {\n    doLast {\n        println android.defaultConfig.versionName\n    }\n}\n```\n\nNow when you run `./gradlew :app:printVersionName`, your version name should be printed in the console. Now all we have to do is use this in our deployment.\n\nJust as there is a `before_install` section of our `.travis.yml`, there is also a `before_deploy`. As such, we can add the following:\n\n```yaml\nbefore_deploy:\n  - export APP_VERSION=$(./gradlew :app:printVersionName)\n```\n\nThis creates an environment variable ("APP_VERSION") containing our app\'s version name, which we can then reference from the actual deployment as follows...\n\n```yaml\ndeploy:\n  - provider: releases\n    api_key: "$GITHUB_TOKEN"\n    file: app/build/outputs/apk/release/*\n    file_glob: true\n    skip_cleanup: true\n    overwrite: true\n    name: "$APP_VERSION"\n    tag_name: "$APP_VERSION"\n    on:\n        branch: master\n```\n\nYay! Now we have fully automated releases on each push to master. Because of the `overwrite` parameter, it will overwrite existing releases if the version number has not been changed (a new release will be created if it has), so they will always be up to date.\n\n# Step 4. Deploying to the Play Store\n\nTravis doesn\'t have a deployment for the Play Store, so we will have to use a third party tool. I found [Triple-T/gradle-play-publisher](https://github.com/Triple-T/gradle-play-publisher/), which should work, except there isn\'t an option to deploy an existing APK without building the project. Not only would a deployment that requires building a project _twice_ be super wasteful and take... well, twice as long, [I ran into problems signing the APK](https://jfenn.me/redirects/?t=twitter&d=status/1061620100409761792) when I tried it, so... let\'s not. Instead, we\'ll modify the `script` to run the `./gradlew publish` command when a build is triggered from the master branch.\n\n## Part A. Setup\n\nSetup is fairly simple; just follow the directions in the plugin\'s readme. However, what should we do with the JSON file? PLEASE DO NOT ADD IT TO GIT. ANYONE WITH THIS FILE HAS ACCESS TO YOUR PLAY CONSOLE. WE\'RE ENCRYPTING IT.\n\nYou can either encrypt it as a separate file, or you can put them both in a tar (`tar -cvf secrets.tar key.jks service.json`), encrypt that, and run `tar -xvf secrets.tar` once it has been decrypted. I am not sure if either will affect how secure they are. I have opted for the tar method as it gives me less things to keep track of.\n\n## Part B. Publishing\n\nNow we can modify the `script` section of our `.travis.yml` to run the `./gradlew publish` command when a build is triggered from the master branch. This can be done using the "TRAVIS_BRANCH" environment variable which Travis handily creates for us. In other words...\n\n```yaml\nscript:\n  - if [ "$TRAVIS_BRANCH" = "master" ]; then ./gradlew publish; else ./gradlew build; fi\n```\n\nThis should build a signed APK and upload it to the Play Store whenever a push is made to the `master` branch, then deploy the same APK to GitHub if it was built successfully. Important to note that using this method, the build will also fail if it has failed to upload the APK to the Play Store - so it _might_ not be an issue with your project if it results in a failure unexpectedly.\n\n## Part C. Changelogs\n\nNow, gradle-play-publisher requires you to specify a changelog at `app/src/main/play/release-notes/en-US/default.txt` for it to publish an APK. What if we want to use the same changelog for GitHub releases? We\'ll add another line to the `before_deploy` section and GitHub deployment to do so.\n\n```yaml\nbefore_deploy:\n    ...\n  - export APP_CHANGELOG=$(cat app/src/main/play/release-notes/en-US/default.txt)\ndeploy:\n  - provider: releases\n    ...\n    body: "$APP_CHANGELOG"\n```\n\n# Finish\n\nHopefully this blog has gone over the basics of using Travis to deploy to GitHub and the Play Store. In later blogs, I hope to also cover how to implement UI and Unit tests, though I have yet to actually use them myself so I cannot yet write an article about them.\n\nIf you would like to see a working example of all of this, you can find it in a sample project [here](https://jfenn.me/redirects/?t=github&d=TravisAndroidExample).\n',
		},
		{
			title: "TypeScript Intermediates - Type Generics",
			description:
				"An introduction to the type generic functionality in TypeScript",
			published: "2019-09-26T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["typescript"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "typescript-type-generics",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "TypeScript Intermediates - Type Generics",
				description:
					"An introduction to the type generic functionality in TypeScript",
				published: "2019-09-26T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["typescript"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nWhile working in various projects, you may come across a weird looking syntax in the codebase: `<>`. No no, not JSX, we're of course talking about type generics. They'll appear next to function calls (`callFn<T>()`), TypeScript types (`Array<any>`), and more.\n\n_Type generics are a way to handle abstract types in your function._ **They act as a variable for types in that they contain information about the way your types will function.** They're very powerful in their own right, and their usage is not just restricted to TypeScript. You'll see many of these concepts applied under very similar terminologies in various languages. Enough on that, however. Let's dive into how to use them! 🏊‍\n\n# The Problem {#generic-usecase-setup}\n\nType generics — on the highest level — _allow you to accept arbitrary data instead of strict typing, making it possible to broaden a type's scope_.\n\nFor example, what if you wanted to make a function that took an argument of `returnProp` and returned the `returnProp` value itself ([the formal name for a function like this is an **identity function**](https://en.wikipedia.org/wiki/Identity_function))? Without type generics, providing a typing for a function like this could be difficult.\n\nTake the following implementation and consider its limitations:\n\n```typescript\nfunction returnProp(returnProp: string): string {\n\treturn returnProp;\n}\n\nreturnProp('Test'); // ✅ This is fine\nreturnProp(4); // ❌ This would fail as `4` is not a string\n```\n\nIn this case, we want to make sure that every possible input type is available for the prop type. Let's take a look at a few potential solutions, with their various pros and cons, and see if we can find a solution that fits the requirements for providing typing for a function like this.\n\n## Potential Solution 1: Unions {#generic-usecase-setup-union-solution}\n\nOne potential solution to this problem might be TypeScript unions. _Unions allow us to define an `or` condition of sorts for our types_. As we want to allow various types for inputs and outputs, perhaps that can help us here!\n\nUsing this method, if we wanted to accept numbers, we could add that as a union:\n\n```typescript\nfunction returnProp(returnProp: string | number): string | number {\n\treturn returnProp;\n}\n\nreturnProp('Test'); // ✅ This is fine\nconst shouldBeNumber = returnProp(4); // ✅ This won't show errors now\n```\n\nHowever, unions have some limitations. You'll find that this doesn't give the example you might want:\n\n```typescript\n// ❌ This will yield an error\n// > Operator '+' cannot be applied to types '4' and 'string | number'.\nconst newNumber = shouldBeNumber + 4;\n```\n\nThe reason that the operation `shouldBeNumber + 4` yields this error is because you've told TypeScript that `shouldBeNumber` is either a number **or** a string by making the output explicitly typed as a union. As a result, TypeScript is unable to do addition between a number and a string (which is one of the potential values) and therefore throws an error.\n\n### Potential Solutions Disclaimer {#silly-examples-disclaimer}\n\n> Author's note:\n>\n> If you were using unions in your property definitions and left your return type blank, TypeScript would be able to infer what the return type should be just fine.\n>\n> That said, we're trying to build on concepts, so we're trying to provide some examples of where this might be used and what it does. There are also instances, such as type definition files, where this inference might not be available to an author of typings, as well as other limitations with this method that we'll see later.\n\n## Potential Solution 2: Function Overloading {#generic-usecase-setup-overloading-solution}\n\nIn order to get around the issues with explicitly returning a union, you _COULD_ utilize function overloading to provide the proper return typings:\n\n```typescript\nfunction returnProp(returnProp: number): number;\nfunction returnProp(returnProp: string): string;\n// While this seems repetitive, TS requires it.\n// Otherwise, it will complain:\n// This overload signature is not compatible with its implementation signature.\nfunction returnProp(returnProp: string | number): string | number {\n\treturn returnProp;\n}\n```\n\nThat said, in addition to having some obnoxious duplicated type information, this method also has its limitations.\n\nFor example, if we wanted to pass in an object of some kind (such as `{}`, a simple empty object), it would be invalid:\n\n```typescript\nreturnProp({}) // Argument of type '{}' is not assignable to parameter of type 'string'.\n```\n\nThis may seem obvious from the typings, but _we ideally want `returnProp` to accept ANY type because **we aren't using any operations that require knowing the type**._ (no addition or subtraction, requiring a number; no string concatenation that might restrict an object from being passed).\n\n## Potential Solution 3: Any {#generic-usecase-setup-any-solution}\n\nOf course, we could use the `any` type to force any input and return type. (Goodness knows I've had my fair share of typing frustrations that ended with a few `any`s in my codebase!)\n\nAlthough this would allow any input type, we'd also be losing any type information between the input and output. As a result our types would be too loose on the return type:\n\n```typescript\nfunction returnSelf(returnProp: any): any {\n\treturn returnProp;\n}\n\nconst returnedObject = returnSelf({objProperty: 12}); // This now works! 🎉\n\nreturnedObject.test(); // This will not return an error but should 🙁\nreturnedObject.objProperty; // This will also (correctly) not throw an error, but TS won't know it's a number ☹️\n```\n\n# The Real Solution {#generics-intro}\n\nSo what's the answer? How can we get preserved type data on both the input and the output??\n\nThe solution is... Well, you've read the title I'm sure.\n\n_Type generics allow us to store loose type data in a **type variable**_. A type variable is _a unique kind of variable that's not exposed to JavaScript but is instead handled by TypeScript to provide expected typing data_. For example, the above example could be rewritten as:\n\n```typescript\nfunction returnSelf<T>(returnProp: T): T {\n\treturn returnProp;\n}\n```\n\nIn this example, we're defining a type variable `T`, then telling TS that both the property and the return type should be the same type.\n\nThis means that you can use the function like this:\n\n```typescript\nconst numberVar = returnSelf(2); // T in this instance is `2`, so it's similar to writing `const numberVal: 2 = 2;`\n\n// Likewise, this object is now returned as if it was just placed on the const\nconst returnedObject = returnSelf({objProperty: 12});\n\n// This will fail, as expected\nreturnedObject.test();\n// This will exist, and TS will know it as a number\nreturnedObject.objProperty;\n```\n\n> Author's note:\n>\n> The type variable does not need to be called `T`. In fact, while it seems to be commonplace for the community to use single-letter type variable names (often due to the length and complexity of the typings), there are many reasons why more explicit type names should be used.\n>\n> Remember, type variables are like other variables in that you need to maintain them and understand what they're doing in your code.\n\n# Okay, but Why? {#logger-example}\n\nWhy might we want to do this? [Returning an item as itself in an identity function](#generic-usecase-setup) is cool, but it's not very useful in its current state. That said, there **are** many, many uses for generics in real-world codebases.\n\nFor example, let's say that we had the following JavaScript code that we wanted to use as a logger:\n\n```javascript\nconst util = require('util'),\n\tfs = require('fs');\n\n// Have the `writeFile` return a promise instead of having to use a callback\nconst writeFileAsync = util.promisify(fs.writeFile);\n\n/**\n * Async functions allows us to use `await` on promises in the function body, try/catch them, and\n * will return their own promise wrapped around the `return` value\n */\nasync function logTheValue(item) {\n\tconst jsonString = JSON.stringify(item, null, 2);\n\n\tlet err = undefined;\n\n\ttry {\n\t\t// Attempt to write a new log file. If this fails, save the error to the `err` variable\n\t\tawait writeFileAsync(`/logs/${Date.now()}`, jsonString);\n\t// Catch any errors and keep them as the `e` variable to assign to `err` later\n\t} catch (e) {\n\t\terr = e;\n\t}\n\n\treturn {\n\t\tloggedValue: jsonString,\n\t\toriginal: item,\n\t\t// If there was no error, return `undefined` here\n\t\terr: err\n\t}\n}\n```\n\nIf we wanted to type the `logTheValue` function, we'd want to make sure to use a type generic for the input parameter `item`. By doing so, we could use that same generic for the return prop of `loggedValue` to ensure they both have the same typing. To do this, we could do so inline:\n\n```typescript\n// Because this is an `async` function, we want to wrap the returned type value in a Promise\nasync function logTheValue<ItemT>(item: ItemT): Promise<{loggedValue: string, original: ItemT, err: Error | undefined}> {\n\t// ... Function body here\n}\n```\n\nAlternatively, we could utilize another feature of generics — the ability to pass the type value of the generic manually — and make an interface with a generic and do so there:\n\n```typescript\ninterface LogTheValueReturnType<originalT> {\n\tloggedValue: string;\n\toriginal: originalT;\n\terr: Error | undefined;\n}\n\n// Notice how we're even wrapping that interface in a built-in type with a generic argument for `Promise`!\nasync function logTheValue<ItemT>(item: ItemT): Promise<LogTheValueReturnType<ItemT>> {\n\t// ... Function body here\n}\n```\n\nWith these few features, we're able to utilize much of the functionality of generics. \n\nHowever, I know I haven't answered what the `<>` really is for. Well, much like type variables, there's also the ability to pass types as \"type arguments\" when generics are applied to a function.\n\nAn example of this would be a syntax like this:\n\n```typescript\nlogTheValue<number>(3);\n```\n\n# Non-Function Generics {#non-function-generics}\n\nAs you saw before with the `LogTheValueReturnType` interface — functions aren't the only ones with generics. In addition to using them within functions and interfaces, you can also use them in classes. \n\nClasses with generics can be particularly helpful for data structures like this:\n\n```typescript\n// DataType might want to be a base64 encoded string, a buffer, or an IntArray\nclass ImageType<DataType> {\n\tdata: DataType;\n\theight: number;\n\twidth: number;\n\n\tconstructor(data: DataType, height: number, width: number) {\n\t\tthis.data = data;\n\t\tthis.height = height;\n\t\tthis.width = width\n\t};\n}\n\nfunction handleImageBuffer(img: ImageType<Buffer>) {}\n```\n\nType generics in classes can be used as method argument and property types alike.\n\nThere's also the ability to use generics within `type` definitions:\n\n```typescript\ninterface ImageType<DataType> {\n\tdata: DataType;\n\theight: number;\n\twidth: number;\t\n}\n\ninterface ImageConvertMethods<DataType> {\n\t// This is the typing of a method. It will take a prop of the generic type and return the generic type\n\ttoPNG: (data: DataType) => DataType;\n\ttoJPG: (data: DataType) => DataType;\n}\n\n\ntype ImageTypeWithConvertMethods<DataType> = ImageType<DataType> & ImageConvertMethods<DataType>\n```\n\n# Okay, but why-_er_? {#polymorphic-functions}\n\nMy my, you don't seem to take my word for it when I tell you that type generics are useful. That's alright, I suppose; After all, doubt while learning can lead to some great questions! 😉\n\nType generics enable us to do things like provide typings for **polymorphic functions**. _Polymorphic functions are functions that can accept a myriad of different types and handle them differently._\n\n> Polymorphic functions are not unique to TypeScript; the things learned here about polymorphic functions can be applied to other languages as well. They also provide some real-world insight into the usages of generics and when they could be used.\n\nFor example, let's take a look at the code for the `toPNG`:\n\n```typescript\nfunction toPNG(data: DataType): DataType {\n\tif (Buffer.isBuffer(data)) {\n\t\treturn convertBufferToPNG(data);\n\t} else if (Array.isArray(data)) {\n\t\tconst imgBuffer = Buffer.from(data);\n\t\tconst pngBuffer = convertBufferToPNG(imgBuffer);\t\t\n\t\treturn Buffer.from(pngBuffer);\n\t// base64 encoded string\n\t} else if (typeof data === 'string') {\n\t\tconst imgBuffer = getBufferFromBaseStr(data);\n\t\tconst pngBuffer = convertBufferToPNG(imgBuffer);\n\t\treturn bufferToBase64(pngBuffer);\t\n\t} else {\n\t\tthrow 'toPNG only accepts arrays, buffers, or strings'\n\t}\n}\n```\n\nEven though this function accepts various data types, it handles them differently under the hood! Functions that have this type of \"accept many, handle each slightly differently\" behavior are called **Polymorphic Functions**. They're particularly useful in utility libraries.\n\n# Restricting The Types {#extends-keyword}\n\nUnfortunately, there's a problem with the above code: we don't know what type `DataType` is. Why does that matter? Well, if it's not a string, a Buffer, or an Array-like, it will throw an error! That's certainly not behavior to run into at runtime.\n\nLet's fix that typing:\n\n```typescript\nfunction toPNG<DataType extends (string | Array<number> | Buffer)>(data: DataType): DataType {\n\t// ...\n}\n```\n\nIn this example _we're using the `extends` keyword to enforce some level of type restriction in the otherwise broad definition of a type generic_. We're using a TypeScript union to say that it can be any one of those types, and we're still able to set the value to the type variable `DataType`.\n\n## Broaden Your Horizons {#imperative-casting-extends}\n\nWe're also able to keep that type restriction broad within itself. Let's say we had a function that only cared if an object had a specific property on it:\n\n```typescript\ninterface TimestampReturn<T> {\n\tisPast: boolean;\n\tisFuture: boolean;\n\tobj: T\n}\nconst checkTimeStamp = <T extends {time: Date}>(obj: T): TimestampReturn<T> => {\n\tlet returnVal: TimestampReturn<T> = {\n\t\tisPast: false,\n\t\tisFuture: false,\n\t\tobj\n\t}\n\t\n\tif (obj.time < Date.now()) {\n\t\treturnVal.isPast = true;\n\t} else {\n\t\treturnVal.isFuture = true;\n\t}\n\t\n\treturn returnVal;\n}\n\n```\n\nIn this case, we can rely on implicit type casting to ensure that we're able to pass `{time: new Date()}` but not `{}` as values for `obj`.\n\n# Conclusion\n\nAnd that's all I have for generics! Their usages are far and wide, and now you're able to apply your knowledge in code! We're hoping to have more posts on TypeScript soon - both more introductory and advanced. \n\nQuestions? Feedback? Sound off in the comments below; we'd love to hear from you!\n",
		},
		{
			title: "The Ultimate Windows Development Environment Guide",
			description:
				"Many developers like MacOS or Linux for development environments, but don't know that Windows has plenty to offer. Become a Windows pro!",
			published: "2020-04-07T05:12:03.284Z",
			edited: "2022-01-05T04:45:30.247Z",
			authors: ["crutchcorn"],
			tags: ["tools", "windows"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "ultimate-windows-development-environment-guide",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "The Ultimate Windows Development Environment Guide",
				description:
					"Many developers like MacOS or Linux for development environments, but don't know that Windows has plenty to offer. Become a Windows pro!",
				published: "2020-04-07T05:12:03.284Z",
				edited: "2022-01-05T04:45:30.247Z",
				authors: ["crutchcorn"],
				tags: ["tools", "windows"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				'\nAsk any developer running a Linux or MacOS machine, and they\'ll be able to tell you what makes their systems such a strong contender for software development. Some of the top contenders I\'ve heard are:\n\n- [Package management](#package-management)\n- [Terminal usage](#terminal-usage)\n- [Keyboard Usage](#keyboard-usage)\n- [Customization](#customization)\n- [Functionality](#functionality)\n\nWhat many don\'t know is that Windows has gained many of these options over the years. Between official tooling such as [WSL2](https://docs.microsoft.com/en-us/windows/wsl/wsl2-install) right around the corner to third-party offerings becoming more-and-more mature, there\'s never been a better time to be a developer on the Windows platform.\n\nMoreover, much of what we\'ll be taking a look at today is either free, open-source, or both! There will be a few mentions of paid software as alternatives to the free options, but I\'ve personally used every piece of commercial software in this article. None of the paid software we mention here has been included as part of a sponsorship or financial deal in any way, I just like them and use them myself.\n\n# Package Management {#package-management}\n\nWhen it comes to CLI package management on Windows, you have two main choices:\n\n- [Chocolatey](https://chocolatey.org/) - a third party package manager that\'s been around since 2011\n- [`winget`](https://github.com/microsoft/winget-cli) - Microsoft\'s official CLI package manager as-of 2020\n\nBoth of them are incredibly polished and ready-to-use today. While `winget` is Microsoft\'s official solution, Chocolatey works on a wider range of systems (back to Windows 7) and more packages.\n\nLet\'s look through both.\n\n## Winget {#winget}\n\nOne of the strongest advantages of `winget` is that it\'s built right into all builds of Windows 11 and most newer builds of Windows 10. \n\nWhat\'s more, you don\'t need to be in an elevated admin shell to install packages. Instead, installers will individually ask you to accept the dialog to give admin rights.\n\nYou can start by searching for a package using `winget search` followed by the name of the package you\'re looking for.\n\n```\nwinget search OBS\n```\n\n![Winget searching for OBS Studio and showing two results](./winget_search.png)\n\nThen, once you\'ve found an `Id` you want to install, simply type it in as `winget install`:\n\n```\nwinget install OBSProject.OBSStudio\n```\n\nYou can see a list of all packages installed using `winget` with the following command:\n\n`winget list`\n\nFinally, you can upgrade all of your `winget` installed packages simply by running:\n\n`winget upgrade --all`\n\n## Chocolatey {#chocolatey}\n\n[Chocolatey only takes a single PowerShell command to install](https://chocolatey.org/install), not unlike [Homebrew for macOS](https://brew.sh/). The comparisons with Homebrew don\'t stop there either. Much like it\'s *nix-y counterparts, Chocolatey is an unofficial repository of software that includes checks of verification for a select number of popular packages.\n\nIt\'s also popular amongst sysadmins due to its ease of deployment across multiple devices and stability.\n\nYou\'ll need to run it in an administrator window, but once you do, you\'ll find the utility straightforward. A simple `choco search package-name` will find related packages to the name you input where areas `choco install package-name` will install the package.\n\nYou can also use `choco list --local-only` to see a list of all locally installed packages. \n\nFinally, `choco upgrade all` will upgrade all locally installed packages.\n\n### Manage Packages via GUI {#chocolatey-gui}\n\nReaders, I won\'t lie to you. I\'m not the kind of person to use a CLI for everything. I absolutely see their worth, but remembering various command is simply not my strong suit even if I understand the core concepts entirely. For people like me, you might be glad to hear that _Chocolatey has a GUI for installing, uninstalling, updating, and searching packages_. It\'s as simple as (Chocolate) pie! More seriously, installing the GUI is as simple as:\n```\nchoco install ChocolateyGUI\n```\n\n![A list of installed software via the Chocolatey GUI](./choco_gui_list.png)\n\nYou can see that it gives a list of installed packages with a simple at-glance view of what packages need updating.\n\n![A search result of the Chocolatey GUI](./choco_gui_search.png)\n\n## Suggested Packages {#suggested-packages}\n\nWhile Chocolatey has a myriad of useful packages for developers, there are some that I have installed on my local machine that I\'d like to highlight in particular.\n\nFor starters, what\'s a developer machine without `git`? Let\'s throw that on:\n\n```\nchoco install git.install\n```\n\nAdditionally, I know a lot of developers would like to have access to common GNU utilities, such as `rm` and `touch`. Using an install flag, you\'re able to add those to your path and put them to work for you:\n\n```\nchoco install git.install--params "/GitAndUnixToolsOnPath"\n```\n\n### CLI Utilities {#cli-packages}\n\n| Name                                              | Choco Package | Winget Package | Explanation                                                  |\n| ------------------------------------------------- | ------------- | -------------- | ------------------------------------------------------------ |\n| [Micro Editor](https://github.com/zyedidia/micro) | `micro`       | N/A            | A great terminal editor (ala Nano). It even supports using the mouse! |\n| [Bat](https://github.com/sharkdp/bat)             | `bat`         | N/A            | A great alternative to `cat` with line numbers and syntax highlighting |\n| [GitHub CLI](https://cli.github.com/)             | `gh`          | `GitHub.cli`   | GitHub\'s official CLI for managing issues, PRs, and more     |\n| [NVM](https://github.com/coreybutler/nvm-windows) | `nvm`         | N/A            | "Node version manager" - Enables users to have multiple installs of different Node versions and dynamically switch between them |\n| [Yarn](https://yarnpkg.com/)                      | `yarn`        | `Yarn.Yarn`    | An alternative to `npm` with better monorepo support. If installed through `choco`, it will support `nvm` switching seamlessly. |\n\nYou\'re able to install all of these packages using `choco`:\n\n```\nchoco install micro bat gh nvm yarn\n```\n\nOr, the ones supported by `winget`:\n\n```\nwinget install --id=GitHub.cli -e  && winget install --id=Yarn.Yarn -e \n```\n\n### IDEs {#ides}\n\n| Name                                                        | Choco Package                                                | Winget Package                                               | Explanation                                                |\n| ----------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------------------------------- |\n| [Visual Studio Code](https://code.visualstudio.com/)        | `vscode`                                                     | `Microsoft.VisualStudioCode`                                 | Popular Microsoft IDE for many languages                   |\n| [Sublime Text](https://www.sublimetext.com/)                | `sublimetext4`                                               | `SublimeHQ.SublimeText.4`                                    | Popular text editor with syntax support for many languages |\n| [Visual Studio](https://visualstudio.microsoft.com/)        | `visualstudio2019professional` / `visualstudio2019community` | `Microsoft.VisualStudio.2019.Professional` / `Microsoft.VisualStudio.2019.Community` | Microsoft\'s flagship IDE                                   |\n| [Jetbrains Toolbox](https://www.jetbrains.com/toolbox-app/) | `jetbrainstoolbox`                                           | `JetBrains.Toolbox`                                          | The installer/updater for JetBrains\' popular IDEs          |\n\nYou\'re able to install all of these packages using `choco`:\n\n```\nchoco install vscode sublimetext3 visualstudio2019community jetbrainstoolbox\n```\n\nOr, with `winget`:\n\n```\nwinget install --id=Microsoft.VisualStudioCode -e && winget install --id=SublimeHQ.SublimeText.4 -e && winget install --id=Microsoft.VisualStudio.2019.Community -e && winget install --id=JetBrains.Toolbox -e \n```\n\n### Others {#utilities}\n\n| Name                                                        | Choco Package                              | Winget Package                                    | Explanation                                                  |\n| ----------------------------------------------------------- | ------------------------------------------ | ------------------------------------------------- | ------------------------------------------------------------ |\n| [PowerToys](https://github.com/microsoft/PowerToys)         | `powertoys`                                | `Microsoft.PowerToys`                             | Built by MS itself, provides SVG/Markdown previews, provides utility for mass renaming, image resizing all from the file explorer itself. It also allows you to configure tiling and more. We\'ll talk about this more later |\n| [Ext2Fsd](https://sourceforge.net/projects/ext2fsd/)        | `ext2fsd`                                  | N/A                                               | A program that enables you to read/write from ex2/ex3/ex4 formatted filesystems |\n| [VirtualBox](https://www.virtualbox.org/)                   | `virtualbox`                               | `Oracle.VirtualBox`                               | A program that allows you to create, run, and edit virtual machines |\n| [VirtualBox Guest Additions](https://www.virtualbox.org/)   | `virtualbox-guest-additions-guest.install` | N/A                                               | The extension to `virtualbox` that provides better USB passthrough support |\n| [FiraCode](https://github.com/tonsky/FiraCode)              | `firacode`                                 | N/A                                               | A popular programming font that supports ligatures           |\n| [`scrcpy`](https://github.com/Genymobile/scrcpy)            | `scrcpy`                                   | N/A                                               | A utility that allows you to mirror your Android phone screen via ADB |\n| [Typora](https://typora.io/)                                | `typora`                                   | `Typora.Typora`                                   | A paid markdown editor with a "preview edit" mode allowing you to edit markdown files similarly to Word |\n| [Postman](https://www.postman.com/)                         | `postman`                                  | `Postman.Postman`                                 | A REST API tester                                            |\n| [Firefox](https://www.mozilla.org/en-US/firefox/new/)       | `Firefox`                                  | `Mozilla.Firefox`                                 | The popular web browser by Mozilla                           |\n| [Licecap](https://www.cockos.com/licecap/)                  | `licecap`                                  | `Cockos.LICEcap`                                  | A quick-and-easy GIF capture software                        |\n| [ScreenToGIF](https://www.screentogif.com/)                 | `screentogif`                              | `NickeManarin.ScreenToGif`                        | Another quick-and-easy GIF capture software with more software options |\n| [7Zip](https://www.7-zip.org/)                              | `7zip`                                     | `7zip.7zip`                                       | Compressed file format manager. Allows you to extract files from various formats |\n| [Java](https://www.oracle.com/java/technologies/downloads/) | `jdk` / `jre`                              | `Oracle.JDK.17` / `Oracle.JavaRuntimeEnvironment` | Java runtime and development kit                             |\n\nYou\'re able to install all of these packages using `choco`:\n\n```\nchoco install powertoys ext2fsd virtualbox virtualbox-guest-additions-guest.install firacode scrcpy typora postman Firefox licecap 7zip jdk jre\n```\n\nOr, the ones supported by `winget`:\n\n```\nwinget install --id=Microsoft.PowerToys -e && winget install --id=Oracle.VirtualBox -e && winget install --id=Typora.Typora -e && winget install --id=Postman.Postman -e && winget install --id=Mozilla.Firefox -e && winget install --id=Cockos.LICEcap -e && winget install --id=NickeManarin.ScreenToGif -e && winget install --id=7zip.7zip -e && winget install --id=Oracle.JDK.17 -e && winget install --id=Oracle.JavaRuntimeEnvironment -e\n```\n\n### Missing from the List {#awesome-windows}\n\nDidn\'t see your favorite utilities or tools? Unfortunately, I only can highlight a few options. That said, there\'s no shortage of utilities, tools, and customization options for Windows. A great collection of utilities to look through would be [the Awesome Windows list](https://github.com/Awesome-Windows/Awesome). At the time of writing, it includes over 300 programs with a short description and a link learn more.\n\n## Microsoft Store {#microsoft-store}\n\nI\'m sure some avid Microsoft fans will have pointed out by now that I forgot something. You know, the official solution by Microsoft? Naturally, I haven\'t forgotten about the Microsoft Store.\n\nWhile some of you may be surprised to hear this, the Microsoft Store has put together a pretty good catalogue of development tools on its storefront. For example, there\'s now a package for Python right on the Microsoft Store. You\'re also able to get quick updates for all of your apps and seamlessly integrate them as if they were typical windows apps.\n\n![A preview of the "Downloads and updates" tab in the Microsoft Store](./windows_store_update.png)\n\n# Terminal Usage {#terminal-usage}\n\nThe terminal is essential for most developers. It\'s a relatively universal utility regardless of what form of programming you\'re into. It\'s important to make sure that your terminal is fully featured  both for functionality and so the user can customize to their taste.\n\n## Terminal Emulators {#terminals}\n\nOne of the most important elements to one\'s experience with the terminal is, well, the terminal itself! While Windows has not historically had many options in this regard, things have turned around in recent years. Additional to the built-in CMD and PowerShell applications, we now have many newcomers, including one from Microsoft itself.\n\nFirst, let\'s start with the third party offerings. We have many options, but the two I want to highlight is `Cmder` and `Terminus`.\n\n### Cmder {#cmder}\n\n[Cmder is an open-source terminal offering](https://github.com/cmderdev/cmder) built on top of a long-standing base called [ConEmu](https://conemu.github.io/). Not only is it a terminal window for you to interface with, but it provides a massive set of configurations. It not only provides configurations for the CMD shell backend but for PowerShell as well, meaning you can freely switch between them (and WSL) to suit your current needs. These configurations can even be used without having to utilize the terminal window. I think the config makes the terminal much more useful and pretty. For example, this is the default view of Cmder:\n\n![A preview of the cmder terminal open on the UU repo](./cmder.png)\n\nAs you can see, there\'s some custom logic for embedding Git metadata in the prompt, a custom `λ` prompt, and even contains some logic for more effective tab autocomplete. You\'re even able to install it via Chocolatey using `choco install cmder`! \n\nThe terminal itself contains all kinds of functionality:\n\n- Multi-line copy+paste\n- Tiling\n- Tabs\n- Customizable UI\n\nThose are just the features I can think of off the top of my head! What\'s nice about Cmder is that even if you don\'t use the terminal itself, you can use the configurations for CMD and PowerShell with other shells if you like. All of the screenshots for the other terminals will be shown using the Cmder configs.\n\n### Terminus {#terminus}\n\nTerminus is another excellent option for those looking for alternative terminal shells. Because it\'s rendered using web tech, it\'s UI is much more customizable. It also has an easy-to-install plugin system to add further functionality to the shell. What you\'re seeing is the initial out-of-the-box experience [with the Cmder configuration applied](https://github.com/cmderdev/cmder/wiki/Seamless-Terminus-Integration)\n\n![A preview of the Terminus shell with the Cmder config](./terminus.png)\n\n### Windows Terminal {#windows-terminal}\n\nLast, but certainly not least, we have the newly-introduced Windows Terminal. This is the new terminal that\'s built by Microsoft itself. [The project is open-source](https://github.com/microsoft/terminal) and is available now [via the Microsoft Store](https://aka.ms/windowsterminal). In fact, in Windows 11, this terminal is now built-in and acts as the default terminal emulator.\n\n![A preview of the Windows Terminal](./windows_terminal.png)\n\nThis terminal shell has been the most stable in my experience. It supports tabs, a highly customizable UI, and supports using multiple terminal applications in different tabs.\n\n#### Cmder Integration {#windows-terminal-cmder}\n\nWhile Cmder integration with Windows Terminal is relatively trivial, it\'s not very well documented. Let\'s walk through how to get it up and running.\n\nYou\'ll want to start by making sure you have an environmental variable called `cmder_root`. This should be set up by default if you installed it using `choco`, but if you\'re unsure, you can check manually. [We outline how to set environmental variables in this article](#env-variables).\n\nOnce we\'re sure that we have the configuration setup properly, we\'ll open up the settings file in Windows Terminal by pressing the dropdown button and selecting "Settings."\n\n![A preview of the Settings button](./windows_terminal_setting.png)\n\nOnce this is done, update your `cmd` setting to have the following `commandline` config property:\n\n```json\n"commandline": "cmd.exe /k %cmder_root%/vendor/init.bat",\n```\n\nYou can even do so for PowerShell:\n\n```json\n"commandline": "powershell.exe -ExecutionPolicy Bypass -NoLogo -NoProfile -NoExit -Command \\"Invoke-Expression \'Import-Module \'\'%cmder_root%/vendor/profile.ps1\'\'\'\\"",\n```\n\nThis is what my `profiles` looks like all together:\n\n```json\n"profiles": [\n    {\n        "guid": "{5b4ef9a8-4506-4ac9-930a-5eb1fd0ebf20}",\n        "name": "Cmder",\n        "commandline": "cmd.exe /k %cmder_root%/vendor/init.bat",\n        "icon": " %cmder_root%/icons/cmder.ico",\n        "hidden": false,\n        "startingDirectory": "%USERPROFILE%/git"\n    },\n    {\n        "guid": "{61c54bbd-c2c6-5271-96e7-009a87ff44bf}",\n        "name": "Windows PowerShell",\n        "commandline": "powershell.exe -ExecutionPolicy Bypass -NoLogo -NoProfile -NoExit -Command \\"Invoke-Expression \'Import-Module \'\'%cmder_root%/vendor/profile.ps1\'\'\'\\"",\n        "hidden": false,\n        "startingDirectory": "%USERPROFILE%/git",\n    },\n],\n```\n\nFinally, if you want to set one of these profiles as default (I wanted to make my new PowerShell config default), you can update the `defaultProfile ` parameter at the top of the file. Mine looked like this:\n\n```json\n"defaultProfile": "{61c54bbd-c2c6-5271-96e7-009a87ff44bf}",\n```\n\n#### Color Configuration {#windows-terminal-colors}\n\nWindows Terminal also supports text and background color customization, among other things. The color settings I used for the screenshot above is the Dracula color theme.  You can add that color theme by adding the following to the `schemes` array in the `profiles.json` file:\n\n```json\n"schemes": [\n    {\n        "name" : "Dracula",\n        "background" : "#282A36",\n        "black" : "#21222C",\n        "blue" : "#BD93F9",\n        "brightBlack" : "#6272A4",\n        "brightBlue" : "#D6ACFF",\n        "brightCyan" : "#A4FFFF",\n        "brightGreen" : "#69FF94",\n        "brightPurple" : "#FF92DF",\n        "brightRed" : "#FF6E6E",\n        "brightWhite" : "#FFFFFF",\n        "brightYellow" : "#FFFFA5",\n        "cyan" : "#8BE9FD",\n        "foreground" : "#F8F8F2",\n        "green" : "#50FA7B",\n        "purple" : "#FF79C6",\n        "red" : "#FF5555",\n        "white" : "#F8F8F2",\n        "yellow" : "#F1FA8C"\n    }\n],\n```\n\nThen, for each of the profiles you want to have that color scheme, add the following property:\n\n```\n"colorScheme": "Dracula"\n```\n\nResulting in the following for my PowerShell config:\n\n```json\n{\n    "guid": "{61c54bbd-c2c6-5271-96e7-009a87ff44bf}",\n    "name": "Windows PowerShell",\n    "commandline": "powershell.exe -ExecutionPolicy Bypass -NoLogo -NoProfile -NoExit -Command \\"Invoke-Expression \'Import-Module \'\'%cmder_root%/vendor/profile.ps1\'\'\'\\"",\n    "hidden": false,\n    "startingDirectory": "%USERPROFILE%/git",\n    "colorScheme": "Dracula"\n}\n```\n\n### Comparisons {#compare-different-terminals}\n\nWhile each of the three terminals offers something different, they each have their own set of pros and cons. Here\'s how I see it:\n\n- [Cmder](#cmder) has the most features of the three. It has so many features that I have not used most of them. That said, it has been known to crash on me from time-to-time.\n- [Terminus](#terminus) is by far the best looking and most configurable of the three. I have even written custom CSS to style every aspect of the terminal before. It\'s easy to do. That said, I\'ve suffered even greater instability and general lack of integration polish (resizing a window has negative impacts, namely) than Cmder.\n- [Windows Terminal](#windows-terminal)\'s weakest link currently is it\'s lack of features. At the moment, it doesn\'t have many of the same conveniences that you might miss from the other two options. That said, between the three, I\'d say it\'s by far the most stable. Additionally, it\'s under heavy development, and the team behind it is moving fast. This is the terminal I use daily, armed with the configuration from Cmder.\n\nI only outlined three terminal emulators here. They are my favorites; I\'ve used them and know they are great terminal solutions, but there are plenty of other options out there. Some of the honorable mentions include:\n\n- [Fluent Terminal](https://github.com/felixse/FluentTerminal)\n- [Hyper Terminal](https://hyper.is/)\n\n## Terminal Styling {#terminal-styling}\n\nAnyone that\'s used `ohmyzsh` on Mac or Linux before can tell you that customizing your terminal shell doesn\'t just stop at picking an emulator.\n\nIn fact, regardless of your emulator, you have a wide swath of customization options such as:\n\n- Various display colors\n- Icons on your path string\n- Spacing between commands\n\n[While some terminals have a quick single (or zero) config change to add some fancy styling](#windows-terminal-cmder), you can have full control over your terminal styling.\n\n### OhMyPosh {#oh-my-posh}\n\nOne option to customize your windows shell styling is [OhMyPosh](https://ohmyposh.dev/). Named after the similarly powerful [`OhMyZSH`](https://ohmyz.sh/), it allows you to have themes you can utilize for both PowerShell and CMD alike.\n\nFor example, this is [my terminal theme](https://github.com/crutchcorn/dotfiles/blob/master/.myposh.json) that\'s being used in PowerShell\n\n![My PowerShell terminal with an emoji at the start and a plethora of colors and arrows. It\'s running `wsl exa -l`](./my_terminal_example.png)\n\n> That emoji at the start? That\'s randomized on every shell start with a preselected list of emoji. Pretty 🔥 if you ask me.\n\n### Powerline Fonts {#powerline-fonts}\n\nOnce setting up OhMyPosh in CMD/PowerShell or OhMyZSH in WSL, you may notice that your terminal display looks weird with some themes:\n\n![A preview of ZSH theme "agnoster" without a proper font installed](./no_powerline.png)\n\nTo get some of these themes working properly, you may need to install a [powerline](https://github.com/ryanoasis/powerline-extra-symbols) enabled font. You have a few options to do this. \n\nYou can do so by [cloning this repository using PowerShell](https://github.com/powerline/fonts). Then `cd fonts` and `./install.ps1`. This script will install all of the fonts one-by-one on your system, fixing the font issues in your terminal. Find which font is your favorite and remember the name of it.\n\nAlternatively, [Microsoft has made a custom font themselves that supports powerline symbols](https://github.com/microsoft/cascadia-code/releases?WT.mc_id=-blog-scottha). To use that font, simply download the `CascadiaPL.ttf` file and install it.\n\nThe final step is to configure your terminal editor to use the new font. Let\'s use the Windows Terminal as an example. Open your settings and inject `"fontFace":  "Cascadia Code PL"` into one of the profiles. The final result should look something like this:\n\n```\n {\n     "guid": "{2c4de342-38b7-51cf-b940-2309a097f518}",\n     "hidden": false,\n     "name": "Ubuntu",\n     "source": "Windows.Terminal.Wsl",\n     "fontFace":  "Cascadia Code PL"\n }\n```\n\nThen, when you open the terminal, you should see the correct terminal display.\n\n![A preview of ZSH theme "agnoster" with the proper font installed](./powerline.png)\n\n\n\n## Make Configuration Changes {#terminal-system-config}\n\nWhile terminals are important, another factor to be considered is the configuration of those terminal shells. It\'s important to keep system-level configuration settings in mind as well. For example, if you need to [make or modify environmental variables](#env-variables) or [make changes to the system path](#env-path). Luckily for us, they both live on the same path. As such, let\'s showcase how to reach the dialog that contains both of these settings before explaining each one in depth.\n\n![Showing the dialog for "This PC" in explorer with the "Properties" option selected](./this_pc_properties.png)\n\nAfter this, select "Advanced system settings."\n\n![The previously mentioned setting highlighted](./about_computer_advanced.png)\n\nAfter this, a dialog should pop up. This dialog should contain as one of the lower buttons "Environmental variables," which is where settings for both environmental variables and path should live.\n\n![The "Environmental variables" button selected](./system_properties.png)\n\n![The "environmental variables" dialog](./environmental_variables_dialog.png)\n\n### Environmental Variables {#env-variables}\n\nWhen working with the CLI, it\'s often important to have environmental variables to customize the functionality of a utility or program. Because Windows has the concept of users, there are two kinds of environment variables that can be set:\n\n- User-specific\n- System-level\n\nEach of them follows their namesakes in their usage. If I set a user-specific environmental variable and change users, I will not receive the same value as the user I\'d set the variable for. Likewise, if I set it for the system, it will apply to all users. The top of the "environmental variables" section applies to the user-level, whereas the bottom level applies to the system. \n\nIn order to add a new one, simply select "New" on whichever level you want to create the environmental variables on. You should see this dialog appear:\n\n![The new user variable dialog](./new_user_var.png)\n\nSimply add the name of the variable and the value of the environmental variable to continue.\n\nYou\'re able to do the same with editing a variable. Simply find the variable, highlight it, then select "Edit" and follow the same process.\n\n### Adding Items to Path {#env-path}\n\nHave you ever run into one of these errors?\n\n- `The term \'program-name\' is not recognized as the name of a cmdlet, function, script file, or operable program.`\n- `\'program-name\' is not recognized as an internal or external command, operable program or batch file.`\n\nIt could be because you don\'t have the program attached to your system path. Your path is what dictates what scripts and programs you\'re able to access globally. For example, there\'s a tool that I like to use [to count the LOC I have in a given project: `scc`](https://github.com/boyter/scc). This project is incredibly useful for quick estimations for fun. The problem? It doesn\'t live on Chocolatey and doesn\'t have an MSI installer. This means that it\'s harder to access via the terminal. Well, no longer! [If I download the ZIP from the releases tab](https://github.com/boyter/scc/releases), and extract it, I\'ll see that it contains a file called `scc.exe`. If I move that folder to `C:\\tools\\scc` and add it to the path, then I can use it in the terminal as if it were any other global util.\n\n![The path that I extracted the scc.exe file to](./scc_path.png)\n\nIn order to add the file to the path, I need to edit the `path` environmental variable.\n\n> [Just as there are two sets of environmental variables](#env-path), there are two sets of `path` env variables. As such, you\'ll have to decide if you want all users to access a variable or if you want to restrict it to your current user. In this example, I\'ll be adding it to the system. \n\nFind the `path` environmental variable and select `"Edit."` \n\n![The path dialog value](./path_dialog.png)\n\n\n\nJust as before, you\'re able to delete and edit a value by highlighting and pressing the respective buttons to the left. Otherwise, you can press "new" which will allow you to start typing. Once you\'re done, you can press "OK" to save your new path settings.\n\n> In order to get SCC running, you may have to close and then re-open an already opened terminal window. Otherwise, running `refreshenv` often updates the path so that you can use the new commands.\n\n## Git Configurations {#git-config}\n\n### Editor {#git-editor}\n\nGit, by default, uses `vim` to edit files. While I understand and respect the power of `vim`, I have never got the hang of `:!qnoWaitThatsNotRight!qq!helpMeLetMeOut`. As such, I tend to change my configuration to use `micro`, the CLI editor mentioned in [the CLI packages section](#cli-packages). In order to do so, I can just run:\n\n``` \ngit config --global core.editor "micro"\n```\n\nHowever, we can go a step further. Let\'s say that we want the full power of VSCode when editing a file via Git - we can do that!\n\n```\ngit config --global core.editor "code --wait"\n```\n\n### Difftool {#git-difftool}\n\nNot only are you able to set VSCode as your editor for rebase messages, but [you can use it as your difftool as well](https://code.visualstudio.com/docs/editor/versioncontrol#_vs-code-as-git-diff-tool)!\n\nSimply edit your global git config (typically found under `%UserProfile%/.gitconfig`) to reflect the following:\n\n```\n[diff]\n  tool = default-difftool\n[difftool "default-difftool"]\n  cmd = code --wait --diff $LOCAL $REMOTE\n```\n\nAnd it should take care of the rest for you.\n\n### Line Endings {#git-line-endings}\n\nWhile most high-level language code is interoperable between different OSes, one of the primary differences between high-level codebases in Windows vs. macOS or Linux is the line-endings. As you might know, Windows uses `\\r\\n` line-ending where Linux and macOS end with `\\n`.\nLuckily for us, Git can automatically convert the Windows line-endings before committing them to the repository. To do so, simply run the following command:\n\n```\ngit config --global core.autocrlf true\n```\n\n## WSL {#wsl}\n\nAlright, alright, I\'m sure you\'ve been expecting to see this here. I can\'t beat around the bush any longer. Windows Subsystem for Linux (WSL) enables users to run commands on a Linux instance without having to dual-boot or run a virtual machine themselves. \n\n> While the initial v1 worked by mapping system calls from Windows to Linux in a somewhat complex method, the new version (WSL2) works differently. WSL2 utilizes a Linux container in the background and enabling you to call into that container. \n>\n> Because of the foundational differences, compatibility with programs should be better in WSL2. If you last tried WSL when it first launched and were underwhelmed, try it again today.\n\nYou\'ll simply want to run the following command in PowerShell as an administrator:\n\n```powershell\nwsl --install\n```\n\nThen reboot your machine. After a reboot, you should be able to search for a Linux distro via the Microsoft Store. There are different options available to you, such as:\n\n- [Debian](https://www.microsoft.com/en-us/p/debian/9msvkqc78pk6)\n- [Kali Linux](https://www.microsoft.com/en-us/p/kali-linux/9pkr34tncv07)\n- [openSUSE](https://www.microsoft.com/en-us/p/opensuse-leap-15-1/9njfzk00fgkv)\n- [Ubuntu](https://www.microsoft.com/en-us/p/ubuntu/9nblggh4msv6)\n\nThere are more distros on the Microsoft Store if you search for them.\n\nOnce done, you simply run `wsl` in a terminal window. This should start-up the distro\'s shell in the directory you were currently in. This is a full installation of Linux, meaning that you\'re able to access its package manager, run programs from it, and modify Windows files.\n\nThere are even tweaks that are done with Windows to make it easier to use. If you run the `code` command to open a file, it will download a "VSCode remote server" to allow you to use your Windows install for both Linux and Windows commands. You can even [share SSH keys between Windows and WSL](https://devblogs.microsoft.com/commandline/sharing-ssh-keys-between-windows-and-wsl-2/)!\n\nThe cross-WSL compatibility isn\'t uni-directional either. You can [open files from your Linux filesystem in Windows](#access-wsl-files), [call Windows executables from WSL](https://docs.microsoft.com/en-us/windows/wsl/interop#run-windows-tools-from-wsl), and much more!\n\n### Shell Configuration {#linux-shell}\n\nIf you prefer an alternative shell, such as ZSH or Fish, you can install those in your distro as well. For example, I have an [`oh-my-zsh`](https://ohmyz.sh/) instance that runs anytime I start-up `wsl`.\n\nTo get the alternative shell running any time you call `bash`, you\'ll need to configure your `.bashrc` file. You\'re able to run `nano ~/.bashrc` to open the file. Once done, add `bash -c zsh` to the top of the file. After this, every time `bash` runs, it will open `zsh`.\n\nThat said, there\'s something a little awkward about using a program called `bash` to run a shell outside of `bash` itself. Additionally, you\'ll notice that if you type `exit` in `zsh`, it won\'t exit to the Windows shell. Instead, it will bring you to `bash` and require one more `exit` before you are back to the shell from whence you came.\n\nTo solve these problems, simply run `chsh -s $(which zsh)` in your WSL instance and use the `wsl` command (as opposed to `bash`) to open your shell. `bash` will still work and bring up the `bash` shell while `wsl` will bring you to `zsh` and work with the `exit` command as expected.\n\nYou can even able to tell Windows Terminal to use WSL as default! If you open Windows Terminal, it should have a default profile for WSL:\n\n```json\n {\n     "guid": "{2c4de342-38b7-51cf-b940-2309a097f518}",\n     "hidden": false,\n     "name": "Ubuntu",\n     "source": "Windows.Terminal.Wsl"\n },\n```\n\nAll you need to do is change the `defaultProfile` to match the `guid` of the WSL profile.\n\n### Accessing Linux Files {#access-wsl-files}\n\nSince [Windows 10 (1903)](https://devblogs.microsoft.com/commandline/whats-new-for-wsl-in-windows-10-version-1903/), you\'re able to access your WSL Linux distro files directly from Windows explorer. To do this, simply look to the sidebar panel of your File Explorer.\n\n![Linux shows up as a sidebar option when you enable WSL](./linux_sidebar.png)\n\nHere, you can read and write files to and from your Linux installation in WSL.\n\n### Linux GUI Programs {#wsl-gui}\n\n[In Windows 11, you\'re now able to run Linux GUI apps with WSL](https://docs.microsoft.com/en-us/windows/wsl/tutorials/gui-apps). Simply install them as you usually would using your distro\'s package manager and run them from the command line.\n\nHere, I\'m using `gedit` that I installed using:\n\n```\nsudo apt install gedit\n```\n\n![Gedit running alongside Notepad](./linux_gui.png)\n\n\n\n### USB Pass-thru {#wsl-usb}\n\nFor some development usage, having USB access from Linux is immensely useful. In particular, when dealing with Linux-only software for flashing microcontrollers or other embedded devices it\'s an absolute necessity.\n\nLuckily, as of late [Microsoft has worked with a third party project to add support to WSL](https://devblogs.microsoft.com/commandline/connecting-usb-devices-to-wsl/) to directly connect USB to Linux. This allows you to do flashing with `dd` and similar\n\n# Keyboard Usage {#keyboard-usage}\n\nWhen asking many of my Linux-favoring friends why they love Linux so much, I\'ve heard one answer time and time again. They love being able to control their computer front, back, and sideways without having to touch the mouse. Well, dear reader, I assure you that Windows provides the same level of control.\n\n## Built-Ins {#built-in-keyboard-shortcuts}\n\nBy default, Windows includes a myriad of shortcuts baked right in that allow you to have powerful usage of your system using nothing but your keyboard. Here are just a few that I think are useful to keep-in-mind:\n\n| Key Combo                                           | What It Does                                                 |\n| --------------------------------------------------- | ------------------------------------------------------------ |\n| <kbd>Win</kbd> + <kbd>S</kbd>                       | Perform a partial screenshot. Allow you to select what you want screenshotted |\n| <kbd>Win</kbd> + <kbd>.</kbd>                       | Bring up the emoji picker. After pressing, start typing to search. |\n| <kbd>Win</kbd> + <kbd>R</kbd>                       | Bring up the "Run" dialog. Will allow you to type in the internal executable name to run it |\n| <kbd>Win</kbd> + <kbd>V</kbd>                       | Open the Windows clipboard manager                           |\n| <kbd>Win</kbd> + <kbd>X</kbd>                       | Bring up a list of actions, including "Start PowerShell as Admin" |\n| <kbd>Win</kbd> + <kbd>L</kbd>                       | Lock your screen                                             |\n| <kbd>Win</kbd> + <kbd>Tab</kbd>                     | Bring up the overview mode of all windows                    |\n| <kbd>Win</kbd> + <kbd>E</kbd>                       | Open file explorer                                           |\n| <kbd>Win</kbd> + <kbd>S</kbd>                       | Open search dialog                                           |\n| <kbd>Win</kbd> + <kbd>D</kbd>                       | Show/hide the desktop                                        |\n| <kbd>Shift</kbd> + <kbd>F10</kbd>                   | Bring up the context menu for the selected item              |\n| <kbd>Win</kbd> + <kbd>Ctrl</kbd> + <kbd>D</kbd>     | Add a new virtual desktop                                    |\n| <kbd>Win</kbd> + <kbd>Ctrl</kbd> + <kbd>Arrow</kbd> | Move between virtual desktops                                |\n| <kbd>Win</kbd> + <kbd>Ctrl</kbd> + <kbd>F4</kbd>    | Close current virtual desktop                                |\n\n\n## Window Tiling {#window-tiling}\n\n"Surely, you can\'t forget about window tiling!"\n\nOh, don\'t worry, I haven\'t. Out of the box, windows supports tiling using the <kbd>Win</kbd> +  <kbd>Arrow</kbd> keys. With these keys, you can lock a window into any of the four corners of a screen, make it take up half the screen, or fill the screen entirely.\n\nMore than that, though, there are many other options out there. One of the paid options that I like using is called [Divvy](https://mizage.com/windivvy/). While it\'s paid, it enables users a powerful ability to layout windows either with their keyboard or mouse alike. I often use it to size windows with my mouse, in fact.\n\n![A preview of Divvy laying out files using the mouse](./divvy.png)\n\nBack at the (Redmond-based) ranch, the [previously mentioned Microsoft made PowerToys](#utilities) gives users [a feature called "FancyZones"](https://github.com/microsoft/PowerToys/blob/master/src/modules/fancyzones/README.md). Using this feature, users can dictate what locations their window snapping behaves in. This overwrites the existing <kbd>Win</kbd> +  <kbd>Arrow</kbd> shortcuts to move a window.\n\n![A preview of PowerZones allowing users to customize how their tiling works](./powerzones.png)\n\nAs you can see, there\'s an incredible amount of customization available with "FancyZones".\n\n# Customization {#customization}\n\nI\'m not sure about you, but when I get a new machine, I want it to feel _mine_. This applies just as much to my wallpaper as it does the stickers I plaster my laptops with. The following software enables some new functionality or aesthetic difference that users might enjoy.\n\n## Free {#free-customization-software}\n\n| Program Name                                                 | What It Is                                                   | Windows Compatibility |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | --------------------- |\n| [Audio Band](https://github.com/dsafa/audio-band)            | Adds an interactive music preview to the taskbar. Integrates with Spotify and others | Windows 10            |\n| [QuickLook](https://github.com/QL-Win/QuickLook)             | Adds MacOS like file preview on pressing spacebar            | Windows 10, 11        |\n| [EarTrumpet](https://github.com/File-New-Project/EarTrumpet) | Allows a more complex audio mixer. Support per-app volume control | Windows 10, 11        |\n| [Rainmeter](https://www.rainmeter.net/)                      | Enables new interactive desktop widgets                      | Windows 7, 8, 10, 11  |\n| [TranslucentTB](https://github.com/TranslucentTB/TranslucentTB) | Allows for more flexibility of taskbar                       | Windows 10, 11*       |\n| [RoundedTB](https://github.com/torchgm/RoundedTB)            | Allows for a rounded, more macOS-dock-like taskbar           | Windows 10, 11        |\n| [TaskbarX](https://github.com/ChrisAnd1998/TaskbarX)         | Like TranslucentTB but also supports centering icons in the TaskBar in Windows 10 | Windows 10, 11*       |\n| [Files UWP](https://github.com/duke7553/files-uwp/releases)  | A modern rewrite of the file explorer in UWP                 | Windows 10, 11        |\n| [Open-Shell](https://github.com/Open-Shell/Open-Shell-Menu)  | An open-source replacement for the start menu                | Windows 7, 8, 10      |\n\n> \\* Functionality may be limited or require further modification for some reason\n\n## Paid\n\n> Just a reminder that none of this software mentioned here due to a sponsorship or financial arrangement of any kind. Please understand that this is all software that I personally use and wanted to share. I\'ve tried my best to find some form of free/open-source replacement and linked them in the "Free" section.\n\n| Program Name                                          | What It Is                                                   | Windows Compatibility | Price         |\n| ----------------------------------------------------- | ------------------------------------------------------------ | --------------------- | ------------- |\n| [DisplayFusion](http://www.displayfusion.com/)        | A multi-monitor utility program. Enables tons of functionality to help manage multiple monitors | Windows 7, 8, 10, 11  | Starts at $29 |\n| [OneCommander](http://onecommander.com/)              | A replacement for the File Explorer with various improvements | Windows 10, 11        | $5            |\n| [TrayStatus](https://www.traystatus.com/)             | Status tray indicators for HDD, CPU, Capslock, and more      | Windows 10, 11        | Starts at $10 |\n| [Groupy](https://www.stardock.com/products/groupy/)   | A replacement for the [now-defunct Sets](https://www.zdnet.com/article/windows-10s-sets-feature-is-gone-and-not-expected-to-return/) functionality. Group unrelated programs into tabs, even if they didn\'t previously support tabs | Windows 10, 11        | $10           |\n| [Start10](https://www.stardock.com/products/start10/) | A replacement for the Windows 10 start menu                  | Windows 10            | $5            |\n| [Start11](https://www.stardock.com/products/start11/) | A replacement for the Windows 11 start menu | Windows 11            | $6            |\n| [StartAllBack](https://www.startallback.com/) | Windows 11 start menu replacement |Windows 11|$5|\n| [StartIsBack](https://www.startisback.com/) | Windows 10 start menu replacement |Windows 10|$5|\n\n# Functionality {#functionality}\n\nWindows also has some differing functionality to Linux/macOS in some critical ways. Some of the functionality you might be used to simply doesn\'t have an obvious analog in Windows. Let\'s take a look at some of these that we have an alternative to.\n\n## Virtual Desktops {#virtual-desktops}\n\nLongtime users of Linux will be quick to note that they\'ve had virtual desktops for years. While a newer feature to the Windows product line, it too was actually introduced in Windows 10! \n\nIf [you press <kbd>Win</kbd> + <kbd>Tab</kbd>, it will open a task view](#built-in-keyboard-shortcuts). On the top right of your screen, you should see a "New desktop" button. If you press it, it will create a new desktop.\n\n![The task view showing the "New desktop" button](./new_desktop_button.png)\n\nOnce you have more than one virtual desktop open, you should see a preview of each window individually.\n\n![What it looks like with more than one desktop](./multiple_desktops.png)\n\nIn order to move a window from one desktop to another, simply drag a window into another desktop\'s preview window.\n\n![What it looks like when you drag a window to a new desktop](./dragging_windows_virtual_desktop.png)\n\nFinally, to delete a virtual desktop, you can hover over the preview of the desktop. Upon doing so, a close button should appear. Click it to close the virtual desktop instance.\n\n![A close button shows up when hovering over a virtual desktop](./close_virtual_desktop.png)\n\n> A feature that\'s soon-to-release is renaming a virtual desktop! This functionality is [being added in the 2020 stable release of Windows](https://blogs.windows.com/windowsexperience/2019/09/06/announcing-windows-10-insider-preview-build-18975/) launching soon!\n\n### Touchpad Users {#virtual-desktop-touchpad-users}\n\nIf you\'re a laptop user (or have a touchpad for your desktop) that supports Windows gestures, you can configure a three or four finger feature to switch desktops with a simple swipe. Simply go to "Settings > Devices > Touchpad" to see if you\'re able to configure this or not. If you are able to, you should be able to select dropdowns to configure which one you\'d like.\n\n![A preview of the touchpad settings page](./touchpad_virtual_desktop.png)\n\n\n\n## Symbolic Links {#symlinks}\n\nSymbolic links are a method of having a shortcut of sorts from one file/folder to another. Think of it as Windows Shortcuts but baked directly into the filesystem level. This may come as a surprise to some developers, but Windows actually has support for symbolic links!\n\nTo use symbolic links from the CLI, you have to first enable developer mode on your install of Windows. To do this, go to your settings app, open "Update & Security," then select in the sidebar "For developers."\n\n![The settings page for "developer mode"](./developer_mode.png)\n\nOnce done, you\'re able to run `mklink`, which provides you the ability to make a symbolic link.\n\n### Usage {#using-mklink}\n\nBy default, it creates a soft link from the first argument to the second. \n```\nmklink Symlink SourceFile\n```\n\nYou\'re also able to add `/D` to make a soft link to a directory:\n```\nmklink /D SymlinkDir SourceFolder\n```\n\nFinally, to make hard links, you use `/H` for files:\n\n```\nmklink /H Symlink SourceFile\n```\n\nAnd `/J` for folders:\n\n```\nmklink /J SymlinkDir SourceFolder\n```\n\n### GUI Alternative {#link-shell-extension}\n\nWhile the CLI enables you to make hard and soft symbolic links, it\'s far from graceful. It would be ideal to have that functionality baked right into the explorer menu options if used frequently. Luckily for us, there\'s an app for that! [Link Shell Extension](https://schinagl.priv.at/nt/hardlinkshellext/linkshellextension.html) adds the options to the context menu itself. It\'s even able to be installed using [Chocolatey](#package-management):\n\n```\nchoco install linkshellextension\n```\n\nSimply right click (or [use the <kbd>Shift</kbd> + <kbd>F10</kbd> shortcut](#built-in-keyboard-shortcuts)) and select "Pick Link Source":\n![The context menu with the option highlighted](./pick_source.png)\n\nThen you\'re able to navigate to the folder you\'re looking for, right click, and select "Drop as...":\n\n![The context menu with the option highlighted](./drop_as.png)\n\nThere are a myriad of options to choose from and should handle any type of symlink you\'d need.\n\n# Additional Configuration {#additional-configuration}\n\nThey may not really count as a customization or making up for a "missing feature,"  but there are a few more things you can do to configure your Windows 10 installation to make life as a developer just a little bit better.\n\n## Long Path Support\n\nDevelopers with many sub-paths (or those that use package managers like `npm`) can tell you just how long their deepest file paths can get. This can cause problems with Windows, because there is a default limit of 260 characters for file paths. This can cause havoc and errors when doing automated tasks that exceed this limit. To fix this, you can either use a Registry Editor or modify an existing Group Policy (depending on which edition of Windows you have). The instructions are a bit complex for users not familiar with registry editing, [but HowToGeek provides a great resource](https://www.howtogeek.com/266621/how-to-make-windows-10-accept-file-paths-over-260-characters/) for making this process relatively trivial.\n\n## Make a Directory Case Sensitive\n\nUsers that have switched from macOS or Linux can tell you that most systems care about case sensitivity when it comes to a file\'s name. This behavior is admittedly at odds with Window\'s handling of files where case sensitivity isn\'t considered much. As someone who\'s tried to rename a file to be lowercase and track the changes in Git can tell you: It can be tricky to get Windows to respect the file name\'s casing. Luckily for us, we\'re able to overwrite this behavior on a per-folder basis. To do so, run the following command:\n\n```\nfsutil.exe file setCaseSensitiveInfo C:\\path\\to\\folder enable\n```\n\nOnce this is done, tada! Your directory is now case sensitive. That said, be warned that this setting does not trickle down to your subfolders: Only the parent will be case sensitive. \n\nLuckily, any folders you create using WSL will be case sensitive by default, enabling you to have files with the same name present with only casing differences between them.\n\n# Conclusion\n\nYou\'ll notice that despite the raw power and capabilities that WSL2 will be bringing to us right around the corner, that I didn\'t touch on it until later in the article. That\'s because, while it\'s an amazing toolset to be able to utilize for those that need it, it\'s not the only thing that you can do to enable your Windows instance to be powerful for development. Windows (and Microsoft as a whole) has come a long way in the past 10 years, and with their continued effort on projects like WSL, VS Code, and the Windows Terminal, the future looks brighter than ever. \n\nI want to take a moment to stop and appreciate all of the hard work that the folks at Microsoft and everyone involved in the projects mentioned have done to enable the kind of work I do daily. Thank you.\n\nIf you have any questions or comments, feel free to ring off in the comment box below. Otherwise, we have [our community Discord](https://discord.gg/FMcvc6T) where we talk not only talk Windows, but Linux, macOS, programming, and everything in between. We look forward to seeing you there!\n',
		},
		{
			title: "Understanding The DOM: How Browsers Show Content On-Screen",
			description:
				"Learn how the browser internally handles HTML and CSS to show the user webpages on-screen",
			published: "2019-11-26T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["webdev", "css", "javascript", "html"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "understanding-the-dom",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Understanding The DOM: How Browsers Show Content On-Screen",
				description:
					"Learn how the browser internally handles HTML and CSS to show the user webpages on-screen",
				published: "2019-11-26T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["webdev", "css", "javascript", "html"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nAny web application relies on some fundamental technologies: HTML, CSS, and JavaScript. Even advanced front-end JavaScript frameworks such as Angular, React, or Vue will utilize some level of HTML to load the JavaScript. That said, how the browser handles HTML and CSS under-the-hood can be quite the mystery. In this article, I'm going to explain what the browser does to understand what it should show to the user.\n\n> If you're unfamiliar with HTML, CSS, or JavaScript, you may want to take a look at [our post that introduces these three items](/posts/intro-to-html-css-and-javascript). They'll provide a good foundation for this article for newcomers to the programming scene or folks who may not be familiar with what those languages do.\n\n# The DOM {#the-dom}\n\nJust as the source code of JavaScript programs are broken down to abstractions that are more easily understood by the computer, so too is HTML. HTML, initially being derived from [SGML (the basis for XML as well)](https://en.wikipedia.org/wiki/Standard_Generalized_Markup_Language), actually _forms a tree structure in memory_ in order to [describe the relationships, layout, and executable tasks for items in the tree](#how-the-browser-uses-the-dom). This tree structure in memory is _called the Document Object Model_ (or _DOM_ for short).\n\nFor example, when you load a file similar to this:\n\n```html\n<!-- index.html -->\n<!-- ids are only added for descriptive purposes -->\n<main id=\"a\">\n\t<ul id=\"b\">\n\t\t<li id=\"c\">Item 1</li>\n\t\t<li id=\"d\">Item 2</li>\n\t</ul>\n\t<p id=\"e\">Text here</p>\n</main>\n```\n\n_The browser takes the items defined in the HTML and turns them into a tree that the browser understands how to lay out and draw on the screen_. That tree, internally, might look something like this:\n\n![A chart showing the document object model layout of the above code. It shows that the 'main' tag is the parent to a 'ul' tag, and so on](./dom_tree.svg \"Diagram showing the above code as a graph\")\n\n> This is an oversimplified example of how the browser interprets HTML, but gets the job done to convey introductory information.\n\nLet's see how this is done.\n\nAt the root of any HTML file, you have three things: tags, attributes, and text content.\n\n```html\n<!-- A \"header\" tag -->\n<header>\n  <!-- An \"a\" tag with an \"href\" attribute -->\n  <a href=\"example.com\">\n    <!-- A text node -->\n    Example Site\n  </a>\n</header>\n```\n\nWhen you type a tag, like `<header>` or `<a>`, you're creating an _element node_. These nodes are then composed to create _\"leaves\"_ on the DOM tree. Attributes are then able to manually add information to these nodes. When you have one element node inside of a separate one, you add a _\"child\"_ to said node. The relationship between the nodes allows metadata, CSS properties, and more to be preserved.\n\nThere's also the idea of a _\"sibling\"_ node. When a node's parent has more than one child, those other nodes are that child node's _\"siblings\"_.\n\n![A chart showing the relationships between parents and siblings](./dom_relationships.svg)\n\nAltogether, the terminology used to refer to the nodes and their various relationships is extremely similar to the terminology often used with family trees.\n\nThere are some rules for the tree that's created from these nodes:\n\n- There must be one \"root\" or \"trunk\" node, and there cannot be more than one root\n- There must be a one-to-many relationship with parents and children. A node:\n\t- May have many children\n\t- Cannot have more than one parent\n- A non-root node may have many siblings as a result of the parent having many children\n\n![A chart showing the aforementioned rules of the node relationships](./dom_relationship_rules.svg)\n\n### How It's Used By The Browser {#how-the-browser-uses-the-dom}\n\nThis tree tells the browser all of the information it needs to execute tasks in order to display and handle interaction with the user. For example, when the following CSS is applied to this HTML file:\n\n```css\n// index.css\n#b li {\n\tbackground: red;\n}\n```\n\n```html\n<!-- index.html -->\n<main id=\"a\">\n\t<p id=\"e\"></p>\n  <ul id=\"b\">\n    <li id=\"c\"></li>\n    <li id=\"d\"></li>\n  </ul>\n</main>\n```\n\nWhile moving through the tree, the browser can keep track of the fact that it needs to find an element with the `ID` of `b` and then mark its `<li>` children with a red background. They're \"children\" because the DOM tree preserves the relationship defined by the HTML.\n\n![A chart showing the 'ul' tag highlighted in green with the children 'li' tags marked in red](./dom_tree_with_css.svg \"Diagram showing the above code as a graph\")\n\n> The `<ul>` element is marked as green just to showcase that it is the element being marked by the first part of the selector.\n\nTypically, the browser will \"visit\" it's nodes in a specific order. For example, in the above chart, the browser might start at the `<main>` tag, then go to the `<p>` tag, then visit the `<ul>` tag, and finally the two children in order from left-to-right (`<li id=\"c\">` , `<li id=\"d\">`).\n\nThe browser, knowing what CSS to look for, is able to see the `<ul>` with the correct ID and know to mark its children with the correct metadata that matches the selector with the relevant CSS.\n\nThis tree relationship also enables CSS selectors such as the [general sibling selector (`~`)](https://developer.mozilla.org/en-US/docs/Web/CSS/General_sibling_combinator) or the [adjacent sibling selector (`+`)](https://developer.mozilla.org/en-US/docs/Web/CSS/Adjacent_sibling_combinator) of find siblings to a given selector.\n\n![A showcase of the above selectors and how they always look forward, never behind](css_selectors_demo.svg)\n\n> Interestingly, one of the questions that I've often heard asked concerns a \"parent selector\". The idea behind the question is that the [direct child selector (`>`)](https://developer.mozilla.org/en-US/docs/Web/CSS/Child_combinator) exists, so why not have the ability to select any parent of `.classname` selectors?\n>\n> The answer behind that? Performance. The [W3 Consortium](https://www.w3.org/Style/CSS/#specs) (the organization that maintains the HTML and CSS standard specifications) points to the tree structure of the DOM and the algorithm used by the browser to traverse the DOM (or, \"visit\" the nodes in order to figure out what CSS to apply) as not being performant when allowing parent selectors.\n>\n> This happens because browsers read from top-to-bottom in the DOM and apply CSS as they find matching nodes; CSS doesn't command the browser to do anything to the DOM, but rather provides the metadata for the DOM to apply the relevant CSS when the browser comes across that specific node.\n>\n> As mentioned before, they start at the root node, keep notes on what they've seen, then move to children. Then, they move to siblings, etc. Specific browsers may have slight deviations on this algorithm, but for the most part, they don't allow for upwards vertical movement of nodes within the DOM.\n\n\n\n# Using The Correct Tags {#accessibility}\n\nHTML, as a specification, has tons of tags that are able to be used at one's disposal. These tags contain various pieces of metadata internally to provide information to the browser about how they should be rendered in the DOM. This metadata can then be handled by the browser how it sees fit; it may apply default CSS styling, it may change the default interaction the user has with it, or even what behavior that element has upon clicking on it (in the case of a button in a form).\n\nSome of these tag defaults are part of the specification, while others are left up to the browser vendor to decide. This is why, in many instances, developers may choose to use something like [`normalize.css`](https://github.com/necolas/normalize.css/) to set all of the element CSS defaults to an explicit set of defaults. Doing so can avoid having the UI of a webpage look different from browser to browser thanks to deviations on default CSS styling on specific tags.\n\nThis metadata is also why it's so important that your application utilizes the expected HTML tags and not simply default to `<div>`s with CSS or JavaScript applied to simulate other items. Two of the biggest advantages to responsibly utilizing the metadata system the browser has built into it by using the correct tags are search engine optimization (SEO) and accessibility.\n\nTake the following example:\n\n```html\n<div>\n\t<div>Bananas</div>\n\t<div>Apples</div>\n\t<div>Oranges</div>\n</div>\n```\n\nIn this example, your browser only knows that you're looking to display text on-screen. If someone utilizing a screen reader reaches the site, the browser doesn't know that it should inform them that there are three items in a list (something that people with low vision would greatly value to know, in order to tab through the list effectively) as you've done nothing to inform the user that it is a list of items: only that it's a set of `<div>` generic containers.\n\nLikewise, when Google's robots walk through your site, they won't be able to parse that you're displaying lists to your users. As a result, your search rating for \"list of best places\" might be impacted since the site doesn't appear to contain any list at all.\n\nWhat can be done to remediate this? Well, by utilizing the proper tags, of course!\n\n```html\n<ol>\n\t<li>Bananas</li>\n\t<li>Apples</li>\n\t<li>Oranges</li>\n</ol>\n```\n\nIn this example, both the browsers as well as Google's scraper bots are able to discern that this is a list with three list items within it.\n\n> While there ARE tags that may potentially impact SEO somewhat significantly, it's unlikely `<ul>` and `<li>` would significantly impact your SEO scores.\n>\n> Needless to say, it's still good to use semantic (correctly tagged) HTML as people that use screen-readers and other assistive technologies benefit greatly from these minor changes. Additionally, it can make code more readable and parsable with automated tools.\n\nWe're able to even add further metadata to an element by using attributes. For example, let's say that I want to add a title to the list to be read upon a screen reader gaining focus on the element; we could use the `aria-label` attribute:\n\n```html\n<ol aria-label=\"My favorite fruits\">\n\t<li>Bananas</li>\n\t<li>Apples</li>\n\t<li>Oranges</li>\n</ol>\n```\n\nIn fact, the metadata that specific tags have by default can be manually applied to an element of a different type. The metadata that is passed to the browser when using `<li>` is typically involving that element pertaining to a `listitem`, using the `role` attribute, we can add that information to a `<div>` itself.\n\n```html\n<ol>\n\t<div role=\"listitem\">Bananas</div>\n\t<div role=\"listitem\">Apples</div>\n\t<div role=\"listitem\">Oranges</div>\n</ol>\n```\n\n> It's worth mentioning that this example is generally considered malpractice. While you may have been able to preserve _some_ of the metadata from a `<li>` tag in a `<div>` element, it's extremely difficult to catch all of the defaults a browser might apply to the original tag that may enhance the experience of someone that uses a screen-reader.\n>\n> This is all to say, unless you have a **really** good reason for using `role` rather than an appropriate tag, stick with the related tag. Just as any other form of engineering, properly employing HTML requires nuance and logic to be deployed at the hand of the implementing developer.\n\n# Element Metadata {#interacting-with-elements-using-js}\n\nIf you've ever written a website that had back-and-forth communication between HTML and JavaScript, you're likely aware that you can access DOM elements from JavaScript: modifying, reading, and creating them to your heart's content.\n\nLet's look at some of the built-in utilities at our disposal for doing so:\n\n- [The `document` global object](document-global-object)\n- [The `Element` base class](element-class)\n- [The event system](#events)\n\n## Document Global Object {#document-global-object}\n\n[As mentioned before, the DOM tree must contain one root node](#the-dom). This node, for any instance of the DOM, is the document entry point. When in the browser, this entry point is exposed to the developer with [the global object `document`](https://developer.mozilla.org/en-US/docs/Web/API/Document). This object has various methods and properties to assist in a meaningful way. For example, given a standard HTML5 document:\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n\t<title>This is a page title</title>\n</head>\n<body>\n\t<p id=\"mainText\">\n    This is the page body\n\t\t<span class=\"bolded\">and it contains</span>\n\t\ta lot of various content within\n    <span class=\"bolded\">the DOM</span>\n\t</p>\n</body>\n</html>\n```\n\nThe `document` object has the ability to get the `<body>` node ([`document.body`](https://developer.mozilla.org/en-US/docs/Web/API/Document/body)), the `<head>` node ([`document.head`](https://developer.mozilla.org/en-US/docs/Web/API/Document/head)), and even the doctype ([`document.doctype`](https://developer.mozilla.org/en-US/docs/Web/API/Document/doctype)).\n\n![A screenshot of the Chrome debugger console displaying those properties](first_document_properties.png)\n\n### Querying Elements\n\nBesides containing static references to `<body>` and `<head>`, there is also a way to query any element by using CSS selectors. For example, if we wanted to get a reference to the single element with the `id` of `mainText`, we could use the CSS selector for an id, combined with [the `querySelector` method on the `document`](https://developer.mozilla.org/en-US/docs/Web/API/Document/querySelector):\n\n```javascript\nconst mainTextElement = document.querySelector('#mainText');\n```\n\n> The `#` in the `#mainText` is the CSS selector syntax for selecting an element based on its `id`. If you had a CSS selector of `#testing`, you'd be looking for an element with the following attribute value:\n>\n> ```\n> id=\"testing\"\n> ```\n\nThis method will return a reference to the element as rendered in the DOM. [While we'll be covering more of what this reference is able to do later](#element-class), for now we can execute this quick bit of code to show that it's the element we intended to query:\n\n```javascript\nconsole.log(mainTextElement.innerHTML); // This will output the HTML that we used to write this element\n```\n\n![A screenshot of the Chrome debugger running the above code](query_selector.png)\n\nWe also have the ability to gain a reference to many elements at once. Given the same HTML document as before, let's say we want to see how many elements have the `bolded` class applied to it. We're able to do so using [the `querySelectorAll` method on the `document`](https://developer.mozilla.org/en-US/docs/Web/API/Document/querySelectorAll).\n\n```javascript\nconst boldedElements = document.querySelectorAll('.bolded');\nconsole.log(boldedElements.length); // Will output 2\nconsole.log(boldedElements[0].innerHTML); // Will output the HTML for that element\n```\n\n![A screenshot of Chrome running the above code](query_selector_all.png)\n\n> It's worth mentioning that the way `querySelector` works is not the same [way that the browser checks a node against the CSS selector data when the browser \"visits\" that node](#how-the-browser-uses-the-dom). `querySelector` and `querySelectorAll` work from a more top-down perspective where it searches the elements one-by-one against the query. First, it finds the top-most layer of the CSS selector. Then it will move to the next item and so-on-so forth until it returns the expected results.\n\n## Element Base Class {#element-class}\n\nWhile `innerHTML` has been used to demonstrate that the element that's gathered is in fact the element that was queried, there are many _many_ more properties and methods that can be run on an element reference.\n\nWhen an element is queried and returned, you're given a reference to that element through the [`Element` base class](https://developer.mozilla.org/en-US/docs/Web/API/Element). This class is what contains the properties and methods that you can use to access and modify the element's metadata.\n\nFor example, let's say that I wanted to see the width and height an element has when rendered on screen. [Using the `Element.prototype.getBoundingClientRect` method](https://developer.mozilla.org/en-US/docs/Web/API/Element/getBoundingClientRect), you can get all of that information and more:\n\n```javascript\nconst mainTextElement = document.querySelector('#mainText');\nconsole.log(mainTextElement.getBoundingClientRect());\n// Will output: DOMRect {x: 8, y: 16, width: 638, height: 18, top: 16, …}\n```\n\n> While the explanation behind the `Element.prototype` is a lengthy one (an article on its own to be sure), suffice it to say that there's a base class for all element references found using `querySelector`. This base class contains a myriad of methods and properties. The `.prototype` loosely refers to those properties and methods in question.\n>\n> This means that all queried elements will have their own `getBoundingClientRect` methods.\n\n### Attributes {#html-attributes}\n\n[As covered earlier, elements are able to have _attributes_ that will apply metadata to an element for the browser to utilize.](#accessibility) However, what I may not have mentioned is that you're able to read and write that metadata, as well as applying new metadata, using JavaScript.\n\nLet's take a slightly modified example from [the correct tags section](#accessibility) to demonstrate:\n\n```html\n<div id=\"divToList\">\n\t<div>Bananas</div>\n\t<div>Apples</div>\n\t<div>Oranges</div>\n</div>\n```\n\nWe could update this list to include the `role`s and `aria-label`s in order to make this non-semantic HTML more relevant in terms of how it reflects its metadata to the browser.\n\nThis metadata that we place directly on the elements themselves are called `attributes` and are part of the HTML specification (also referred to as the HTML API in this document). This metadata can be accessed and modified from JavaScript by using the `Element`'s [`getAttribute`](https://developer.mozilla.org/en-US/docs/Web/API/Element/getAttribute) to read the key-value pairing and [`setAttribute`](https://developer.mozilla.org/en-US/docs/Web/API/Element/setAttribute) to set the value to that attribute on an element.\n\nLet's look at how we can set the `role` and `aria-label`s in the DOM using JavaScript:\n\n```javascript\nconst divToListEl = document.querySelector('#divToList');\n// Get the `role` attribute to demonstrate that there's no currently present role\nconsole.log(divToListEl.getAttribute('role')); // `null`\n// Let's set a role that emulates a `list`\n// Set the value from the HTML API using the Element method `setAttribute`\ndivToListEl.setAttribute('role', 'list');\n// And let's add an aria-label, for good measure\ndivToListEl.setAttribute('aria-label', 'My favorite fruits');\n// Get the value from the HTML API using the Element method `getAttribute`\nconsole.log(divToListEl.getAttribute('role')); // `'list'`\n\n// Using the CSS selector to get the children of the divs\nconst listItems = document.querySelectorAll('#divToList > *');\n\n// Now, for all of the items in that list, let's use an aria `role` to make them reflect as listitems in their metadata to the browser\nfor (var i = 0; i < listItems.length; i++) {\n\tlistItems[i].setAttribute('role', 'listitem');\n}\n```\n\nOnce this is run, if you inspect the elements tab in your debugger, you should be left with HTML that looks like this:\n\n```html\n<div id=\"divToList\" role=\"list\" aria-label=\"My favorite fruits\">\n\t<div role=\"listitem\">Bananas</div>\n\t<div role=\"listitem\">Apples</div>\n\t<div role=\"listitem\">Oranges</div>\n</div>\n```\n\n... which is significantly more accessible for users that utilize screen readers, [as mentioned previously](#accessibility). You'll notice that despite not having any of the ARIA attributes prior, the `setAttribute` was able to implicitly create them with the newly placed values.\n\n### Properties {#element-properties}\n\n[As mentioned in a prior section, elements also have properties and methods associated with the instance of the underlying base class](#element-class). These properties are different from attributes as they are not part of the HTML specification. Instead, they're standardized JavaScript `Element` API additions. Some of these properties are able to be exposed to HTML and provide a two-way binding to-and-from the HTML API and the JavaScript `Element` API.\n\n> Unfortunately, for various historical reasons, the list of properties that support this bi-directional mapping between the `Element` API and the HTML API is sporadic and inconsistent. Some elements that support a mapping between the two APIs even only support uni-directional mapping where updating one will not update another.\n>\n> This is a round-about way of saying, \"It is confusing and complicated what properties have attribute bindings and which don't and why. It's okay if you don't get it right away\". Even seasoned developers might not be aware of some of the limitations. That all said, let's continue on with some examples that _do_ follow the bi-directional implicit API mapping to showcase how it works and learn more about properties.\n\nFor example, if you have [the style attribute](https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/style) associated with an element you're working with, you're able to read the values of the element:\n\n```html\n<!-- index.html -->\n<div style=\"background-color: green; color: white; width: 200px; height: 400px;\" id=\"greenEl\">\n  This element is green\n</div>\n```\n\n```javascript\n// index.js\nconst greenElement = document.querySelector('#greenEl');\nconsole.log(greenElement.style.backgroundColor); // 'green'\n```\n\n![A screenshot of the element and the debugger console of the above code](green_style_element.png)\n\nNot only are you able to read the value in question, but you can write and edit them as well:\n\n```javascript\ngreenElement.style.backgroundColor = 'red';\n```\n\nWill turn the element's background color red, for example.\n\n![The element has now turned the background red](red_style_element.png)\n\nSomewhat silly, seeing as how the `<div>` is no longer green. 🤭\n\n#### Limitations {#attribute-limitations}\n\nWhile attributes can be of great use to store data about an element, there's a limitation: Values are always stored as strings. This means that objects, arrays, and other non-string primitives must find a way to go to and from strings when being read and written.\n\n> While you've seen `style` attribute be read and written to by an object interface, if you inspect the element or use the `getAttribute` to access the attribute's HTML API value, you'll find that it's really a string with a pleasant API wrapped around it that lets you use an object to interface with the attribute value.\n>\n> ```javascript\n> console.log(mainTextElement.getAttribute('style')); // This will return a string value, despite the API that lets you use an object to read and write\n> ```\n>\n> The reasoning behind this incongruity is due to [the implicit mapping of the HTML API and the `Element` API, as mentioned at the start of the previous section](#element-properties). The limitations described here will also apply to the HTML API of those types of properties.\n\nFor example, we can [use `data` attributes](https://developer.mozilla.org/en-US/docs/Learn/HTML/Howto/Use_data_attributes) in order to read and write values via attributes to any given element.\n\n```html\n<!-- index.html -->\n<ul id=\"list\" data-listitems=\"2\">\n  <li>List item 1</li>\n  <li>List item 2</li>\n</ul>\n```\n\n```javascript\n// index.js\nconst listEl = document.querySelector('#list');\nconsole.log(listEl.dataset.listitems); // '2'\nlistEl.dataset.listitems = 3;\nconsole.log(listEl.dataset.listitems); // '3'\n```\n\n![Demonstrating that dataset values are able to be read and written](list_dataset.png)\n\nNote that I wrote the string `'3'` instead of the numerical value `3` in the code sample's outputs in the comments despite using the numerical `3` to set the value. This behavior is due to how default non-string values are saved to attributes.\n\nBy default, the primitive's `toString` will be called to store values.\n\n```javascript\nelement.dataset.userInfo = {name: \"Tony\"};\nconsole.log(element.dataset.userInfo); // \"[object Object]\"\n/**\n * \"[object Object]\" is because it's running `Object.prototype.toString()`\n * to convert the object to a string to store on the attribute\n */\n```\n\n> If you're having a difficult time understanding why `toString` is bring run or what `prototype` is doing here, don't worry; you're in good company. The JavaScript prototype system is complex and can be difficult to follow.\n>\n> For now, it will suffice just to know that you're only able to store strings in an element attribute.\n\n\n\n## Events {#events}\n\nJust as your browser uses the DOM to handle on-screen content visibility, your browser also utilizes the DOM for knowing how to handle user interactions. The way your browser handles user interaction is by listening for _events_ that occur when the user takes action or when other noteworthy changes occur.\n\nFor example, say you have a form that includes a default `<button>` element. When that button is pressed, it fires a `submit` event that then _bubbles_ up the DOM tree until it finds a [`<form>` element](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/form). By default, this `<form>` element sends a [`GET` HTML request](https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/GET) to the server once it receives the `submit` event.\n\n![The bubble flow of the `submit` event](./submit_form.svg)\n\n_Bubbling_, as shown here, is the default behavior of any given event. Its behavior is to move an event up the DOM tree to the nodes above it, moving from child to parent until it hits the root. Parent nodes can respond to these events as expected, stop their upward motion on the tree, and more.\n\n### Event Listening {#event-bubbling}\n\nMuch like many of the other internal uses of the DOM discussed in this article, you're able to hook into this event system to handle user interaction yourself.\n\nLet's look at an example of some code doing so:\n\n```html\n<!DOCTYPE html>\n<html>\n<head>\n\t<title>This is a page title</title>\n</head>\n<body>\n\t<div id=\"red\" style=\"height: 400px; width: 400px; background: red;\">\n\t\t<div id=\"blue\" style=\"height: 300px; width: 300px; background: blue;\">\n\t\t\t<div id=\"green\" style=\"height: 200px; width: 200px; background: green;\"></div>\n\t\t</div>\n\t</div>\n\t<script>\n\t\tconst redEl = document.querySelector('#red');\n\t\tconst blueEl = document.querySelector('#blue');\n\t\tconst greenEl = document.querySelector('#green');\n\n\t\tredEl.addEventListener('click', () => {\n\t\t\tconsole.log(\"A click handled on red using bubbling\");\n\t\t\t// This is set to false in order to use bubbling. We'll cover the `true` case later on\n\t\t}, false);\n\n\t\tblueEl.addEventListener('click', (event) => {\n\t\t\t// Stop the click event from moving further up in the bubble\n\t\t\tevent.stopPropagation();\n\t\t\tconsole.log(\"A click handled on blue using bubbling\");\n\t\t}, false);\n\n\n\t\tgreenEl.addEventListener('click', () => {\n\t\t\tconsole.log(\"A click handled on green using bubbling\");\n\t\t}, false);\n\t</script>\n</body>\n</html>\n```\n\n\nIn this example, we're adding click listeners to three squares, each one smaller than their parent square. This allows us to see the effect of bubbling in our console. If you click on the red square, you'd expect the event to bubble up to `<body>`, but not down to `#green`. Likewise, if you clicked on the green square, you'd expect the event to bubble up to both `#blue` and `#red` as well as `<body>`.\n\nHowever, as you can see, we're running `stopPropagation` on the event in the blue square. This will make the click event stop bubbling. This means that any click events that are called on `#green` will not make it to `#red` as they will be stopped at `#blue`.\n\n![The event bubbles upwards from green to blue but then is stopped by the stopPropagate call](./stop_propagration.svg)\n\nYou can see a running example of this here:\n\n<iframe src=\"https://stackblitz.com/edit/event-bubbling-demo?ctl=1&embed=1&file=index.js&hideExplorer=1&hideNavigation=1\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\n### Capturing {#event-capturing}\n\nBubbling isn't the only way events are able to move. Just as they can move up from the bottom, they can also move from the top down. This method of emitting events is known as _capture mode_.\n\nLet's take the a look at some example code, with the same HTML as before but a new set of JavaScript:\n\n```javascript\nredEl.addEventListener('click', () => {\n  console.log(\"A click handled on red using capturing\");\n  // Setting true here will switch to capture mode\n}, true);\n\nblueEl.addEventListener('click', (event) => {\n  // Stop the click event from moving further down in the bubble\n  event.stopPropagation();\n  console.log(\"A click handled on blue using capturing\");\n}, true);\n\n\ngreenEl.addEventListener('click', () => {\n  console.log(\"A click handled on green using capturing\");\n}, true);\n```\n\nAs demonstrated by the code above, `stopPropagation` works as you might expect it to in capture mode as well!\n\n\n\n![stopPropagation works similarly to how it does in bubble mode, just that it stops events from moving _down_ the tree](./capture_stop_propagation.svg)\n\nThis means that when the user clicks on the red square, you'll see the following in your console:\n\n```\n\"A click handled on red using capturing\"\n\"A click handled on blue using capturing\"\n```\n\nYou won't see anything from the green square's `eventListener`, however.\n\n<iframe src=\"https://stackblitz.com/edit/event-capture-demo?ctl=1&embed=1&file=index.js&hideExplorer=1&hideNavigation=1\" sandbox=\"allow-modals allow-forms allow-popups allow-scripts allow-same-origin\"></iframe>\n\nYou'll also notice that if you click on the green square, you'll never see the `\"A click handled on green using capture\"` message. This is due to the `stopPropagation`, as mentioned before. The click is being registered on the red square first and then stopped on the blue square.\n\n# Conclusion\n\nThis post is filled to the brim with information. 😵 Even I, the author, had a few amazing folks give it a re-read to confirm what I've written. Please don't be afraid or ashamed to re-read anything that might not have made sense or to revisit the post whenever a question arises. Hopefully, this has been a helpful exploration of the DOM and the ways you interact with it using code.\n\nPlease ask any questions or comments in our comments section and remember that we have [a Discord](https://discord.gg/FMcvc6T) for further conversation, including any questions!\n",
		},
		{
			title: "Adding Cathage Dependencies into React Native",
			description:
				"CocoaPods is a great dependency manager, but some need Carthage still. Let's walk through how to integrate Carthage with React Native!",
			published: "2020-10-13T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["ios", "react native"],
			attached: [],
			license: {
				id: "cc-by-4",
				footerImg: "https://i.creativecommons.org/l/by/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by/4.0/",
				name: "Attribution 4.0 International (CC BY 4.0)",
				displayName: "Creative Commons Attribution 4.0 International License",
			},
			slug: "using-carthage-with-react-native",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Adding Cathage Dependencies into React Native",
				description:
					"CocoaPods is a great dependency manager, but some need Carthage still. Let's walk through how to integrate Carthage with React Native!",
				published: "2020-10-13T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["ios", "react native"],
				attached: [],
				license: "cc-by-4",
			},
			contentMeta:
				"\nAs with anything in engineering, picking the right package manager for a project can be highly situational. Even in the webdev space: we have the mainstream appeal of [`npm`](https://www.npmjs.com/), the feature-rich [`yarn`](https://yarnpkg.com/), and others. Even moderately sized web applications need to face this question at some point in their development — The answer isn't always straightforward. However, React Native applications have the added complexity of needing to manage native dependencies as well as web dependencies.\n\nFor iOS dependency management, there are two major players: [Cocoapods](https://cocoapods.org/) and [Carthage](https://github.com/Carthage/Carthage/).\n\nWhile React Native ships with Cocoapods support out-of-the-box, it's not immediately clear how to add Carthage packages to your project.\n\n# Install\n\nLet's start with a caveat to adding Carthage to your projects: You cannot migrate your entire app's dependencies to use it. This is because React Native's dependencies [have not been packaged for usage in Carthage](https://github.com/facebook/react-native/issues/13835). \n\nAs such, you will always have an additional package manager to consider with your native dependencies.\n\nNow that we have that disclaimer out-of-the-way let's look into how to install Carthage so that you can use it in your projects.\n\nThere are three main methods you may use to install Carthage:\n\n1. [Downloading the Installer directly from GitHub releases](https://github.com/Carthage/Carthage/releases). Once you download the `.pkg` file, run it to start the installer\n2. If you have Homebrew installed, you can run `brew install carthage`\n3. Lastly, if you use MacPorts, you can run `sudo port install carthage`\n\nNow that you have Carthage installed, you can start using it in your projects.\n\n# Usage\n\nJust as npm has the `package.json` file, Carthage has the `Cartfile`. You'll want to create a file named `Cartfile` next to your `.xcworkspace` file. If your project was configured with the [React Native CLI](https://github.com/react-native-community/cli), this folder would be your `:projectRoot/ios` directory. \n\nOnce this file is created, you want to store your dependencies in the `ios/Cartfile` file. For [my React Native Git Client](https://gitshark.dev), we wanted to add a dependency called [Objective-Git](https://github.com/libgit2/objective-git) to our project. As such, our `Cartfile` looks like the following:\n\n```\ngithub \"libgit2/objective-git\"\n```\n\nOnce you've added your dependency, you'll want to `cd` into the `ios` directory run `carthage update` to install the dependency:\n\n```\ncd ios\ncarthage update\n```\n\nOnce this is done, you'll be left with a new folder and file:\n\n- `Cartfile.resolved` - File\n- `Carthage` - Folder\n\n> What is the `Cartfile.resolved` file? What does the `Cartfile.resolved` file do?\n\nYou can think of `Cartfile.resolved` as the `package-lock.json` file - it tells the package manager which version of the dependencies to use when running the package installation command (`carthage update`). As such, just like the `package-lock.json`, you'll want to commit this to your project's Git repo.\n\nThe `Carthage` folder, on the other hand, is similar to your `node_modules`. It's the downloaded dependencies that are resolved from the `Cartfile.resolved` file. As such, you may choose to `gitignore` the `Carthage` folder. However, [the Carthage official documentation](https://github.com/Carthage/Carthage/blob/master/Documentation/Artifacts.md) leaves a note regarding this decision:\n\n> You are not required to commit this folder to your repository, but you may wish to if you want to guarantee that the built versions of each dependency will always be accessible at a later date.\n\nFor [my company](https://oceanbit.dev), we ultimately decided to follow the web's standard and not commit our `Carthage` folders. As such, we needed to add the following line to our project's `.gitignore` file:\n\n```\nios/Carthage/Checkouts/\nios/Carthage/Build/\n```\n\nHowever, just as [npm suggests you commit the `package-lock.json` file](https://github.com/npm/cli/blob/release-6.14.7/docs/content/configuring-npm/package-lock-json.md), you should commit the `Cartfile.resolved` file as well, to ensure consistency in package version resolution.\n\n# Project Configuration\n\nThere are some final steps that're needed when utilizing Carthage for your package manager. All of these changes will be made in XCode to support building your project with your new dependencies.\n\n- Go into your `ios/Carthage/Build` folder. You should see a collection of folders for your dependencies that have built `.framework` files. I have dedicated `Mac` and `iOS` folders for my dependency, but yours may not.\n  ![The Carthage build folder](./carthage_build.png)\n\n- First, go to your app's \"target.\" Then, go to the \"General\" tab and find the \"Frameworks, Libraries, and Embedded Content\" section. Drag and drop the `.framework` file from your dependency into the said section.![Linked Frameworks](frameworks_embedd.png)\n\n- Next, navigate to the \"Build Phases\" tab. In the top left corner, click the “+” icon and choose “New Run Script Phase”\n  ![Add a New Run Script Phase](./add_run_script.png)\n\n- Leave the \"shell\" as `/bin/sh`, but set the contents of the run script to:\n\n  ```\n  /usr/local/bin/carthage copy-frameworks\n  ```\n\n  ![Run script contents](./carthage_run_script.png)\n  Finally, add the path to your dependencies' `.framework` files, like this:\n\n  ```\n  $(SRCROOT)/Carthage/Build/iOS/ObjectiveGit.framework\n  ```\n\nPlease keep in mind that there may be additional steps that some dependencies want you to move forward with to integrate with your projects. Refer to the documentation for the dep for more information.\n\n# Conclusion\n\nAs with any decision made in engineering, the choice to add Carthage as a secondary native dependency for your React Native projects is a high contextual one. However, I hope that with the information on utilizing it properly, it alleviates some of the stress in integrating it.\n\nIf you run into any problems integrating Carthage, you can always ask for help in the comments down below or [join our Discord](https://discord.gg/FMcvc6T) and ask for help there as well.\n\n",
		},
		{
			title: "Uttering Hello — The Site's First Post",
			description:
				"An introduction to Unicorn Utterances, including a mission statement and general roadmap",
			published: "2019-06-29T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["announcements"],
			attached: [],
			license: {
				id: "cc-by-4",
				footerImg: "https://i.creativecommons.org/l/by/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by/4.0/",
				name: "Attribution 4.0 International (CC BY 4.0)",
				displayName: "Creative Commons Attribution 4.0 International License",
			},
			slug: "uttering-hello-introduction-post",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Uttering Hello — The Site's First Post",
				description:
					"An introduction to Unicorn Utterances, including a mission statement and general roadmap",
				published: "2019-06-29T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["announcements"],
				attached: [],
				license: "cc-by-4",
			},
			contentMeta:
				"\nLearning itself is such an interesting thing to think about. \n\nI have always been driven to learn more about the world around me. I find the act of simply understanding a topic fascinating. One of the things I've come to love learning about the most is Computer Science. There are so many people with exceptional knowledge that I've been blessed to be mentored by, be adjacent to, or even be friends with. Because of them, I am where I am today.\n\nLikewise, I love being able to relay the things that others have taught me in a way that I feel to be expressive and accessible to others. As I've grown as a developer and person, I've found that there seems to be a lack of resources in a number of topics that I've come across. As a result, I've spent countless hours pouring over confusing, loosely compiled, or otherwise inaccessible resources. Oftentimes, I would find myself unable to learn with resources and had to rely on \"playing\" with the code itself or turning to others and relying on verbal affirmation of information in order to learn some topics better. Being able to take that experience and improve upon it and share it is always an exciting idea for me. \n\nOver time, I've found myself wanting to share that information more and more: joining bootcamps to become a TA, writing some small-scale blog posts, giving talks. It's been a blast! I love meeting new people, hearing their experience, and often learning not only from talking to them, but by having to teach (which requires me to gain a deeper understanding in the things I want to teach and share). \n\nToday, I'm starting on a new project to share even more. One of the goals of said project is to grow what I hope to be a fantastic community that is able to benefit from the things shared here and contribute to even further community engagement. I want to start a blog. Well, that might be what it is now, but I want it to be more in the future and leaving it like that is underselling the idea. Let's talk about the project's ultimate goals.\n\n# Ultimate Goals\n\nI want this site to turn into a fully-fledged resource hub. Looking towards the distant future, I'd love nothing more than to have there be educational content leading from a rudimentary understanding of computers to advanced concepts within computer science.\n\nPart of this would include having a community surrounding the content - being able to have others involved in a communal space where information is shared, created, and discussed. I want this community to be a safe place for anyone, regardless of skill level, to be able to learn and feel safe and comfortable asking questions that they might be afraid to or embarrassed to otherwise.\n\nIgnoring skill level, I also acknowledge that there are various learning styles. While some can pick up on verbal teaching quickly, others may have difficulties learning without text to read through. While the site is focused on article-style content currently, I'd love to be able to expand this project into other avenues of computer science educational content in the future.\n\n# Present Goals\n\nThis project is going to be a long-standing effort to try to write as often as possible to realize this goal. I know this is a lofty goal though, and I don't want to do it alone. While creating this blog, I have ensured that other authors should have the lowest barrier to contributing as possible. We have author pages built, filtering and searching on our pages, and an [open GitHub repository](https://github.com/crutchcorn/unicorn-utterances). We love and welcome pull requests, new content, code maintenance on the site, bug reports, and general discussion.\n\nIn terms of content, there is an extremely in-depth article which is being edited as we speak. Within the next few weeks, keep your eye out for new posts on the site. If you use RSS to keep up with your favorite content, [we have that as well](https://unicorn-utterances.com/rss.xml).\n\nFinally, I immediately want to be accessible to people of all forms of physical capabilities. Great care has been taken to ensure this site follows proper accessibility requirements. If there is anything on the site pertaining to accessibility that does not work, please let us know, it will be treated as diligently as any other bug preventing users from accessing the site.\n\n# Who's Helped!\n\nThough the site is young, we've already had some amazing folks help us along the way creating what we have now (and what we're going to be doing in the immediate future 🤫)\n\nStarting with the logo, I've been absolutely blessed to have the amazing [Vukasin](https://twitter.com/vukash_in) (creator of CandyCons, PixBit, etc) create a fun and cute logo that you've almost certainly seen by now (if not, the homepage has it in decent quality. Go and take a peek - it's \"aww\" worthy for certain!)\n\nAs for the site's design, that was handled by the supremely talented and ever-lastingly patient (sorry for the iterations there, bud!) [Tom Wellington](https://twitter.com/tommy_emo_).\n\nDue to time constraints on my part, much of his designs weren't able to be realized for the launch, but needless to say we have an exciting roadmap ahead and making his designs a reality is certainly one of them.\n\nLast, but certainly not least, the site has had some incredible help with getting the site live and deployed from [Evelyn Hathaway](https://twitter.com/evelynhathaway_). She's been an amazing help both in terms of giving suggestions and feedback on all ends of the site as well as getting hosting working properly, handling SSL, redirects, etc. Sincerely couldn't do it without her\n\n# What's Next\n\nWe have some exciting stuff coming up. As mentioned before, there's going to be an in-depth post coming very soon. We also have many posts that've been started, but need editing and finalization before being sent out. That's not the end, though. There's an absolutely gargantuan list of other posts I'd like to work on, and it seems to be growing every day.\n\nYou can keep up-to-date either by [following me on Twitter](https://twitter.com/crutchcorn) or by utilizing [our RSS feed](https://unicorn-utterances.com/rss.xml)\n",
		},
		{
			title: "Virtual Memory Overview",
			description:
				"An overview of how operating systems give processes their own address space.",
			published: "2020-05-19T12:45:00.000Z",
			authors: ["seanmiller"],
			tags: ["computer science", "cpp"],
			attached: [],
			license: {
				id: "cc-by-nc-nd-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "https://creativecommons.org/licenses/by-nc-nd/4.0/",
				name: "Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) License",
			},
			slug: "virtual-memory-overview",
			locale: "en",
			authorsMeta: [
				{
					id: "seanmiller",
					name: "Sean Miller",
					firstName: "Sean",
					lastName: "Miller",
					description:
						"Howdy! Computer Science major at Texas A&M University, with a minor in cybersecurity. Super passionate about all things software!",
					socials: {
						twitter: "beastosean",
						github: "tamuseanmiller",
						website: "https://sean.millerfamily.tech",
						linkedIn: "tamuseanmiller",
					},
					pronouns: "he",
					profileImg: "./seanmiller.jpg",
					color: "#551a8b",
					roles: ["author"],
					profileImgMeta: {
						height: 3451,
						width: 3452,
						relativePath: "./seanmiller.jpg",
						relativeServerPath: "/content/data/seanmiller.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\seanmiller.jpg",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Virtual Memory Overview",
				description:
					"An overview of how operating systems give processes their own address space.",
				published: "2020-05-19T12:45:00.000Z",
				authors: ["seanmiller"],
				tags: ["computer science", "cpp"],
				attached: [],
				license: "cc-by-nc-nd-4",
			},
			contentMeta:
				"\nMemory in your standard computer works in a much more abstract and complex way then you would initially expect. I'm writing this from the point of someone developing software and less about someone understanding each part of the hardware.\n\n# Virtual Memory {#virtual-memory}\n\nOperating systems (OS) are the ones in control of all of the physical memory in your computer. This is a safeguard to make sure that memory is being allocated fairly to all processes. The way this is done is by a concept called **Virtual Memory**. As the name suggests, it means that it's shrouding the physical memory in hardware with seemingly infinite storage (in reality, you're limited by various elements of your hardware, but the amount of memory you can assign to virtual memory is typically orders of magnitude higher than the amount you can store in physical memory) for each process that is created. This is accomplished by using more than just your main memory in the case that if you need more storage, then the OS can also store it on your hard drive or SSD. Even though it may seem like a slower alternative, it allows much more freedom for processes without wrecking your computer.\n\n![Representation of how virtual memory works](./virtual_memory.svg)\n\nVirtual Memory uses what are called **page tables** that point to a memory map which will then finally point to either your physical memory or something like an HDD. It works like a cache where each entry in a page table is only used when absolutely necessary. Whenever a process comes in it only stores the \"pages\" that the OS thinks the process will need in main memory while the rest stay behind. This reduces the amount of memory that is taken up as well as speeding up the overall time it would take to complete a process.\n\n## What Virtual Memory looks like in C/C++ {#virtual-memory-cpp}\n\nIn C/C++ your virtual memory is broken up into ~4 basic \"blocks\" for where different aspects of your code are stored. The four memory areas are Code, Static/Global contexts, Stack, and Heap. The code section as you can probably guess is where your local code is held, it's specifically for the syntax of the area of the code that is being read. The Static/Global contexts are also as expected, either your global variables or your static methods that are set. The last two are the more complex areas and the two that you will want to have the most understanding in if you are working with a language that doesn't have garbage collection.\n\n- Heap\n- Stack\n- Static/Global\n- Code\n\n# The Stack {#stack}\n\nThe stack is where all of your local variables from the inner contexts are stored. The more local the variable the higher they are on the stack to eventually be popped off. The stack data structure is the same one that is used in memory, and it works by placing objects in by **LIFO**(Last in First out). Just like a stack of papers, you can see the paper on top of the stack but none of the others. You also can't reach inside of the stack, you have to remove the papers on top to see the papers below.\n\n```cpp\n// Stack variable definition\nint num = 12;\n```\n\n# The Heap {#heap}\n\nThe heap is where you store objects that seem to be global in nature. In C/C++ when you're swapping between methods and you want an object that you are returning to go outside of the local context of the method, you use the **new** or **malloc()** keywords. The heap is another data structure that works like a binary tree held in a normal array or list. This shows that there is a hierarchical difference compared to the stack.\n\n```cpp\n// Heap Object definition\nItem bat = new Item();\n```\n\nThe heap is where you have to be the most careful because even after termination of the program, whatever you placed on the heap will still be there. This is what creates memory leaks, it's a good rule to know that whenever you call the **new** or **malloc()** keywords, you need an equal number of **delete** or **free()** keywords present.\n\nYou will most likely use the heap when you want to create something with a higher scope, or if you want to access it dynamically. That means that your spot on the stack is a set size, but when you create something on the heap it can be any size that you want. The downside is that C uses pointers that sit on the stack in order to access the heap so it will end up being much slower.\n\n## Putting it together\n\n```cpp\n#include <vector>\n#include <iostream>\n\nusing namespace std;\n\n// Creating a new global vector\nvector<int> *vec;\n\n// Example method that fills a new vector of size \"length\" with zeros\nvoid example1(int length) {\n\tvec = new vector<int>(length, 0);\n}\n\n// Example method that creates a stack variable\nvoid example2(int length) {\n\tvector<int> retVal(length, 1);\n\t*vec = retVal;\n}\n\n// main method for testing\nint main() {\n\t// Memory address of the heap that is stores on the stack\n\tcout << vec << endl;\n\n\t// Define vec by calling example1\n\texample1(10);\n\n\tcout << vec << endl;\n\n\tfor (int val : *vec) {\n\t\tcout << val << \", \";\n\t}\n\n\tcout << endl;\n\n\t// Redefine vec by calling example2\n\texample2(10);\n\t\n\tcout << vec << endl;\n\tfor (int val : *vec) {\n\t\tcout << val << \", \";\n\t}\n\tdelete vec;\n}\n```\n\nJust so we understand what is going on here, I created a global vector pointer that I did not define. Therefore it is just on the stack represented as a '0'. When example1() is called it allocates memory for vec on the heap and instantiates a vector with all zeros. You can access the vector using the memory address on the stack. When I print out just \"vec\" it will print out the memory address of the location on the heap where it is stored, when I call *vec it then goes to that memory location on the heap. More on pointers in a later article.\n\nThe other method, example2(), just creates a new local vector and sets vec equal to it. You'll see why this is problematic later on. When the program is run in the order example1() -> example2() everything will work fine. And here is the output:\n\n```\n0\n\n0x80004ae10\n\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n\n0x80004ae10\n\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n```\n\n**But**, when you call it in the other order, calling example2() first, this is what happens...\n\n```\n0\n```\n\nWhat happens is you get a segfault. This segfault occurs because you're trying to assign a value to a pointer when that pointer isn't pointing anywhere. You're trying to access memory that doesn't exist.\n\n# Review/Conclusion {#conclusion}\n\nOperating systems protect physical memory by giving each process a seemingly infinite amount of virtual memory where they each have their own address space that doesn't affect any other processes. Understanding this and how the virtual memory is represented is a fundamental building block in becoming a better and more efficient programmer.\n\nUnclear about something regarding virtual memory? Maybe you'd like to expand on some of the subjects touched on here? Be sure to join us [in our Discord Server](https://discord.gg/FMcvc6T) and ask away! We like to chat, hang out, and enjoy talking CS-related subjects!\n",
		},
		{
			title: "Vue Composition API Inspector",
			description:
				"A peek under the hood of Vue compilation. See how Vue interpretes TypeScript",
			published: "2022-07-30T09:30:00.000Z",
			edited: "2022-07-30T09:30:00.000Z",
			authors: ["splatkillwill"],
			tags: ["webdev", "vue"],
			attached: [],
			license: {
				id: "cc-by-nc-nd-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "https://creativecommons.org/licenses/by-nc-nd/4.0/",
				name: "Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) License",
			},
			slug: "vue-composition-inspector",
			locale: "en",
			authorsMeta: [
				{
					id: "splatkillwill",
					name: "William (Will) Lohan",
					firstName: "William",
					lastName: "Lohan",
					description: "",
					socials: {
						github: "william-lohan",
						twitch: "splat_killwill",
						website: "https://gatimus.com/",
						linkedIn: "william-lohan-b202637a",
					},
					pronouns: "they/themselves",
					profileImg: "./splatkillwill.jpg",
					color: "#BF00FF",
					roles: ["author"],
					profileImgMeta: {
						height: 512,
						width: 512,
						relativePath: "./splatkillwill.jpg",
						relativeServerPath: "/content/data/splatkillwill.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\splatkillwill.jpg",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Vue Composition API Inspector",
				description:
					"A peek under the hood of Vue compilation. See how Vue interpretes TypeScript",
				published: "2022-07-30T09:30:00.000Z",
				edited: "2022-07-30T09:30:00.000Z",
				authors: ["splatkillwill"],
				tags: ["webdev", "vue"],
				attached: [],
				license: "cc-by-nc-nd-4",
			},
			contentMeta:
				'\nI\'ve recently been upgrading a Vue 2 JavaScript project using the [Options API](https://vuejs.org/guide/introduction.html#options-api) for single file components to Vue 3 typescript and taking advantage of the [Composition API](https://vuejs.org/guide/introduction.html#composition-api).\n\nFor example going from this Options API:\n\n```js\nexport default {\n  props: {\n    name: {\n      type: String,\n      required: true.\n    }\n  },\n  emits: [\'someEvent\', \'increaseBy\']\n};\n```\n\nto this Composition API:\n\n```ts\n const props = defineProps<{\n  name: string;\n }>();\n\n const emit = defineEmits<{\n  (event: \'someEvent): void;\n  (event: \'increaseBy\', value: number): void;\n }>();\n```\n\nSome of conversions from the `emits` and `props` options of the Options API to the `defineEmits` and `defineProps` functions [type-based syntax](https://vuejs.org/guide/typescript/composition-api.html) of the Composition API were not straightforward. I was also curious about how Vue handled interfaces.TypeScript interfaces are constructs that only exists during design time and compile time. They are stripped away when traspiled before the JavaScript runtime so how do they effect the behavior of the component? Spoiler alert, it\'s just `{ type: Object }`.\n\nI wondered if there was a way to see how Vue interpreted the generic parameters passed to `defineEmits` and `defineProps`. If you notice the docs say you don\'t need to import the `defineEmits` and `defineProps` functions. This is because they are actually [macros](https://github.com/vuejs/core/blob/a95554d35c65e5bfd0bf9d1c5b908ae789345a6d/packages/compiler-sfc/src/compileScript.ts#L58-L62) for the JavaScript functions of the same name. Before the full TypeScript pass is done the Vue webpack plugin uses TypeScript\'s AST (abstract syntax tree) to derive the options for JavaScript version of the functions.\n\n> If you\'re not familiar with what an AST is, [we have an article that explains it here.](/posts/how-computers-speak#ast)\n\nIf it weren\'t for the macro:\n\n```ts\n  defineProps<{\n    prop1: string;\n    prop2: number;\n  }>();\n```\n\nwould just become:\n\n```js\n  defineProps();\n```\n\nresulting in an error for missing parameters.\n\nIf you look at Vue\'s SFC (single file component) compiler source, there is a function called [`compileScript`](https://github.com/vuejs/core/blob/a95554d35c65e5bfd0bf9d1c5b908ae789345a6d/packages/compiler-sfc/src/compileScript.ts#L141). I started out trying to call this function with the minimum number of parameters that wouldn\'t error, mocking any required parameters that weren\'t important. Eventually I found an other function called [`parse`](https://github.com/vuejs/core/blob/a95554d35c65e5bfd0bf9d1c5b908ae789345a6d/packages/compiler-sfc/src/parse.ts#L96). That gave me most of the parameters I needed leaving only the component id left to mock.\n\nWhat I came up with is a little script that will take a .vue file of the SFC and spit out how Vue interpretes the TypeScript.\n\n\n```js\nimport { readFile, writeFile } from "fs";\nimport parseArgs from "minimist";\nimport { parse, compileScript } from "@vue/compiler-sfc";\n\nconst { file, out } = parseArgs(process.argv.slice(2), {\n  string: ["file", "out"],\n  alias: {\n    file: "f",\n    out: "o"\n  }\n});\n\nconst filename = file;\nconst mockId = "xxxxxxxx";\n\nreadFile(filename, "utf8", (err, data) => {\n  const { descriptor } = parse(data, {\n    filename\n  });\n  const { content } = compileScript(descriptor, {\n    inlineTemplate: true,\n    templateOptions: {\n      filename\n    },\n    id: mockId\n  });\n\n  if (out) {\n    writeFile(out, "utf8", content);\n  } else {\n    process.stdout.write(content);\n  }\n});\n```\n\n> Try for yourself [here](https://stackblitz.com/edit/node-fzuykn?file=index.js)\n\nFor example the following component:\n\n```ts\n  interface Bar {\n    prop1: string;\n    prop2: number;\n  }\n\n  defineProps<{\n    bar: Bar;\n    bars: Bar[];\n    asdf1?: boolean;\n    asdf2: string[];\n  }>();\n```\n\noutputs:\n\n```ts\ninterface Bar {\n    prop1: string;\n    prop2: number;\n  }\n\n\nexport default /*#__PURE__*/_defineComponent({\n  __name: \'demo\',\n  props: {\n    bar: { type: Object, required: true },\n    bars: { type: Array, required: true },\n    asdf1: { type: Boolean, required: false },\n    asdf2: { type: Array, required: true }\n  },\n  setup(__props: any) {\n\n\n\n\nreturn (_ctx: any,_cache: any) => {\n  return (_openBlock(), _createElementBlock("div"))\n}\n}\n```\n\nAs you see the SFC compiler takes the TypeScript type info and builds the prop objects. Primatives are one to one. Interfaces are Objects and the `?` optional syntax drives the `required` property.\n',
		},
		{
			title: "Web Components 101: Framework Comparison",
			description:
				"While web components can be used standalone, they're paired best with a framework. With that in mind, which is the best and why?",
			published: "2021-12-02T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["lit", "vue", "react", "angular"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/web-components-101-framework-comparison/",
			series: "Web Components 101",
			order: 4,
			slug: "web-components-101-framework-comparison",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Web Components 101: Framework Comparison",
				description:
					"While web components can be used standalone, they're paired best with a framework. With that in mind, which is the best and why?",
				published: "2021-12-02T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["lit", "vue", "react", "angular"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/web-components-101-framework-comparison/",
				series: "Web Components 101",
				order: 4,
			},
			contentMeta:
				'\r\nAlright alright, I know for a lot of the last article seemed like a big ad for Lit. That said, I promise I’m not unable to see the advantages of other frameworks. Lit is a tool in a web developer’s toolbox. Like any tool, it has its pros and cons: times when it’s the right tool for the job, and other times when it’s less so.\r\n\r\nThat said, I’d argue that using an existing framework is more often the better tool for the job than vanilla web components. \r\n\r\nTo showcase this, let’s walk through some of these frameworks and compare and contrast them to home-growing web components.\r\n\r\n# Pros and Cons of Vanilla Web Components\r\n\r\nWhile web frameworks are the hot new jazz - it’s not like we couldn’t make web applications before them. With the advent of W3C standardized web components (without Lit), doing so today is better than it’s ever been.\r\n\r\nHere are some pros and cons of Vanilla JavaScript web components:\r\n\r\n<table class="wp-block-table">     <tbody>         <tr>             <th>                 Pros             </th>             <th>                 Cons             </th>         </tr>         <tr>             <td>                 <ul>                     <li><span>No framework knowledge required</span></li>                     <li><span>Less reliance on framework</span></li>                 </ul>                 <ul>                     <li><span>Maintenance</span></li>                     <li><span>Bugs</span></li>                     <li><span>Security issues</span></li>                 </ul>                 <ul>                     <li><span>Smaller “hello world” size</span></li>                     <li><span>More control over render behavior</span></li>                 </ul>             </td>             <td>                 <ul>                     <li><span>Re-rendering un-needed elements is slow</span></li>                     <li><span>Handling event passing is tricky</span></li>                     <li><span>Creating elements can be overly verbose</span></li>                     <li><span>Binding to props requires element query</span></li>                     <li><span>You’ll end up building Lit, anyway</span></li>                 </ul>             </td>         </tr>     </tbody> </table>\r\n\r\nTo the vanilla way of doing things’ credit, there’s a bit of catharsis knowing that you’re relying on a smaller pool of upstream resources. There’s also a lessened likelihood of some bad push to NPM from someone on the Lit team breaking your build.\r\n\r\nLikewise - for smaller apps - you’re likely to end up with a smaller output bundle. That’s a huge win!\r\n\r\nFor smaller applications where performance is critical, or simply for the instances where you need to be as close to the DOM as possible, vanilla web components can be the way to go.\r\n\r\nThat said, it’s not all roses. After all, this series has already demonstrated that things like event passing and prop binding are verbose compared to Lit. Plus, things may not be as good as they seem when it comes to performance.\r\n\r\n## Incremental Rendering\r\n\r\n\r\nOn top of the aforementioned issues with avoiding a framework like Lit, something we haven’t talked about much is incremental rendering. A great example of this would come into play if we had an array of items we wanted to render, and weren’t using Lit. \r\n\r\nEvery time we needed to add a single item to that list, our `innerHTML` trick would end up constructing a new element for every single item in the list. What’s worse is that every subelement would render as well!\r\n\r\nThis means that if you have an element like this:\r\n\r\n```html\r\n<li><a href=”https://example.com”><div class=”flex p-12 bg-yellow”><span>Go to this location</span></div></a></li>\r\n<li><a href=”https://example.com”><div class=”flex p-12 bg-yellow”><span>Go to this location</span></div></a></li>\r\n```\r\n\r\nAnd only needed to update the text for a single item in the list, you’d end up creating 4 more elements for the item you wanted to update… On top of recreating the 5 nodes (including the [Text Node](https://developer.mozilla.org/en-US/docs/Web/API/Text)) for every other item in the list.\r\n\r\n## Building Your Own Framework\r\n\r\nAs a result of the downsides mentioned, many that choose to utilize vanilla web components often end up bootstrapping their own home-grown version of Lit.\r\n\r\nHere’s the problem with that: You’ll end up writing Lit yourself, sure, but with none of the upsides of an existing framework.\r\n\r\nThis is the problem with diving headlong into vanilla web components on their own. Even in our small examples in the article dedicated to vanilla web components, we emulated many of the patterns found within Lit. Take this code from the article:\r\n\r\n```html\r\n<script>\r\n  class MyComponent extends HTMLElement {\r\n    todos = [];\r\n\r\n    connectedCallback() {\r\n      this.render();\r\n    }\r\n   \r\n    // This function can be accessed in element query to set internal data externally\r\n    setTodos(todos) {\r\n      this.todos = todos;\r\n      this.clear();\r\n      this.render();\r\n    }\r\n\r\n    clear() {\r\n      for (const child of this.children) {\r\n        child.remove();\r\n      }\r\n    }\r\n   \r\n    render() {\r\n      this.clear();\r\n   \r\n      // Do logic\r\n    }\r\n   \r\n  }\r\n\r\n  customElements.define(\'my-component\', MyComponent);\r\n</script>\r\n<script>  class MyComponent extends HTMLElement {    todos = [];     connectedCallback() {      this.render();    }       // This function can be accessed in element query to set internal data externally    setTodos(todos) {      this.todos = todos;      this.clear();      this.render();    }     clear() {      for (const child of this.children) {        child.remove();      }    }       render() {      this.clear();         // Do logic    }     }   customElements.define(\'my-component\', MyComponent);</script>\r\n```\r\n\r\nHere, we’re writing our own `clear` logic, handling dynamic value updates, and more.\r\n\r\nThe obvious problem is that we’d then have to copy and paste most of this logic in many components in our app. But let’s say that we were dedicated to this choice, and broke it out into a class that we could then extend.\r\n\r\nHeck, let’s even add in some getters and setters to make managing state easier:\r\n\r\n```html\r\n<script>\r\n  // Base.js\r\n  class OurBaseComponent extends HTMLElement {\r\n    connectedCallback() {\r\n      this.doRender();\r\n    }\r\n\r\n    createState(obj) {\r\n        return Object.keys(obj).reduce((prev, key) => {\r\n            // This introduces bugs\r\n            prev["_" + key] = obj[key];\r\n            prev[key] = {\r\n                get: () => prev["_" + key],\r\n                set: (val) => this.changeData(() => prev["_" + key] = val);\r\n            }\r\n        }, {})\r\n    }\r\n   \r\n    changeData(callback) {\r\n      callback();\r\n      this.clear();\r\n      this.doRender();\r\n    }\r\n\r\n    clear() {\r\n      for (const child of this.children) {\r\n        child.remove();\r\n      }\r\n    }\r\n   \r\n    doRender(callback) {\r\n      this.clear();\r\n      callback();\r\n    }   \r\n  }\r\n</script>\r\n<script>  // Base.js  class OurBaseComponent extends HTMLElement {    connectedCallback() {      this.doRender();    }     createState(obj) {        return Object.keys(obj).reduce((prev, key) => {            // This introduces bugs            prev["_" + key] = obj[key];            prev[key] = {                get: () => prev["_" + key],                set: (val) => this.changeData(() => prev["_" + key] = val);            }        }, {})    }       changeData(callback) {      callback();      this.clear();      this.doRender();    }     clear() {      for (const child of this.children) {        child.remove();      }    }       doRender(callback) {      this.clear();      callback();    }     }</script>\r\n```\r\n\r\nNow our usage should look fairly simple!\r\n\r\n```html\r\n<script>\r\n  // MainFile.js\r\n  class MyComponent extends OurBaseComponent {\r\n    state = createState({todos: []});\r\n\r\n    render() {\r\n        this.doRender(() => {\r\n            this.innerHTML = `<h1>You have ${this.state.todos.length} todos</h1>`\r\n        })\r\n    }\r\n  }\r\n\r\n  customElements.define(\'my-component\', MyComponent);\r\n</script>\r\n<script>  // MainFile.js  class MyComponent extends OurBaseComponent {    state = createState({todos: []});     render() {        this.doRender(() => {            this.innerHTML = `<h1>You have ${this.state.todos.length} todos</h1>`        })    }  }   customElements.define(\'my-component\', MyComponent);</script>\r\n```\r\n\r\nThat’s only 13 lines to declare a UI component!\r\n\r\nOnly now you have a bug with namespace collision of state with underscores, your `doRender` doesn’t handle async functions, and you still have many of the downsides listed below!\r\n\r\nYou could work on fixing these, but ultimately, you’ve created a basis of what Lit looks like today, but now you’re starting at square one. No ecosystem on your side, no upstream maintainers to lean on.\r\n\r\n# Pros and Cons of Lit Framework\r\n\r\nWith the downsides (and upsides) of vanilla web components in mind, let’s compare the pros and cons of what building components using Lit looks like:\r\n\r\n<table class="wp-block-table">     <tbody>         <tr>             <th>                 Pros             </th>             <th>                 Cons             </th>         </tr>         <tr>             <td>                 <ul>                     <li><span>Faster re-renders* that are automatically                             handled</span></li>                     <li><span>More consolidated UI/logic</span></li>                     <li><span>More advanced tools after mastery</span></li>                     <li><span>Smaller footprint than other frameworks</span></li>                 </ul>             </td>             <td>                 <ul>                     <li><span>Framework knowledge required</span></li>                     <li><span>Future breaking changes</span></li>                     <li><span>Not as widely known/used as other frameworks (Vue,                             React, Angular)</span></li>                 </ul>                 <p><span></span></p>             </td>         </tr>     </tbody> </table>\r\n\r\nWhile there is some overlap between this list of pros and cons and the one for avoiding Lit in favor of home-growing, there’s a few other items here.\r\n\r\nNamely, this table highlights the fact that Lit isn’t the only framework for building web components. There’s huge alternatives like React, Vue, and Angular. These ecosystems have wider adoption and knowledge than Lit, which may make training a team to use Lit more difficult.\r\n\r\nHowever, Lit has a key advantage over them, ignoring being able to output to web components for a moment - we’ll come back to that.\r\n\r\n\r\nEven compared to other frameworks, Lit is uniquely lightweight.\r\n\r\nCompare the bundle sizes of Vue - a lightweight framework in it’s own right - compared to Lit.\r\n\r\n![Lit weighs in at 16.3 kilobytes while Vue weighs in at 91.9 kilobytes](./bundlephobia.png)\r\n\r\nWhile tree shaking will drastically reduce the bundle size of Vue for smaller applications, Lit will still likely win out for a simple component system.\r\n\r\n# Other Frameworks \r\n\r\nLit framework isn’t alone in being able to output to web components, however. In recent years, other frameworks have explored and implemented various methods of writing code for a framework that outputs to web components.\r\n\r\n\r\nFor example, the following frameworks have official support for creating web components without changing implementation code:\r\n\r\n- [Vue](https://v3.vuejs.org/guide/web-components.html#definecustomelement)\r\n- [Angular](https://angular.io/guide/elements)\r\n- [Preact](https://github.com/preactjs/preact-custom-element)\r\n\r\nVue 3, in particular, has made massive strides in improving the web component development experience for their users.\r\n\r\nWhat’s more is that these tools tend to have significantly larger ecosystems. Take Vue for example.\r\n\r\nWant the ability to change pages easily? [Vue Router](https://router.vuejs.org/)\r\n\r\nWant a global store solution? [Vuex\r\n](https://vuex.vuejs.org/)Prefer similar class based components? [Vue Class Component Library](https://class-component.vuejs.org/)\r\n\r\nPrebuilt UI components? [Ant Design](https://www.antdv.com/docs/vue/introduce/)\r\n\r\nWhile some ecosystem tools might exist in Lit, they certainly don’t have the same breadth.\r\n\r\nThat’s not to say it’s all good in the general web component ecosystem. Some frameworks, like React, [have issues with Web Component interop](https://custom-elements-everywhere.com/), that may impact your ability to merge those tools together.\r\n\r\n# Why Web Components?\r\n\r\nYou may be asking - if you’re going to use a framework like Vue or React anyway, why even bother with web components? Couldn’t you instead write an app in one of those frameworks, without utilizing web components?\r\n\r\nYou absolutely can, and to be honest - this is how most apps that use these frameworks are built.\r\n\r\nBut web components play a special role in companies that have multiple different projects: Consolidation.\r\n\r\nLet’s say that you work for BigCorp - the biggest corporation in Corpville.\r\n\r\nBigCorp has dozens and dozens of full-scale applications, and not all of them are using the same frontend framework. This might sound irresponsible of BigCorp’s system architects, but in reality, sometimes a framework is better geared towards specific applications. Additionally, maybe some of the apps were part of an acquisition or merger that brought them into the company.\r\n\r\nAfter all, the user doesn’t care (or often, know) about what framework a tool is built with. You know what a user does care about? The fact that each app in a collection all have vastly different UIs and buttons.\r\n\r\n![Two different apps, each with different text cutoff points in their button\'s text](./two_apps.png)\r\n\r\nWhile this is clearly a bug, if both codebases implement the buttons on their own, you’ll inevitably end up with these types of problems; this being on top of the work-hours your teams have to spend redoing one-another’s work for their respective frameworks.\r\n\r\nAnd that’s all ignoring how difficult it can be to get designers to have consistency between different project’s design components - like buttons.\r\n\r\nWeb Components solve this problem.\r\n\r\nIf you build a shared component system that exports web components, you can then use the same codebase across multiple frameworks.\r\n\r\nOnce the code is written and exported into web components, it’s trivial to utilize these new web components in your application. Like, it can be a [single line of code trivial.](https://v3.vuejs.org/guide/web-components.html#tips-for-a-vue-custom-elements-library)\r\n\r\nFrom this point, you’re able to make sure the logic and styling of these components are made consistent between applications - even if different frameworks.\r\n\r\n# Conclusion\r\n\r\nWhile web components have had a long time in the oven, they came out swinging! And while Lit isn’t the only one at the table, they’ve certainly found a strong foothold in capabilities.\r\n\r\nLit’s lightweightness, paired with web component’s abilities to integrate between multiple frameworks is an incredible one-two punch that makes it a strong candidate for any shared component system.\r\n\r\nWhat’s more, the ability to transfer knowledge from other frameworks makes it an easy tool to place in your toolbox for usage either now or in the future.\r\n\r\nRegardless; whether you’re using Vue, React, Angular, Lit, Vanilla Web Components, or anything else, we wish you happy engineering!\r\n',
		},
		{
			title: "Web Components 101: History",
			description:
				"Web components have had a long history to get where they are today. Let's look back to see where they came from & their immense growth!",
			published: "2021-12-21T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["webdev", "history"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink: "https://coderpad.io/blog/web-components-101-history/",
			series: "Web Components 101",
			order: 1,
			slug: "web-components-101-history",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Web Components 101: History",
				description:
					"Web components have had a long history to get where they are today. Let's look back to see where they came from & their immense growth!",
				published: "2021-12-21T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["webdev", "history"],
				attached: [],
				license: "coderpad",
				originalLink: "https://coderpad.io/blog/web-components-101-history/",
				series: "Web Components 101",
				order: 1,
			},
			contentMeta:
				'\r\nWeb components enjoy large-scale usage today. From YouTube to GitHub and many other major organizations, it’s safe to say they’ve made their way into commonplace frontend development practices. \r\n\r\nThat wasn’t always the case. After all, web components had to start somewhere. And web development can be particularly picky with what succeeds and what doesn’t.\r\n\r\nSo then, how did web components succeed? What was their path to broad adoption? And what are the origins behind the APIs used for modern web components?\r\n\r\nLet’s walk through a short history of web components and the related ecosystem to answer these questions.\r\n\r\n# 2010: The Early Days of MVC in JS\r\n\r\nWhile the concept of [“Model View Controller”, also commonly called MVC](https://en.wikipedia.org/wiki/Model–view–controller), has been around for some time, in JavaScript itself it failed to take hold early on.\r\n\r\nHowever, in 2010, there was an explosion around MVC and it’s related cousin: Model View View-Controller (MVVC) ). This explosion came courtesy of a slew of new frameworks that launched only a few months apart from one-another.\r\n\r\n[Knockout was one of the first to introduce strict MVC patterns inside of JavaScript in July 2010](https://github.com/knockout/knockout/releases/tag/v1.0.0). Knockout supported observable-based UI binding. Here, you could declare a Model, and bind data from said model directly to your HTML.\r\n\r\n```html\r\n<!-- Demo of KnockoutJS -->\r\n<table class="mails" data-bind="with: chosenFolderData">\r\n    <thead><tr><th>Subject</th></tr></thead>\r\n    <tbody data-bind="foreach: mails">\r\n        <tr><td data-bind="text: subject"></td></tr>\r\n    </tbody>\r\n</table>\r\n<script>\r\nfunction WebmailViewModel() {\r\n    // Data\r\n    var self = this;\r\n    self.chosenFolderData = ko.observable();\r\n\r\n    $.get(\'/mail\', { folder: \'Inbox\'}, self.chosenFolderData)\r\n};\r\n\r\nko.applyBindings(new WebmailViewModel());\r\n</script>\r\n```\r\n\r\n![A list of emails based on their subjects](./knockout_demo.png)\r\n\r\nWhile this works great for UI binding, it lacks the componentization aspect we’ve come to expect from modern frameworks.\r\n\r\n------\r\n\r\nThis was improved in the ecosystem when [Backbone saw its first release in October 2010](https://github.com/jashkenas/backbone/releases/tag/0.1.0). It introduced a `[View](https://backbonejs.org/#View-extend)`, similar to what we might expect a component to be like today.\r\n\r\n```javascript\r\nvar DocumentRow = Backbone.View.extend({\r\n  tagName: "li",\r\n  className: "document-row",\r\n  events: {\r\n    "click .icon":          "open",\r\n    "click .button.edit":   "openEditDialog",\r\n    "click .button.delete": "destroy"\r\n  },\r\n  initialize: function() {\r\n    this.listenTo(this.model, "change", this.render);\r\n  },\r\n  render: function() {\r\n    ...\r\n  }\r\n});\r\n```\r\n\r\nHere, we can see that we can now bind events, classes, and more to a single tag. This aligns better with the types of components we’d see in, say, React or Lit.\r\n\r\n------\r\n\r\nBut that’s not all we saw in October that year. We also saw the [initial release of Angular.js](https://github.com/angular/angular.js/releases/tag/v0.9.0) only 10 days after Backbone’s release.\r\n\r\nHere, we can see that it introduced a concept of controllers into the document, similar to the `Model`s of Knockout. It allowed two-way bindings from UI to data and back.\r\n\r\n```html\r\n<div ng-controller="TodoListController as todoList">\r\n  <ul>\r\n    <li ng-repeat="todo in todoList.todos">{{todo.text}}</li>\r\n  </ul>\r\n  <form ng-submit="todoList.addTodo()">\r\n    <input\r\n      type="text"\r\n      ng-model="todoList.todoText"\r\n    />\r\n    <input class="btn-primary" type="submit" value="add" />\r\n  </form>\r\n</div>\r\n<script>\r\n  angular\r\n    .module("todoApp", [])\r\n    .controller("TodoListController", function () {\r\n      var todoList = this;\r\n      todoList.todos = [\r\n        { text: "learn AngularJS" },\r\n        { text: "build an AngularJS app" },\r\n      ];\r\n\r\n      todoList.addTodo = function () {\r\n        todoList.todos.push({ text: todoList.todoText });\r\n        todoList.todoText = "";\r\n      };\r\n    });\r\n</script>\r\n```\r\n\r\nWhile Angular was the last of the three mentioned here, it had a huge impact. It was the first time Google released a JavaScript-based MVC based library into the wild.\r\n\r\nNot only did they build the library, [they used it to build Google’s Feedback tool](https://www.youtube.com/watch?v=r1A1VR0ibIQ) - which powers almost all of Google’s products today. This represented a shift from their prior Java-based “[Google Web Toolkit” (GWT)](http://www.gwtproject.org/) that was widely used before.\r\n\r\nLater, with the [acquisition of DoubleClick](https://www.nytimes.com/2007/04/14/technology/14DoubleClick.html), the team that was working on the [migration of the DoubleClick platform for Google decided to use Angular.js as well](https://www.youtube.com/watch?v=r1A1VR0ibIQ).\r\n\r\n# 2011: A Glimmer in W3C Standard’s Eye\r\n\r\nWith Angular.js continuing to grow within Google, it’s no surprise that they continued researching in-JavaScript HTML bindings.\r\n\r\nOn this topic, Alex Russel - then a Senior Staff Engineer at Google, working on the web platform team - [gave a talk at the Fronteers conference](https://fronteers.nl/congres/2011/sessions/web-components-and-model-driven-views-alex-russell).\r\n\r\nIn this talk, he introduces a host of libraries that allow building custom elements with experimental new APIs.\r\n\r\n```html\r\n<script>\r\nclass Comment extends HTMLElement {\r\n\r\n  constructor(attrs = {}) {\r\n    super(attrs);\r\n    this.textContent = attrs.text || lorem;\r\n    this.shadow = new ShadowRoot(this);\r\n    this.buildUI();\r\n  }\r\n\r\n  buildUI() { ... }\r\n}\r\n\r\nHTMLElement.register(\'x-comment\', Comment);\r\n\r\nvar c = new Comment("Howdy, pardner!");\r\ndocument.body.appendChild(c);\r\n</script>\r\n\r\n<x-comment>...</x-comment>\r\n```\r\n\r\nHere, he utilized the [TraceUR compiler](https://web.archive.org/web/20210311050620/https://github.com/google/traceur-compiler) (a precursor to Babel) to add classes (remember, [`class` wouldn’t land in JavaScript stable until ES6 in 2015](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes)) to build a new “custom element”.\r\n\r\nThis combined with their [new MDV library](https://web.archive.org/web/20110509081454/http://code.google.com/p/mdv) in order to create a similar development environment to what we have in browser APIs today. \r\n\r\nIt’s important to note that at this stage, nothing was formalized inside of a specification - It was all experimental libraries acting as playgrounds for APIs.\r\n\r\nThat would change soon after.\r\n\r\n# 2013: Things Start Heating Up\r\n\r\nIn early 2013 the Google team created a [Working Draft of a specification for Custom Elements](https://web.archive.org/web/20130608123733/http://www.w3.org/TR/custom-elements/). Alongside similar working drafts for Shadow DOM APIs, they were colloquially called “[Custom Elements v0](https://www.html5rocks.com/en/tutorials/webcomponents/customelements/)”.\r\n\r\nWith [Google Chrome’s release in 2008](https://googleblog.blogspot.com/2008/09/fresh-take-on-browser.html), they had the ability to quickly implement these non-standard APIs into Chrome in order to allow application developers to utilize them before specification stabilization.\r\n\r\n\r\nOne such example of this was [Polymer, which was a component library based on v0 APIs to provide two-way UI binding using MVC.](https://web.archive.org/web/20130515211406/http://www.polymer-project.org/) It’s initial alpha release was announced in early 2013, alongside the specifications.\r\n\r\nAt [Google Dev Summit 2013, they walked through its capabilities ](https://www.youtube.com/watch?v=DH1vTVkqCDQ)and how it was able to run in other browsers by utilizing polyfills.\r\n\r\n------\r\n\r\nFacebook, not one to be outdone on the technical engineering front, [introduced React into public in 2013](https://www.youtube.com/watch?v=GW0rj4sNH2w)\r\n\r\nWhile Polymer went deeper into the MVC route, [React relied more heavily on unidirectionality](https://coderpad.io/blog/master-react-unidirectional-data-flow/) in order to avoid state mutations.\r\n\r\n# 2016 & 2017: Formative Years\r\n\r\nWhile only the year prior, Polymer 1.0 was released with the usage of v0 custom element spec, [2016 saw the release of the custom element v1 specification](https://web.archive.org/web/20161030051600/http://w3c.github.io/webcomponents/spec/custom/).\r\n\r\n\r\nThis new version of the specification was not backwards compatible, and as a result required a shift to the new version of the specification in order to function properly. Polyfills were continued to be used as a stop-gate for browsers that didn’t have a v0 implementation.\r\n\r\nWhile [v1 was already implemented into Chrome in late 2016](https://web.archive.org/web/20161101052413/http://caniuse.com/#feat=custom-elementsv1), it wasn’t until 2017 with the release of Polymer 2.0 that it would be adopted back into the library that helped draft the specification.\r\n\r\nBecause of this, while [YouTube’s new Polymer rewrite](https://blog.youtube/news-and-events/a-sneak-peek-at-youtubes-new-look-and/) theoretically was a huge step towards the usage of web components, it posed a problem. Browsers like [Firefox without a v0 implementation were forced to continue to use Polyfills](https://web.archive.org/web/20180724154806/https://twitter.com/cpeterso/status/1021626510296285185), which are slower than native implementations.\r\n\r\n# 2018 and Beyond: Maturity\r\n\r\n2018 is where Web Components really found their foothold.\r\n\r\nFor a start, [Mozilla implemented the v1 specification APIs into their stable release of Firefox](https://www.mozilla.org/en-US/firefox/63.0/releasenotes/), complete with dedicated devtools. Finally, developers could use all of the web components’ APIs in their app, cross-browser, and without any concern for non-Chrome performance.\r\n\r\nOn top of that, React’s unidirectionality seemed to have won over the Polymer team. The Polymer team announced that it would [migrate away from bidirectional binding and towards a one-way bound `LitElement`](https://www.polymer-project.org/blog/2018-05-02-roadmap-update#libraries)\r\n\r\nThat `LitElement` would then turn into a dedicated framework called “[Lit](https://coderpad.io/blog/web-components-101-lit-framework/)”, developed to replace Polymer as its successor, that would hit [v1 in 2019](https://github.com/lit/lit/releases/tag/v1.0.0) and [v2 in 2021](https://github.com/lit/lit/releases/tag/lit%402.0.0).\r\n\r\n# Timeline\r\n\r\nWhew! That’s a lot to take in. Let’s see it all from a thousand foot view:\r\n\r\n- 2010: \r\n  - [Knockout.js released](https://github.com/knockout/knockout/releases/tag/v1.0.0)\r\n  - [Backbone.js alpha released](https://github.com/jashkenas/backbone/releases/tag/0.1.0)\r\n  - [Angular.js made open-source](https://web.archive.org/web/20100413141437/http://getangular.com/)\r\n\r\n- 2011:\r\n  - [MDV (Polymer predecessor) introduced at a conference](https://fronteers.nl/congres/2011/sessions/web-components-and-model-driven-views-alex-russell)\r\n\r\n- 2013:\r\n  - [Working draft spec for Web Components (v0) released](https://web.archive.org/web/20130608123733/http://www.w3.org/TR/custom-elements/)\r\n  - [Polymer (Google’s web component framework) announced](https://www.youtube.com/watch?v=DH1vTVkqCDQ)\r\n  - [React open-sourced](https://www.youtube.com/watch?v=GW0rj4sNH2w)\r\n\r\n- 2015:\r\n  - [Polymer 1.0 released](https://web.archive.org/web/20150814004009/https://www.polymer-project.org/1.0/)\r\n\r\n- 2016:\r\n  - [Custom elements v1 spec released](https://web.archive.org/web/20161030051600/http://w3c.github.io/webcomponents/spec/custom/)\r\n  - [YouTube rewritten in Polymer](https://blog.youtube/news-and-events/a-sneak-peek-at-youtubes-new-look-and/)\r\n- 2017:\r\n  - [Polymer 2.0 released](https://github.com/Polymer/polymer/releases/tag/v2.0.0)\r\n\r\n- 2018:\r\n  - [Polymer announces start of migration to “LitElement”](https://www.polymer-project.org/blog/2018-05-02-roadmap-update#libraries)\r\n  - [Firefox enables web components (Polyfills no longer needed)](https://www.mozilla.org/en-US/firefox/63.0/releasenotes/)\r\n\r\n- 2019:\r\n  - [Lit framework 1.0 released](https://github.com/lit/lit/releases/tag/v1.0.0)\r\n\r\n- 2021\r\n  - [Lit 2.0 released](https://github.com/lit/lit/releases/tag/lit%402.0.0)\r\n\r\n# Conclusion\r\n\r\nIn the past 10 years we’ve seen massive changes to the web development ecosystem. No more is this more apparent than the development and continued growth of web components.\r\n\r\nHopefully this should put any future learnings about web components and [framework comparisons](https://coderpad.io/blog/web-components-101-framework-comparison/) into perspective.\r\n\r\nWe’ve waited a long time to see many of these ideas fully standardized into the web platform, and, now that they’re here, they’re helping accelerate growth of many platforms.\r\n\r\nWant to learn how to build them yourself?\r\n\r\nWe have articles about how to build web components [without a framework](https://coderpad.io/blog/intro-to-web-components-vanilla-js/) as well as using [Google’s Lit framework](https://coderpad.io/blog/web-components-101-lit-framework/).\r\n',
		},
		{
			title: "Web Components 101: Lit Framework",
			description:
				"Google pushed for web components, sure, but they didn't stop there. They also went on to make an amazing framework to help build them: Lit!",
			published: "2021-11-04T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["webdev", "lit"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/web-components-101-lit-framework/",
			series: "Web Components 101",
			order: 3,
			slug: "web-components-101-lit-framework",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Web Components 101: Lit Framework",
				description:
					"Google pushed for web components, sure, but they didn't stop there. They also went on to make an amazing framework to help build them: Lit!",
				published: "2021-11-04T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["webdev", "lit"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/web-components-101-lit-framework/",
				series: "Web Components 101",
				order: 3,
			},
			contentMeta:
				'\r\nRecently we talked about [what web components are and how you can build a web app utilizing them with only vanilla JavaScript](https://coderpad.io/blog/intro-to-web-components-vanilla-js/).\r\n\r\nWhile web components are absolutely usable with only vanilla JavaScript, more complex usage, especially pertaining to value binding, can easily become unwieldy.\r\n\r\nOne potential solution might be using a web component framework such as VueJS or React. However, web-standard components can still be a massive boon to development.\r\n\r\nAs such, there’s a framework called [“Lit”](https://lit.dev/) that is developed specifically to leverage web components. With [Lit 2.0 recently launching as a stable release](https://lit.dev/blog/2021-09-21-announcing-lit-2/), we thought we’d take a look at how we can simplify web component development.\r\n\r\n# HTML\r\n\r\nOne of the greatest strengths of custom elements is the ability to contain multiple other elements. This makes it so that you can have custom elements for every scale: from a button to an entire page.\r\n\r\nTo do this in a vanilla JavaScript custom element, you can use `innerHTML` to create new child elements.\r\n\r\n```html\r\n<script>\r\nclass MyComponent extends HTMLElement {\r\n  connectedCallback() {\r\n      this.render();\r\n  }\r\n\r\n  render() {\r\n      this.innerHTML = \'<p>Hello!</p>\';\r\n  }\r\n}\r\n\r\ncustomElements.define(\'hello-component\', MyComponent);\r\n</script>\r\n\r\n<hello-component></hello-component>\r\n```\r\n\r\nThis initial example looks fairly similar to what the Lit counterpart of that code looks like:\r\n\r\n```html\r\n<script type="module">\r\nimport { html, LitElement } from "https://cdn.skypack.dev/lit";\r\n\r\nexport class HelloElement extends LitElement {\r\n    render() {\r\n        return html`\r\n              <p>Hello!</p>\r\n        `;\r\n    }\r\n}\r\n\r\nwindow.customElements.define(\'hello-component\', HelloElement);\r\n</script>\r\n\r\n<hello-component></hello-component>\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=194516" loading="lazy"></iframe>\r\n\r\nThere are two primary differences from the vanilla JavaScript example. First, we no longer need to use the `connectedCallback` to call `render`. The LitElement’s `render` function is called by Lit itself whenever needed - such as when data changes or for an initial render - avoiding the need to manually re-call the render method. \r\n\r\nThat said, Lit components fully support the same lifecycle methods as a vanilla custom elements.\r\n\r\nThe second, easier-to-miss change from the vanilla JavaScript component to the Lit implementation, is that when we set our HTML, we don’t simply use a basic template literal (`<p>test</p>`): we pass the function `html` to the template literal (`html\\`<p>test</p>\\``).\r\n\r\nThis leverages [a somewhat infrequently used feature of template literals called tagged templates](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#tagged_templates). Tagged templates allow a template literal to be passed to a function. This function can then transform the output based on the string input and expected interpolated placeholders.\r\n\r\nBecause tagged templates return a value like any other function, you can assign the return value of `html` to a variable.\r\n\r\n```javascript\r\nrender {\r\n    const el = html`\r\n            <p>Hello!</p>\r\n      `;\r\n    return el;\r\n}\r\n```\r\n\r\nIf you were to `console.log` this value, you’d notice that it’s not an [HTMLElement](https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement). Instead, it’s a custom value that Lit utilizes to render to proper DOM nodes.\r\n\r\n# Event Binding\r\n\r\n“If the syntax is so similar, why would I add a framework to build custom elements?”\r\n\r\nWell, while the Vanilla JavaScript and Lit custom element code look similar for a small demo: The story changes dramatically when you look to scale up.\r\n\r\nFor example, if you wanted to render a button and add a click event to the button with vanilla JavaScript, you’d have to abandon the `innerHTML` element assignment method.\r\n\r\nFirst, we’ll create an element using `document.createElement`, then add events, and finally utilize [an element method like `append`](https://developer.mozilla.org/en-US/docs/Web/API/Element/append) to add the node to the DOM.\r\n\r\n```html\r\n<script>\r\nclass MyComponent extends HTMLElement {\r\n  connectedCallback() {\r\n    this.render();\r\n  }\r\n\r\n  sayHello() {\r\n    alert("Hi there!");\r\n  }\r\n\r\n  render() {\r\n    const button = document.createElement(\'button\');\r\n    button.innerText = "Say Hello!";\r\n    button.addEventListener(\'click\', this.sayHello);\r\n    this.append(button);\r\n  }\r\n}\r\n\r\nwindow.customElements.define(\'hello-component\', MyComponent);\r\n</script>\r\n\r\n<hello-component></hello-component>\r\n```\r\n\r\nWhile this works for the initial render, it doesn’t handle any of the edgecases that,at scale,can cause long-term damage to your app’s maintainability & performance. \r\n\r\nFor example, future re-renders of the element will duplicate the button. To solve this, you must iterate through all of the element’s [`children`](https://developer.mozilla.org/en-US/docs/Web/API/Element/children) and [`remove`](https://developer.mozilla.org/en-US/docs/Web/API/Element/remove) them one-by-one.\r\n\r\nFurther, once the element is removed from the DOM, the click listener is not implicitly removed in the background. Because of this, it’s never released from memory and is considered a memory leak. If this issue continued to occur during long-term usage of your app, it would likely bloat memory usage and eventually crash or hang.\r\n\r\nTo solve this, you’d need to assign a variable for every `addEventListener` you had present. This may be simple for one or two events, but add too many and it can be difficult to keep track.\r\n\r\nAnd all of this ignores the maintenance standpoint: What does that code do at a glance?\r\n\r\nIt doesn\'t look anything like HTML and as a result, requires you to consistently context shift between writing standard HTML in a string and using the DOM APIs to construct elements. \r\n\r\nLuckily, Lit doesn’t have these issues. Here’s the same button construction and rendering to a custom element using Lit instead of vanilla JavaScript:\r\n\r\n```html\r\n<script type="module">\r\nimport { html, LitElement } from "https://cdn.skypack.dev/lit";\r\n\r\nexport class HelloElement extends LitElement {\r\n    sayHello() {\r\n          alert("Hi there!");\r\n    }\r\n\r\n    render() {\r\n        return html`\r\n            <button @click=${this.sayHello}>Say Hello!</button>\r\n        `;\r\n    }\r\n}\r\n\r\nwindow.customElements.define(\'hello-component\', HelloElement);\r\n</script>\r\n\r\n<hello-component></hello-component>\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=194518" loading="lazy"></iframe>\r\n\r\nYup, that’s all. Lit allows you to bind elements by using the `@` sign and passing the function as a placeholder to the `html` tagged template. Not only does this look much HTML-like, it handles event cleanup, re-rendering, and more.\r\n\r\n# Attributes & Properties\r\n\r\nAs we learned before, there are two ways to pass values between and into components: attributes and values.\r\n\r\nPreviously, when we were using vanilla JavaScript, we had to define these separately. Moreover, we had to declare which attributes to dynamically listen to value changes of.\r\n\r\n```javascript\r\nclass MyComponent extends HTMLElement {\r\n  connectedCallback() {\r\n      this.render();\r\n  }\r\n\r\n  static get observedAttributes() {\r\n      return [\'message\'];\r\n  }\r\n\r\n  attributeChangedCallback(name, oldValue, newValue) {\r\n      this.render();\r\n  }\r\n\r\n  render() {\r\n      const message = this.attributes.message.value || \'Hello world\';\r\n      this.innerHTML = `<h1>${message}</h1>`;\r\n  }\r\n}\r\n```\r\n\r\nIn Lit, we declare attributes and properties using a static getter and treat them as normal values in any of our functions.\r\n\r\n```javascript\r\nimport { html, LitElement } from "https://cdn.skypack.dev/lit";\r\n\r\nexport class HelloElement extends LitElement {\r\n  static get properties() {\r\n      return {\r\n          message: {type: String},\r\n      };\r\n  }\r\n\r\n  constructor() {\r\n      super();\r\n      this.message = \'Hello world\';\r\n  }\r\n\r\n  render() {\r\n      return html`\r\n    <h1>${this.message}</h1>\r\n  `;\r\n  }\r\n}\r\n\r\nwindow.customElements.define(\'hello-component\', HelloElement);\r\n```\r\n\r\nFor starters, we no longer have to manually call “render” when a property’s value is changed. Lit will re-render when values are changed.\r\n\r\nThat’s not all, though: Keen eyed readers will notice that we’re declaring a type associated with the `message` property.\r\n\r\nUnlike the [React ecosystem’s PropTypes](https://github.com/facebook/prop-types), the `type` subproperty doesn’t do runtime type validation. Instead, it acts as an automatic type converter.\r\n\r\nThis can be of great help as the knowledge that attributes can only be strings can be difficult to remember while debugging.\r\n\r\nFor example, we can tell Lit to convert an attribute to a Number and it will migrate from a string that looks like a number to an actual JavaScript type number.\r\n\r\n```html\r\n<script type="module">\r\nimport { html, LitElement } from "https://cdn.skypack.dev/lit";\r\n\r\nexport class HelloElement extends LitElement {\r\n  static get properties() {\r\n      return {\r\n          val: {type: Number},\r\n      };\r\n  }\r\n\r\n  render() {\r\n      return html`\r\n    <h1>${this.val} is typeof ${typeof this.val}</h1>\r\n  `;\r\n  }\r\n}\r\n\r\nwindow.customElements.define(\'hello-component\', HelloElement);\r\n</script>\r\n\r\n<!-- This will show "123 is typeof number"  -->\r\n<hello-component val="123"></hello-component>\r\n<!-- This will show "NaN is typeof number"  -->\r\n<hello-component val="Test"></hello-component>\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=194519" loading="lazy"></iframe>\r\n\r\n## Attribute Reactivity\r\n\r\n\r\nOne of the biggest benefits of not having to call `render` manually is that Lit is able to render contents when they need to update.\r\n\r\nFor example, given this example, the contents will render properly to update with new values.\r\n\r\n```javascript\r\nimport { html, LitElement } from "lit";\r\n\r\nexport class ChangeMessageElement extends LitElement {\r\n  static get properties() {\r\n      return {\r\n          message: {type: String},\r\n      };\r\n  }\r\n\r\n  changeSelectedMsg() {\r\n      const newMsg = msgs[Math.floor(Math.random() * msgs.length)];\r\n      this.message = newMsg;\r\n  }\r\n\r\n  constructor() {\r\n      super();\r\n      this.message = \'Hello world\';\r\n  }\r\n\r\n  render() {\r\n      return html`\r\n    <button @click="${this.changeSelectedMsg}">Toggle</button>\r\n    <hello-component message=${this.message}></hello-component>\r\n  `;\r\n  }\r\n}\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=181069" loading="lazy"></iframe>\r\n\r\n# Reactive Data Binding\r\n\r\nThis reactivity comes with its own set of limitations. While numbers and strings are able to be set fairly trivially, objects (and by extension arrays) are a different story.\r\n\r\nThis is because, in order for Lit to know what properties to update in render, an object must have a different reference value from one to another. [This is just how React and other frameworks detect changes in state as well.](https://www.coletiv.com/blog/dangers-of-using-objects-in-useState-and-useEffect-ReactJS-hooks/)\r\n\r\n```javascript\r\nexport class FormElement extends LitElement {\r\n  constructor() { /* ... */ }\r\n  static get properties() {\r\n      return {\r\n          todoList: {type: Array},\r\n          inputVal: {type: String},\r\n      };\r\n  }\r\n\r\n  _onSubmit(e) {\r\n      e.preventDefault();       /* This works, because we’re changing the object reference */\r\n      this.todoList = [...this.todoList, this.inputVal];       /* But this would not, because we aren’t */\r\n      // this.todoList.push(this.inputVal);       this.inputVal = \'\';\r\n  }\r\n\r\n  _onChange(e) {\r\n      this.inputVal = e.target.value;\r\n  }\r\n \r\n  render() {\r\n      return html`\r\n    <form @submit="${this._onSubmit}">\r\n      <input .value="${this.inputVal}" @change="${this._onChange}" type="text" />\r\n      <button type="submit">Add</button>\r\n    </form>\r\n    <todo-component todos=${this.todoList}></todo-component>\r\n  `;\r\n  }\r\n}\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=181090" loading="lazy"></iframe>\r\n\r\nYou may also notice that we’re binding both the user’s input and output to set and reflect the state. [This is exactly how other frameworks like React also expect you to manage user state](https://coderpad.io/blog/master-react-unidirectional-data-flow/). \r\n\r\n# Prop Passing with Lit’s Dot Synax\r\n\r\nHTML attributes are not the only way to pass data to a web component. Properties on the element class are a way to pass more than just a string to an element.\r\n\r\nWhile the `type` field can help solve this problem as well, you’re still limited by serializability, meaning that things like functions won’t be able to be passed by attributes.\r\n\r\nWhile properties are a more robust method of data passing to web components, they’re seldomly used in vanilla JavaScript due to their complexity in coding.\r\n\r\nFor example, this is a simple demonstration of passing an array.\r\n\r\n```html\r\n<html>\r\n  <head>\r\n    <!-- Render object array as "ul", passing fn to checkbox change event -->\r\n    <script>\r\n      class MyComponent extends HTMLElement {\r\n        property = [];\r\n     \r\n        connectedCallback() {\r\n          this.render();\r\n        }\r\n     \r\n        render() {\r\n          this.innerHTML = `<h1>${this.property.length}</h1>`;\r\n        }\r\n      }\r\n   \r\n      customElements.define(\'my-component\', MyComponent);\r\n    </script>\r\n   \r\n    <script>\r\n      function changeElement() {\r\n        const compEl = document.querySelector(\'#mycomp\');\r\n        compEl.property = [\r\n          \'Testing\',\r\n          \'Second\',\r\n          \'Another\'\r\n        ];      \r\n        compEl.render();\r\n      }\r\n    </script>\r\n   \r\n  </head>\r\n  <body>\r\n    <my-component id="mycomp"></my-component>\r\n    <button onclick="changeElement()">Change to 3</button>\r\n  </body>\r\n</html>\r\n```\r\n\r\nFirst, you have to get a reference to the element using an API like `querySelector`. This means you need to introduce a new reference to the component and make sure the IDs match in both parts of code.\r\n\r\nThen, just as is the case with updating attribute values, we need to manually call the “render” function in order to update the UI.\r\n\r\nBut those complaints aside, there’s still one more: It places your data and component tags in two different areas. Because of this, it can be more difficult to debug or figure out what data is being passed to what component.\r\n\r\nLit takes a different approach. Within a Lit `html` tagged template, add a period before an attribute binding and suddenly it will pass as a property instead.\r\n\r\n```html\r\n<script type="module">\r\nimport { html, LitElement } from "https://cdn.skypack.dev/lit";\r\n\r\nclass MyElement extends LitElement {\r\n  static get properties() {\r\n    return {\r\n      property: {type: Array},\r\n    };\r\n  }\r\n\r\n  render() {\r\n    return html`\r\n      <h1>${this.property.length}</h1>\r\n    `;\r\n  }\r\n}\r\n\r\nwindow.customElements.define(\'my-component\', MyElement);\r\n\r\nclass ChangeMessageElement extends LitElement {\r\n    static get properties() {\r\n      return {\r\n        array: {type: Array},\r\n      };\r\n    }\r\n\r\n    constructor() {\r\n      super();\r\n      this.array = [];\r\n    }\r\n\r\n    changeElement() {\r\n      this.array = [\r\n        \'Testing\',\r\n        \'Second\',\r\n        \'Another\'\r\n      ];      \r\n    }\r\n\r\n    render() {\r\n        return html`\r\n      <!-- If "property" didn\'t have a period, it would pass as attribute -->\r\n      <my-component .property=${this.array}></my-component>\r\n      <button @click=${this.changeElement}>Change to 3</button>\r\n    `;\r\n    }\r\n}\r\n\r\nwindow.customElements.define(\'change-message-component\', ChangeMessageElement);\r\n</script>\r\n\r\n<change-message-component></change-message-component>\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=194520" loading="lazy"></iframe>\r\n\r\nThis works because properties and attributes are both created at the same time with Lit.\r\n\r\nHowever, due to the period binding not being HTML standard, it comes with the side effect of having to use a Lit template in order to bind properties. This tends not to be a problem in applications - since many tend to use and compose components throughout their applications.\r\n\r\n# Array Rendering\r\n\r\nIn our article about vanilla JavaScript web components, we built a simple todo list. Let’s take another look at that example, but this time using Lit for our component code. We’ll get started with a parent `FormElement`, which will manage the data and user input.\r\n\r\n```javascript\r\nclass FormElement extends LitElement {\r\n  static get properties() {\r\n      return {\r\n          todoList: {type: Array},\r\n          inputVal: {type: String},\r\n      };\r\n  }\r\n\r\n  _onSubmit(e) {\r\n      e.preventDefault();\r\n      this.todoList = [...this.todoList, {name: this.inputVal, completed: false}];\r\n      this.inputVal = \'\';\r\n  }\r\n\r\n  // ...\r\n\r\n  render() {\r\n      return html`\r\n    <button @click=${this.toggleAll}>Toggle all</button>\r\n    <form @submit=${this._onSubmit}>\r\n      <input .value=${this.inputVal} @change=${this._onChange} type="text" />\r\n\r\n      <button type="submit">Add</button>\r\n    </form>\r\n    <!-- Notice the period in ".todos" -->\r\n    <todo-component .todos=${this.todoList}></todo-component>\r\n  `;\r\n  }\r\n}\r\n```\r\n\r\nNow that we have a form that contains an array, an important question arises: how do we iterate through an array in order to create individual elements for a list?\r\n\r\nWell, while [React has `Array.map](https://reactjs.org/docs/lists-and-keys.html)` and [Vue has `v-for`](https://v3.vuejs.org/guide/list.html#mapping-an-array-to-elements-with-v-for), Lit uses a `repeat` function. Here’s an example:\r\n\r\n```javascript\r\nclass TodoElement extends LitElement {\r\n  // ...\r\n\r\n  render() {\r\n      return html`\r\n    <ul>\r\n      ${repeat(this.todos, (todo) => html`\r\n        <li>\r\n          <input type="checkbox" .checked=${todo.completed}/>\r\n          ${todo.name}\r\n        </li>\r\n      `)}\r\n    </ul>\r\n  `;\r\n  }\r\n}\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=181092" loading="lazy"></iframe>\r\n\r\n# Passing Functions\r\n\r\nBefore we step away from code to talk pros and cons about Lit itself (shh, spoilers!); let’s take a look at a code sample that demonstrates many of the benefits over vanilla JavaScript web components we’ve talked about today.\r\n\r\nReaders of the previous blog post will remember that when passing an array of objects to a web component, things looked pretty decent.\r\n\r\nIt wasn’t until we tried binding event listeners to an array of objects that things got complex (and messy). Between needing to manually create elements using `document`, dealing with `querySelector` to pass properties, manually calling “render”, and needing to implement a custom “clear” method - it was a messy experience.\r\n\r\nLet’s see how Lit handles the job.\r\n\r\n```javascript\r\nclass TodoElement extends LitElement {\r\n  // ...\r\n \r\n  render() {\r\n      const headerText = this.todos\r\n          .filter(todo => todo.completed).length;\r\n\r\n      return html`\r\n    <h1>${headerText}</h1>\r\n    <ul>\r\n      ${repeat(this.todos, (todo) => html`\r\n        <li>\r\n          <input type="checkbox" @change=${todo.onChange} .checked=${todo.completed}/>\r\n          ${todo.name}\r\n        </li>\r\n      `)}\r\n    </ul>\r\n  `;\r\n  }\r\n}\r\n```\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=181093" loading="lazy"></iframe>\r\n\r\nYou will notice that we’re using a `filter` within our `render` method. Because this logic is within the `render` method, it will run on every UI update. This is important to note in case you have expensive operations: you should avoid running those within the render method.\r\n\r\nOutside of this, however - that’s all there is! It reads just like HTML would (with the added benefit of cleanup and prop passing), handles dynamic data, and more!\r\n\r\n# Conclusion\r\n\r\nThe ability to leverage Lit in an application makes maintaining and improving a project easier than rolling web components yourself.\r\n\r\nLit demonstrates significant growth in web components from the early days of [Polymer](http://polymer-project.org/). This growth is in no small part due to the Lit team themselves, either!\r\n\r\nBefore it was a fully fledged framework, the project started from the `lit-html` package, which was an offshoot of Polymer. The Polymer team was instrumental in standardizing the modern variant of web components.\r\n\r\nThe ability to use Lit can strongly enhance web component development, but there are other options out there. Next time, we’ll talk about what the competitors are doing, what the pros and cons of each are, and how you can make the best choice for your applications.\r\n',
		},
		{
			title: "What do file extensions do?",
			description:
				"A file extension isn't the only way a file is inditified, so what does it do?",
			published: "2020-07-11T20:58:16.292Z",
			edited: "2020-07-11T20:58:16.292Z",
			authors: ["skatcat31"],
			tags: ["computer science"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "what-do-files-extensions-do",
			locale: "en",
			authorsMeta: [
				{
					id: "skatcat31",
					name: "Robert Mennell",
					firstName: "Robert",
					lastName: "Mennell",
					description:
						"A fullstack engineer who loves learning new things, playing video games, and his wife.\nIf you can learn it, you can do it.\nIf you can do it well, you've learned it.",
					socials: { github: "skatcat31", linkedIn: "rnmennell" },
					color: "#ba68c8",
					profileImg: "./hello.png",
					pronouns: "he",
					roles: ["author", "community"],
					profileImgMeta: {
						height: 2048,
						width: 2048,
						relativePath: "./hello.png",
						relativeServerPath: "/content/data/hello.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\hello.png",
					},
					rolesMeta: [
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "What do file extensions do?",
				description:
					"A file extension isn't the only way a file is inditified, so what does it do?",
				published: "2020-07-11T20:58:16.292Z",
				edited: "2020-07-11T20:58:16.292Z",
				authors: ["skatcat31"],
				tags: ["computer science"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\r\n> A filename extension or file type is an identifier specified as a suffix to the name of  computer file. - [Wikipedia](https://en.wikipedia.org/wiki/Filename_extension)\r\n\r\nA long & terse explanation of a file extension exists but to boil it down into simpler terms the file extension is used by a computer to check against a registry of programs to see if a program is registered on the system that can open the file. While there are some differences based on how they are treated by the operating system you use, in most cases, they are used as a simple check to allow a system to see what program can open the file.\r\n\r\n# Viewing the File Extension\r\n\r\nWhen most people look at a file they probably don't see a file extension after the name. Often, by default, the file extension is hidden from the user. You can easily find articles that outline how to [turn file extensions on for macOS](https://support.apple.com/guide/mac-help/show-or-hide-filename-extensions-on-mac-mchlp2304/mac) or [how to turn it on for Windows](https://www.howtogeek.com/205086/beginner-how-to-make-windows-show-file-extensions/). Now when looking at the file its extension will be visible right after the name.\r\n\r\n![A preview of what it's like to have file extensions on and off in Windows 10](./file_extensions.png)\r\n\r\nAs an example, most pictures you have will end in `.jpg`, `.png`, `.gif`, `.webp`, or `.avif`. A program will have a `.exe`, `.bash`, or `.bat`. A music file might have a `.mp3`, `.mp4`, `.flac`, or `.ogg`. A text file can be `.docx`, `.txt`, or `.odf`. Then there are spreadsheets, videos, hardware drivers, databases, and many other types of file extensions with more being made every day.\r\n\r\nKeep in mind, these file extensions are just part of the file name, they aren't part of your file's contents. If you were to remove or change the file extension and then add it back, nothing bad would happen to your file and it would act the same as it did before.\r\n\r\n# Opening the File\r\n\r\nWhenever you open a file, whether it's through a double click or open a file in an operating system from a menu the computer will go and see if there is a program registered to open that type of file extension. If it can find one registered to open the file, it takes the file and sends it to the program. If it can't find one then the computer will ask you to choose one of the programs on your computer that are registered to be associated with the file type to be used to open those types of files from now on. Of course, you could also tell your computer to change the program used to open the file menu and telling it to \"open with\" for a different program or by editing the file association table manually to register the program for the future. Then the program starts up then it opens the file and then the program can show the file in the way it is supposed to.\r\n\r\n# What happens if you open a file with another program\r\n\r\n> This is a serious warning about the following information: You can make your files unrecoverable if you change the file extension or open a file with another program it is not designed to be opened with. This can lead to a permanent loss of data. The following is only an example and should not be taken as an endorsement to try this on your system. DO NOT TRY THIS AT HOME WITHOUT TAKING PROPER PRECAUTIONS!\r\n\r\nA file on a computer is stored the same way as everything on a computer is: in a binary representation. Any program works with binary, and thus you could forcibly open a file with another program either by manually making the program open the file or by changing the file's extension. See the warning above. This can ruin the file depending on the program used to open it and should only be done if you know what you're doing and must do this. Sometimes though a file will open just fine. This can commonly be seen with Text files and Image files. Often when you change the file extension and open it in an appropriate program it will open just fine. Sometimes it won't, but that is due to the program and not the file. The file opens just fine because the very beginning of the binary representation is a set of [Magic Bytes](https://en.wikipedia.org/wiki/File_format#Magic_number) that identify the type of file beyond just the file extension. This identifying information is then used by the program to match the instruction set to operate the type of file. Not all programs operate this way though. Some of them only rely on opening known good files, and if used to open a file will just start operating on it right away. This is often how a program destroys a file because it was designed to work on specific types of files and because that program is single-use it is never designed to safely use other file types so it doesn't check for them and relies purely on the operating system to call the program. Although rare, these programs do exist. More often than not though the two systems are used together. If you don't change the extension or open a program with an unexpected program this is a rare occurrence.\r\n\r\n# A basic understanding\r\n\r\nNow armed with knowledge about what a file extension is, how it helps a computer, and a little about the backup mechanisms meant to aid this series of systems it probably makes more sense why there are different programs for different types of files.\r\n",
		},
		{
			title: "What's An Algorithm?",
			description:
				"A quick introduction into what algorithms are, what they're made of and why they're an important part of understanding how programming languages work",
			published: "2022-08-26T18:00:00.000Z",
			authors: ["qarnax"],
			tags: ["computer science"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "what-is-an-algorithm",
			locale: "en",
			authorsMeta: [
				{
					id: "qarnax",
					name: "Qarnax",
					firstName: "",
					lastName: "",
					description:
						"I'm a frontend developer and indie game enthusiast 👾 \n I enjoy learning new things and building my own stuff 🔧 and I love helping people get into coding 😊",
					socials: {
						twitch: "qarnax_",
						twitter: "qarnax",
						github: "qarnax801",
					},
					profileImg: "./qarnax.jpg",
					color: "",
					roles: ["developer", "author", "community", "translator"],
					profileImgMeta: {
						height: 735,
						width: 736,
						relativePath: "./qarnax.jpg",
						relativeServerPath: "/content/data/qarnax.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\qarnax.jpg",
					},
					rolesMeta: [
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
						{ id: "translator", prettyname: "Translator" },
					],
				},
			],
			frontmatterBackup: {
				title: "What's An Algorithm?",
				description:
					"A quick introduction into what algorithms are, what they're made of and why they're an important part of understanding how programming languages work",
				published: "2022-08-26T18:00:00.000Z",
				authors: ["qarnax"],
				tags: ["computer science"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nIf you ever used GPS instructions to get somewhere, or followed a recipe book to make apple pie, or even dialed a phone to call a friend, then you already executed what you can call an **Algorithm**.\n\nIn simple terms, an algorithm is a set of instructions that lead to a certain result. If you execute it correctly, you get the result you wanted, a delicious apple pie!\nBut if you somehow mess up an instruction (like leaving the pie in the oven for 2 hours instead of 1 hour like the recipe book tells you to) then you end up with a bad result, and you would have to start over.\n\nThe same thing applies for machines. If you give a computer a clear set of instructions, it’ll execute them in order to reach the desired result. There is, however, a huge difference between telling another person how to solve a certain equation, and telling a computer to do the same thing, because computers have [their own language](https://unicorn-utterances.com/posts/how-computers-speak#hdd), which is very different from human language.\n\nHowever, if you understand what an algorithm is, and how to break down tasks into a small set of very basic instructions, it will be a lot easier to deal with programming languages later in your learning journey.\n\n# Algorithms & Computers\n\nTo emphasize why the concept of algorithms is very important, you have to understand that an algorithm describes the steps that need to be taken (from **START** to **END**) to do a certain task, independently from any programming language.\nIn other words, no matter what programming language people use for a certain task, the same “thought process” can be applied everywhere.\n\nLet’s say you are asked to write down the instructions needed to go from point **A** to point **B** as shown in this map below:\n\n![A maze with a series of blocks oriented cleanly in a North East South West direction. Point 'A' is to the top right, while 'B' is to the bottom left, with a few blocks in between.](./mapOne.png)\n\nA very basic algorithm can be written down as such:\n\n```elixir\nSTART\n\t- Head East\n\t- Head South to the intersection\n\t- Head East to the intersection\nEND\n```\n\nThe instructions are pretty straightforward, so anyone can follow them. Of course there are other routes you can take to get to point **B**, so you can make your set of instructions as simple or as complex as you want to, but you’ll learn with time that sometimes, just because there are very few instructions, doesn’t mean that your algorithm is the most efficient.\n\nLet’s look at the example here below:\n\n![A maze with a series of blocks oriented cleanly in a North East South West direction. Point 'A' is right next to a subway station 'A', while point 'B' is right next to a subway station 'B'.](./mapTwo.png)\n\nHere we can do one of two algorithms to get from point A to point B:\n\n**Algorithm N°1:**\n```elixir\nSTART\n\t- Head South\n\t- Head East\nEND\n```\n\n**Algorithm N°2:**\n```elixir\nSTART\n\t- Enter subway station 'A'\n\t- Take the subway to subway station 'B'\n\t- Exit subway station 'B'\n\t- Head East\nEND\n```\n\nWhile Algorithm N°1 has only **2 instructions**, it would take someone more time and energy to walk from point A to B, while if you follow Algorithm N°2, it has **4 instructions**, but you get to save time and energy compared to the first Algorithm.\n\nThe same thing goes for a computer program, sometimes, just because there are a few lines of code, doesn’t mean it’s gonna run the fastest or be the most performant.\n\nBut before we can get into what makes an algorithm fast or better suited for one task or the other, let's first look at what an algorithm can be made of.\n\n# Building blocks of an algorithm\n\nLet’s take a look at an example that has something more to do with computers: *a basic arithmetic operation.*\n\nIf you were asked to calculate 1 + 2, it would take you less than a second, because in your brain “it’s obviously 3”, right? But what if you were asked to break down that operation into steps like we did in the previous example?\n\nIf we follow the same thought process as before, we could write something like this:\n\n```elixir\nSTART\n\t- Take the number 1\n\t- Take the number 2\n\t- Add them together\n\t- Obtain the number 3\nEND\n```\n\nThat's a pretty simple algorithm. But for a computer to be able to take two values and apply an arithmetic operation between them, it needs to store them somewhere first before it does anything with them, which brings us to out next point: \"**Variables**\"\n\n## Variables\n\nIn any computer program, we often have to temporarily store values for different operations. These values can be inputs _(from the user through the keyboard)_ or from the computer storage, or sometimes even values from other operations made by the computer itself as shown in this example:\n\n**_Calculating 2 to the power of 3_**:\n```elixir\nSTART\n\t- Take the number 2\n\t- Take another number 2\n\t- Multiply 2 by 2\n\t- Obtain the number 4\n\t- Take another number 2\n\t- Multiply 4 by 2\n\t- Obtain the number 8\nEND\n```\n\nIn the fourth step, we have to store the value **4** which is returned by the computer itself, in order to multiply it again by the number **2** to get the final result.\n\n> Values stored by a computer don’t always have to be numbers though, they can also be letters *(known in programming languages as characters, like a, b, k, y…)*, words *(known as “strings”, which means “strings of characters”)*, and other types of variables that you’ll meet later on as you deal with programming languages.\n\nWhenever the computer needs to store a value of any kind, it uses what we call a “Variable”.\n\nA variable can be initially considered as a box to keep things in. And since there can be millions of \"boxes\" inside a computer, we need to differentiate them, which is why each one has a unique name, address (where it's kept in the memory), etc.\n\nSo, for any value that needs to be used, we can ask the computer to create a unique **variable** and **assign** our value to that variable so that we're able to use it throughout the code.\n\nTo illustrate how that works, let's look at this visual representation of how addition between two values happens:\n\n![Visual representation of how adding two values happens in an algorithm with the help of variables](./variables.png)\n\nIf we want to be even more specific on what happens inside the computer, we could re-write the algorithm like this:\n\n```elixir\nSTART\n\t- Take the number 1 and put it in a box called Box1\n\t- Take the number 2 and put it in a box called Box2\n\t- Add them together and put that value in a box called Box3\n\t- Display the value of Box3 on the screen\nEND\n```\n\nYou will notice in our illustration that there's a block that says \"A function that displays values\", but ignore that for the moment because we'll get to what functions are in a few.\n\n> A more extensive explanation on how computers store and handle variables can be found [here](https://unicorn-utterances.com/posts/how-computers-speak).\n\nNow that we've established how values are stored, comes the part where the computer handles the different instructions given, with the help of what we can call \"**Operators**\"\n\n## Operators\n\nIn any programming language, you'll find a set of different symbols used to execute specific operations on either one variable, or between 2 or more variables.\n\nThe simplest (and most common) ones are arithmetic operators: **Addition (+), Subtraction (-), Multiplication(x) and Division (÷)**\n\n> Note that in several programming languages, the 4 arithmetic operators can be used for more than just mathematical operations between numbers. A simple example is adding two words together in JavaScript to form another word, as such: `\"Mathe\" + \"matical\"`\n\nThere are of course other operators that you'll get into as you start coding, but we won't get into all of them. Instead we'll look into one that is very common, and that's the **Equal sign =**\nAs opposed to how it's usually used in simple arithmetics, as the part to indicate \"this is the result\", in most programming languages, it actually means something completely different.\n\nLet's take a look at the same example we used before, where we added two numbers together, and take the first instruction:\n\n`- Take the number 1`\n\nIf we take into consideration the part where we talked about \"storing values\", we mentioned \"**assigning**\" values to variables. The **Equal sign (=)** is what we can use to _'put'_ values into variables. So a more exact way of describing that instruction would be:\n\n`- Assign the number 1 to a variable`\n\nWith all of that put into consideration, let's try to write an algorithm that is a little bit more comprehensible to a computer:\n\n```elixir\nSTART\n\t- Assign the number 1 to a variable\n\t- Assign the number 2 to another variable\n\t- Add the values of the two variables together\n\t- Obtain the number 3\nEND\n```\n\nAll of this sounds great! However, we're still dealing with very simple operations. So what about big complex instructions? Like if we take a calculator, and try to calculate the **square root** of a certain number, how does it do that? Especially considering that the computer can't understand \"Square root\", and can only do very basic operations.\n\nTo do that, we'd have to create specific \"sets of instructions\" that we can call for specific steps. Those sets of instructions are called \"**Functions**\"\n\n## Functions\n\nA function is a set of instructions that is defined _once_, but can be used _as many times as necessary_. In other words, it's a \"pre-made chunk of simple instructions used to perform a complex task on demand\".\nFor different purposes, we can create different functions to make performing tasks easier for ourselves.\n\nThe big advantage of making a function is to be able to quickly and easily use it without having to write the entire set of instructions over and over again, because over time you'll see that some tasks have to be performed hundreds of times in an applications, and to make all of that easier, functions are the way to go.\n\nA good example where these functions can come in handy is when trying to do bulk-tasks, like cooking multiple pies at once:\n\n```elixir\nBAKE_START\n   - Pre-heat the oven to 350\n   - Put the pie in the oven\n   - Wait an hour\n   - Take the pie out of the oven\nBAKE_END\nSTART\n\t- Prepare apple pie\n\t- Prepare rhubarb pie\n\t- BAKE apple pie\n\t- BAKE rhubarb pie \nEND\n```\n\nHere we are calling the `BAKE` function instead of writing the instructions over and over each time we need them.\n\n# Pseudo-code vs. Programming languages\n\nNow that we covered the essentials of what an algorithm is and how to break down tasks into instructions or “pseudo-code”, let’s have a little taste of programming languages, by comparing an algorithm (written in English) to how it’s written in two different programming languages.\n\nLet’s take our previous example where we calculated 1 + 2, and see how it’s written in two of the most popular programming languages nowadays: JavaScript and Python.\n\n**Pseudo-code:**\n```elixir\nSTART\n\t- Assign the number 1 to a variable\n\t- Assign the number 2 to another variable\n\t- Add the values of the two variables together\n\t- Obtain the number 3\nEND\n```\n\n**JavaScript:**\n```javascript\nvariableOne = 1;\nvariableTwo = 2;\nconsole.log(variableOne + variableTwo)\n// We obtain the number 3\n```\n\n**Python**\n```python\nvariableOne = 1\nvariableTwo = 2\nprint(variableOne + variableTwo)\n# We obtain the number 3\n```\n\nIf we compare the 3 different programs line by line, we can see that the steps are exactly the same:\n- We put the number 1 in a variable (that we call variableOne in this case)\n- We put the number 2 in another variable (that we call variableTwo)\n- We “Add the two values together” using the + operator.\n- We get the result, which is 3\n\n> Note that `console.log` and `print` are functions in JavaScript and Python respectively, used to log values for the user to see on screen.\n\nSo, as we already mentioned in the beginning of this article, we can see that the thought process is in fact the same whether we use pseudo-code, JavaScript or Python (as is the case with so many other programming languages).\n\nOf course there’s a lot more to programming languages than these steps, especially considering what we've talked about in the \"Functions\" section. But this will hopefully give you an idea on how they work in general, and how you can break down any process before you actually write in in JavaScript or Python or any other language you may get into as you go further into coding.\n\n# Conclusion\n\nAlgorithms are not an alien concept to anyone, since each of us tends to follow different sets of steps to achieve the different tasks we run into everyday, and in this article we covered how to break down any task into very small steps and how that concept is exactly how a computer runs programs.\nAnd despite the many different ways a program can be written, there's no correlation whatsoever between how long the code is and how performant it is, because as we've seen, an algorithm can be made of multiple instructions that could require either small operations (like addition or subtraction) or complex functions (made up of multiple small operations).\nThose basics, along with the sneak peek we had into actual programming languages, will hopefully serve as a good base for what's up ahead! But If you have any questions at all, make sure you drop a comment below, or [join our discord community](https://discord.gg/FMcvc6T).\n",
		},
		{
			title: "What is Primitive obsession and how to fix it",
			description:
				"Primitive obsession is an extremely common code smell, and when identified and fix, it greatly helps to reduce the amount of bugs that you may find in your code.",
			published: "2022-07-19T14:52:03.000Z",
			authors: ["alexchadwick"],
			tags: ["opinion", "csharp", "computer science"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			originalLink:
				"https://alexchadwick.com/what-is-primitive-obsession-and-how-do-you-fix-it",
			slug: "what-is-primitive-obsession",
			locale: "en",
			authorsMeta: [
				{
					id: "alexchadwick",
					name: "Alex Chadwick",
					firstName: "Alex",
					lastName: "Chadwick",
					description:
						"I'm a full-stack web developer in the UK (but born in sunny Spain!) \n I spend too much time reading articles on clean code and not enough refactoring 🤣",
					socials: {
						twitch: "alexchadwicc",
						twitter: "TheAlexChadwick",
						github: "AlexChadwickP",
						linkedin: "alexchadwickp",
						website: "https://alexchadwick.com",
					},
					pronouns: "he",
					profileImg: "./alexchadwick.jpg",
					color: "",
					roles: ["author", "translator"],
					profileImgMeta: {
						height: 2316,
						width: 2315,
						relativePath: "./alexchadwick.jpg",
						relativeServerPath: "/content/data/alexchadwick.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\alexchadwick.jpg",
					},
					rolesMeta: [
						{ id: "author", prettyname: "Author" },
						{ id: "translator", prettyname: "Translator" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "What is Primitive obsession and how to fix it",
				description:
					"Primitive obsession is an extremely common code smell, and when identified and fix, it greatly helps to reduce the amount of bugs that you may find in your code.",
				published: "2022-07-19T14:52:03.000Z",
				authors: ["alexchadwick"],
				tags: ["opinion", "csharp", "computer science"],
				attached: [],
				license: "cc-by-nc-sa-4",
				originalLink:
					"https://alexchadwick.com/what-is-primitive-obsession-and-how-do-you-fix-it",
			},
			contentMeta:
				"\nPrimitive obsession is an extremely common code smell, and when identified and fix, it greatly helps to reduce the amount of bugs that you may find in your code. This code smell is one that most developers can't intuitively identify.\n\n# What are primitive types?\nIn order to know what primitive obsession is about, it's useful to firstly define primitive types. Primitive types are essentially the **basic building blocks** of a language. These are integers, strings, chars, floating-point numbers etc.\n\n# What is Primitive obsession?\nPrimitive obsession is when your codebase relies on primitive types more than it should, and this results in them being able to control the logic of your application to some extent.\n\nFor example, you may have the following in C#:\n\n\n```cs\nclass User {\n  public int Id { get; set; }\n  public string Name { get; set; }\n}\n``` \n\nAnd this may look like a perfectly good type. However it is flawed in various ways. For example, we're not able to easily enforce any sort of constraints.\n\nHere we've got an `Id` that is an integer. But an ID is unlikely to be for example a negative number. However number can hold negative values, so it's not really fully representing our ID.\n\nHowever let's have a look at the following example:\n\n# How to fix Primitive Obsession\n\n```cs\nclass Id {\n  public int Value { get; set; }\n  public Id(int value) {\n    if (value < 0) throw new ArgumentException(\"An ID cannot be negative\");\n\n    Value = value;\n  }\n}\n\nclass User {\n  public Id UserId { get; set; }\n  public string Name { get; set; }\n}\n```\n\nNow we know for certain that `UserId` will never be an invalid value. Never in our code will we have to check whether it's a negative number.\n\nThis is a very simplified example, so it may look a bit weird, but it's enough to show off the gist of what Primitive Obsession is.\n\nAnother example could be for example a password field.\n\n```cs\nclass Credentials {\n  public string Password { get; set; }\n} \n```\n\nIf this was an actual class, then it could pose many problems. For starters, it's difficult to know whether a `Password` will pass all validation checks, and so we'll need to perform an operation every time we need this information. However what would happen if we made a custom type that ensures that the value will be validated?\n\n```cs\nclass ValidPassword {\n  public string Value { get; }\n\n  public ValidPassword(string password) {\n    if (!isValidPassword(password)) throw new ArgumentException(\"The password did not pass validation\");\n\n    Value = password;\n  }\n\n  public void ChangePassword(string newPassword) {\n    if(!isValidPassword(password)) throw new ArgumentException(\"The new password did not pass validation\");\n\n    Value = newPassword;\n  }\n\n  private static bool isValidPassword(string password) {\n    /* ... Code to make sure a password follows a certain set of rules ... */\n  }\n}\n\nclass User {\n  public ValidPassword Password { get; set; }\n}\n```\n\nNow we know for absolute certain that the `Password` of a `User` is always going to be valid. In fact we can also use the `ChangePassword` function to make sure that any new values are also valid. It will always be valid.\n\nYou could even go a step further and make it immutable, but I'll leave that for another time!\n\n# Conclusion\nPrimitive Obsession is one of the least identified code smells, and for some reason isn't as popular as others.\n\nA good way I've found to identify primitive obsession is to see if you often find yourself checking if a variable satisfies a set of rules. If that's the case then you're better of making a custom type for it, with a constructor that is able to validate the input of the value you're trying to assign to it.\n\nI hope you've enjoyed the article. If so, I'd appreciate it if you shared and left feedback!\n",
		},
		{
			title:
				"What is Server Side Rendering (SSR) and Static Site Generation (SSG)?",
			description:
				"An explanation of what server-side rendering is, what static site generation is, and how you can utilize them in React, Angular, or Vue!",
			published: "2020-03-24T05:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["ssr", "ssg", "nextjs", "react"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "what-is-ssr-and-ssg",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title:
					"What is Server Side Rendering (SSR) and Static Site Generation (SSG)?",
				description:
					"An explanation of what server-side rendering is, what static site generation is, and how you can utilize them in React, Angular, or Vue!",
				published: "2020-03-24T05:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["ssr", "ssg", "nextjs", "react"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				"\nIn recent years, projects like [Zeit's NextJS](https://nextjs.org/) and [Gatsby](https://www.gatsbyjs.org/) have garnered acclaim and higher and higher usage numbers. Not only that, but their core concepts of Server Side Rendering (SSR) and Static Site Generation (SSG) have been seen in other projects and frameworks such as [Angular Universal](https://angular.io/guide/universal), [ScullyIO](https://scully.io/), and [NuxtJS](https://nuxtjs.org/). Why is that? What _is_ SSR and SSG? How can I use these concepts in my applications?\n\nWe'll walk through all of these questions and provide answers for each. First, we have to have an understanding of how a typical HTML site is able to serve content to your user.\n\n# Vanilla HTML Sites\n\nWhile many sites today are built using a component-based framework like Angular, React, or Vue, there's nothing wrong with good ole' HTML. For sites like this, you typically provide an HTML file for each of the routes of your site. When the user requests one of the routes, your server will return the HTML for it. From there, [your browser parses that code and provides the content directly to the user](/posts/understanding-the-dom/). All in all, the process looks something like this:\n\n1) You build HTML, CSS, JS\n2) You put it on a server\n3) The client downloads the HTML, CSS, JS from server\n4) The client immediately sees content on screen\n\n![A diagram explaining how the steps above would flow](./normal.svg)\n\nThis is a reasonably straightforward flow once you get the hang of it. Let's take a look at what happens when you throw a component-based framework into the fray.\n\n# Client Side Rendering {#csr}\n\nWhile you may not be familiar with this term, you're more than likely familiar with how you'd implement one of these; After all, this is the default when building an Angular, React, or Vue site. Let's use a React site as an example. When you build a typical React SPA without utilizing a framework like NextJS or Gatsby, you'd:\n\n1) You build the React code\n2) You put it on a server\n3) The client downloads the React code from the server\n4) The React code runs and generates the HTML/CSS on the client's computer\n5) The user **then** sees the content on screen after React runs\n\n![A diagram explaining how the steps above would flow](./csr.svg)\n\nThis is because React's code has to initialize to render the components on screen before it can spit out HTML for the browser to parse. Sure, there's an initial HTML file that might have loading spinner, but until your components have time to render, that's hardly useful content for your user. _While these load times can be sufficient for smaller applications_, if you have many components loading on-screen, _you may be in trouble if you want to keep your time-to-interactive (TTI) low_. That scenario is where SSR often comes into play.\n\n# Server Side Rendering (SSR) {#ssr}\n\nBecause React has to initialize _somewhere_, what if we were to move the initial rendering off to the server? Imagine - for each request the user sends your way, you spin up an instance of React. Then, you're able to serve up the initial render (also called \"fully hydrated\") HTML and CSS to the user, ready to roll. That's just what server-side rendering is!\n\n1) You build the React code\n2) You put it on a server\n3) The client requests data\n4) The server runs the React code on the server to generate the HTML/CSS\n5) The server then sends the generated HTML/CSS on screen\n6) The user then sees the content on screen. React doesn't have to run on their computer\n\n![A diagram explaining how the steps above would flow](./ssr.svg)\n\nThere are more improvements than there might initially see, however! Because you're hosting from a server - which has better network connectivity than a user's machine - you're able to make much faster network requests to perform that initial render.\n\nSay you need to grab data from the database to populate the screen's data, you're able to do that much faster as a result. Instead of displaying the user a loading screen while you wait to grab the data, you can simply tell your client, \"don't show anything until I send you HTML that I've generated from React.\" Due to the speed of your network, you can typically ship down a hydrated UI from database data as quickly as you'd typically be able to display a spinner.\n\nMoreover, if you have your server and database in the same hosting location, you're even able to avoid out-of-intranet calls, which would provide faster, more reliable connectivity for your initial render.\n\nThat said because you're relying on server functionality to do this rendering, you have to have a custom server setup. No simple CDN hosting here - your server has to initialize and render each user's page on request.\n\n# Static Site Generation (SSG) {#ssg}\n\nIf SSR is [\"passing the buck\"](https://en.wikipedia.org/wiki/Buck_passing) to the server to generate the initial page, then SSG is passing the buck to you - the developer.\n\nWhile the industry widely recognizes the term \"Static Site Generation,\" I prefer the term \"compile-side rendering\" or \"compile-time server-side rendering.\" This is because I feel they outline a better explanation of the flow of displaying content to the user. On an SSG site, you'd:\n\n1) You build the React code\n2) You generate the HTML and CSS on your development machine before deploying to a server (run build)\n3) You put the generated built code on a server\n4) The client downloads the HTML, CSS, JS from the built code on the server\n5) The client immediately sees content on screen\n\n![A diagram explaining how the aforementioned steps would flow](./ssg.svg)\n\nThis simply extends the existing build process that many front-end frameworks have. After [Babel's done with its transpilation](https://babeljs.io/), it merely executes code to compile your initial screen into static HTML and CSS. This isn't entirely dissimilar from how SSR hydrates your initial screen, but it's done at compile-time, not at request time. \n\nSince you're only hosting HTML and CSS again, you're able to host your site as you would a client-side rendered app: Using a CDN. This means that you can geo-sparse your hosting much more trivially but comes with the caveat that you're no longer to do rapid network queries to generate the UI as you could with SSR.\n\n# Pros and Cons {#pros-and-cons}\n\nIt may be tempting to look through these options, find one that you think is the best, and [overfit](https://en.wiktionary.org/wiki/overfit) yourself into a conclusion that one is superior to all the others. That said, each of these methods has its strengths and weaknesses.\n\n\n| Tool                         | Pros                                                         | Cons                                                         |\n| ---------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| Vanilla HTM                  | <ul aria-label=\"HTML Pros\"><li>Fast</li></ul>                | <ul aria-label=\"HTML Cons\"><li>Hard to scale</li></ul>       |\n| Client Side Rendering (CSR)  | <ul aria-label=\"CSR Pros\"><li>Easy to scale</li><li>Ease of engineering</li></ul> | <ul aria-label=\"CSR Cons\"><li>Slow JS initialization</li><li>SEO concerns</li></ul> |\n| Server Server Render (SSR)   | <ul aria-label=\"SSR Pros\"><li>Query based optimization</li><li>Better SEO handling</li><li>Usable without client JS enabled</li></ul> | <ul aria-label=\"SSR Cons\"><li>Heavier server load</li><li>Needs specific server</li><li>More dev effort than CSR</li></ul> |\n| Compile Time Rendering (SSG) | <ul aria-label=\"SSG Pros\"><li>Layout based optimization</li><li>Better SEO handling</li><li>Usable without client JS enabled</li><li>CDN hostable</li></ul> | <ul aria-label=\"SSG Cons\"><li>No access to query data</li><li>More dev effort than CSR</li></ul> |\n\nConsider each of these utilities a tool in your toolbox. You may be working on a landing page for a client where SSG would fit best — working on an internal SPA that only has a limited budget allocated to it? Client-side rendering might be your best bet there! Are you working on a public-facing app that highly depends on real-time data? SSR's for you! Each of these has its utility in their problem-space. It's good to keep that in mind when selecting one for your next project.\n\nIn fact, if you're using a framework that supports more than one of these methods ([like NextJS does as-of version 9.3](https://nextjs.org/blog/next-9-3)), knowing which of these utilities to use for which pages can be critical for optimizing your app.\n\n# A Note Regarding Performance Benchmarks {#lighthouse}\n\nI was once tasked with migrating a landing page with an associated blog from CSR to use SSG. Once I had done so, however, I noticed that [my Lighthouse score](https://developers.google.com/web/tools/lighthouse) had gone _down_ despite my page rendering a much more useful initial page significantly faster than it'd taken for my app's spinner to go away.\n\n> \"Why did my lighthouse scores go down when using SSG?\"\n\nI wasn't able to find an answer quickly, but eventually, I found out. Lighthouse scores based on many factors. One of those factors is \"time until fully loaded.\" Here's where my problems came into play:\n\nWhen doing server-side rendering or static site generation, you're shipped HTML and CSS. Then, to ensure your app fully works and is interactive after the intial load, it will preload the framework you built your site in. Once your framework preloads, it will oftentimes re-render the initial page that was shipped with HTML/CSS. Because the page is both pre-hydrated and responsible for initializing the framework afterwards on the client machine, your benchmarks may potentially suffer, despite the experience being better.\n\n![A chart outlining how in SSG once the code is shipped, it simply needs to initialize on the client's browser](./ssg_slowdown.svg)\n\n> While it's _technically_ possible to do things like [compile React entirely out of an exported NextJS site](https://github.com/zeit/next.js/issues/5054), it's far from trivial and doesn't fit _most_ usage very well. It's certainly a harder mental model at the very least.\n\nHere's an anecdote that was told to me by [Aaron Frost](https://twitter.com/aaronfrost) (the creator of the SSG utility [Scully](http://scully.io/)) about this scenario:\n\n> There once was an airport that had low ratings from an audit company that rated an airport's speed and quality. The biggest complaint from the rating was that the time it took to get un-boarded and to the baggage claim was too long. One of the reasons for this was due to how the planes were landing. When the planes landed, they were far away from the baggage claim, forcing their customers to walk a long distance before getting to the baggage claim.\n>\n> The airport decided to re-arrange how their planes landed in the future. While the customers seemed to be much happier overall, they received a lower rating on their next audit. This clearly contradicted the claims of their fliers. It turns out that the way the auditor was rating the airport was how much downtime they had before receiving a bag. While the others enjoyed reading articles on their phones during the downtime, the auditor was able to start their timer sooner as a result of walking for a shorter period of time.\n\nAll in all, while lighthouse might score you lower, you can rest assured that your customers will be happier knowing that you have a much more useful interaction on first glance than a site that doesn't use something like SSG.\n\n# Conclusion\n\nAs mentioned previously, having SSR and SSG in your toolbox are incredibly useful to have at your disposal. While not appropriate for every application, those that are tend to see great advantages from the concepts. Hopefully we've been able to provide a bit of insight that'll spark further learning and research into them.\n\n\n\nNow you have familiarity with what SSR and SSG are, maybe you want to take a stab at implementing it? [We took a look recently at creating a blog using an Angular SSG solution called Scully](/posts/making-an-angular-blog-with-scully/).\n\n\nAs always, let us know what you think down in the comments below or [in our community Discord](https://discord.gg/FMcvc6T).\n",
		},
		{
			title: "When to use HashMap instead of Loop",
			description: "Learn to use when to use HashMap instead of Loop",
			published: "2022-06-24T05:12:03.284Z",
			edited: "2022-06-27T05:12:04.284Z",
			authors: ["kaleem"],
			tags: ["javascript", "computer science"],
			attached: [],
			originalLink:
				"https://dev.to/kaleemniz/when-to-use-map-instead-of-loop-3cda",
			license: {
				id: "cc-by-nc-nd-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "https://creativecommons.org/licenses/by-nc-nd/4.0/",
				name: "Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) License",
			},
			slug: "when-to-use-map-instead-of-loop",
			locale: "en",
			authorsMeta: [
				{
					id: "kaleem",
					name: "Kaleem",
					firstName: "Kaleem",
					lastName: "",
					description:
						"Software Engineer, Simplifying programming, writing about learnings and lessons learned.",
					socials: {
						twitter: "kaleemniz",
						github: "kaleem68",
						linkedIn: "nixamani5",
					},
					pronouns: "he",
					profileImg: "./kaleem.jpeg",
					color: "#a8b3ba",
					roles: ["author"],
					profileImgMeta: {
						height: 344,
						width: 344,
						relativePath: "./kaleem.jpeg",
						relativeServerPath: "/content/data/kaleem.jpeg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\kaleem.jpeg",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "When to use HashMap instead of Loop",
				description: "Learn to use when to use HashMap instead of Loop",
				published: "2022-06-24T05:12:03.284Z",
				edited: "2022-06-27T05:12:04.284Z",
				authors: ["kaleem"],
				tags: ["javascript", "computer science"],
				attached: [],
				originalLink:
					"https://dev.to/kaleemniz/when-to-use-map-instead-of-loop-3cda",
				license: "cc-by-nc-nd-4",
			},
			contentMeta:
				'Many programmers use a **loop** or **filter** where HashMap data structure could be considered.\n\n## Finding user by id using Loops\n```js\nlet userIdToBeSearched = 103;\nconst users = [\n    {id: 101, name: "Josh"},\n    {id: 102, name: "Mosh"},\n    {id: 103, name: "Eli"},\n    {id: 104, name: "Jad"},\n    {id: 105, name: "Susan"}\n];\n\nlet user = null;\nfor (let i = 0; i < users.length; i++) {\n    if (users[i].id === userIdToBeSearched) {\n        user = users[i];\n        break;\n    }\n}\n\nif (user) {\n    console.log("User Found: ", user);\n} else {\n    console.log("user does not exit with id: ", userIdToBeSearched);\n}\n```\nThe above solution has a time complexity of **O(n)**, where n represents the number of users. If there are 1 thousand users, in the worst case, we will search every user to find a match.\n\n> Considering user id will be unique for each user, this is a good indication to use a HashMap instead of a loop since all keys in the Map are Unique.\n\n## Finding user by id using Map\n```js\nlet userIdToBeSearched = 103;\nconst users = new Map();\nusers.set(101, {id: 101, name: "Josh"});\nusers.set(102, {id: 102, name: "Mosh"});\nusers.set(103, {id: 103, name: "Eli"});\nusers.set(104, {id: 104, name: "Jad"});\nusers.set(105, {id: 105, name: "Susan"});\n\nif(users.has(userIdToBeSearched)){\n  console.log("User Found: ", users.get(userIdToBeSearched));\n}\nelse {\n  console.log("user does not exit with id: ", userIdToBeSearched);\n}\n```\nWhen using a **Map**, it takes constant time **O(1)** to find the user! All great, but note constructing the HashMap from the array still requires **O(n)** time.\n\nIn conclusion, use Map when frequently searching based on the **unique** field such as **id**. Please note Map cannot be used in case of searching based on the non-unique field such as **name**\n\nThank you for reading! Check the part 2 where we discuss **A Practical Use Case** of HashMaps. [When to use HashMap instead of Loop Part 2](https://dev.to/kaleemniz/when-to-use-hashmap-instead-of-loop-part-2-31pi)\n',
		},
		{
			title: "Why React 18 Broke Your App",
			description:
				"React 18's internal changes improved a lot, but may have broken your app in the process. Here's why and how you can fix it",
			published: "2022-01-27T22:12:03.284Z",
			authors: ["crutchcorn"],
			tags: ["react", "webdev"],
			attached: [],
			license: {
				id: "coderpad",
				footerImg: "/sponsors/coderpad.svg",
				licenceType: "Owned by CoderPad",
				explainLink: "https://coderpad.io/about-us/",
				name: "Written for CoderPad, reposted to Unicorn Utterances",
				displayName: "Written for CoderPad",
			},
			originalLink:
				"https://coderpad.io/blog/development/why-react-18-broke-your-app/",
			slug: "why-react-18-broke-your-app",
			locale: "en",
			authorsMeta: [
				{
					id: "crutchcorn",
					name: "Corbin Crutchley",
					firstName: "Corbin",
					lastName: "Crutchley",
					description:
						"Corbin is a senior developer with a passion for helping others. 💜\nThey're focused on ensuring that learning is open and fun. 🦄\nThey blog, livestream, code, and more to reach those goals to help others! 💅",
					socials: {
						twitter: "crutchcorn",
						github: "crutchcorn",
						twitch: "crutchcorn",
					},
					pronouns: "they/themselves",
					profileImg: "./crutchcorn.png",
					color: "#ba68c8",
					roles: ["devops", "developer", "author", "community"],
					profileImgMeta: {
						height: 1572,
						width: 1572,
						relativePath: "./crutchcorn.png",
						relativeServerPath: "/content/data/crutchcorn.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\crutchcorn.png",
					},
					rolesMeta: [
						{ id: "devops", prettyname: "Dev-ops" },
						{ id: "developer", prettyname: "Developer" },
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Why React 18 Broke Your App",
				description:
					"React 18's internal changes improved a lot, but may have broken your app in the process. Here's why and how you can fix it",
				published: "2022-01-27T22:12:03.284Z",
				authors: ["crutchcorn"],
				tags: ["react", "webdev"],
				attached: [],
				license: "coderpad",
				originalLink:
					"https://coderpad.io/blog/development/why-react-18-broke-your-app/",
			},
			contentMeta:
				'\r\nYou’ve just gotten done with [your React 18 upgrade](https://coderpad.io/blog/how-to-upgrade-to-react-18/), and, after some light QA testing, don’t find anything. “An easy upgrade,” you think.\r\n\r\nUnfortunately, down the road, you receive some internal bug reports from other developers that make it sound like your debounce hook isn’t working quite right. You decide to make a minimal reproduction and create a demo of said hook.\r\n\r\nYou expect it to throw an “alert” dialog after a second of waiting, but weirdly, the dialog never runs at all.\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=200065"  loading="lazy"></iframe>\r\n\r\nThis is strange because it was working just last week on your machine! Why did this happen? What changed?\r\n\r\n**The reason your app broke in React 18 is that you’re using `StrictMode`.**\r\n\r\nSimply go into your `index.js` (or `index.ts`) file, and change this bit of code:\r\n\r\n```jsx\r\nrender(\r\n  <StrictMode>\r\n    <App />\r\n  </StrictMode>\r\n);\r\n```\r\n\r\nTo read like this:\r\n\r\n```jsx\r\nrender(\r\n    <App />\r\n);\r\n```\r\n\r\nAll of the bugs that were seemingly introduced within your app in React 18 are suddenly gone.\r\n\r\n\r\nOnly one problem: These bugs are real and existed in your codebase before React 18 - you just didn’t realize it.\r\n\r\n## Proof of broken component\r\n\r\nLooking at our example from before, we’re using [React 18’s `createRoot` API](https://coderpad.io/blog/how-to-upgrade-to-react-18/) to render our `App` inside of a `StrictMode` wrapper in lines 56 - 60.\r\n\r\n<iframe src="https://app.coderpad.io/sandbox?question_id=200065"  loading="lazy"></iframe>\r\n\r\nCurrently, when you press the button, it doesn’t do anything. However, if you remove the \r\n\r\n`StrictMode` and reload the page, you can see an `Alert` after a second of being debounced.\r\n\r\nLooking through the code, let’s add some `console.log`s into our `useDebounce`, since that’s where our function is supposed to be called.\r\n\r\n```jsx\r\nfunction useDebounce(cb, delay) {\r\n  const inputsRef = React.useRef({ cb, delay });\r\n  const isMounted = useIsMounted();\r\n  React.useEffect(() => {\r\n    inputsRef.current = { cb, delay };\r\n  });\r\n  return React.useCallback(\r\n    _.debounce((...args) => {\r\n        console.log("Before function is called", {inputsRef, delay, isMounted: isMounted()});\r\n          if (inputsRef.current.delay === delay && isMounted())\r\n                      console.log("After function is called");\r\n                  inputsRef.current.cb(...args);\r\n        }, delay),\r\n    [delay]\r\n  );\r\n}\r\n```\r\n\r\n> ```\r\n> Before function is called Object { inputsRef: {…}, delay: 1000, isMounted: false }\r\n> ```\r\n\r\nOh! It seems like `isMounted` is never being set to true, and therefore the `inputsRef.current` callback is not being called: that’s our function we wanted to be debounced.\r\n\r\nLet’s take a look at the `useIsMounted()` codebase:\r\n\r\n```jsx\r\nfunction useIsMounted() {\r\n  const isMountedRef = React.useRef(true);\r\n  React.useEffect(() => {\r\n    return () => {\r\n          isMountedRef.current = false;\r\n    };\r\n  }, []);\r\n  return () => isMountedRef.current;\r\n}\r\n```\r\n\r\nThis code, at first glance, makes sense. After all, while we’re doing a cleanup in the return function of `useEffect` to remove it at first render, `useRef`\'s initial setter runs at the start of each render, right?\r\n\r\nWell, not quite.\r\n\r\n## What changed in React 18?\r\n\r\nIn older versions of React, you would mount a component once and that would be it. As a result, the initial value of `useRef` and `useState` could almost be treated as if they were set once and then forgotten about.\r\n\r\nIn React 18, the React developer team decided to change this behavior and [re-mount each component more than once in strict mode](https://github.com/reactwg/react-18/discussions/19). This is in strong part due to the fact that a potential future React feature will have exactly that behavior.\r\n\r\nSee, one of the features that the React team is hoping to add in a future release utilizes a concept of “[reusable state](https://reactjs.org/docs/strict-mode.html#ensuring-reusable-state)”. The general idea behind reusable state is such that if you have a tab that’s un-mounted (say when the user tabs away), then re-mounted (when the user tabs back), React will recover the data that was assigned to said tab component. This data being immediately available allows you to render the respective component immediately without hesitation.\r\n\r\nBecause of this, while data inside of, say, `useState` may be persisted, it’s imperative that effects are properly cleaned up and handled properly. [To quote the React docs](https://reactjs.org/docs/strict-mode.html#ensuring-reusable-state):\r\n\r\n> This feature will give React better performance out-of-the-box but requires components to be resilient to effects being mounted and destroyed multiple times.\r\n\r\nHowever, this behavior shift in Strict Mode within React 18 isn’t just protective future-proofing from the React team: it’s also a reminder to follow React’s rules properly and to clean up your actions as expected.\r\n\r\nAfter all, the [React team themselves have been warning that an empty dependent array](https://reactjs.org/docs/hooks-reference.html#usememo) (`[]` as the second argument) should not guarantee that it only runs once for ages now.\r\n\r\nIn fact, this article may be a bit of a misnomer - [the React team says they’ve upgraded thousands of components in Facebook’s core codebase without significant issues](https://github.com/reactwg/react-18/discussions/19#discussioncomment-796197=). More than likely, a majority of applications out there will be able to upgrade to the newest version of React without any problems. \r\n\r\nAll that said, these React missteps crawl their way into our applications regardless. While the React team may not anticipate many breaking apps, these errors seem relatively common enough to warrant an explanation.\r\n\r\n## How to fix the remounting bug\r\n\r\nThe code I linked before was written by me in a production application and it\'s wrong. Instead of relying on `useRef` to initialize the value once, we need to ensure the initialization runs on every instance of `useEffect`.\r\n\r\n```jsx\r\nfunction useIsMounted() {\r\n  const isMountedRef = React.useRef(true);\r\n  React.useEffect(() => {\r\n  isMountedRef.current = true; // Added this line  \r\n  return () => {\r\n      isMountedRef.current = false;\r\n    };\r\n  }, []);\r\n  return () => isMountedRef.current;\r\n}\r\n```\r\n\r\nThis is true for the inverse as well! We need to make sure to run cleanup on any components that we may have forgotten about before.\r\n\r\nMany ignore this rule for `App` and other root elements that they don’t intend to re-mount, but with new strict mode behaviors, that guarantee is no longer a safe bet.\r\n\r\nTo solve this application across your app, look for the following signs:\r\n\r\n- Side effects with cleanup but no setup (like our example)\r\n- A side effect without proper cleanup\r\n- Utilizing `[]` in `useMemo` and `useEffect` to assume that said code will only run once\r\n\r\nOne this code is eliminated, you should be back to a fully functioning application and can re-enable StrictMode in your application!\r\n\r\n## Conclusion\r\n\r\nReact 18 brings many amazing features to the table, such as [new suspense features](https://reactjs.org/docs/concurrent-mode-suspense.html), [the new useId hook](https://github.com/reactwg/react-18/discussions/111), [automatic batching](https://github.com/reactwg/react-18/discussions/21), and more. While refactor work to support these features may be frustrating at times, it’s important to remember that they a serve real-world benefit to the user.\r\n\r\nFor example, React 18 also introduces some functionality to debounce renders in order to create a much nicer experience when rapid user input needs to be processed.\r\n\r\nFor more on the React 18 upgrade process, take a look at [our instruction guide on how to upgrade to React 18](https://coderpad.io/blog/how-to-upgrade-to-react-18/)\r\n',
		},
		{
			title: "Windows Subsystem for Linux",
			description:
				"Utilize the best of both worlds — Windows and Linux — without having to dual boot. Windows Subset for Linux (WSL) lets you run software designed for Linux in Windows.",
			published: "2022-05-24T22:07:20.000Z",
			edited: "2022-05-24T22:07:20.000Z",
			authors: ["splatkillwill"],
			tags: ["windows", "linux"],
			attached: [],
			license: {
				id: "cc-by-nc-nd-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "https://creativecommons.org/licenses/by-nc-nd/4.0/",
				name: "Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0) License",
			},
			originalLink: "https://gatimus.com/blog/windows-subsystem-for-linux",
			slug: "windows-subsystem-for-linux",
			locale: "en",
			authorsMeta: [
				{
					id: "splatkillwill",
					name: "William (Will) Lohan",
					firstName: "William",
					lastName: "Lohan",
					description: "",
					socials: {
						github: "william-lohan",
						twitch: "splat_killwill",
						website: "https://gatimus.com/",
						linkedIn: "william-lohan-b202637a",
					},
					pronouns: "they/themselves",
					profileImg: "./splatkillwill.jpg",
					color: "#BF00FF",
					roles: ["author"],
					profileImgMeta: {
						height: 512,
						width: 512,
						relativePath: "./splatkillwill.jpg",
						relativeServerPath: "/content/data/splatkillwill.jpg",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\splatkillwill.jpg",
					},
					rolesMeta: [{ id: "author", prettyname: "Author" }],
					pronounsMeta: {
						id: "they/themselves",
						they: "they",
						them: "them",
						their: "their",
						theirs: "theirs",
						themselves: "themselves",
					},
				},
			],
			frontmatterBackup: {
				title: "Windows Subsystem for Linux",
				description:
					"Utilize the best of both worlds — Windows and Linux — without having to dual boot. Windows Subset for Linux (WSL) lets you run software designed for Linux in Windows.",
				published: "2022-05-24T22:07:20.000Z",
				edited: "2022-05-24T22:07:20.000Z",
				authors: ["splatkillwill"],
				tags: ["windows", "linux"],
				attached: [],
				license: "cc-by-nc-nd-4",
				originalLink: "https://gatimus.com/blog/windows-subsystem-for-linux",
			},
			contentMeta:
				"\nWindows Subsystem for Linux (WSL) lets you run software designed for Linux. This gives Windows users access to tools and web developers environments closer resembling that of their peers or the webservers hosting their code.\n\n## Getting Started \n\nFirst make sure Windows is updated, WSL required additional setup steps prior to version 2004. Then run open PowerShell (as Admin) and run `wsl --list --online`. This will list all the available OS's for WSL.\n\n```shell\nPS C:\\Users\\user> wsl --list --online\nThe following is a list of valid distributions that can be installed.\nInstall using 'wsl --install -d <Distro>'.\n\nNAME            FRIENDLY NAME\nUbuntu          Ubuntu\nDebian          Debian GNU/Linux\nkali-Linux      Kali Linux Rolling\nopenSUSE-42     openSUSE Leap 42\nSLES-12         SUSE Linux Enterprise Server v12\nUbuntu-16.04    Ubuntu 16.04 LTS\nUbuntu-18.04    Ubuntu 18.04 LTS\nUbuntu-20.04    Ubuntu 20.04 LTS\n```\n\n## Installing \n\nPick your favorite flavor, mine is Ubuntu or Debian if I think I might need any older tools. Then run `wsl --install -d <Distro>`.\n\n```shell\nPS C:\\Users\\user> wsl --install -d Ubuntu\nDownloading: Ubuntu\n```\n\nAfter a while you will see this prompt. Enter a user name that you want to use for the Linux environment and password twice.\n\n```\nInstalling, this may take a few minutes...\nPlease create a default UNIX user account. The username does not need to match your Windows username.\nFor more information visit: https://aka.ms/wslusers\nEnter new UNIX username: user\nNew password:\nRetype new password:\n```\n\nIf all goes well you should land in a Linux prompt like this.\n\n```\npasswd: password updated successfully\nInstallation successful!\n...\nuser@MACHINE_NAME:~$\n```\n\n## Setup \n\nRun `sudo apt update` to refresh all your apt-get repos.\n\n```shell\nuser@MACHINE_NAME:~$ sudo apt update\n[sudo] password for user:\nGet:1 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n...\nGet:45 http://archive.ubuntu.com/ubuntu focal-backports/multiverse amd64 c-n-f Metadata [116 B]\nFetched 22.0 MB in 7s (2985 kB/s)\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\n243 packages can be upgraded. Run 'apt list --upgradable' to see them.\n```\n\nThen all your favorite tools.\n\n```shell\nuser@MACHINE_NAME:~$ sudo apt install build-essential git cmake\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following additional packages will be installed:\n...\nDo you want to continue? [Y/n] Y\n...\nuser@MACHINE_NAME:~$\n```\n\n> Note: If you are looking to get into C or C++ development `build-essential` is a good package to remember to get compilers\n\n### Visual Studio Code Integration\n\nYou can use your regular Windows installation of Visual Studio Code to interact directly with the Linux environment. Install the [Remote Development](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack) extension pack or just [Remote - WSL](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-wsl). Then you can use the Remote Explorer to browse WSL Targets (WSL OS's you've installed). All the projects and files are in and commands run in the Linux environment.\n\n![Visual Studio Code showing a side panel with a list of \"WSL Targets\". There are two targets: Debian and Ubuntu with a project called \"my-project\" active in Ubuntu](./Screenshot_2021-10-17_171944.jpg)\n\n> Note: The `Remote Development` extension pack also includes `Remote - SSH` which allows you to interact with remote Linux environments exactly the same way\n\nTo test it out we can throw a `hello.cpp` in there.\n\n```cpp\n#include <iostream>\n\nint main()\n{\n  std::cout << \"Hello World!\\n\";\n  return 0;\n}\n```\n\n![The files sidebar open in a VSCode instance showing a project containing C plus plus files open in WSL Ubuntu](./Screenshot_2021-10-21_205232.jpg)\n\n<!-- Does this need a conclusion paragraph (I suck at those) -->\n",
		},
		{
			title: "Writing better tests for Angular with Angular Testing Library",
			description:
				"A simple explination of writing better tests for Angular applications and setting up Angular Testing Library",
			published: "2020-05-12T04:45:30.247Z",
			edited: "2020-06-09T04:45:30.247Z",
			authors: ["skatcat31"],
			tags: ["testing", "angular"],
			attached: [],
			license: {
				id: "cc-by-nc-sa-4",
				footerImg: "https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png",
				licenceType: "Creative Commons License",
				explainLink: "http://creativecommons.org/licenses/by-nc-sa/4.0/",
				name: "Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)",
				displayName:
					"Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License",
			},
			slug: "writing-better-angular-tests",
			locale: "en",
			authorsMeta: [
				{
					id: "skatcat31",
					name: "Robert Mennell",
					firstName: "Robert",
					lastName: "Mennell",
					description:
						"A fullstack engineer who loves learning new things, playing video games, and his wife.\nIf you can learn it, you can do it.\nIf you can do it well, you've learned it.",
					socials: { github: "skatcat31", linkedIn: "rnmennell" },
					color: "#ba68c8",
					profileImg: "./hello.png",
					pronouns: "he",
					roles: ["author", "community"],
					profileImgMeta: {
						height: 2048,
						width: 2048,
						relativePath: "./hello.png",
						relativeServerPath: "/content/data/hello.png",
						absoluteFSPath:
							"C:\\Users\\crutchcorn\\git\\Unicorn\\astro-unicorn\\content\\data\\hello.png",
					},
					rolesMeta: [
						{ id: "author", prettyname: "Author" },
						{ id: "community", prettyname: "Community Leader" },
					],
					pronounsMeta: {
						id: "he",
						they: "he",
						them: "him",
						their: "his",
						theirs: "his",
						themselves: "himself",
					},
				},
			],
			frontmatterBackup: {
				title: "Writing better tests for Angular with Angular Testing Library",
				description:
					"A simple explination of writing better tests for Angular applications and setting up Angular Testing Library",
				published: "2020-05-12T04:45:30.247Z",
				edited: "2020-06-09T04:45:30.247Z",
				authors: ["skatcat31"],
				tags: ["testing", "angular"],
				attached: [],
				license: "cc-by-nc-sa-4",
			},
			contentMeta:
				'\r\nSome evangelicals say that before code ever exists, there always needs to be a test to know how the code should be written. That frankly isn\'t true. A test isn\'t _strictly_ needed to determine how to code. What **is** needed are tests that give confidence that as code is written, a change to already existing functionality doesn\'t happen and that new functionality will behave properly as time goes on. To this end, a lot of testing libraries and frameworks exist. Often times, tests are written in regards to the library or framework used and not to the end product\'s specifications. For Angular, this is especially true when the default testing implementation is for testing angular, and not for testing what a developer would use Angular to build. **Tests should be written in the same way a user would use them.** We don\'t need to test Angular; we need to test what we make with Angular.\r\n\r\n# Writing tests for an Angular application does not mean testing Angular {#test-the-web-not-angular}\r\n\r\nIn regards to Angular and writing tests, we must first understand what the tests are for. For a great many projects, that means testing a webpage. In proper testing for a webpage, the underlying library should be able to be changed at any time for maintainability purposes, and the tests should still work. To that end, we must write tests for the web and not for Angular. When using the Angular CLI, it sets up some tests, but when looking closely at the tests, it becomes apparent that the tests are testing Angular and not the output.\r\n\r\n```js\r\nit(\'should create the app\', () => {\r\n  const fixture = TestBed.createComponent(AppComponent);\r\n  const app = fixture.componentInstance;\r\n  expect(app).toBeTruthy();\r\n});\r\n```\r\n\r\nThis test isn\'t a very good test. It doesn\'t say anything about the actual output of the application component itself. When the output is a full, rich webpage and tests are testing Angular, then the tests won\'t do much when the content of the webpage is changed.\r\n\r\nWhile the default testing setup does allow for the writing of tests that would test the outputted HTML they are still specific to Angular\r\n\r\n```js\r\nit(\'should render title\', () => {\r\n  const fixture = TestBed.createComponent(AppComponent);\r\n  fixture.detectChanges();\r\n  const compiled = fixture.nativeElement;\r\n  expect(compiled.querySelector(\'.content span\').textContent).toContain(\'The app is running!\');\r\n});\r\n```\r\n\r\nThat test looks a little better, but it\'s still very tied to Angular. The test requires in-depth knowledge of how Angular actually routes and moves all the bits around to write tests for it, and as a result, the tests are completely tied into Angular and the current API footprint. If — over the years — Angular is retired, these tests will no longer be valid.\r\n\r\nIf the tests were just tailored to the outputted DOM or containers it would be a much easier and more adaptable test.\r\n\r\n```js\r\ntest(\'should render counter\', async () => {\r\n  await render(AppComponent);\r\n  expect(document.querySelector(\'.content span\').innerText).toBe(\'The app is running!\');\r\n});\r\n```\r\n\r\nThis test no longer even needs Angular to be the library chosen. It just requires that a render method, when given the component, will render it to the DOM present in the testing environment. This can be run in the Framework, and even tested against in a real world browser. This is a good test in that the first `span` inside of `.content` has the `innerText` value expected in the test. These are all JavaScript and DOM APIs and thus can be trusted in any environment that adheres to them.\r\n\r\nWriting tests that don\'t rely on testing Angular, but instead rely on the DOM, allows the application to be tested in a way that a user would use the application instead of the way that Angular internally works.\r\n\r\n# Fixing that shortcoming using Testing Library {#testing-library}\r\n\r\nThankfully, writing tests like these have been made simple by a testing library simply called "[Testing Library](https://testing-library.com)." Testing Library is a collection of libraries for various frameworks and applications. One of the supported libraries is Angular, through the [Angular Testing Library](https://testing-library.com/docs/angular-testing-library/intro). This can be used to test Angular apps in a simple DOM focused manner with some nice helpers to make it even easier to work with. It relies on [Jest](https://jestjs.io/) as an extension to the Jasmine testing framework to make testing easier, and more end-results focused. With that tooling, a project can have tests much less focused on Angular and much more focused on what is being made.\r\n\r\n## Transitioning to Jest and Angular Testing Library {#transitioning-to-jest}\r\n\r\n### Get rid of Karma {#remove-karma}\r\n\r\nAngular ships with Karma alongside Jasmine for running tests and collecting coverage. With Jest, an Angular project no longer needs Karma or the other packages that would be installed by the Angular CLI.\r\n\r\n#### Uninstall Karma\r\n\r\n```bash\r\nnpm uninstall karma karma-chrome-launcher karma-coverage-istanbul-reporter karma-jasmine karma-jasmine-html-reporter\r\n```\r\n\r\n#### Remove the leftover configurations {#remove-karma-config}\r\n\r\nDeleting the following will remove the leftover configuration files from the project:\r\n\r\n```bash\r\nkarma.config.js\r\nsrc/test.ts\r\n```\r\n\r\nOnce those two files are deleted, any references to `src/test.ts` will need to be removed. Removing the paths from the following file that reference them cleans it up easily enough:\r\n\r\n```json\r\ntsconfig.spec.json\r\n{\r\n  ...,\r\n  "files": [\r\n    "src/test.ts", <- delete\r\n    ...\r\n    ]\r\n}\r\n```\r\n\r\nThe project also no longer needs the `test` key inside of `angular.json` as it stands, and thus it\'s contents can be removed. Don\'t worry, we\'ll be making `ng test` work again later.\r\n```json\r\nangular.json\r\n{\r\n  ...,\r\n  "test": {} <- delete contents, but leave the key\r\n  ....\r\n}\r\n```\r\n\r\nFinally the project no longer needs the Jasmine types in the spec configuration\r\n\r\n```json\r\ntsconfig.spec.json\r\n{\r\n  ...,\r\n  "compilerOptions": {\r\n    ...,\r\n    "types": [\r\n      "jasmine", <- delete\r\n      ...\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\nNow the project is ready for installing any other test runner.\r\n\r\n### Setting up Jest {#setup-jest}\r\n\r\nNow that the project has no Karma it can be setup with Jest\r\n\r\n#### Install Jest\r\n\r\n```bash\r\nnpm i -D @types/jest jest jest-preset-angular ts-jest @angular-builders/jest\r\n```\r\n\r\nThis installs Jest, the types for Jest, a TypeScript pre-processor for Jest, and a preset that makes setting up Jest much easier.\r\n\r\n#### Configure Jest\r\n\r\nThe project now needs to know how to best utilize Jest. Creating and modify the following files will allow Jest to load it\'s own configuration.\r\n\r\n```js\r\njest.config.js\r\nmodule.exports = {\r\n    preset: \'jest-preset-angular\',\r\n    setupFilesAfterEnv: [\r\n        \'<rootDir>/jest.setup.ts\'\r\n    ]\r\n};\r\n```\r\n\r\n```typescript\r\njest.setup.ts\r\nimport \'jest-preset-angular\';\r\n```\r\n\r\n```json\r\ntsconfig.spec.json\r\n{\r\n  ...,\r\n  "compilerOptions": {\r\n    ...,\r\n    "types": [\r\n      "jest", <- new\r\n      ...\r\n    ]\r\n  }\r\n}\r\n```\r\n\r\n```json\r\ntsconfig.json\r\n{\r\n  ...,\r\n  "compilerOptions": {\r\n    ...,\r\n    "esModuleInterop": true, <- new\r\n    "emitDecoratorMetadata": true, <- new\r\n    ...\r\n  },\r\n  ...\r\n}\r\n```\r\n\r\n```json\r\npackage.json\r\n{\r\n  ...,\r\n  "scripts": {\r\n    ...,\r\n    "test": "jest --coverage --config ./jest.config.js", <- new\r\n    "test:watch": "jest -o --watch --config ./jest.config.js", <- new\r\n    ...\r\n  },\r\n  ...\r\n}\r\n```\r\n\r\n```json\r\nangular.json\r\n{\r\n  ...,\r\n  "test": {\r\n    "builder": "@angular-builders/jest:run" <- new\r\n  }\r\n  ....\r\n}\r\n```\r\n\r\nJest is now the test runner for the projectand it can be run with NPM, Yarn, or the Angular CLI. It can now be used in combination with Testing Library.\r\n\r\n### Install Angular Testing Library\r\n\r\nNow the project is ready to have better tests written for it and by using [Angular Testing Library](https://testing-library.com/docs/angular-testing-library/intro) the tests can be simplified with some great helpers.\r\n\r\n```bash\r\nnpm install --save-dev @testing-library/angular\r\n```\r\n\r\n# Ready, Steady, Test! {#conclusion}\r\n\r\nNow that the project has a better testing library with some great helpers better tests can be written. There are plenty of [great examples](https://testing-library.com/docs/angular-testing-library/examples) for learning and [Tim Deschryver](https://timdeschryver.dev/blog/good-testing-practices-with-angular-testing-library) has more examples to help in that endeavor, and the Angular Testing Library will make tests much simpler to write and maintain. With Angular, good tests, and plenty of confidence anyone would be happy to ship a project with this setup.\r\n',
		},
	],
};

export default index;
